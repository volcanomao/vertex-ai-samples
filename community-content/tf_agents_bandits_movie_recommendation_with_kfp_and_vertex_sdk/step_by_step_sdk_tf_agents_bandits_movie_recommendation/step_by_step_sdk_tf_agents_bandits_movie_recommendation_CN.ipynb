{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f11e1b3d"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aa8753fd"
   },
   "source": [
    "# 使用Vertex AI 构建强化学习应用程序的逐步指南"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b36aad4b"
   },
   "source": [
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/tree/master/community-content/tf_agents_bandits_movie_recommendation_with_kfp_and_vertex_sdk/step_by_step_sdk_tf_agents_bandits_movie_recommendation/step_by_step_sdk_tf_agents_bandits_movie_recommendation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab上运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/tree/master/community-content/tf_agents_bandits_movie_recommendation_with_kfp_and_vertex_sdk/step_by_step_sdk_tf_agents_bandits_movie_recommendation/step_by_step_sdk_tf_agents_bandits_movie_recommendation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a27e7ec1"
   },
   "source": [
    "## 概述\n",
    "该演示展示了在构建电影推荐系统时使用[TF-Agents](https://www.tensorflow.org/agents)和[Vertex AI](https://cloud.google.com/vertex-ai)的情况，利用强化学习。该演示适用于希望使用TensorFlow和TF-Agents库创建强化学习应用程序的开发人员，利用Vertex AI服务（包括自定义训练、自定义预测、在托管端点上部署模型和提取预测）。建议开发人员对基本强化学习理论有所了解，特别是上下文匪徒的公式以及TF-Agents接口。请注意，上下文匪徒形成了RL的一种特殊情况，其中代理器采取的行动不会改变环境的状态。“上下文”指的是代理在了解上下文（环境观察）的情况下从一组动作中选择。\n",
    "\n",
    "### 数据集\n",
    "该演示使用[MovieLens 100K](https://www.kaggle.com/prajitdatta/movielens-100k-dataset)数据集来模拟具有用户及其偏好的环境。它位于`gs://cloud-samples-data/vertex-ai/community-content/tf_agents_bandits_movie_recommendation_with_kfp_and_vertex_sdk/u.data`。\n",
    "\n",
    "### 目标\n",
    "在本笔记本中，您将学习如何使用Vertex AI的自定义训练、自定义预测和端点部署服务构建基于TF-Agents（特别是匪类模块）的强化应用程序。\n",
    "对于自定义训练，您将实施基于策略的训练，在该训练中您将与基于MovieLens的模拟环境进行交互，以（1）获取环境观察、（2）根据给定观察选择动作使用数据收集策略，以及（3）获取与（1）（2）对应的奖励形式的环境反馈。这些数据片段形成训练数据记录。此过程与离线训练不同，离线训练中您不一定与策略实际输出的操作相关联的训练数据。\n",
    "\n",
    "此演示由2个主要步骤组成：\n",
    "1. 在本地运行，使用[TF-Agents](https://www.tensorflow.org/agents)实现。\n",
    "2. 在[Vertex AI](https://cloud.google.com/vertex-ai)上执行。\n",
    "\n",
    "除了培训、预测和预测工作流程外，该演示还展示以下优化技术：\n",
    "1. 使用Vertex AI进行超参数调整\n",
    "2. 使用TensorBoard Profiler对训练过程和资源进行配置分析，可为加速改进、扩展等目的提供信息\n",
    "\n",
    "该演示参考了来自以下代码的内容：[此TF-Agents示例](https://github.com/tensorflow/agents/blob/master/tf_agents/bandits/agents/examples/v2/train_eval_movielens.py)、[此Vertex AI SDK自定义容器训练示例](https://github.com/GoogleCloudPlatform/ai-platform-samples/blob/master/ai-platform-unified/notebooks/unofficial/sdk/AI_Platform_(Unified)_SDK_BigQuery_Custom_Container_Training.ipynb)和[此Vertex AI SDK自定义容器预测示例](https://github.com/GoogleCloudPlatform/ai-platform-samples/blob/master/ai-platform-unified/notebooks/unofficial/sdk/AI_Platform_(Unified)_SDK_Custom_Container_Prediction.ipynb)。\n",
    "\n",
    "### 成本\n",
    "\n",
    "本教程使用Google Cloud的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Build\n",
    "* Cloud Storage\n",
    "* Container Registry\n",
    "\n",
    "了解[Vertex AI价格](https://cloud.google.com/vertex-ai/pricing)、[Cloud Build价格](https://cloud.google.com/build/pricing)、[Cloud Storage价格](https://cloud.google.com/storage/pricing)和[Container Registry价格](https://cloud.google.com/container-registry/pricing)，使用[定价计算器](https://cloud.google.com/products/calculator/)根据您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8f78d1d3"
   },
   "source": [
    "### 设置本地开发环境\n",
    "\n",
    "**如果您正在使用Colab或Google Cloud笔记本**，您的环境已经满足运行此笔记本的所有要求。您可以跳过此步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17c51ff4"
   },
   "source": [
    "否则，请确保您的环境符合此笔记本的要求。\n",
    "您需要以下内容：\n",
    "\n",
    "* Google Cloud SDK\n",
    "* Git\n",
    "* Python 3\n",
    "* virtualenv\n",
    "* 在使用Python 3的虚拟环境中运行的Jupyter笔记本\n",
    "\n",
    "Google Cloud指南[设置Python开发环境](https://cloud.google.com/python/setup)和[Jupyter安装指南](https://jupyter.org/install)提供了满足这些要求的详细说明。以下步骤提供了一套简化的说明：\n",
    "\n",
    "1. [安装并初始化Cloud SDK。](https://cloud.google.com/sdk/docs/)\n",
    "\n",
    "2. [安装Python 3。](https://cloud.google.com/python/setup#installing_python)\n",
    "\n",
    "3. [安装virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv)并创建一个使用Python 3的虚拟环境。激活虚拟环境。\n",
    "\n",
    "4. 要安装Jupyter，请在终端shell中命令行运行`pip3 install jupyter`。\n",
    "\n",
    "5. 要启动Jupyter，请在终端shell中命令行运行`jupyter notebook`。\n",
    "\n",
    "6. 在Jupyter Notebook Dashboard中打开此笔记本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "525895b8"
   },
   "source": [
    "安装额外的包\n",
    "\n",
    "安装在您的笔记本环境中尚未安装的额外包依赖，例如 AI 平台 SDK 和 TF-Agents。请使用每个包的最新主要 GA 版本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e36c4ded"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Google Cloud Notebook product has specific requirements\n",
    "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
    "\n",
    "# Google Cloud Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ede5245e"
   },
   "outputs": [],
   "source": [
    "! pip3 install {USER_FLAG} google-cloud-aiplatform\n",
    "! pip3 install {USER_FLAG} google-cloud-storage\n",
    "! pip3 install {USER_FLAG} numpy\n",
    "! pip3 install {USER_FLAG} cloudml-hypertune\n",
    "! pip3 install {USER_FLAG} --upgrade tensorflow\n",
    "! pip3 install {USER_FLAG} --upgrade pillow\n",
    "! pip3 install {USER_FLAG} --upgrade tf-agents\n",
    "! pip3 install {USER_FLAG} --upgrade tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed24f0a0"
   },
   "source": [
    "重新启动内核\n",
    "\n",
    "安装额外的软件包后，您需要重新启动笔记本内核，以便它可以找到这些软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ef50bba"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1c2d29f"
   },
   "source": [
    "在开始之前\n",
    "\n",
    "### 选择GPU运行时\n",
    "\n",
    "**确保如果有这个选项的话，您正在一个GPU运行时中运行这个笔记本。在Colab中，选择“运行时 --> 更改运行时类型 > GPU”**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c8c8359"
   },
   "source": [
    "### 设置您的谷歌云项目\n",
    "\n",
    "**不管您的笔记本环境如何，以下步骤都是必需的。**\n",
    "\n",
    "1. [选择或创建一个谷歌云项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建帐户时，您将获得$300的免费信用，用于支付计算/存储成本。\n",
    "\n",
    "2. [确保为您的项目启用计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "3. [启用 Vertex AI API、Cloud Build API、Cloud Storage API 和 Container Registry API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,cloudbuild.googleapis.com,storage.googleapis.com,containerregistry.googleapis.com)。\n",
    "\n",
    "4. 如果您在本地运行此笔记本，您需要安装 [Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "5. 在下面的单元格中输入您的项目ID。然后运行该单元格，以确保\n",
    "Cloud SDK为本笔记本中的所有命令使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter 运行以 `!` 开头的行作为shell命令，并将以 `$` 开头的Python变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df1b5637"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用`gcloud`来获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "503e374c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40209c4d"
   },
   "source": [
    "否则，请在这里设置您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2f665b78"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
    "    PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d3d2d6b"
   },
   "source": [
    "时间戳\n",
    "\n",
    "如果您正在参加现场教程会话，您可能正在使用共享的测试帐户或项目。为了避免用户在创建的资源之间发生名称冲突，您为每个实例会话创建一个时间戳，并将其附加到您在本教程中创建的资源名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9954b4b2"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba11364f"
   },
   "source": [
    "###验证您的Google云账户\n",
    "\n",
    "**如果您正在使用Google云笔记本**，您的环境已经经过验证。请跳过此步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5620ef36"
   },
   "source": [
    "如果您正在使用Colab，请运行下面的单元格，并按提示进行身份验证，通过oAuth认证您的帐户。\n",
    "\n",
    "否则，请按照以下步骤操作：\n",
    "\n",
    "1. 在Cloud控制台中，转到[**创建服务帐号密钥**页面](https://console.cloud.google.com/apis/credentials/serviceaccountkey)。\n",
    "\n",
    "2. 点击**创建服务帐号**。\n",
    "\n",
    "3. 在**服务帐号名称**字段中输入一个名称，然后点击**创建**。\n",
    "\n",
    "4. 在**授予此服务账户对项目的访问权限**部分，点击**角色**下拉列表。在筛选框中输入\"Vertex AI\"，并选择**Vertex AI管理员**。在筛选框中输入\"Storage Object Admin\"，并选择**Storage Object Admin**。\n",
    "\n",
    "5. 点击*创建*。一个包含您密钥的JSON文件将下载到您的本地环境中。\n",
    "\n",
    "6. 在下面的单元格中，将您的服务帐号密钥的路径作为`GOOGLE_APPLICATION_CREDENTIALS`变量输入，并运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "de998f81"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "# The Google Cloud Notebook product has specific requirements\n",
    "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
    "\n",
    "# If on Google Cloud Notebooks, then don't execute this code\n",
    "if not IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1275cce1"
   },
   "source": [
    "### 创建一个云存储存储桶\n",
    "\n",
    "**无论您使用的是哪种笔记本环境，以下步骤都是必需的。**\n",
    "\n",
    "在本教程中，一个云存储存储桶保存MovieLens数据集文件，用于模型训练。Vertex AI还会将训练作业生成的经过训练的模型保存在同一个存储桶中。使用这个模型工件，您可以创建Vertex AI模型和端点资源，以便提供在线预测。\n",
    "\n",
    "在下面设置您的云存储存储桶的名称。它必须在所有云存储存储桶中是唯一的。\n",
    "\n",
    "您还可以更改`REGION`变量，该变量在本笔记本的其余部分中使用。确保在[选择可用Vertex AI服务的地区](https://cloud.google.com/vertex-ai/docs/general/locations#available_regions)时选择一个地区。您不能使用多区域存储存储桶进行与Vertex AI的训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a686c328"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"gs://[your-bucket-name]\"  # @param {type:\"string\"} The bucket should be in same region as uCAIP. The bucket should not be multi-regional for custom training jobs to work.\n",
    "REGION = \"[your-region]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4acc461c"
   },
   "outputs": [],
   "source": [
    "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_NAME = \"gs://\" + PROJECT_ID + \"aip-\" + TIMESTAMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "443d5920"
   },
   "source": [
    "只有当您的存储桶尚不存在时：运行以下单元格以创建您的云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2f75ab50"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d0bfd8d"
   },
   "source": [
    "最后，通过检查云存储桶的内容来验证访问权限："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39a302fb"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5eee5de"
   },
   "source": [
    "导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcf2a9c4"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Dict, List, Optional, TypeVar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from google.cloud import aiplatform, storage\n",
    "from tf_agents.agents import TFAgent\n",
    "from tf_agents.bandits.agents import lin_ucb_agent\n",
    "from tf_agents.bandits.agents.examples.v2 import trainer\n",
    "from tf_agents.bandits.environments import (environment_utilities,\n",
    "                                            movielens_py_environment)\n",
    "from tf_agents.bandits.metrics import tf_metrics as tf_bandit_metrics\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import TFEnvironment, tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.metrics.tf_metric import TFStepMetric\n",
    "from tf_agents.policies import policy_saver\n",
    "\n",
    "if tf.__version__[0] != \"2\":\n",
    "    raise Exception(\"The trainer only runs with TensorFlow version 2.\")\n",
    "\n",
    "T = TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1b5689db"
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = f\"{BUCKET_NAME}/artifacts\"  # @param {type:\"string\"} Root directory for writing logs/summaries/checkpoints.\n",
    "ARTIFACTS_DIR = f\"{BUCKET_NAME}/artifacts\"  # @param {type:\"string\"} Where the trained model will be saved and restored.\n",
    "PROFILER_DIR = f\"{BUCKET_NAME}/profiler\"  # @param {type:\"string\"} Directory for TensorBoard Profiler artifacts.\n",
    "DATA_PATH = f\"{BUCKET_NAME}/artifacts/u.data\"  # Location of the MovieLens 100K dataset's \"u.data\" file.\n",
    "RAW_BUCKET_NAME = BUCKET_NAME[5:]  # Remove the prefix `gs://`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "347158a267fe"
   },
   "outputs": [],
   "source": [
    "# Copy the sample data into your DATA_PATH\n",
    "! gsutil cp \"gs://cloud-samples-data/vertex-ai/community-content/tf_agents_bandits_movie_recommendation_with_kfp_and_vertex_sdk/u.data\"  $DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6cdf060"
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters.\n",
    "BATCH_SIZE = 8  # @param {type:\"integer\"} Training and prediction batch size.\n",
    "TRAINING_LOOPS = 5  # @param {type:\"integer\"} Number of training iterations.\n",
    "STEPS_PER_LOOP = 2  # @param {type:\"integer\"} Number of driver steps per training iteration.\n",
    "\n",
    "# Set MovieLens simulation environment parameters.\n",
    "RANK_K = 20  # @param {type:\"integer\"} Rank for matrix factorization in the MovieLens environment; also the observation dimension.\n",
    "NUM_ACTIONS = 20  # @param {type:\"integer\"} Number of actions (movie items) to choose from.\n",
    "PER_ARM = False  # Use the non-per-arm version of the MovieLens environment.\n",
    "\n",
    "# Set agent parameters.\n",
    "TIKHONOV_WEIGHT = 0.001  # @param {type:\"number\"} LinUCB Tikhonov regularization weight.\n",
    "AGENT_ALPHA = 10.0  # @param {type:\"number\"} LinUCB exploration parameter that multiplies the confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a172d4ef"
   },
   "source": [
    "实施和本地执行（可选）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4554cda"
   },
   "source": [
    "定义RL模块[局部]\n",
    "\n",
    "定义一个[MovieLens特定的赌博环境]，一个[线性UCB代理]和[遗憾度量]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "797db45e"
   },
   "outputs": [],
   "source": [
    "# Define RL environment.\n",
    "env = movielens_py_environment.MovieLensPyEnvironment(\n",
    "    DATA_PATH, RANK_K, BATCH_SIZE, num_movies=NUM_ACTIONS, csv_delimiter=\"\\t\")\n",
    "environment = tf_py_environment.TFPyEnvironment(env)\n",
    "\n",
    "# Define RL agent/algorithm.\n",
    "agent = lin_ucb_agent.LinearUCBAgent(\n",
    "    time_step_spec=environment.time_step_spec(),\n",
    "    action_spec=environment.action_spec(),\n",
    "    tikhonov_weight=TIKHONOV_WEIGHT,\n",
    "    alpha=AGENT_ALPHA,\n",
    "    dtype=tf.float32,\n",
    "    accepts_per_arm_features=PER_ARM)\n",
    "print(\"TimeStep Spec (for each batch):\\n\", agent.time_step_spec, \"\\n\")\n",
    "print(\"Action Spec (for each batch):\\n\", agent.action_spec, \"\\n\")\n",
    "print(\"Reward Spec (for each batch):\\n\", environment.reward_spec(), \"\\n\")\n",
    "\n",
    "# Define RL metric.\n",
    "optimal_reward_fn = functools.partial(\n",
    "    environment_utilities.compute_optimal_reward_with_movielens_environment,\n",
    "    environment=environment)\n",
    "regret_metric = tf_bandit_metrics.RegretMetric(optimal_reward_fn)\n",
    "metrics = [regret_metric]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d59e7c7"
   },
   "source": [
    "### 在本地训练模型\n",
    "\n",
    "定义训练逻辑（on-policy训练）。以下函数与[trainer.train](https://github.com/tensorflow/agents/blob/r0.8.0/tf_agents/bandits/agents/examples/v2/trainer.py#L104)相同，但它会跟踪中间指标值并将不同的工件保存到不同的位置。您也可以直接调用[trainer.train](https://github.com/tensorflow/agents/blob/r0.8.0/tf_agents/bandits/agents/examples/v2/trainer.py#L104)，它也会训练策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ba2b6e7"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    root_dir: str,\n",
    "    agent: TFAgent,\n",
    "    environment: TFEnvironment,\n",
    "    training_loops: int,\n",
    "    steps_per_loop: int,\n",
    "    additional_metrics: Optional[List[TFStepMetric]] = None,\n",
    "    training_data_spec_transformation_fn: Optional[Callable[[T], T]] = None,\n",
    ") -> Dict[str, List[float]]:\n",
    "    \"\"\"Performs `training_loops` iterations of training on the agent's policy.\n",
    "\n",
    "    Uses the `environment` as the problem formulation and source of immediate\n",
    "    feedback and the agent's algorithm, to perform `training-loops` iterations\n",
    "    of on-policy training on the policy.\n",
    "    If one or more baseline_reward_fns are provided, the regret is computed\n",
    "    against each one of them. Here is example baseline_reward_fn:\n",
    "    def baseline_reward_fn(observation, per_action_reward_fns):\n",
    "        rewards = ... # compute reward for each arm\n",
    "        optimal_action_reward = ... # take the maximum reward\n",
    "        return optimal_action_reward\n",
    "\n",
    "    Args:\n",
    "        root_dir: Path to the directory where training artifacts are written.\n",
    "        agent: An instance of `TFAgent`.\n",
    "        environment: An instance of `TFEnvironment`.\n",
    "        training_loops: An integer indicating how many training loops should be run.\n",
    "        steps_per_loop: An integer indicating how many driver steps should be\n",
    "           executed and presented to the trainer during each training loop.\n",
    "        additional_metrics: Optional; list of metric objects to log, in addition to\n",
    "          default metrics `NumberOfEpisodes`, `AverageReturnMetric`, and\n",
    "          `AverageEpisodeLengthMetric`.\n",
    "        training_data_spec_transformation_fn: Optional; function that transforms\n",
    "          the data items before they get to the replay buffer.\n",
    "\n",
    "    Returns:\n",
    "        A dict mapping metric names (eg. \"AverageReturnMetric\") to a list of\n",
    "        intermediate metric values over `training_loops` iterations of training.\n",
    "    \"\"\"\n",
    "    if training_data_spec_transformation_fn is None:\n",
    "        data_spec = agent.policy.trajectory_spec\n",
    "    else:\n",
    "        data_spec = training_data_spec_transformation_fn(\n",
    "            agent.policy.trajectory_spec)\n",
    "    replay_buffer = trainer.get_replay_buffer(data_spec, environment.batch_size,\n",
    "                                              steps_per_loop)\n",
    "\n",
    "    # `step_metric` records the number of individual rounds of bandit interaction;\n",
    "    # that is, (number of trajectories) * batch_size.\n",
    "    step_metric = tf_metrics.EnvironmentSteps()\n",
    "    metrics = [\n",
    "        tf_metrics.NumberOfEpisodes(),\n",
    "        tf_metrics.AverageEpisodeLengthMetric(batch_size=environment.batch_size)\n",
    "    ]\n",
    "    if additional_metrics:\n",
    "        metrics += additional_metrics\n",
    "\n",
    "    if isinstance(environment.reward_spec(), dict):\n",
    "        metrics += [tf_metrics.AverageReturnMultiMetric(\n",
    "            reward_spec=environment.reward_spec(),\n",
    "            batch_size=environment.batch_size)]\n",
    "    else:\n",
    "        metrics += [\n",
    "            tf_metrics.AverageReturnMetric(batch_size=environment.batch_size)]\n",
    "\n",
    "    # Store intermediate metric results, indexed by metric names.\n",
    "    metric_results = defaultdict(list)\n",
    "\n",
    "    if training_data_spec_transformation_fn is not None:\n",
    "        def add_batch_fn(data): return replay_buffer.add_batch(training_data_spec_transformation_fn(data)) \n",
    "        \n",
    "    else:\n",
    "        add_batch_fn = replay_buffer.add_batch\n",
    "\n",
    "    observers = [add_batch_fn, step_metric] + metrics\n",
    "\n",
    "    driver = dynamic_step_driver.DynamicStepDriver(\n",
    "        env=environment,\n",
    "        policy=agent.collect_policy,\n",
    "        num_steps=steps_per_loop * environment.batch_size,\n",
    "        observers=observers)\n",
    "\n",
    "    training_loop = trainer.get_training_loop_fn(\n",
    "        driver, replay_buffer, agent, steps_per_loop)\n",
    "    saver = policy_saver.PolicySaver(agent.policy)\n",
    "\n",
    "    for _ in range(training_loops):\n",
    "        training_loop()\n",
    "        metric_utils.log_metrics(metrics)\n",
    "        for metric in metrics:\n",
    "            metric.tf_summaries(train_step=step_metric.result())\n",
    "            metric_results[type(metric).__name__].append(metric.result().numpy())\n",
    "    saver.save(root_dir)\n",
    "    return metric_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35fb761a"
   },
   "source": [
    "训练RL策略并收集中间指标结果。同时，使用[TensorBoard Profiler](https://www.tensorflow.org/guide/profiler)来对训练过程和资源进行剖析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "416255c2"
   },
   "outputs": [],
   "source": [
    "tf.profiler.experimental.start(PROFILER_DIR)\n",
    "\n",
    "metric_results = train(\n",
    "    root_dir=ROOT_DIR,\n",
    "    agent=agent,\n",
    "    environment=environment,\n",
    "    training_loops=TRAINING_LOOPS,\n",
    "    steps_per_loop=STEPS_PER_LOOP,\n",
    "    additional_metrics=metrics)\n",
    "\n",
    "tf.profiler.experimental.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b8cd364"
   },
   "source": [
    "### 评估RL指标[本地]\n",
    "\n",
    "您可以可视化遗憾和平均回报指标随着训练步骤的演变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02da0069"
   },
   "outputs": [],
   "source": [
    "def plot(metric_results, metric_name):\n",
    "    plt.plot(metric_results[metric_name])\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.title(\"{} versus Step\".format(metric_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37c36cb2"
   },
   "outputs": [],
   "source": [
    "plot(metric_results, \"RegretMetric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c58d38a2"
   },
   "outputs": [],
   "source": [
    "plot(metric_results, \"AverageReturnMetric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df762eee"
   },
   "source": [
    "加载[TensorBoard Profiler](https://www.tensorflow.org/guide/profiler)相关内容，以进行培训过程和资源的数据分析。可视化不同设备上的操作统计信息、操作追踪等信息。这些信息可以帮助您识别培训性能中的瓶颈，并指导您对速度和/或可扩展性的潜在改进。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ab99a957"
   },
   "outputs": [],
   "source": [
    "# If on Google Cloud Notebooks, then don't execute this code.\n",
    "if not IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    if \"google.colab\" in sys.modules:\n",
    "\n",
    "        # Load the TensorBoard notebook extension.\n",
    "        %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6c51d88c"
   },
   "outputs": [],
   "source": [
    "# If on Google Cloud Notebooks, then don't execute this code.\n",
    "if not IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    if \"google.colab\" in sys.modules:\n",
    "\n",
    "        %tensorboard --logdir $PROFILER_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7abd938a"
   },
   "source": [
    "对于Google Cloud笔记本，您可以执行以下操作：\n",
    "\n",
    "1. 从GCP控制台打开[Cloud Shell](https://cloud.google.com/shell)。\n",
    "2. 安装依赖项：`pip3 install tensorflow==2.5.0 tensorboard-plugin-profile==2.5.0`。\n",
    "3. 运行以下命令：`tensorboard --logdir <PROFILER_DIR>`。您将看到输出消息 \"TensorBoard 2.5.0 at http://localhost:<PORT>/（按下CTRL+C退出）\"。记下端口号。\n",
    "4. 您可以单击[Web Preview](https://cloud.google.com/shell/docs/using-web-preview)按钮并查看TensorBoard仪表板和性能分析结果。您需要将Web Preview的端口配置为与第3步中收到的端口相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18f04365"
   },
   "source": [
    "在Vertex AI中执行\n",
    "\n",
    "该部分包括以下步骤：\n",
    "1. 对`policy_util`和`task`模块运行单元测试\n",
    "2. 创建超参数调整和训练自定义容器\n",
    "3. 提交超参数调整作业 [可选]\n",
    "4. 创建自定义预测容器\n",
    "5. 提交自定义容器训练作业\n",
    "6. 部署训练好的模型到终端\n",
    "7. 在终端上进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "db60f0d0"
   },
   "source": [
    "在`policy_util`和`task`模块上运行单元测试\n",
    "\n",
    "在`src/training/`中运行模块的单元测试。\n",
    "\n",
    "在`src/tests/`中找到测试，并在测试文件中填写标有“FILL IN”的配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "262fc060"
   },
   "outputs": [],
   "source": [
    "! python3 -m unittest src/tests/test_policy_util.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b60196e2"
   },
   "outputs": [],
   "source": [
    "! python3 -m unittest src/tests/test_task.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3726c506"
   },
   "source": [
    "### 创建超参数调整和训练自定义容器\n",
    "\n",
    "创建一个自定义容器，可用于超参数调整和训练。相关的源代码位于`src/training/`目录下。这将作为自定义容器的内部脚本。\n",
    "\n",
    "与之前一样，训练函数与[trainer.train](https://github.com/tensorflow/agents/blob/r0.8.0/tf_agents/bandits/agents/examples/v2/trainer.py#L104)相同，但它会跟踪中间度量值，支持超参数调整，并（针对训练）将工件保存到不同的位置。超参数调整和训练的训练逻辑相同。\n",
    "\n",
    "#### 执行超参数调整：\n",
    "- 代码不保存模型工件。它从Vertex AI超参数调整服务接收命令行参数作为超参数值，并使用cloudml-hypertune在每次试验时向Vertex AI报告训练结果度量值。\n",
    "- 请注意，如果决定保存模型工件，将它们保存在相同目录可能会在超参数调整作业中使用并行试验时导致覆盖错误。推荐的方法是将每次试验的工件保存到不同的子目录。这也可以帮助您从不同试验中恢复所有工件，并潜在地避免重新训练。\n",
    "- 在[这里](https://cloud.google.com/vertex-ai/docs/training/containers-overview#hyperparameter_tuning_with_custom_containers)阅读有关自定义容器的超参数调整更多信息；在[这里](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview)阅读有关超参数调整支持的更多信息。\n",
    "\n",
    "#### 执行训练：\n",
    "- 该代码将模型工件保存到`os.environ[\"AIP_MODEL_DIR\"]`以及`ARTIFACTS_DIR`，如此[所需](https://github.com/googleapis/python-aiplatform/blob/v0.8.0/google/cloud/aiplatform/training_jobs.py#L2202)。\n",
    "- 如果您想对函数进行更改，请确保仍将训练的策略保存为SavedModel以清理目录，并避免保存检查点和其他工件，以便将模型部署到终端处理工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bc407245"
   },
   "outputs": [],
   "source": [
    "HPTUNING_TRAINING_CONTAINER = \"hptuning-training-custom-container\"  # @param {type:\"string\"} Name of the container image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cb2b0eb"
   },
   "source": [
    "创建一个 Cloud Build YAML 文件\n",
    "\n",
    "使用[Kaniko](https://github.com/GoogleContainerTools/kaniko)构建超参数调整/训练容器。您可以应用缓存并指定构建机器类型。另外，您也可以使用 Docker 构建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "29bd8084"
   },
   "outputs": [],
   "source": [
    "cloudbuild_yaml = \"\"\"steps:\n",
    "- name: 'gcr.io/kaniko-project/executor:latest'\n",
    "  args: ['--destination=gcr.io/{PROJECT_ID}/{HPTUNING_TRAINING_CONTAINER}:latest',\n",
    "         '--cache=true',\n",
    "         '--cache-ttl=99h']\n",
    "options:\n",
    "  machineType: 'E2_HIGHCPU_8'\"\"\".format(\n",
    "    PROJECT_ID=PROJECT_ID,\n",
    "    HPTUNING_TRAINING_CONTAINER=HPTUNING_TRAINING_CONTAINER,\n",
    ")\n",
    "\n",
    "with open(\"cloudbuild.yaml\", \"w\") as fp:\n",
    "    fp.write(cloudbuild_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb8520d3"
   },
   "source": [
    "#### 编写一个Dockerfile\n",
    "\n",
    "- 使用[cloudml-hypertune](https://github.com/GoogleCloudPlatform/cloudml-hypertune) Python包来将训练指标报告给Vertex AI以进行超参数调优。\n",
    "- 使用Google [Cloud Storage客户端库](https://cloud.google.com/storage/docs/reference/libraries)在训练期间读取从先前的超参数调优作业中学到的最佳超参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7105edd4"
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "# Specifies base image and tag.\n",
    "FROM gcr.io/google-appengine/python\n",
    "WORKDIR /root\n",
    "\n",
    "# Installs additional packages.\n",
    "RUN pip3 install cloudml-hypertune==0.1.0.dev6\n",
    "RUN pip3 install google-cloud-storage==1.39.0\n",
    "RUN pip3 install tensorflow==2.5.0\n",
    "RUN pip3 install tensorboard-plugin-profile==2.5.0\n",
    "RUN pip3 install tf-agents==0.8.0\n",
    "RUN pip3 install matplotlib==3.4.2\n",
    "\n",
    "# Copies training code to the Docker image.\n",
    "COPY src/training /root/src/training\n",
    "\n",
    "# Sets up the entry point to invoke the task.\n",
    "ENTRYPOINT [\"python3\", \"-m\", \"src.training.task\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8dcc653"
   },
   "source": [
    "使用云构建构建定制容器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "313967e3"
   },
   "outputs": [],
   "source": [
    "! gcloud builds submit --config cloudbuild.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bb1b30a"
   },
   "source": [
    "### 提交超参数调整作业 [可选]\n",
    "\n",
    "- 使用自定义容器提交一个超参数训练作业。阅读更多关于在示例中使用 Python 包作为替代使用自定义容器的详细信息 [这里](https://cloud.google.com/vertex-ai/docs/training/using-hyperparameter-tuning#create)。\n",
    "- 定义超参数、最大试验数量、并行试验数量、参数搜索算法、机器规格、加速器、工作池等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fb3158b"
   },
   "outputs": [],
   "source": [
    "RUN_HYPERPARAMETER_TUNING = True  # Execute hyperparameter tuning instead of regular training.\n",
    "TRAIN_WITH_BEST_HYPERPARAMETERS = False  # Do not train.\n",
    "\n",
    "HPTUNING_RESULT_DIR = \"hptuning/\"  # @param {type: \"string\"} Directory to store the best hyperparameter(s) in `BUCKET_NAME` and locally (temporarily).\n",
    "HPTUNING_RESULT_PATH = os.path.join(HPTUNING_RESULT_DIR, \"result.json\")  # @param {type: \"string\"} Path to the file containing the best hyperparameter(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1222fe3"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6dbfdf0f"
   },
   "outputs": [],
   "source": [
    "def create_hyperparameter_tuning_job_sample(\n",
    "    project: str,\n",
    "    display_name: str,\n",
    "    image_uri: str,\n",
    "    args: List[str],\n",
    "    location: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\"\n",
    ") -> None:\n",
    "    \"\"\"Creates a hyperparameter tuning job using a custom container.\n",
    "\n",
    "    Args:\n",
    "        project: GCP project ID.\n",
    "        display_name: GCP console display name for the hyperparameter tuning job in\n",
    "            Vertex AI.\n",
    "        image_uri: URI to the hyperparameter tuning container image in Container\n",
    "            Registry.\n",
    "        args: Arguments passed to the container.\n",
    "        location: Service location.\n",
    "        api_endpoint: API endpoint, eg. `<location>-aiplatform.googleapis.com`.\n",
    "\n",
    "    Returns:\n",
    "        A string of the hyperparameter tuning job ID.\n",
    "    \"\"\"\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.JobServiceClient(client_options=client_options)\n",
    "\n",
    "    # study_spec\n",
    "    # Metric based on which to evaluate which combination of hyperparameter(s) to choose\n",
    "    metric = {\n",
    "        \"metric_id\": \"final_average_return\",  # Metric you report to Vertex AI.\n",
    "        \"goal\": aiplatform.gapic.StudySpec.MetricSpec.GoalType.MAXIMIZE,\n",
    "    }\n",
    "\n",
    "    # Hyperparameter(s) to tune\n",
    "    training_loops = {\n",
    "        \"parameter_id\": \"training-loops\",\n",
    "        \"discrete_value_spec\": {\"values\": [4, 16]},\n",
    "        \"scale_type\": aiplatform.gapic.StudySpec.ParameterSpec.ScaleType.UNIT_LINEAR_SCALE,\n",
    "    }\n",
    "    steps_per_loop = {\n",
    "        \"parameter_id\": \"steps-per-loop\",\n",
    "        \"discrete_value_spec\": {\"values\": [1, 2]},\n",
    "        \"scale_type\": aiplatform.gapic.StudySpec.ParameterSpec.ScaleType.UNIT_LINEAR_SCALE,\n",
    "    }\n",
    "\n",
    "    # trial_job_spec\n",
    "    machine_spec = {\n",
    "        \"machine_type\": \"n1-standard-4\",\n",
    "        \"accelerator_type\": aiplatform.gapic.AcceleratorType.ACCELERATOR_TYPE_UNSPECIFIED,\n",
    "        \"accelerator_count\": None,\n",
    "    }\n",
    "    worker_pool_spec = {\n",
    "        \"machine_spec\": machine_spec,\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": image_uri,\n",
    "            \"args\": args,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # hyperparameter_tuning_job\n",
    "    hyperparameter_tuning_job = {\n",
    "        \"display_name\": display_name,\n",
    "        \"max_trial_count\": 4,\n",
    "        \"parallel_trial_count\": 2,\n",
    "        \"study_spec\": {\n",
    "            \"metrics\": [metric],\n",
    "            \"parameters\": [training_loops, steps_per_loop],\n",
    "            \"algorithm\": aiplatform.gapic.StudySpec.Algorithm.RANDOM_SEARCH,\n",
    "        },\n",
    "        \"trial_job_spec\": {\"worker_pool_specs\": [worker_pool_spec]},\n",
    "    }\n",
    "    parent = f\"projects/{project}/locations/{location}\"\n",
    "\n",
    "    # Create job\n",
    "    response = client.create_hyperparameter_tuning_job(\n",
    "        parent=parent,\n",
    "        hyperparameter_tuning_job=hyperparameter_tuning_job)\n",
    "    job_id = response.name.split(\"/\")[-1]\n",
    "    print(\"Job ID:\", job_id)\n",
    "    print(\"Job config:\", response)\n",
    "\n",
    "    return job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aa831e5e"
   },
   "outputs": [],
   "source": [
    "args = [\n",
    "    f\"--data-path={DATA_PATH}\",\n",
    "    f\"--batch-size={BATCH_SIZE}\",\n",
    "    f\"--rank-k={RANK_K}\",\n",
    "    f\"--num-actions={NUM_ACTIONS}\",\n",
    "    f\"--tikhonov-weight={TIKHONOV_WEIGHT}\",\n",
    "    f\"--agent-alpha={AGENT_ALPHA}\",\n",
    "]\n",
    "if RUN_HYPERPARAMETER_TUNING:\n",
    "    args.append(\"--run-hyperparameter-tuning\")\n",
    "elif TRAIN_WITH_BEST_HYPERPARAMETERS:\n",
    "    args.append(\"--train-with-best-hyperparameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "763c9af3"
   },
   "outputs": [],
   "source": [
    "job_id = create_hyperparameter_tuning_job_sample(\n",
    "    project=PROJECT_ID,\n",
    "    display_name=\"movielens-hyperparameter-tuning-job\",\n",
    "    image_uri=f\"gcr.io/{PROJECT_ID}/{HPTUNING_TRAINING_CONTAINER}:latest\",\n",
    "    args=args,\n",
    "    location=REGION,\n",
    "    api_endpoint=f\"{REGION}-aiplatform.googleapis.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bafc0e05"
   },
   "source": [
    "完成此操作大约需要 ~20 分钟。\n",
    "\n",
    "#### 检查超参数调整作业状态\n",
    "\n",
    "- 详细了解如何管理作业 [点击这里](https://cloud.google.com/vertex-ai/docs/training/using-hyperparameter-tuning#manage)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c959a9f3"
   },
   "outputs": [],
   "source": [
    "def get_hyperparameter_tuning_job_sample(\n",
    "    project: str,\n",
    "    hyperparameter_tuning_job_id: str,\n",
    "    location: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    ") -> aiplatform.HyperparameterTuningJob:\n",
    "    \"\"\"Gets the current status of a hyperparameter tuning job.\n",
    "\n",
    "    Args:\n",
    "        project: GCP project ID.\n",
    "        hyperparameter_tuning_job_id: Hyperparameter tuning job ID.\n",
    "        location: Service location.\n",
    "        api_endpoint: API endpoint, eg. `<location>-aiplatform.googleapis.com`.\n",
    "\n",
    "    Returns:\n",
    "        Details of the hyperparameter tuning job, such as its running status,\n",
    "        results of its trials, etc.\n",
    "    \"\"\"\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.JobServiceClient(client_options=client_options)\n",
    "    name = client.hyperparameter_tuning_job_path(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        hyperparameter_tuning_job=hyperparameter_tuning_job_id)\n",
    "    response = client.get_hyperparameter_tuning_job(name=name)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7742abe2"
   },
   "outputs": [],
   "source": [
    "trials = None\n",
    "while True:\n",
    "    response = get_hyperparameter_tuning_job_sample(\n",
    "        project=PROJECT_ID,\n",
    "        hyperparameter_tuning_job_id=job_id,\n",
    "        location=REGION,\n",
    "        api_endpoint=f\"{REGION}-aiplatform.googleapis.com\")\n",
    "    if response.state.name == 'JOB_STATE_SUCCEEDED':\n",
    "        print(\"Job succeeded.\\nJob Time:\", response.update_time - response.create_time)\n",
    "        trials = response.trials\n",
    "        print(\"Trials:\", trials)\n",
    "        break\n",
    "    elif response.state.name == \"JOB_STATE_FAILED\":\n",
    "        print(\"Job failed.\")\n",
    "        break\n",
    "    elif response.state.name == \"JOB_STATE_CANCELLED\":\n",
    "        print(\"Job cancelled.\")\n",
    "    break\n",
    "    else:\n",
    "        print(f\"Current job status: {response.state.name}.\")\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72e0a69d"
   },
   "source": [
    "寻找每个度量标准的最佳参数组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "389e131c"
   },
   "outputs": [],
   "source": [
    "if trials:\n",
    "    # Dict mapping from metric names to the best metric values seen so far\n",
    "    best_objective_values = dict.fromkeys(\n",
    "        [metric.metric_id for metric in trials[0].final_measurement.metrics],\n",
    "        -np.inf)\n",
    "    # Dict mapping from metric names to a list of the best combination(s) of\n",
    "    # hyperparameter(s). Each combination is a dict mapping from hyperparameter\n",
    "    # names to their values.\n",
    "    best_params = defaultdict(list)\n",
    "    for trial in trials:\n",
    "        # `final_measurement` and `parameters` are `RepeatedComposite` objects.\n",
    "        # Reference the structure above to extract the value of your interest.\n",
    "        for metric in trial.final_measurement.metrics:\n",
    "            params = {\n",
    "                param.parameter_id: param.value for param in trial.parameters}\n",
    "            if metric.value > best_objective_values[metric.metric_id]:\n",
    "                best_params[metric.metric_id] = [params]\n",
    "            elif metric.value == best_objective_values[metric.metric_id]:\n",
    "                best_params[param.parameter_id].append(params)  # Handle cases where multiple hyperparameter values lead to the same performance.\n",
    "    print(\"Best hyperparameter value(s):\")\n",
    "    for metric, params in best_params.items():\n",
    "        print(f\"Metric={metric}: {sorted(params)}\")\n",
    "else:\n",
    "    print(\"No hyperparameter tuning job trials found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0497a5c"
   },
   "source": [
    "将感兴趣的度量标准的最佳超参数组合转换为JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebced166"
   },
   "outputs": [],
   "source": [
    "! mkdir $HPTUNING_RESULT_DIR\n",
    "\n",
    "with open(HPTUNING_RESULT_PATH, \"w\") as f:\n",
    "    json.dump(best_params[\"final_average_return\"][0], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a38871a"
   },
   "source": [
    "上传最佳超参数到GCS以用于训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0a674285"
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "bucket = storage_client.bucket(RAW_BUCKET_NAME)\n",
    "blob = bucket.blob(HPTUNING_RESULT_PATH)\n",
    "blob.upload_from_filename(HPTUNING_RESULT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b402962"
   },
   "source": [
    "### 创建自定义预测容器\n",
    "\n",
    "与训练一样，创建一个自定义预测容器。此容器处理与常规 TensorFlow 模型不同的 TF-Agents 特定逻辑。具体来说，它使用训练过的策略找到预测的动作。相关的源代码位于 `src/prediction/`。\n",
    "查看 Vertex AI 预测的其他选项[此处](https://cloud.google.com/vertex-ai/docs/predictions/getting-predictions)。\n",
    "\n",
    "#### 提供预测：\n",
    "- 使用 [`tensorflow.saved_model.load`](https://www.tensorflow.org/agents/api_docs/python/tf_agents/policies/PolicySaver#usage) 而不是 [`tf_agents.policies.policy_loader.load`](https://github.com/tensorflow/agents/blob/r0.8.0/tf_agents/policies/policy_loader.py#L26) 来加载训练过的策略，因为后者产生的对象类型是 [`SavedModelPyTFEagerPolicy`](https://github.com/tensorflow/agents/blob/402b8aa81ca1b578ec1f687725d4ccb4115386d2/tf_agents/policies/py_tf_eager_policy.py#L137)，其 `action()` 方法不适用于此处。\n",
    "- 请注意，预测请求仅包含观察数据而不包含奖励。这是因为：预测任务是一个独立的请求，不需要对系统状态有先前的了解。与此同时，最终用户只知道他们在此刻观察到的内容。奖励是在动作执行后产生的信息，因此最终用户不会知道奖励。在处理预测请求时，您需要创建一个 [`TimeStep`](https://www.tensorflow.org/agents/api_docs/python/tf_agents/trajectories/TimeStep) 对象（包含 `observation`、`reward`、`discount`、`step_type`），使用 [`restart()`](https://www.tensorflow.org/agents/api_docs/python/tf_agents/trajectories/restart) 函数传入一个 `observation`。此函数会创建轨迹步骤中的第一个 TimeStep，在这个步骤中，奖励为0，折扣为1，步骤类型标记为第一个时间步。换句话说，每个预测请求形成一个新轨迹中的第一个 `TimeStep`。\n",
    "- 对于预测响应，请避免使用 NumPy 类型的值；相反，使用诸如 [`tolist()`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.tolist.html) 这样的方法将其转换为本机 Python 值，而不是 `list()`。\n",
    "- `src/prediction` 目录中存在一个预启动脚本。FastAPI 在启动服务器之前执行此脚本。`PORT` 环境变量被设置为等于 `AIP_HTTP_PORT`，以便在 Vertex AI 期望的相同端口上运行 FastAPI。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1723a927"
   },
   "outputs": [],
   "source": [
    "PREDICTION_CONTAINER = \"prediction-custom-container\"  # @param {type:\"string\"} Name of the container image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3dc8994"
   },
   "source": [
    "创建一个Cloud Build YAML文件\n",
    "\n",
    "使用[Kaniko](https://github.com/GoogleContainerTools/kaniko)来构建自定义预测容器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15ca50b2"
   },
   "outputs": [],
   "source": [
    "cloudbuild_yaml = \"\"\"steps:\n",
    "- name: 'gcr.io/kaniko-project/executor:latest'\n",
    "  args: ['--destination=gcr.io/{PROJECT_ID}/{PREDICTION_CONTAINER}:latest',\n",
    "         '--cache=true',\n",
    "         '--cache-ttl=99h']\n",
    "  env: ['AIP_STORAGE_URI={ARTIFACTS_DIR}']\n",
    "options:\n",
    "  machineType: 'E2_HIGHCPU_8'\"\"\".format(\n",
    "    PROJECT_ID=PROJECT_ID,\n",
    "    PREDICTION_CONTAINER=PREDICTION_CONTAINER,\n",
    "    ARTIFACTS_DIR=ARTIFACTS_DIR\n",
    ")\n",
    "\n",
    "with open(\"cloudbuild.yaml\", \"w\") as fp:\n",
    "    fp.write(cloudbuild_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65e32312"
   },
   "source": [
    "定义依赖关系\n",
    "\n",
    "- 请注意，这些依赖关系应该彼此兼容（例如，tensorflow==2.5.0 需要 numpy<=1.19.2）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4945bc35"
   },
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "numpy~=1.19.2\n",
    "six~=1.15.0\n",
    "typing-extensions~=3.7.4\n",
    "pillow==9.0.0\n",
    "tf-agents==0.8.0\n",
    "tensorflow==2.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "201c8b24"
   },
   "source": [
    "写一个Dockerfile\n",
    "\n",
    "注意：保留服务器目录`app`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3f8b0df0"
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
    "\n",
    "COPY src/prediction /app\n",
    "COPY requirements.txt /app/requirements.txt\n",
    "\n",
    "RUN pip3 install -r /app/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dd4cffc"
   },
   "source": [
    "使用Cloud Build构建预测容器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d4417c4"
   },
   "outputs": [],
   "source": [
    "! gcloud builds submit --config cloudbuild.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6895e6d5"
   },
   "source": [
    "### 提交自定义容器训练作业\n",
    "\n",
    "- 请再次注意，存储桶必须与服务位置位于同一地区，并且不应该是多区域的。\n",
    "- 更多关于CustomContainerTrainingJob的源代码，请访问[此处](https://github.com/googleapis/python-aiplatform/blob/v0.8.0/google/cloud/aiplatform/training_jobs.py#L2153)。\n",
    "- 与本地执行类似，您可以使用TensorBoard Profiler来跟踪训练进程和资源，并使用以下命令可视化相应的工件： `%tensorboard --logdir $PROFILER_DIR`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f05d08a"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ab31a8da"
   },
   "outputs": [],
   "source": [
    "RUN_HYPERPARAMETER_TUNING = False  # Execute regular training instead of hyperparameter tuning.\n",
    "TRAIN_WITH_BEST_HYPERPARAMETERS = True  # @param {type:\"bool\"} Whether to use learned hyperparameters in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "218eca21"
   },
   "outputs": [],
   "source": [
    "args = [\n",
    "    f\"--artifacts-dir={ARTIFACTS_DIR}\",\n",
    "    f\"--profiler-dir={PROFILER_DIR}\",\n",
    "    f\"--data-path={DATA_PATH}\",\n",
    "    f\"--batch-size={BATCH_SIZE}\",\n",
    "    f\"--rank-k={RANK_K}\",\n",
    "    f\"--num-actions={NUM_ACTIONS}\",\n",
    "    f\"--tikhonov-weight={TIKHONOV_WEIGHT}\",\n",
    "    f\"--agent-alpha={AGENT_ALPHA}\",\n",
    "]\n",
    "if RUN_HYPERPARAMETER_TUNING:\n",
    "    args.append(\"--run-hyperparameter-tuning\")\n",
    "elif TRAIN_WITH_BEST_HYPERPARAMETERS:\n",
    "    args.append(\"--train-with-best-hyperparameters\")\n",
    "    args.append(f\"--best-hyperparameters-bucket={RAW_BUCKET_NAME}\")\n",
    "    args.append(f\"--best-hyperparameters-path={HPTUNING_RESULT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8080155"
   },
   "outputs": [],
   "source": [
    "job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=\"train-movielens\",\n",
    "    container_uri=f\"gcr.io/{PROJECT_ID}/{HPTUNING_TRAINING_CONTAINER}:latest\",\n",
    "    command=[\"python3\", \"-m\", \"src.training.task\"] + args,  # Pass in training arguments, including hyperparameters.\n",
    "    model_serving_container_image_uri=f\"gcr.io/{PROJECT_ID}/{PREDICTION_CONTAINER}:latest\",\n",
    "    model_serving_container_predict_route=\"/predict\",\n",
    "    model_serving_container_health_route=\"/health\")\n",
    "\n",
    "print(\"Training Spec:\", job._managed_model)\n",
    "\n",
    "model = job.run(\n",
    "    model_display_name=\"movielens-model\",\n",
    "    replica_count=1,\n",
    "    machine_type=\"n1-standard-4\",\n",
    "    accelerator_type=\"ACCELERATOR_TYPE_UNSPECIFIED\",\n",
    "    accelerator_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3971b79d"
   },
   "outputs": [],
   "source": [
    "print(\"Model display name:\", model.display_name)\n",
    "print(\"Model ID:\", model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfd47f03"
   },
   "source": [
    "部署训练模型到一个端点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1c2fd020"
   },
   "outputs": [],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cffc159f"
   },
   "outputs": [],
   "source": [
    "print(\"Endpoint display name:\", endpoint.display_name)\n",
    "print(\"Endpoint ID:\", endpoint.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c85b31b0"
   },
   "source": [
    "### 在终端上进行预测\n",
    "- 把预测输入放入一个名为`instances`的列表中。观察结果应该是维度为(BATCH_SIZE, RANK_K)的。在这里阅读更多关于MovieLens仿真环境观察的信息：(https://github.com/tensorflow/agents/blob/v0.8.0/tf_agents/bandits/environments/movielens_py_environment.py#L32-L138)。\n",
    "- 在这里阅读更多关于终端预测API的信息：(https://cloud.google.com/sdk/gcloud/reference/ai/endpoints/predict)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "670e5055"
   },
   "outputs": [],
   "source": [
    "endpoint.predict(\n",
    "    instances=[\n",
    "        {\"observation\": [list(np.ones(20)) for _ in range(8)]},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51780141"
   },
   "source": [
    "## 概要\n",
    "\n",
    "### 电影评价（MovieLens）模拟环境的目的是什么？\n",
    "\n",
    "电影评价（MovieLens）环境*模拟*了包含用户及其各自偏好的真实世界环境。在内部，电影评价（MovieLens）模拟环境接收用户对电影项目的评级矩阵，并对该评级矩阵执行`RANK_K`矩阵分解，以解决矩阵的稀疏性问题。完成构建步骤后，环境可以生成维度为`RANK_K`的用户向量来代表模拟环境中的用户，并能够确定任何用户和电影项目对之间的近似奖励。在强化学习的术语中，用户向量称为观察值，推荐的电影项目称为行动，近似评级则称为奖励。因此，这个环境定义了面临的强化学习问题：如何推荐电影以最大化用户评级，在一个模拟世界中的用户，其偏好由电影评价（MovieLens）数据集定义，同时没有关于环境内部机制的任何知识。\n",
    "\n",
    "需要注意的是，用户向量可能不与原始评级矩阵中的维度相同，并且近似评级（以解决评级数据的稀疏性）可能不等同于原始评级。用户向量中的各个条目并不对应于真实世界的含义，比如用户年龄等。在预测请求中，观察值是与电影评价（MovieLens）模拟环境生成的用户向量相同空间中的用户向量。换句话说，它们代表用户的方式与电影评价（MovieLens）环境生成的用户向量/观察值相同。\n",
    "\n",
    "这个演示采用电影评价（MovieLens）环境是因为可以基于公共数据集而无需与真实世界通信；这种通信会给演示必需的步骤增加额外负担，很可能依赖于难以推广到您产品需求的特定实现。\n",
    "\n",
    "### 如何将这个演示应用于生产环境\n",
    "\n",
    "#### 步骤 0：演示\n",
    "\n",
    "通过使用电影评价（MovieLens）模拟环境来了解这个演示。\n",
    "\n",
    "#### 步骤 1：离线模拟\n",
    "\n",
    "为了评估您的强化学习模型的性能，您可能需要首先运行离线模拟，以确定您的强化学习模型是否符合生产要求。在这种情况下，您可以拥有一个静态数据集，类似于电影评价（MovieLens）数据集但可能更大，并且您可以构建一个自定义模拟环境来代替电影评价（MovieLens）模拟环境。在自定义环境中，您可以决定如何构建观察值和奖励，例如如何使用用户向量来表示用户及这些向量的样子，也许通过神经网络中的嵌入层。您可以像对待电影评价（MovieLens）一样应用剩余步骤和代码，然后评估您的模型。完成离线模拟后，您可以继续进行启动模型的下一步，例如进行A/B测试。\n",
    "\n",
    "#### 步骤 2：真实世界系统\n",
    "\n",
    "当您在生产环境中部署这个演示的步骤时，您将需要用真实世界系统或与真实世界对接的通信机制替换电影评价（MovieLens）模拟环境。在训练中，您从真实世界环境中提取用户向量/观察值和评分/奖励。此时，用户向量中的各个条目可能具有实际含义，比如用户年龄。同样，您可以决定如何构建观察值和奖励。在预测中，封装在预测请求中的观察值再次是与训练中相同类型的用户向量，具有相同的真实世界含义；您可以用相同的机制生成它们。\n",
    "\n",
    "您的预测目标再次是确定为特定用户推荐哪些电影项目。您会使用您确定的机制用用户向量代表该用户，将该向量作为观察值发送，并在响应中获取推荐的电影项目。\n",
    "\n",
    "### 性能和可扩展性分析\n",
    "\n",
    "你可以使用TensorBoard Profiler，以及其他TensorBoard功能，来分析训练性能并找到加速和/或更好扩展应用程序的解决方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f532a8c5"
   },
   "source": [
    "## 清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于此教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4eb6a875"
   },
   "outputs": [],
   "source": [
    "# Delete endpoint resource\n",
    "! gcloud ai endpoints delete $endpoint.name --quiet --region $REGION\n",
    "\n",
    "# Delete model resource\n",
    "! gcloud ai models delete $model.name --quiet\n",
    "\n",
    "# Delete Cloud Storage objects that were created\n",
    "! gsutil -m rm -r $ARTIFACTS_DIR"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "step_by_step_sdk_tf_agents_bandits_movie_recommendation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
