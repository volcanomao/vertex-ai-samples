{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46d6c164544f"
   },
   "outputs": [],
   "source": [
    "# Copyright 2020 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "åœ¨[Vertex AI](https://cloud.google.com/vertex-ai)ä¸Šè®­ç»ƒã€è°ƒæ•´å’Œéƒ¨ç½²PyTorchæ–‡æœ¬åˆ†ç±»æ¨¡å‹\n",
    "ç»†è°ƒé¢„è®­ç»ƒçš„[BERT](https://huggingface.co/bert-base-cased)æ¨¡å‹ä»¥è¿›è¡Œæƒ…æ„Ÿåˆ†ç±»ä»»åŠ¡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4cRE8IbIrIV"
   },
   "source": [
    "# æ¦‚è¿°\n",
    "\n",
    "è¿™ä¸ªç¤ºä¾‹æºè‡ªToken-Classification [notebook](https://github.com/huggingface/notebooks/blob/master/examples/token_classification.ipynb)å’Œrun_glue.py (https://github.com/huggingface/transformers/blob/v2.5.0/examples/run_glue.py)ã€‚\n",
    "æˆ‘ä»¬å°†å¯¹**`bert-base-cased`**ï¼ˆé¢„è®­ç»ƒï¼‰æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œç”¨äºæƒ…æ„Ÿåˆ†ç±»ä»»åŠ¡ã€‚\n",
    "æ‚¨å¯ä»¥åœ¨[Hugging Face Hub](https://huggingface.co/bert-base-cased)æ‰¾åˆ°æœ‰å…³è¯¥æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯ã€‚\n",
    "\n",
    "è¦äº†è§£å…³äºæœ€å…ˆè¿›çš„PyTorch/Tensorflow/JAXçš„æ›´å¤šnotebooksï¼Œæ‚¨å¯ä»¥æ¢ç´¢[Hugging FaceNotebooks](https://huggingface.co/transformers/notebooks.html)ã€‚\n",
    "\n",
    "### æ•°æ®é›†\n",
    "\n",
    "æˆ‘ä»¬å°†ä½¿ç”¨[Hugging Face Datasets](https://huggingface.co/datasets)ä¸­çš„[IMDBç”µå½±è¯„è®ºæ•°æ®é›†](https://huggingface.co/datasets/imdb)ã€‚\n",
    "\n",
    "### ç›®æ ‡\n",
    "\n",
    "å¦‚ä½•åœ¨[Vertex AI](https://cloud.google.com/vertex-ai)ä¸Šæ„å»ºã€è®­ç»ƒã€è°ƒæ•´å’Œéƒ¨ç½²PyTorchæ¨¡å‹ï¼Œå¹¶å¼ºè°ƒå¯¹åœ¨Vertex AIä¸Šè®­ç»ƒå’Œéƒ¨ç½²PyTorchæ¨¡å‹çš„ä¸€æµæ”¯æŒã€‚\n",
    "\n",
    "### ç›®å½•\n",
    "\n",
    "è¿™ä¸ªnotebookæ¶µç›–äº†ä»¥ä¸‹éƒ¨åˆ†ï¼š\n",
    "\n",
    "- [åˆ›å»ºNotebookså®ä¾‹](#Creating-Notebooks-instance-on-Google-Cloud)\n",
    "- [è®­ç»ƒ](#Training)\n",
    "    - [åœ¨Notebookä¸­æœ¬åœ°è¿è¡Œè®­ç»ƒ](#Training-locally-in-the-notebook)\n",
    "    - [åœ¨Vertex AIä¸Šè¿è¡Œè®­ç»ƒä½œä¸š](#Training-on-Vertex-AI)\n",
    "        - [ä½¿ç”¨é¢„æ„å»ºå®¹å™¨è¿›è¡Œè®­ç»ƒ](#Run-Custom-Job-on-Vertex-AI-Training-with-a-pre-built-container)\n",
    "        - [ä½¿ç”¨è‡ªå®šä¹‰å®¹å™¨è¿›è¡Œè®­ç»ƒ](#Run-Custom-Job-on-Vertex-AI-Training-with-custom-container)\n",
    "- [è°ƒæ•´](#Hyperparameter-Tuning) \n",
    "    - [åœ¨Vertex AIä¸Šè¿è¡Œè¶…å‚æ•°è°ƒæ•´ä½œä¸š](#Run-Hyperparameter-Tuning-Job-on-Vertex-AI)\n",
    "- [éƒ¨ç½²](#Deploying)\n",
    "    - [åœ¨Vertex AI Predictionsä¸Šä½¿ç”¨è‡ªå®šä¹‰å®¹å™¨éƒ¨ç½²æ¨¡å‹](#Deploying-model-on-Vertex AI-Predictions-with-custom-container)\n",
    "\n",
    "### æˆæœ¬\n",
    "\n",
    "æœ¬æ•™ç¨‹ä½¿ç”¨Google Cloud Platform (GCP)çš„è®¡è´¹ç»„ä»¶ï¼š\n",
    "\n",
    "* [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)\n",
    "* [Vertex AI Training](https://cloud.google.com/vertex-ai/docs/training/custom-training)\n",
    "* [Vertex AI Predictions](https://cloud.google.com/vertex-ai/docs/predictions/getting-predictions)\n",
    "* [Cloud Storage](https://cloud.google.com/storage)\n",
    "* [Container Registry](https://cloud.google.com/container-registry)\n",
    "* [Cloud Build](https://cloud.google.com/build) *[å¯é€‰]*\n",
    "\n",
    "äº†è§£[Vertex AI Pricing](https://cloud.google.com/vertex-ai/pricing)ã€[Cloud Storage Pricing](https://cloud.google.com/storage/pricing)å’Œ[Cloud Build Pricing](https://cloud.google.com/build/pricing)ï¼Œå¹¶ä½¿ç”¨[Pricing Calculator](https://cloud.google.com/products/calculator/)æ ¹æ®æ‚¨çš„é¢„æœŸä½¿ç”¨é‡ç”Ÿæˆæˆæœ¬ä¼°ç®—ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cda8ab8b7a04"
   },
   "source": [
    "åœ¨è°·æ­Œäº‘ä¸Šåˆ›å»ºç¬”è®°æœ¬å®ä¾‹\n",
    "\n",
    "æ­¤ç¬”è®°æœ¬å‡è®¾ä½ æ­£åœ¨ä½¿ç”¨å¸¦æœ‰GPUè¿è¡Œæ—¶çš„PyTorch 1.9 DLVMå¼€å‘ç¯å¢ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨è°·æ­Œäº‘æ§åˆ¶å°æˆ–`gcloud`å‘½ä»¤åˆ›å»ºä¸€ä¸ªç¬”è®°æœ¬å®ä¾‹ã€‚\n",
    "\n",
    "```\n",
    "gcloud notebooks instances create example-instance \\\n",
    "    --vm-image-project=deeplearning-platform-release \\\n",
    "    --vm-image-family=pytorch-1-9-cu110-notebooks \\\n",
    "    --machine-type=n1-standard-4 \\\n",
    "    --location=us-central1-a \\\n",
    "    --boot-disk-size=100 \\\n",
    "    --accelerator-core-count=1 \\\n",
    "    --accelerator-type=NVIDIA_TESLA_V100 \\\n",
    "    --install-gpu-driver \\\n",
    "    --network=default\n",
    "```\n",
    "***\n",
    "**æ³¨æ„ï¼š**åœ¨åˆ›å»ºå¸¦æœ‰GPUçš„å®ä¾‹ä¹‹å‰ï¼Œæ‚¨å¿…é¡»å…ˆç¡®è®¤æ‚¨æœ‰GPUé…é¢ã€‚è¯·æ£€æŸ¥[é…é¢](https://console.cloud.google.com/iam-admin/quotas)é¡µé¢ä»¥ç¡®ä¿æ‚¨çš„é¡¹ç›®ä¸­æœ‰è¶³å¤Ÿçš„GPUå¯ç”¨ã€‚å¦‚æœGPUæœªåœ¨é…é¢é¡µé¢åˆ—å‡ºæˆ–æ‚¨éœ€è¦é¢å¤–çš„GPUé…é¢ï¼Œè¯·[è¯·æ±‚æé«˜é…é¢](https://cloud.google.com/compute/quotas#requesting_additional_quota)ã€‚å…è´¹è¯•ç”¨è´¦æˆ·é»˜è®¤ä¸ä¼šè·å¾—GPUé…é¢ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5178273783dd"
   },
   "source": [
    "### è®¾ç½®æ‚¨çš„æœ¬åœ°å¼€å‘ç¯å¢ƒ\n",
    "\n",
    "**å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨Colabæˆ–Google Cloudç¬”è®°æœ¬**ï¼Œæ‚¨çš„ç¯å¢ƒå·²ç»ç¬¦åˆè¿è¡Œæ­¤ç¬”è®°æœ¬çš„æ‰€æœ‰è¦æ±‚ã€‚æ‚¨å¯ä»¥è·³è¿‡æ­¤æ­¥éª¤ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1a1ead2cb5e3"
   },
   "source": [
    "å¦åˆ™ï¼Œè¯·ç¡®ä¿æ‚¨çš„ç¯å¢ƒç¬¦åˆæœ¬ç¬”è®°æœ¬çš„è¦æ±‚ã€‚æ‚¨éœ€è¦ä»¥ä¸‹å†…å®¹ï¼š\n",
    "\n",
    "* Google Cloud SDK\n",
    "* Git\n",
    "* Python 3\n",
    "* virtualenv\n",
    "* åœ¨ä½¿ç”¨Python 3çš„è™šæ‹Ÿç¯å¢ƒä¸­è¿è¡Œçš„Jupyterç¬”è®°æœ¬\n",
    "\n",
    "Google CloudæŒ‡å—[è®¾ç½®Pythonå¼€å‘ç¯å¢ƒ](https://cloud.google.com/python/setup)å’Œ[Jupyterå®‰è£…æŒ‡å—](https://jupyter.org/install)æä¾›äº†æ»¡è¶³è¿™äº›è¦æ±‚çš„è¯¦ç»†è¯´æ˜ã€‚ä»¥ä¸‹æ­¥éª¤æä¾›äº†ä¸€ä¸ªç®€åŒ–çš„æŒ‡å—ï¼š\n",
    "\n",
    "1. [å®‰è£…å¹¶åˆå§‹åŒ–Cloud SDKã€‚](https://cloud.google.com/sdk/docs/)\n",
    "2. [å®‰è£…Python 3ã€‚](https://cloud.google.com/python/setup#installing_python)\n",
    "3. [å®‰è£…virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv)å¹¶åˆ›å»ºä¸€ä¸ªä½¿ç”¨Python 3çš„è™šæ‹Ÿç¯å¢ƒã€‚æ¿€æ´»è™šæ‹Ÿç¯å¢ƒã€‚\n",
    "4. è¦å®‰è£…Jupyterï¼Œåœ¨ç»ˆç«¯ä¸­çš„å‘½ä»¤è¡Œä¸­è¿è¡Œ`pip3 install jupyter`ã€‚\n",
    "5. è¦å¯åŠ¨Jupyterï¼Œåœ¨ç»ˆç«¯ä¸­çš„å‘½ä»¤è¡Œä¸­è¿è¡Œ`jupyter notebook`ã€‚\n",
    "6. åœ¨Jupyter Notebookä»ªè¡¨æ¿ä¸­æ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a864c22307c"
   },
   "source": [
    "### å®‰è£…é¢å¤–çš„åŒ…\n",
    "\n",
    "æ­¤ç¬”è®°æœ¬æ‰€éœ€çš„Pythonä¾èµ–é¡¹åŒ…æ‹¬[Transformers](https://pypi.org/project/transformers/)ï¼Œ[Datasets](https://pypi.org/project/datasets/)å’Œ[hypertune](https://github.com/GoogleCloudPlatform/cloudml-hypertune)å°†åœ¨ç¬”è®°æœ¬å®ä¾‹å†…éƒ¨å®‰è£…ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fd00fa70a2a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Google Cloud Notebook product has specific requirements\n",
    "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
    "\n",
    "# Google Cloud Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2974254ea6be"
   },
   "outputs": [],
   "source": [
    "!pip -q install {USER_FLAG} --upgrade transformers\n",
    "!pip -q install {USER_FLAG} --upgrade datasets\n",
    "!pip -q install {USER_FLAG} --upgrade tqdm\n",
    "!pip -q install {USER_FLAG} --upgrade cloudml-hypertune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0c1dcadc2c8"
   },
   "source": [
    "æˆ‘ä»¬å°†ä½¿ç”¨[Pythonçš„Vertex AI SDK](https://cloud.google.com/vertex-ai/docs/start/client-libraries#python)ä¸Vertex AIæœåŠ¡è¿›è¡Œäº¤äº’ã€‚é«˜çº§çš„`aiplatform`åº“æ—¨åœ¨é€šè¿‡ä½¿ç”¨åŒ…è£…å™¨ç±»å’Œç‰¹å®šçš„é»˜è®¤å€¼æ¥ç®€åŒ–å¸¸è§çš„æ•°æ®ç§‘å­¦å·¥ä½œæµç¨‹ã€‚\n",
    "\n",
    "#### å®‰è£…Pythonçš„Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ab3fb1551abe"
   },
   "outputs": [],
   "source": [
    "!pip -q install {USER_FLAG} --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f361541eff05"
   },
   "source": [
    "é‡æ–°å¯åŠ¨å†…æ ¸\n",
    "\n",
    "åœ¨å®‰è£…é¢å¤–çš„åŒ…ä¹‹åï¼Œæ‚¨éœ€è¦é‡æ–°å¯åŠ¨ç¬”è®°æœ¬å†…æ ¸ï¼Œä»¥ä¾¿å®ƒå¯ä»¥æ‰¾åˆ°è¿™äº›åŒ…ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2d77a223d63d"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bebb3b46278"
   },
   "source": [
    "åœ¨å¼€å§‹ä¹‹å‰\n",
    "\n",
    "é€‰æ‹©ä¸€ä¸ªGPUè¿è¡Œæ—¶\n",
    "\n",
    "å¦‚æœæœ‰è¿™ä¸ªé€‰é¡¹ï¼Œè¯·ç¡®ä¿ä½ åœ¨GPUè¿è¡Œæ—¶ä¸­è¿è¡Œè¿™ä¸ªç¬”è®°æœ¬ã€‚åœ¨Colabä¸­ï¼Œé€‰æ‹©â€œè¿è¡Œæ—¶ --> æ›´æ”¹è¿è¡Œæ—¶ç±»å‹ > GPUâ€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1e4d8f0c294"
   },
   "source": [
    "### è®¾ç½®æ‚¨çš„ Google Cloud é¡¹ç›®\n",
    "\n",
    "**æ— è®ºæ‚¨ä½¿ç”¨çš„æ˜¯å“ªç§ç¬”è®°æœ¬ç¯å¢ƒï¼Œéƒ½éœ€è¦æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œã€‚**\n",
    "\n",
    "1. [é€‰æ‹©æˆ–åˆ›å»ºä¸€ä¸ª Google Cloud é¡¹ç›®](https://console.cloud.google.com/cloud-resource-manager)ã€‚å½“æ‚¨é¦–æ¬¡åˆ›å»ºå¸æˆ·æ—¶ï¼Œæ‚¨ä¼šè·å¾—$300 çš„å…è´¹ä¿¡ç”¨é¢åº¦ç”¨äºæ”¯ä»˜è®¡ç®—/å­˜å‚¨æˆæœ¬ã€‚\n",
    "1. [ç¡®ä¿æ‚¨çš„é¡¹ç›®å·²å¯ç”¨è®¡è´¹åŠŸèƒ½](https://cloud.google.com/billing/docs/how-to/modify-project)ã€‚\n",
    "1. åœ¨æ‚¨çš„é¡¹ç›®ä¸­å¯ç”¨ä»¥ä¸‹ APIï¼Œè¿™äº› API æ˜¯è¿è¡Œæ•™ç¨‹æ‰€å¿…éœ€çš„\n",
    "    - [Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)\n",
    "    - [Cloud Storage API](https://console.cloud.google.com/flows/enableapi?apiid=storage.googleapis.com)\n",
    "    - [Container Registry API](https://console.cloud.google.com/flows/enableapi?apiid=containerregistry.googleapis.com)\n",
    "    - [Cloud Build API](https://console.cloud.google.com/flows/enableapi?apiid=cloudbuild.googleapis.com)\n",
    "1. å¦‚æœæ‚¨æ­£åœ¨æœ¬åœ°è¿è¡Œè¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å°†éœ€è¦å®‰è£… [Cloud SDK](https://cloud.google.com/sdk)ã€‚\n",
    "1. åœ¨ä¸‹é¢çš„å•å…ƒæ ¼ä¸­è¾“å…¥æ‚¨çš„é¡¹ç›® IDã€‚ç„¶åè¿è¡Œè¯¥å•å…ƒæ ¼ï¼Œä»¥ç¡®ä¿ Cloud SDK å¯¹æœ¬ç¬”è®°æœ¬ä¸­çš„æ‰€æœ‰å‘½ä»¤ä½¿ç”¨æ­£ç¡®çš„é¡¹ç›®ã€‚\n",
    "\n",
    "**æ³¨æ„**ï¼šJupyter ä¼šå°†ä»¥ `!` å¼€å¤´çš„è¡Œè§†ä¸º shell å‘½ä»¤ï¼Œå®ƒä¼šå°†ä»¥ `$` å¼€å¤´çš„ Python å˜é‡æ’å€¼åˆ°è¿™äº›å‘½ä»¤ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36a4450b7c2e"
   },
   "source": [
    "è®¾ç½®æ‚¨çš„é¡¹ç›®ID\n",
    "\n",
    "**å¦‚æœæ‚¨ä¸çŸ¥é“æ‚¨çš„é¡¹ç›®ID**ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`gcloud`æˆ–`google.auth`æ¥è·å–æ‚¨çš„é¡¹ç›®IDã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "019e546007a3"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # <---CHANGE THIS TO YOUR PROJECT\n",
    "\n",
    "import os\n",
    "\n",
    "# Get your Google Cloud project ID using google.auth\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    import google.auth\n",
    "\n",
    "    _, PROJECT_ID = google.auth.default()\n",
    "    print(\"Project ID: \", PROJECT_ID)\n",
    "\n",
    "# validate PROJECT_ID\n",
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    print(\n",
    "        f\"Please set your project id before proceeding to next step. Currently it's set as {PROJECT_ID}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c9906f72b18"
   },
   "source": [
    "æ—¶é—´æˆ³\n",
    "\n",
    "å¦‚æœæ‚¨æ­£åœ¨å‚åŠ ç›´æ’­æ•™ç¨‹ï¼Œæ‚¨å¯èƒ½ä¼šä½¿ç”¨å…±äº«æµ‹è¯•å¸æˆ·æˆ–é¡¹ç›®ã€‚ä¸ºäº†é¿å…ç”¨æˆ·åœ¨åˆ›å»ºçš„èµ„æºä¹‹é—´å‘ç”Ÿåç§°å†²çªï¼Œæ‚¨å¯ä»¥ä¸ºæ¯ä¸ªå®ä¾‹ä¼šè¯åˆ›å»ºä¸€ä¸ªæ—¶é—´æˆ³ï¼Œå¹¶å°†å…¶é™„åŠ åˆ°æ‚¨åœ¨æ­¤æ•™ç¨‹ä¸­åˆ›å»ºçš„èµ„æºåç§°ä¸Šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e90182316f63"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_timestamp():\n",
    "    return datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "\n",
    "TIMESTAMP = get_timestamp()\n",
    "print(f\"TIMESTAMP = {TIMESTAMP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d96aec55eba"
   },
   "source": [
    "### éªŒè¯æ‚¨çš„Google Cloudè´¦æˆ·\n",
    "\n",
    "---\n",
    "\n",
    "**å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨Google Cloudç¬”è®°æœ¬**ï¼Œæ‚¨çš„ç¯å¢ƒå·²ç»é€šè¿‡éªŒè¯ã€‚è¯·è·³è¿‡æ­¤æ­¥éª¤ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82f63fb3401f"
   },
   "source": [
    "å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨Colabï¼Œè¯·è¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼å¹¶æŒ‰ç…§æç¤ºè¿›è¡Œèº«ä»½éªŒè¯ä»¥é€šè¿‡oAuthè¿›è¡Œèº«ä»½éªŒè¯ã€‚\n",
    "\n",
    "å¦åˆ™ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š\n",
    "\n",
    "1. åœ¨Cloudæ§åˆ¶å°ä¸­ï¼Œè½¬åˆ°[åˆ›å»ºæœåŠ¡å¸å·å¯†é’¥é¡µé¢](https://console.cloud.google.com/apis/credentials/serviceaccountkey)ã€‚\n",
    "2. ç‚¹å‡»**åˆ›å»ºæœåŠ¡å¸å·**ã€‚\n",
    "3. åœ¨**æœåŠ¡å¸å·åç§°**å­—æ®µä¸­è¾“å…¥åç§°ï¼Œç„¶åç‚¹å‡»**åˆ›å»º**ã€‚\n",
    "4. åœ¨**æˆäºˆæ­¤æœåŠ¡å¸å·å¯¹é¡¹ç›®çš„è®¿é—®æƒé™**éƒ¨åˆ†ï¼Œç‚¹å‡»**è§’è‰²**ä¸‹æ‹‰åˆ—è¡¨ã€‚åœ¨è¿‡æ»¤æ¡†ä¸­è¾“å…¥â€œVertex AIâ€ï¼Œå¹¶é€‰æ‹©**Vertex AIç®¡ç†å‘˜**ã€‚åœ¨è¿‡æ»¤æ¡†ä¸­è¾“å…¥â€œå­˜å‚¨å¯¹è±¡ç®¡ç†å‘˜â€ï¼Œç„¶åé€‰æ‹©**å­˜å‚¨å¯¹è±¡ç®¡ç†å‘˜**ã€‚\n",
    "5. ç‚¹å‡»*åˆ›å»º*ã€‚åŒ…å«æ‚¨çš„å¯†é’¥çš„JSONæ–‡ä»¶å°†ä¸‹è½½åˆ°æœ¬åœ°ç¯å¢ƒä¸­ã€‚\n",
    "6. åœ¨ä¸‹é¢çš„å•å…ƒæ ¼ä¸­è¾“å…¥æ‚¨æœåŠ¡å¸å·å¯†é’¥çš„è·¯å¾„ä½œä¸º`GOOGLE_APPLICATION_CREDENTIALS`å˜é‡ï¼Œå¹¶è¿è¡Œè¯¥å•å…ƒæ ¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "535223fa4b84"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "# The Google Cloud Notebook product has specific requirements\n",
    "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
    "\n",
    "# If on Google Cloud Notebooks, then don't execute this code\n",
    "if not IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35094e21d888"
   },
   "source": [
    "### åˆ›å»ºä¸€ä¸ªäº‘å­˜å‚¨æ¡¶\n",
    "\n",
    "**æ— è®ºæ‚¨ä½¿ç”¨å“ªç§ç¬”è®°æœ¬ç¯å¢ƒï¼Œä»¥ä¸‹æ­¥éª¤éƒ½æ˜¯å¿…éœ€çš„ã€‚**\n",
    "\n",
    "ä½¿ç”¨ Cloud SDK æäº¤è®­ç»ƒä½œä¸šæ—¶ï¼Œæ‚¨éœ€è¦å°†åŒ…å«è®­ç»ƒä»£ç çš„ Python åŒ…ä¸Šä¼ åˆ°ä¸€ä¸ªäº‘å­˜å‚¨æ¡¶ä¸­ã€‚Vertex AI å°†ä»è¯¥åŒ…ä¸­è¿è¡Œä»£ç ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼ŒVertex AI è¿˜å°†åœ¨åŒä¸€ä¸ªå­˜å‚¨æ¡¶ä¸­ä¿å­˜è®­ç»ƒä½œä¸šäº§ç”Ÿçš„è®­ç»ƒæ¨¡å‹ã€‚ä½¿ç”¨è¿™ä¸ªæ¨¡å‹å·¥ä»¶ï¼Œæ‚¨å¯ä»¥åˆ›å»º Vertex AI æ¨¡å‹å’Œç«¯ç‚¹èµ„æºï¼Œä»¥ä¾¿æä¾›åœ¨çº¿é¢„æµ‹ã€‚\n",
    "\n",
    "è¯·åœ¨ä¸‹é¢è®¾ç½®æ‚¨çš„äº‘å­˜å‚¨æ¡¶åç§°ã€‚å®ƒå¿…é¡»åœ¨æ‰€æœ‰çš„äº‘å­˜å‚¨æ¡¶ä¸­æ˜¯å”¯ä¸€çš„ã€‚\n",
    "\n",
    "æ‚¨ä¹Ÿå¯ä»¥æ›´æ”¹ `REGION` å˜é‡ï¼Œå®ƒå°†åœ¨æœ¬ç¬”è®°æœ¬çš„å…¶ä½™æ“ä½œä¸­ä½¿ç”¨ã€‚ç¡®ä¿é€‰æ‹©ä¸€ä¸ª Vertex AI æœåŠ¡å¯ç”¨çš„åŒºåŸŸã€‚æ‚¨ä¸èƒ½ä½¿ç”¨å¤šåŒºåŸŸå­˜å‚¨æ¡¶è¿›è¡Œ Vertex AI è®­ç»ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e07102312039"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"gs://[your-bucket-name]\"  # <---CHANGE THIS TO YOUR BUCKET\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13b11a8299d6"
   },
   "outputs": [],
   "source": [
    "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_NAME = f\"gs://{PROJECT_ID}aip-{get_timestamp()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4908f26b84be"
   },
   "outputs": [],
   "source": [
    "print(f\"PROJECT_ID = {PROJECT_ID}\")\n",
    "print(f\"BUCKET_NAME = {BUCKET_NAME}\")\n",
    "print(f\"REGION = {REGION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a3aae29644f"
   },
   "source": [
    "åªæœ‰å½“æ‚¨çš„å­˜å‚¨æ¡¶å°šä¸å­˜åœ¨æ—¶: è¿è¡Œä»¥ä¸‹å•å…ƒæ ¼æ¥åˆ›å»ºæ‚¨çš„äº‘å­˜å‚¨å­˜å‚¨æ¡¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25f9882bab87"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2586e4ed72ad"
   },
   "source": [
    "æœ€åï¼Œé€šè¿‡æ£€æŸ¥äº‘å­˜å‚¨æ¡¶çš„å†…å®¹æ¥éªŒè¯è®¿é—®æƒé™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "315724257beb"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "276e063f41eb"
   },
   "source": [
    "### å¯¼å…¥åº“å¹¶å®šä¹‰å¸¸é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e894d41223e3"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import google.auth\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import gapic as aip\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "from google.protobuf.json_format import MessageToDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8330d87de404"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f656723ac8ed"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import ClassLabel, Sequence, load_dataset\n",
    "from transformers import (AutoModelForSequenceClassification, AutoTokenizer,\n",
    "                          EvalPrediction, Trainer, TrainingArguments,\n",
    "                          default_data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "29b773f66d1b"
   },
   "outputs": [],
   "source": [
    "print(f\"Notebook runtime: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"PyTorch version : {torch.__version__}\")\n",
    "print(f\"Transformers version : {datasets.__version__}\")\n",
    "print(f\"Datasets version : {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9805f4ffaa4d"
   },
   "outputs": [],
   "source": [
    "APP_NAME = \"finetuned-bert-classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4c7643572342"
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3d8c26c6c98"
   },
   "source": [
    "# è®­ç»ƒ\n",
    "\n",
    "åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†é€šè¿‡å¾®è°ƒ[Hugging Face Transformers](https://github.com/huggingface/transformers)çš„é¢„è®­ç»ƒæ¨¡å‹æ¥è®­ç»ƒä¸€ä¸ªPyTorchæ¨¡å‹ã€‚æˆ‘ä»¬é¦–å…ˆä¼šåœ¨æœ¬åœ°è®­ç»ƒæ¨¡å‹ï¼Œç„¶ååœ¨[Vertex AIè®­ç»ƒæœåŠ¡](https://cloud.google.com/vertex-ai/docs/training/custom-training)ä¸Šè¿›è¡Œè®­ç»ƒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ba110a456ac"
   },
   "source": [
    "åœ¨ç¬”è®°æœ¬ä¸Šè¿›è¡Œæœ¬åœ°åŸ¹è®­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPRbBNbIrIl"
   },
   "source": [
    "åŠ è½½æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7QYTpxXIrIl"
   },
   "source": [
    "å¯¹äºè¿™ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[Hugging Face Datasets](https://huggingface.co/datasets/)ä¸­çš„[IMDBç”µå½±è¯„è®ºæ•°æ®é›†](https://huggingface.co/datasets/imdb)æ¥è¿›è¡Œæƒ…æ„Ÿåˆ†ç±»ä»»åŠ¡ã€‚æˆ‘ä»¬ä½¿ç”¨[Hugging Face Datasets](https://github.com/huggingface/datasets)åº“æ¥ä¸‹è½½æ•°æ®ã€‚å¯ä»¥é€šè¿‡`load_dataset`å‡½æ•°å¾ˆå®¹æ˜“åœ°å®Œæˆè¿™ä¸ªä»»åŠ¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IreSlFmlIrIm"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzfPtOMoIrIu"
   },
   "source": [
    "`dataset`å¯¹è±¡æœ¬èº«æ˜¯[`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict)ï¼Œå…¶ä¸­åŒ…å«äº†è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†çš„ä¸€ä¸ªé”®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWiVUF0jIrIv"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Total # of rows in training dataset {} and size {:5.2f} MB\".format(\n",
    "        dataset[\"train\"].shape[0], dataset[\"train\"].size_in_bytes / (1024 * 1024)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Total # of rows in test dataset {} and size {:5.2f} MB\".format(\n",
    "        dataset[\"test\"].shape[0], dataset[\"test\"].size_in_bytes / (1024 * 1024)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3EtYfeHIrIz"
   },
   "source": [
    "è¦è®¿é—®ä¸€ä¸ªå®é™…å…ƒç´ ï¼Œæ‚¨éœ€è¦é¦–å…ˆé€‰æ‹©ä¸€ä¸ªæ‹†åˆ†ï¼Œç„¶åç»™å‡ºä¸€ä¸ªç´¢å¼•ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6HrpprwIrIz"
   },
   "outputs": [],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQPMGfEFLhFd"
   },
   "source": [
    "ä½¿ç”¨`unique`æ–¹æ³•æå–æ ‡ç­¾åˆ—è¡¨ã€‚è¿™å°†ä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨ä¸è¿›è¡Œç¡¬ç¼–ç æ ‡ç­¾çš„æƒ…å†µä¸‹å°è¯•å…¶ä»–æ•°æ®é›†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYw3eIHfLhFd"
   },
   "outputs": [],
   "source": [
    "label_list = dataset[\"train\"].unique(\"label\")\n",
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHUmphG3IrI3"
   },
   "source": [
    "ä¸ºäº†äº†è§£æ•°æ®çš„æ ·è²Œï¼Œä»¥ä¸‹å‡½æ•°å°†åœ¨æ•°æ®é›†ä¸­éšæœºé€‰æ‹©ä¸€äº›ç¤ºä¾‹ï¼ˆè‡ªåŠ¨è§£ç æ ‡ç­¾ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3j8APAoIrI3"
   },
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=2):\n",
    "    assert num_examples <= len(\n",
    "        dataset\n",
    "    ), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset) - 1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset) - 1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(\n",
    "                lambda x: [typ.feature.names[i] for i in x]\n",
    "            )\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZy5tRB_IrI7"
   },
   "outputs": [],
   "source": [
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "### æ•°æ®é¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVx71GdAIrJH"
   },
   "source": [
    "åœ¨æˆ‘ä»¬å¯ä»¥å°†è¿™äº›æ–‡æœ¬é¦ˆé€ç»™æˆ‘ä»¬çš„æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹å®ƒä»¬è¿›è¡Œé¢„å¤„ç†ã€‚è¿™æ˜¯é€šè¿‡ä¸€ä¸ªé¢„è®­ç»ƒçš„Hugging Face Transformers [`Tokenizer`ç±»](https://huggingface.co/transformers/main_classes/tokenizer.html)æ¥å®Œæˆçš„ï¼Œè¯¥ç±»ä¼šå¯¹è¾“å…¥è¿›è¡Œtokenizeï¼ˆåŒ…æ‹¬å°†tokenè½¬æ¢ä¸ºé¢„è®­ç»ƒè¯æ±‡ä¸­çš„ç›¸åº”IDï¼‰ï¼Œç„¶åå°†å…¶æ”¾å…¥æ¨¡å‹æœŸæœ›çš„æ ¼å¼ï¼ŒåŒæ—¶ç”Ÿæˆæ¨¡å‹éœ€è¦çš„å…¶ä»–è¾“å…¥ã€‚\n",
    "\n",
    "ä¸ºäº†åšåˆ°è¿™ä¸€åˆ‡ï¼Œæˆ‘ä»¬ä½¿ç”¨`AutoTokenizer.from_pretrained`æ–¹æ³•å®ä¾‹åŒ–æˆ‘ä»¬çš„tokenizerï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿ï¼š\n",
    "\n",
    "- æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªä¸æˆ‘ä»¬æƒ³è¦ä½¿ç”¨çš„æ¨¡å‹æ¶æ„ç›¸å¯¹åº”çš„tokenizerï¼Œ\n",
    "- æˆ‘ä»¬ä¸‹è½½ç”¨äºé¢„è®­ç»ƒç‰¹å®šæ£€æŸ¥ç‚¹æ—¶ä½¿ç”¨çš„è¯æ±‡è¡¨ã€‚\n",
    "\n",
    "è¯¥è¯æ±‡è¡¨å°†è¢«ç¼“å­˜ï¼Œå› æ­¤ä¸‹æ¬¡è¿è¡Œå•å…ƒæ ¼æ—¶ä¸ä¼šé‡æ–°ä¸‹è½½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "178b1743fd36"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "max_seq_length = 128\n",
    "model_name_or_path = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXNLu_-nIrJI"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    use_fast=True,\n",
    ")\n",
    "# 'use_fast' ensure that we use fast tokenizers (backed by Rust) from the ğŸ¤— Tokenizers library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muc7yghlLhFf"
   },
   "source": [
    "æ‚¨å¯ä»¥é€šè¿‡å¿«é€Ÿåˆ†è¯å™¨åœ¨[æ¨¡å‹å¤§è¡¨æ ¼](https://huggingface.co/transformers/index.html#bigtable)ä¸Šæ£€æŸ¥å¯ç”¨æ¨¡å‹çš„ç±»å‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rowT4iCLIrJK"
   },
   "source": [
    "ä½ å¯ä»¥ç›´æ¥åœ¨ä¸€ä¸ªå¥å­ä¸Šè°ƒç”¨è¿™ä¸ªåˆ†è¯å™¨ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5hBlsrHIrJL"
   },
   "outputs": [],
   "source": [
    "tokenizer(\"Hello, this is one sentence!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeT4rxOGLhFf"
   },
   "source": [
    "æ ¹æ®æ‚¨é€‰æ‹©çš„æ¨¡å‹ï¼Œæ‚¨å°†åœ¨ä¸Šé¢å•å…ƒæ ¼è¿”å›çš„å­—å…¸ä¸­çœ‹åˆ°ä¸åŒçš„é”®ã€‚å¯¹äºæˆ‘ä»¬åœ¨è¿™é‡Œè¦åšçš„äº‹æƒ…æ¥è¯´å¹¶ä¸é‡è¦ï¼ˆåªéœ€çŸ¥é“å®ƒä»¬æ˜¯åé¢æˆ‘ä»¬è¦å®ä¾‹åŒ–çš„æ¨¡å‹æ‰€éœ€çš„ï¼‰ï¼Œå¦‚æœæ‚¨æ„Ÿå…´è¶£ï¼Œå¯ä»¥åœ¨[æ­¤æ•™ç¨‹](https://huggingface.co/transformers/preprocessing.html)ä¸­äº†è§£æ›´å¤šä¿¡æ¯ã€‚\n",
    "\n",
    "**æ³¨æ„ï¼š** å¦‚æœåƒè¿™é‡Œä¸€æ ·ï¼Œæ‚¨çš„è¾“å…¥å·²ç»è¢«åˆ†æˆå•è¯ï¼Œæ‚¨åº”è¯¥ä½¿ç”¨å‚æ•°`is_split_into_words=True`å°†å•è¯åˆ—è¡¨ä¼ é€’ç»™æ‚¨çš„æ ‡è®°å™¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPunumj-LhFg"
   },
   "outputs": [],
   "source": [
    "example = dataset[\"train\"][4]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3-m0sGHLhFg"
   },
   "outputs": [],
   "source": [
    "tokenizer(\n",
    "    [\"Hello\", \",\", \"this\", \"is\", \"one\", \"sentence\", \"split\", \"into\", \"words\", \".\"],\n",
    "    is_split_into_words=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G73hFICnLhFg"
   },
   "source": [
    "è¯·æ³¨æ„ï¼Œtransformersé€šå¸¸ä½¿ç”¨å­è¯åˆ†è¯å™¨è¿›è¡Œé¢„è®­ç»ƒï¼Œè¿™æ„å‘³ç€å³ä½¿æ‚¨çš„è¾“å…¥å·²è¢«åˆ†å‰²ä¸ºå•è¯ï¼Œè¿™äº›å•è¯ä¸­çš„æ¯ä¸€ä¸ªä¹Ÿå¯èƒ½è¢«åˆ†å‰²ä¸ºæ›´å°çš„å­è¯ã€‚è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªä¾‹å­ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8c6f3c11353"
   },
   "outputs": [],
   "source": [
    "# Dataset loading repeated here to make this cell idempotent\n",
    "# Since we are over-writing datasets variable\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Mapping labels to ids\n",
    "# NOTE: We can extract this automatically but the `Unique` method of the datasets\n",
    "# is not reporting the label -1 which shows up in the pre-processing.\n",
    "# Hence the additional -1 term in the dictionary\n",
    "label_to_id = {1: 1, 0: 0, -1: 0}\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"\n",
    "    Tokenize the input example texts\n",
    "    NOTE: The same preprocessing step(s) will be applied\n",
    "    at the time of inference as well.\n",
    "    \"\"\"\n",
    "    args = (examples[\"text\"],)\n",
    "    result = tokenizer(\n",
    "        *args, padding=\"max_length\", max_length=max_seq_length, truncation=True\n",
    "    )\n",
    "\n",
    "    # Map labels to IDs (not necessary for GLUE tasks)\n",
    "    if label_to_id is not None and \"label\" in examples:\n",
    "        result[\"label\"] = [label_to_id[example] for example in examples[\"label\"]]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# apply preprocessing function to input examples\n",
    "dataset = dataset.map(preprocess_function, batched=True, load_from_cache_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "å¾®è°ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBiW8UpKIrJW"
   },
   "source": [
    "ç°åœ¨æˆ‘ä»¬çš„æ•°æ®å‡†å¤‡å¥½äº†ï¼Œæˆ‘ä»¬å¯ä»¥ä¸‹è½½é¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹å¹¶å¯¹å…¶è¿›è¡Œå¾®è°ƒã€‚\n",
    "\n",
    "å¾®è°ƒæ¶‰åŠé‡‡ç”¨å·²ç»ä¸ºç‰¹å®šä»»åŠ¡è®­ç»ƒè¿‡çš„æ¨¡å‹ï¼Œç„¶åè°ƒæ•´è¯¥æ¨¡å‹ä»¥ç”¨äºå¦ä¸€ä¸ªç±»ä¼¼ä»»åŠ¡ã€‚å…·ä½“è€Œè¨€ï¼Œè°ƒæ•´æ¶‰åŠå¤åˆ¶é¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹ä¸­çš„æ‰€æœ‰å±‚ï¼ŒåŒ…æ‹¬æƒé‡å’Œå‚æ•°ï¼Œä½†ä¸åŒ…æ‹¬è¾“å‡ºå±‚ã€‚ç„¶åæ·»åŠ ä¸€ä¸ªæ–°çš„è¾“å‡ºåˆ†ç±»å™¨å±‚ï¼Œç”¨äºé¢„æµ‹å½“å‰ä»»åŠ¡çš„æ ‡ç­¾ã€‚æœ€åä¸€æ­¥æ˜¯ä»å¤´å¼€å§‹è®­ç»ƒè¾“å‡ºå±‚ï¼Œè€Œé¢„å…ˆè®­ç»ƒæ¨¡å‹çš„æ‰€æœ‰å±‚å‚æ•°éƒ½è¢«å†»ç»“ã€‚è¿™æ ·å¯ä»¥å­¦ä¹ æ¥è‡ªé¢„å…ˆè®­ç»ƒè¡¨ç¤ºçš„å†…å®¹ï¼Œå¹¶å¯¹æ›´é€‚åˆå…·ä½“ä»»åŠ¡çš„æ›´é«˜çº§ç‰¹å¾è¡¨ç¤ºè¿›è¡Œâ€œå¾®è°ƒâ€ï¼Œä¾‹å¦‚åœ¨è¿™ç§æƒ…å†µä¸‹åˆ†ææƒ…æ„Ÿã€‚\n",
    "\n",
    "å¯¹äºç¬”è®°æœ¬ä¸­åˆ†ææƒ…æ„Ÿçš„æƒ…æ™¯ï¼Œé¢„å…ˆè®­ç»ƒçš„BERTæ¨¡å‹å·²ç»å¯¹è¯­è¨€çš„è®¸å¤šä¿¡æ¯è¿›è¡Œäº†ç¼–ç ï¼Œå› ä¸ºè¯¥æ¨¡å‹æ˜¯ä»¥è‡ªç›‘ç£æ–¹å¼åœ¨å¤§å‹è‹±è¯­æ•°æ®è¯­æ–™åº“ä¸Šè¿›è¡Œè®­ç»ƒçš„ã€‚ç°åœ¨æˆ‘ä»¬åªéœ€è¦ç¨å¾®è°ƒæ•´å®ƒä»¬ï¼Œä½¿ç”¨å®ƒä»¬çš„è¾“å‡ºä½œä¸ºæƒ…æ„Ÿåˆ†ç±»ä»»åŠ¡çš„ç‰¹å¾ã€‚è¿™æ„å‘³ç€åœ¨ä¸€ä¸ªæ›´å°çš„æ•°æ®é›†ä¸Šè¿›è¡Œæ›´å¿«çš„å¼€å‘è¿­ä»£ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ›´å¤§çš„è®­ç»ƒæ•°æ®é›†è®­ç»ƒç‰¹å®šçš„è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d032e91d6c3"
   },
   "source": [
    "ç”±äºæˆ‘ä»¬æ‰€æœ‰çš„ä»»åŠ¡éƒ½æ¶‰åŠä»¤ç‰Œåˆ†ç±»ï¼Œæˆ‘ä»¬ä½¿ç”¨`AutoModelForSequenceClassification`ç±»ã€‚ä¸åˆ†è¯å™¨ä¸€æ ·ï¼Œ`from_pretrained`æ–¹æ³•å°†ä¸ºæˆ‘ä»¬ä¸‹è½½å¹¶ç¼“å­˜æ¨¡å‹ã€‚æˆ‘ä»¬å”¯ä¸€éœ€è¦æŒ‡å®šçš„æ˜¯æˆ‘ä»¬é—®é¢˜çš„æ ‡ç­¾æ•°é‡ï¼ˆæˆ‘ä»¬å¯ä»¥ä»ä¹‹å‰çœ‹åˆ°çš„ç‰¹å¾ä¸­è·å–ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TlqNaB8jIrJW"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name_or_path, num_labels=len(label_list)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CczA5lJlIrJX"
   },
   "source": [
    "**æ³¨æ„ï¼š**è­¦å‘Šå‘Šè¯‰æˆ‘ä»¬æ­£åœ¨ä¸¢å¼ƒä¸€äº›æƒé‡ï¼ˆ`vocab_transform`å’Œ`vocab_layer_norm`å±‚ï¼‰ï¼ŒåŒæ—¶éšæœºåˆå§‹åŒ–å¦ä¸€äº›æƒé‡ï¼ˆ`pre_classifier`å’Œ`classifier`å±‚ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿™æ˜¯ç»å¯¹æ­£å¸¸çš„ï¼Œå› ä¸ºæˆ‘ä»¬æ­£åœ¨ç§»é™¤ç”¨äºåœ¨æ©æ¨¡è¯­è¨€å»ºæ¨¡ç›®æ ‡ä¸Šé¢„è®­ç»ƒæ¨¡å‹çš„å¤´éƒ¨ï¼Œå¹¶ç”¨ä¸€ä¸ªæˆ‘ä»¬æ²¡æœ‰é¢„è®­ç»ƒæƒé‡çš„æ–°å¤´éƒ¨æ›¿æ¢å®ƒï¼Œå› æ­¤åº“è­¦å‘Šæˆ‘ä»¬åœ¨ä½¿ç”¨æ­¤æ¨¡å‹è¿›è¡Œæ¨ç†ä¹‹å‰åº”è¯¥å¾®è°ƒæ­¤æ¨¡å‹ï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬è¦åšçš„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_N8urzhyIrJY"
   },
   "source": [
    "è¦å®ä¾‹åŒ–ä¸€ä¸ª`Trainer`ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰å¦å¤–ä¸‰ä¸ªäº‹ç‰©ã€‚æœ€é‡è¦çš„æ˜¯[`TrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments)ï¼Œå®ƒæ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰å±æ€§ä»¥è‡ªå®šä¹‰è®­ç»ƒçš„ç±»ã€‚å®ƒéœ€è¦ä¸€ä¸ªæ–‡ä»¶å¤¹åç§°ï¼Œç”¨äºä¿å­˜æ¨¡å‹çš„æ£€æŸ¥ç‚¹ï¼Œå…¶ä»–æ‰€æœ‰å‚æ•°éƒ½æ˜¯å¯é€‰çš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bliy8zgjIrJY"
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    output_dir=\"/tmp/cls\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "km3pGVdTIrJc"
   },
   "source": [
    "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†è¯„ä¼°è®¾ç½®ä¸ºåœ¨æ¯ä¸ªæ—¶ä»£ç»“æŸæ—¶è¿›è¡Œï¼Œè°ƒæ•´å­¦ä¹ ç‡ï¼Œä½¿ç”¨ç¬”è®°æœ¬é¡¶éƒ¨å®šä¹‰çš„â€œbatch_sizeâ€å¹¶è‡ªå®šä¹‰è®­ç»ƒçš„æ—¶ä»£æ•°é‡ï¼Œä»¥åŠæƒé‡è¡°å‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqynGv2DLhFk"
   },
   "source": [
    "ä¸ºæˆ‘ä»¬çš„`Trainer`å®šä¹‰çš„æœ€åä¸€ä»¶äº‹æ˜¯å¦‚ä½•ä»é¢„æµ‹ä¸­è®¡ç®—æŒ‡æ ‡ã€‚æ‚¨å¯ä»¥å®šä¹‰è‡ªå®šä¹‰çš„compute_metricså‡½æ•°ã€‚å®ƒæ¥å—ä¸€ä¸ª`EvalPrediction`å¯¹è±¡ï¼ˆå…·æœ‰predictionså’Œlabel_idså­—æ®µçš„namedtupleï¼‰ï¼Œå¹¶ä¸”å¿…é¡»è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²åˆ°æµ®ç‚¹æ•°çš„å­—å…¸ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V233MNZgLhFk"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aehFUe14LhFl"
   },
   "source": [
    "ç°åœ¨æˆ‘ä»¬åˆ›å»ºâ€œTrainerâ€å¯¹è±¡ï¼Œå‡ ä¹å¯ä»¥å‡†å¤‡å¥½å¼€å§‹è®­ç»ƒäº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imY1oC3SIrJf"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=default_data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b4255e2209f"
   },
   "source": [
    "æ‚¨å¯ä»¥å‘`trainer`å¯¹è±¡æ·»åŠ å›è°ƒå‡½æ•°ï¼Œä»¥è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯çš„è¡Œä¸ºï¼Œä¾‹å¦‚æå‰åœæ­¢ã€åœ¨è¯„ä¼°é˜¶æ®µç»“æŸæ—¶æŠ¥å‘ŠæŒ‡æ ‡æˆ–åšå‡ºä»»ä½•å†³ç­–ã€‚åœ¨æ­¤ç¬”è®°æœ¬çš„è¶…å‚æ•°è°ƒæ•´éƒ¨åˆ†ï¼Œæˆ‘ä»¬ä¸º`trainer`æ·»åŠ äº†ä¸€ä¸ªå›è°ƒå‡½æ•°ï¼Œä»¥è‡ªåŠ¨åŒ–è¶…å‚æ•°è°ƒæ•´è¿‡ç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdzABDVcIrJg"
   },
   "source": [
    "æˆ‘ä»¬ç°åœ¨å¯ä»¥é€šè¿‡è°ƒç”¨`train`æ–¹æ³•æ¥å¾®è°ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZHmdWPELhFl"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4d3fcb41541c"
   },
   "outputs": [],
   "source": [
    "saved_model_local_path = \"./models\"\n",
    "!mkdir ./models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aac64fb35302"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(saved_model_local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKASz-2vIrJi"
   },
   "source": [
    "`evaluate` æ–¹æ³•å…è®¸æ‚¨åœ¨è¯„ä¼°æ•°æ®é›†ä¸Šå†æ¬¡è¯„ä¼°æˆ–åœ¨å¦ä¸€ä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOUcBkX8IrJi"
   },
   "outputs": [],
   "source": [
    "history = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d890a62c57c6"
   },
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX97-EH5LhFm"
   },
   "source": [
    "è¦è·å¾—è®¡ç®—çš„å…¶ä»–åº¦é‡æŒ‡æ ‡ï¼Œå¦‚æ¯ä¸ªç±»åˆ«çš„ç²¾åº¦ã€å¬å›ç‡æˆ–F1åˆ†æ•°ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨`predict`æ–¹æ³•çš„ç»“æœä¸Šåº”ç”¨ä¸ä¹‹å‰ç›¸åŒçš„å‡½æ•°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cae4fdf26f2"
   },
   "source": [
    "### ä½¿ç”¨ç¤ºä¾‹æ ·æœ¬åœ¨æœ¬åœ°è¿è¡Œé¢„æµ‹\n",
    "\n",
    "ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨åº”ç”¨è®­ç»ƒæœŸé—´ä½¿ç”¨çš„é¢„å¤„ç†å‡½æ•°åï¼Œé¢„æµ‹è¾“å…¥æ–‡æœ¬çš„æƒ…æ„Ÿæ ‡ç­¾ã€‚æˆ‘ä»¬å°†åœ¨ç¬”è®°æœ¬ä¸­æœ¬åœ°è¿è¡Œé¢„æµ‹ï¼Œç„¶åå±•ç¤ºå¦‚ä½•ä½¿ç”¨[TorchServe](https://pytorch.org/serve/)åœ¨Vertex AI Predictionsä¸Šéƒ¨ç½²æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21ab30d5518c"
   },
   "outputs": [],
   "source": [
    "model_name_or_path = \"bert-base-cased\"\n",
    "label_text = {0: \"Negative\", 1: \"Positive\"}\n",
    "saved_model_path = saved_model_local_path\n",
    "\n",
    "\n",
    "def predict(input_text, saved_model_path):\n",
    "    # initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "    # preprocess and encode input text\n",
    "    tokenizer_args = (input_text,)\n",
    "    predict_input = tokenizer(\n",
    "        *tokenizer_args,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    # load trained model\n",
    "    loaded_model = AutoModelForSequenceClassification.from_pretrained(saved_model_path)\n",
    "\n",
    "    # get predictions\n",
    "    output = loaded_model(predict_input[\"input_ids\"])\n",
    "\n",
    "    # return labels\n",
    "    label_id = torch.argmax(*output.to_tuple(), dim=1)\n",
    "\n",
    "    print(f\"Review text: {input_text}\")\n",
    "    print(f\"Sentiment : {label_text[label_id.item()]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e594d72fa8e4"
   },
   "outputs": [],
   "source": [
    "# example #1\n",
    "review_text = (\n",
    "    \"\"\"Jaw dropping visual affects and action! One of the best I have seen to date.\"\"\"\n",
    ")\n",
    "predict_input = predict(review_text, saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dd393f0d38c1"
   },
   "outputs": [],
   "source": [
    "# example #2\n",
    "review_text = \"\"\"Take away the CGI and the A-list cast and you end up with film with less punch.\"\"\"\n",
    "predict_input = predict(review_text, saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46a8d95366ee"
   },
   "source": [
    "## åœ¨Vertex AIä¸Šçš„åŸ¹è®­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e97e8af2376c"
   },
   "source": [
    "æ‚¨å¯ä»¥åœ¨Notebookså®ä¾‹ä¸Šè¿›è¡Œæœ¬åœ°å®éªŒã€‚ä½†æ˜¯ï¼Œå¯¹äºæ›´å¤§çš„æ•°æ®é›†æˆ–æ¨¡å‹ï¼Œé€šå¸¸éœ€è¦å‚ç›´æ‰©å±•è®¡ç®—æˆ–æ°´å¹³åˆ†å¸ƒå¼è®­ç»ƒã€‚æ‰§è¡Œæ­¤ä»»åŠ¡çš„æœ€æœ‰æ•ˆæ–¹å¼æ˜¯åˆ©ç”¨[Vertex AIå®šåˆ¶è®­ç»ƒæœåŠ¡](https://cloud.google.com/vertex-ai/docs/training/custom-training)ï¼ŒåŸå› å¦‚ä¸‹ï¼š\n",
    "\n",
    "- **è‡ªåŠ¨æä¾›å’Œå»æ‰èµ„æº**ï¼šåœ¨Vertex AIä¸Šè¿›è¡Œè®­ç»ƒä½œä¸šå°†è‡ªåŠ¨æä¾›è®¡ç®—èµ„æºï¼Œæ‰§è¡Œè®­ç»ƒä»»åŠ¡ï¼Œå¹¶ç¡®ä¿ä¸€æ—¦è®­ç»ƒä½œä¸šå®Œæˆå°±åˆ é™¤è®¡ç®—èµ„æºã€‚\n",
    "- **å¯é‡ç”¨æ€§å’Œå¯ç§»æ¤æ€§**ï¼šæ‚¨å¯ä»¥å°†è®­ç»ƒä»£ç åŠå…¶å‚æ•°å’Œä¾èµ–é¡¹æ‰“åŒ…åˆ°ä¸€ä¸ªå®¹å™¨ä¸­ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªå¯ç§»æ¤çš„ç»„ä»¶ã€‚ç„¶åå¯ä»¥åœ¨ä¸åŒçš„åœºæ™¯ä¸‹è¿è¡Œæ­¤å®¹å™¨ï¼Œä¾‹å¦‚è¶…å‚æ•°è°ƒæ•´ã€ä¸åŒçš„æ•°æ®æºç­‰ã€‚\n",
    "- **è§„æ¨¡è®­ç»ƒ**ï¼šæ‚¨å¯ä»¥åœ¨AIä¸Šè¿è¡Œä¸€ä¸ª[åˆ†å¸ƒå¼è®­ç»ƒä½œä¸š](https://cloud.google.com/vertex-ai/docs/training/distributed-training)ï¼Œå…è®¸æ‚¨åœ¨é›†ç¾¤ä¸­è·¨å¤šä¸ªèŠ‚ç‚¹å¹¶è¡Œè®­ç»ƒæ¨¡å‹ï¼Œä»è€Œç¼©çŸ­è®­ç»ƒæ—¶é—´ã€‚\n",
    "- **æ—¥å¿—è®°å½•å’Œç›‘æ§**ï¼šè®­ç»ƒæœåŠ¡å°†ä½œä¸šçš„æ¶ˆæ¯è®°å½•åˆ°[Cloud Logging](https://cloud.google.com/logging/docs)ï¼Œå¯ä»¥åœ¨ä½œä¸šè¿è¡Œæ—¶è¿›è¡Œç›‘æ§ã€‚\n",
    "\n",
    "åœ¨è¿™éƒ¨åˆ†ç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºå¦‚ä½•é€šè¿‡æ‰“åŒ…ä»£ç å¹¶åˆ›å»ºè®­ç»ƒç®¡é“æ¥æ‰©å±•Vertex AIçš„è®­ç»ƒä½œä¸šã€‚ä½¿ç”¨[Vertex AIå®šåˆ¶è®­ç»ƒæœåŠ¡](https://cloud.google.com/vertex-ai/docs/training/custom-training)è¿è¡Œè®­ç»ƒä½œä¸šæœ‰ä¸‰ä¸ªæ­¥éª¤ï¼š\n",
    "\n",
    "- **æ­¥éª¤1**ï¼šç¡®å®šè®­ç»ƒä»£ç ç»“æ„ - æ‰“åŒ…ä¸ºPythonæºåˆ†å‘æˆ–è‡ªå®šä¹‰å®¹å™¨é•œåƒ\n",
    "- **æ­¥éª¤2**ï¼šé€‰æ‹©è‡ªå®šä¹‰è®­ç»ƒæ–¹æ³• - è‡ªå®šä¹‰ä½œä¸šã€è¶…å‚æ•°è®­ç»ƒä½œä¸šæˆ–è®­ç»ƒç®¡é“\n",
    "- **æ­¥éª¤3**ï¼šè¿è¡Œè®­ç»ƒä½œä¸š\n",
    "\n",
    "![custom-training-on-vertex-ai](./images/custom-training-on-vertex-ai.png)\n",
    "\n",
    "#### å®šåˆ¶è®­ç»ƒæ–¹æ³•\n",
    "\n",
    "æ‚¨å¯ä»¥åœ¨Vertex AIä¸Šåˆ›å»ºä¸‰ç§ç±»å‹çš„èµ„æºæ¥è®­ç»ƒè‡ªå®šä¹‰æ¨¡å‹ï¼š\n",
    "\n",
    "- **[è‡ªå®šä¹‰ä½œä¸š](https://cloud.google.com/vertex-ai/docs/training/create-custom-job)**ï¼šé€šè¿‡è‡ªå®šä¹‰ä½œä¸šï¼Œæ‚¨å¯ä»¥é…ç½®åœ¨Vertex AIä¸Šè¿è¡Œè®­ç»ƒä»£ç çš„è®¾ç½®ï¼Œå¦‚å·¥ä½œæ± è§„æ ¼ - æœºå™¨ç±»å‹ã€åŠ é€Ÿå™¨ã€Pythonè®­ç»ƒè§„æ ¼æˆ–è‡ªå®šä¹‰å®¹å™¨è§„æ ¼ã€‚\n",
    "- **[è¶…å‚æ•°è°ƒæ•´ä½œä¸š](https://cloud.google.com/vertex-ai/docs/training/using-hyperparameter-tuning)**ï¼šè¶…å‚æ•°è°ƒæ•´ä½œä¸šæ ¹æ®æ‚¨é…ç½®çš„æ ‡å‡†è‡ªåŠ¨è°ƒæ•´æ¨¡å‹çš„è¶…å‚æ•°ï¼Œä¾‹å¦‚ä¼˜åŒ–çš„ç›®æ ‡/æŒ‡æ ‡ã€è¶…å‚æ•°å€¼å’Œè¿è¡Œçš„è¯•éªŒæ¬¡æ•°ã€‚\n",
    "- **[è®­ç»ƒç®¡é“](https://cloud.google.com/vertex-ai/docs/training/create-training-pipeline)**ï¼šåœ¨æˆåŠŸå®Œæˆè®­ç»ƒä½œä¸šåï¼Œç¼–æ’è‡ªå®šä¹‰è®­ç»ƒä½œä¸šæˆ–è¶…å‚æ•°è°ƒæ•´ä½œä¸šçš„é™„åŠ æ­¥éª¤ã€‚\n",
    "\n",
    "è¯·å‚è€ƒ[æ–‡æ¡£](https://cloud.google.com/vertex-ai/docs/training/custom-training-methods)äº†è§£æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚\n",
    "\n",
    "åœ¨æœ¬ç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»è‡ªå®šä¹‰ä½œä¸šå’Œè¶…å‚æ•°è°ƒæ•´ä½œä¸šã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "585ba542aa40"
   },
   "source": [
    "### æ‰“åŒ…è®­ç»ƒåº”ç”¨ç¨‹åº\n",
    "\n",
    "åœ¨ Vertex AI ä¸Šè¿è¡Œè®­ç»ƒä½œä¸šä¹‹å‰ï¼Œè®­ç»ƒåº”ç”¨ç¨‹åºçš„ä»£ç å’Œä»»ä½•ä¾èµ–é¡¹å¿…é¡»è¢«æ‰“åŒ…å¹¶ä¸Šä¼ åˆ°æ‚¨çš„ Google Cloud é¡¹ç›®å¯ä»¥è®¿é—®çš„ Cloud Storage å­˜å‚¨æ¡¶ã€å®¹å™¨æ³¨å†Œè¡¨æˆ– Artifact Registry ä¸­ã€‚æœ¬èŠ‚å±•ç¤ºäº†å¦‚ä½•åœ¨äº‘ä¸­æ‰“åŒ…å’Œéƒ¨ç½²æ‚¨çš„åº”ç”¨ç¨‹åºã€‚\n",
    "\n",
    "æœ‰ä¸¤ç§æ–¹å¼å¯ä»¥æ‰“åŒ…æ‚¨çš„åº”ç”¨ç¨‹åºå’Œä¾èµ–é¡¹å¹¶åœ¨ Vertex AI ä¸Šè¿›è¡Œè®­ç»ƒï¼š\n",
    "\n",
    "1.ä½¿ç”¨[Pythonæºä»£ç åˆ†å‘](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container)ï¼Œå°†è®­ç»ƒä»£ç å’Œä¾èµ–é¡¹æ‰“åŒ…ï¼Œå¹¶ä¸ Vertex AI ä¸Šçš„[é¢„æ„å»ºå®¹å™¨](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers)ä¸€èµ·ä½¿ç”¨\n",
    "2.ä½¿ç”¨[Dockerå®¹å™¨](https://cloud.google.com/ai-platform/training/docs/custom-containers-training)æ‰“åŒ…ä¾èµ–é¡¹æ¥ä½¿ç”¨[è‡ªå®šä¹‰å®¹å™¨](https://cloud.google.com/ai-platform/training/docs/custom-containers-training)\n",
    "\n",
    "**æ­¤ç¬”è®°æœ¬å±•ç¤ºäº†åœ¨ Vertex AI ä¸Šè¿è¡Œè‡ªå®šä¹‰è®­ç»ƒä½œä¸šçš„ä¸¤ç§æ‰“åŒ…é€‰é¡¹ã€‚**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4b8b5333b577"
   },
   "source": [
    "#### æ¨èçš„åŸ¹è®­åº”ç”¨ç¨‹åºç»“æ„\n",
    "\n",
    "æ‚¨å¯ä»¥æ ¹æ®å–œå¥½æ„å»ºåŸ¹è®­åº”ç”¨ç¨‹åºçš„ç»“æ„ã€‚ç„¶è€Œï¼Œ[ä»¥ä¸‹ç»“æ„](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container#structure)åœ¨Vertex AIç¤ºä¾‹ä¸­å¸¸ç”¨ï¼Œä½¿æ‚¨çš„é¡¹ç›®ç»„ç»‡ç»“æ„ç±»ä¼¼äºç¤ºä¾‹å¯ä»¥æ›´è½»æ¾åœ°è·Ÿéšç¤ºä¾‹ã€‚\n",
    "\n",
    "æˆ‘ä»¬æœ‰ä¸¤ä¸ªç›®å½• `python_package` å’Œ `custom_container` æ˜¾ç¤ºäº†ä¸¤ç§æ‰“åŒ…æ–¹æ³•ã€‚æ¯ä¸ªç›®å½•ä¸­çš„ `README.md` æ–‡ä»¶ä¸­è¯¦ç»†è¯´æ˜äº†ç›®å½•ç»“æ„å’Œå¦‚ä½•åœ¨æœ¬åœ°å’Œäº‘ç«¯è¿è¡Œåº”ç”¨ç¨‹åºçš„æŒ‡å¯¼ã€‚\n",
    "\n",
    "```\n",
    ".\n",
    "â”œâ”€â”€ custom_container\n",
    "â”‚   â”œâ”€â”€ Dockerfile\n",
    "â”‚   â”œâ”€â”€ README.md\n",
    "â”‚   â”œâ”€â”€ scripts\n",
    "â”‚   â”‚   â””â”€â”€ train-cloud.sh\n",
    "â”‚   â””â”€â”€ trainer -> ../python_package/trainer/\n",
    "â”œâ”€â”€ python_package\n",
    "â”‚   â”œâ”€â”€ README.md\n",
    "â”‚   â”œâ”€â”€ scripts\n",
    "â”‚   â”‚   â””â”€â”€ train-cloud.sh\n",
    "â”‚   â”œâ”€â”€ setup.py\n",
    "â”‚   â””â”€â”€ trainer\n",
    "â”‚       â”œâ”€â”€ __init__.py\n",
    "â”‚       â”œâ”€â”€ experiment.py\n",
    "â”‚       â”œâ”€â”€ metadata.py\n",
    "â”‚       â”œâ”€â”€ model.py\n",
    "â”‚       â”œâ”€â”€ task.py\n",
    "â”‚       â””â”€â”€ utils.py\n",
    "â””â”€â”€ pytorch-text-classification-vertex-ai-train-tune-deploy.ipynb    --> è¿™ä¸ªç¬”è®°æœ¬\n",
    "```\n",
    "\n",
    "1. ä¸»é¡¹ç›®ç›®å½•åŒ…å«æ‚¨çš„`setup.py`æ–‡ä»¶æˆ–å¸¦æœ‰ä¾èµ–é¡¹çš„`Dockerfile`ã€‚\n",
    "2. ä½¿ç”¨åä¸º`trainer`çš„å­ç›®å½•æ¥å­˜å‚¨æ‚¨çš„ä¸»åº”ç”¨ç¨‹åºæ¨¡å—å’Œ`scripts`ç”¨äºæäº¤æœ¬åœ°æˆ–äº‘ç«¯çš„åŸ¹è®­ä½œä¸šã€‚\n",
    "3. åœ¨`trainer`ç›®å½•å†…ï¼š\n",
    "    - `task.py` - ä¸»åº”ç”¨ç¨‹åºæ¨¡å—ï¼Œåˆå§‹åŒ–å’Œè§£æä»»åŠ¡å‚æ•°(è¶…å‚æ•°)ï¼Œä»¥åŠè®­ç»ƒçš„å…¥å£ç‚¹ã€‚\n",
    "    - `model.py` - åŒ…æ‹¬ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹åˆ›å»ºå¸¦æœ‰åºåˆ—åˆ†ç±»å¤´çš„æ¨¡å‹çš„å‡½æ•°ã€‚\n",
    "    - `experiment.py` - è¿è¡Œæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å®éªŒï¼Œå¹¶å¯¼å‡ºæœ€ç»ˆæ¨¡å‹ã€‚\n",
    "    - `metadata.py` - å®šä¹‰ç”¨äºåˆ†ç±»ä»»åŠ¡çš„å…ƒæ•°æ®ï¼Œå¦‚é¢„å®šä¹‰æ¨¡å‹æ•°æ®é›†åç§°ã€ç›®æ ‡æ ‡ç­¾ã€‚\n",
    "    - `utils.py` - åŒ…æ‹¬è¯¸å¦‚è¯»å–æ•°æ®çš„æ•°æ®è¾“å…¥å‡½æ•°ã€å°†æ¨¡å‹ä¿å­˜åˆ°GCSå­˜å‚¨æ¡¶ç­‰å®ç”¨å‡½æ•°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7466d414a0e"
   },
   "source": [
    "åœ¨Vertex AI Trainingä¸Šä½¿ç”¨é¢„æ„å»ºçš„å®¹å™¨è¿è¡Œè‡ªå®šä¹‰ä½œä¸š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1a675e6ee9dc"
   },
   "source": [
    "Vertex AIæä¾›Dockerå®¹å™¨æ˜ åƒï¼Œå¯ä»¥ä½œä¸º[é¢„æ„å»ºå®¹å™¨](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers#available_container_images)ç”¨äºè‡ªå®šä¹‰è®­ç»ƒã€‚è¿™äº›å®¹å™¨åŒ…æ‹¬åœ¨åŸºäºæœºå™¨å­¦ä¹ æ¡†æ¶å’Œæ¡†æ¶ç‰ˆæœ¬çš„è®­ç»ƒä»£ç ä¸­å¸¸ç”¨çš„ä¾èµ–é¡¹ã€‚\n",
    "\n",
    "åœ¨è¿™ä¸ªç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬æ­£åœ¨ä½¿ç”¨Hugging Face Datasetsï¼Œå¹¶ä½¿ç”¨PyTorchå¯¹Hugging Face Transformersåº“ä¸­çš„å˜æ¢å™¨æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œç”¨äºæƒ…æ„Ÿåˆ†æä»»åŠ¡ã€‚æˆ‘ä»¬å°†ä½¿ç”¨[PyTorchçš„é¢„æ„å»ºå®¹å™¨](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers#pytorch)ï¼Œå¹¶é€šè¿‡åœ¨`setup.py`æ–‡ä»¶ä¸­æ·»åŠ æ ‡å‡†Pythonä¾èµ–é¡¹`transformers`ã€`datasets`å’Œ`tqdm`æ¥æ‰“åŒ…è®­ç»ƒåº”ç”¨ç¨‹åºä»£ç ã€‚\n",
    "\n",
    "![åœ¨Vertex AIè®­ç»ƒä¸­ä½¿ç”¨é¢„æ„å»ºå®¹å™¨è¿›è¡Œè®­ç»ƒ](./images/training-with-prebuilt-containers-on-vertex-training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9481da82c2ca"
   },
   "source": [
    "å°†å˜é‡åˆå§‹åŒ–ä¸ºå®šä¹‰é¢„å…ˆæ„å»ºçš„å®¹å™¨æ˜ åƒã€è®­ç»ƒåº”ç”¨ç¨‹åºçš„ä½ç½®å’Œè®­ç»ƒæ¨¡å—ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "100eac26f547"
   },
   "outputs": [],
   "source": [
    "PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.1-7:latest\"\n",
    ")\n",
    "\n",
    "PYTHON_PACKAGE_APPLICATION_DIR = \"python_package\"\n",
    "\n",
    "source_package_file_name = f\"{PYTHON_PACKAGE_APPLICATION_DIR}/dist/trainer-0.1.tar.gz\"\n",
    "python_package_gcs_uri = (\n",
    "    f\"{BUCKET_NAME}/pytorch-on-gcp/{APP_NAME}/train/python_package/trainer-0.1.tar.gz\"\n",
    ")\n",
    "python_module_name = \"trainer.task\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bdb8c21d0d5"
   },
   "source": [
    "ä»¥ä¸‹æ˜¯ç”¨äºè®­ç»ƒåº”ç”¨ç¨‹åºçš„`setup.py`æ–‡ä»¶ã€‚`setup.py`ä¸­çš„`find_packages()`å‡½æ•°åŒ…æ‹¬`trainer`ç›®å½•åœ¨åŒ…ä¸­ï¼Œå› ä¸ºå®ƒåŒ…å«äº†`__init__.py`ï¼Œå‘Šè¯‰[Python Setuptools](https://setuptools.readthedocs.io/en/latest/)å°†çˆ¶ç›®å½•çš„æ‰€æœ‰å­ç›®å½•åŒ…å«ä¸ºä¾èµ–é¡¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9dcb9b353ff3"
   },
   "outputs": [],
   "source": [
    "%%writefile ./{PYTHON_PACKAGE_APPLICATION_DIR}/setup.py\n",
    "\n",
    "from setuptools import find_packages\n",
    "from setuptools import setup\n",
    "import setuptools\n",
    "\n",
    "from distutils.command.build import build as _build\n",
    "import subprocess\n",
    "\n",
    "\n",
    "REQUIRED_PACKAGES = [\n",
    "    'transformers',\n",
    "    'datasets',\n",
    "    'tqdm',\n",
    "    'cloudml-hypertune'\n",
    "]\n",
    "\n",
    "setup(\n",
    "    name='trainer',\n",
    "    version='0.1',\n",
    "    install_requires=REQUIRED_PACKAGES,\n",
    "    packages=find_packages(),\n",
    "    include_package_data=True,\n",
    "    description='Vertex AI | Training | PyTorch | Text Classification | Python Package'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a90b5019436d"
   },
   "source": [
    "è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥åˆ›å»ºä¸€ä¸ªæºåˆ†å‘åŒ…ï¼Œdist/trainer-0.1.tar.gz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fe9d30e9806"
   },
   "outputs": [],
   "source": [
    "!cd {PYTHON_PACKAGE_APPLICATION_DIR} && python3 setup.py sdist --formats=gztar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b769681d231"
   },
   "source": [
    "ç°åœ¨å°†åŒ…å«è®­ç»ƒåº”ç”¨ç¨‹åºçš„æºåˆ†å‘ä¸Šä¼ åˆ°äº‘å­˜å‚¨æ¡¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3492f5366aa"
   },
   "outputs": [],
   "source": [
    "!gsutil cp {source_package_file_name} {python_package_gcs_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e4a3c5a11a1"
   },
   "source": [
    "éªŒè¯æºåˆ†å‘å­˜åœ¨äºäº‘å­˜å‚¨æ¡¶ä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "29fd8224d9cb"
   },
   "outputs": [],
   "source": [
    "!gsutil ls -l {python_package_gcs_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daf738249701"
   },
   "source": [
    "#### *[å¯é€‰]* **åœ¨æœ¬åœ°è¿è¡Œè‡ªå®šä¹‰è®­ç»ƒä»»åŠ¡**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dae35b9f526e"
   },
   "source": [
    "åœ¨å°†å·¥ä½œæäº¤åˆ°äº‘ç«¯ä¹‹å‰ï¼Œæ‚¨å¯ä»¥é€šè¿‡ç›´æ¥è°ƒç”¨`trainer.task`æ¨¡å—åœ¨æœ¬åœ°è¿è¡Œè®­ç»ƒä»»åŠ¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9defbf6fd074"
   },
   "outputs": [],
   "source": [
    "!cd {PYTHON_PACKAGE_APPLICATION_DIR} && python -m trainer.task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a1a4281ff7f"
   },
   "source": [
    "åœ¨Vertex AIä¸Šè¿è¡Œè‡ªå®šä¹‰è®­ç»ƒä½œä¸š\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨[Pythonçš„Vertex AI SDK](https://cloud.google.com/vertex-ai/docs/start/client-libraries#client_libraries)æ¥åˆ›å»ºå’Œæäº¤è®­ç»ƒä½œä¸šåˆ°Vertex AIè®­ç»ƒæœåŠ¡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d2957ef04fd"
   },
   "source": [
    "åˆå§‹åŒ–Pythonç‰ˆçš„Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4a578b55943"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b0fed34b728"
   },
   "source": [
    "é…ç½®å’Œæäº¤è‡ªå®šä¹‰ä½œä¸šåˆ°Vertex AIè®­ç»ƒæœåŠ¡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8f24d5bdc31d"
   },
   "source": [
    "ä½¿ç”¨[é¢„æ„å»ºå®¹å™¨](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers)é•œåƒå’Œå°è£…ä¸ºPythonæºä»£ç åˆ†å‘çš„PyTorchè®­ç»ƒä»£ç ï¼Œé…ç½®ä¸€ä¸ª[è‡ªå®šä¹‰ä½œä¸š](https://cloud.google.com/vertex-ai/docs/training/create-custom-job)ã€‚\n",
    "\n",
    "**æ³¨æ„ï¼š**åœ¨ä½¿ç”¨Vertex AI SDK for Pythonæäº¤è®­ç»ƒä½œä¸šæ—¶ï¼Œå®ƒä¼šåˆ›å»ºä¸€ä¸ª[è®­ç»ƒç®¡é“](https://cloud.google.com/vertex-ai/docs/training/create-training-pipeline)ï¼Œè¯¥ç®¡é“åœ¨Vertex AIè®­ç»ƒæœåŠ¡ä¸Šå¯åŠ¨è‡ªå®šä¹‰ä½œä¸šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daababed95ac"
   },
   "outputs": [],
   "source": [
    "print(f\"APP_NAME={APP_NAME}\")\n",
    "print(\n",
    "    f\"PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI={PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI}\"\n",
    ")\n",
    "print(f\"python_package_gcs_uri={python_package_gcs_uri}\")\n",
    "print(f\"python_module_name={python_module_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1f7cff892eb8"
   },
   "outputs": [],
   "source": [
    "JOB_NAME = f\"{APP_NAME}-pytorch-pkg-ar-{get_timestamp()}\"\n",
    "print(f\"JOB_NAME={JOB_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7f68fec44ed"
   },
   "outputs": [],
   "source": [
    "job = aiplatform.CustomPythonPackageTrainingJob(\n",
    "    display_name=f\"{JOB_NAME}\",\n",
    "    python_package_gcs_uri=python_package_gcs_uri,\n",
    "    python_module_name=python_module_name,\n",
    "    container_uri=PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aaeb607c356e"
   },
   "outputs": [],
   "source": [
    "training_args = [\"--num-epochs\", \"2\", \"--model-name\", \"finetuned-bert-classifier\"]\n",
    "\n",
    "model = job.run(\n",
    "    replica_count=1,\n",
    "    machine_type=\"n1-standard-8\",\n",
    "    accelerator_type=\"NVIDIA_TESLA_V100\",\n",
    "    accelerator_count=1,\n",
    "    args=training_args,\n",
    "    sync=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bff8906cce7b"
   },
   "source": [
    "**ç›‘æ§è‡ªå®šä¹‰å·¥ä½œè¿›åº¦**\n",
    "\n",
    "æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹é“¾æ¥[æ­¤å¤„](https://console.cloud.google.com/vertex-ai/training/training-pipelines/)ç›‘æ§ä»äº‘æ§åˆ¶å°å¯åŠ¨çš„è‡ªå®šä¹‰å·¥ä½œï¼Œæˆ–è€…ä½¿ç”¨gcloud CLIå‘½ä»¤[`gcloud beta ai custom-jobs stream-logs`](https://cloud.google.com/sdk/gcloud/reference/beta/ai/custom-jobs/stream-logs)\n",
    "\n",
    "![åœ¨Vertex AIåŸ¹è®­ä¸­ç›‘æ§è‡ªå®šä¹‰å·¥ä½œè¿›åº¦](./images/vertex-training-monitor-custom-job.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "760ab4b88042"
   },
   "source": [
    "åœ¨ä½œä¸šæˆåŠŸå®Œæˆåï¼Œé€šè¿‡è®­ç»ƒä»£ç éªŒè¯å†™å…¥GCSçš„æ¨¡å‹æ„ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39570bd8def9"
   },
   "outputs": [],
   "source": [
    "job_response = MessageToDict(job._gca_resource._pb)\n",
    "gcs_model_artifacts_uri = job_response[\"trainingTaskInputs\"][\"baseOutputDirectory\"][\n",
    "    \"outputUriPrefix\"\n",
    "]\n",
    "print(f\"Model artifacts are available at {gcs_model_artifacts_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09eaae731189"
   },
   "outputs": [],
   "source": [
    "!gsutil ls -lr $gcs_model_artifacts_uri/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "813e2b1e6185"
   },
   "source": [
    "### ä½¿ç”¨ gcloud CLI ä½¿ç”¨ Python æºä»£ç åˆ†å‘æäº¤è‡ªå®šä¹‰ä½œä¸š\n",
    "\n",
    "æ‚¨å¯ä»¥ä½¿ç”¨ [`gcloud beta ai custom-jobs create`](https://cloud.google.com/sdk/gcloud/reference/beta/ai/custom-jobs/create) å‘½ä»¤å°†è®­ç»ƒä½œä¸šæäº¤åˆ° Vertex AI è®­ç»ƒæœåŠ¡ã€‚`gcloud` å‘½ä»¤å°†æ‚¨çš„è®­ç»ƒåº”ç”¨ç¨‹åºæš‚å­˜åˆ° GCS å­˜å‚¨æ¡¶å¹¶æäº¤è®­ç»ƒä½œä¸šã€‚\n",
    "\n",
    "```\n",
    "gcloud beta ai custom-jobs create \\\n",
    "    --display-name=${JOB_NAME} \\\n",
    "    --region ${REGION} \\\n",
    "    --python-package-uris=${PACKAGE_PATH} \\\n",
    "    --worker-pool-spec=replica-count=1,machine-type='n1-standard-8',accelerator-type='NVIDIA_TESLA_V100',accelerator-count=1,executor-image-uri=${IMAGE_URI},python-module='trainer.task',local-package-path=\"../python_package/\" \\\n",
    "    --args=\"--model-name\",\"finetuned-bert-classifier\",\"--job-dir\",$JOB_DIR\n",
    "```\n",
    "\n",
    "- `worker-pool-spec` å‚æ•°å®šä¹‰äº†è‡ªå®šä¹‰ä½œä¸šä½¿ç”¨çš„å·¥ä½œæ± é…ç½®ã€‚ä»¥ä¸‹æ˜¯ `worker-pool-spec` ä¸­çš„å­—æ®µï¼š\n",
    "    - å°†`executor-image-uri`è®¾ç½®ä¸º`us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.1-7:latest`ä»¥ä¾¿åœ¨é¢„æ„å»ºçš„ PyTorch v1.7 GPU å›¾åƒä¸Šè¿›è¡Œè®­ç»ƒ\n",
    "    - å°† `local-package-path` è®¾ç½®ä¸ºè®­ç»ƒä»£ç çš„è·¯å¾„\n",
    "    - å°† `python-module` è®¾ç½®ä¸º `trainer.task`ï¼Œè¯¥æ¨¡å—æ˜¯å¯åŠ¨åº”ç”¨ç¨‹åºçš„ä¸»è¦æ¨¡å—\n",
    "    - è®¾ç½®`accelerator-type`å’Œ`machine-type`ä»¥è®¾ç½®è¿è¡Œåº”ç”¨ç¨‹åºçš„è®¡ç®—ç±»å‹\n",
    "\n",
    "æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[æ–‡æ¡£](https://cloud.google.com/sdk/gcloud/reference/beta/ai/custom-jobs/create#--args)ã€‚\n",
    "\n",
    "åœ¨ `./python_package/scripts/train-cloud.sh` ä¸­çš„è„šæœ¬åŒ…å«äº†å¯åŠ¨è‡ªå®šä¹‰ä½œä¸šå’Œç›‘è§†æ—¥å¿—çš„ `gcloud` å‘½ä»¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d974c52416b8"
   },
   "outputs": [],
   "source": [
    "!cd python_package && ./scripts/train-cloud.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edafdf2321d5"
   },
   "source": [
    "é™¤äº†Cloud Consoleä¹‹å¤–ï¼Œæ‚¨è¿˜å¯ä»¥é€šè¿‡ä¼ é€’ä½œä¸šIDä½¿ç”¨[gcloud CLI](https://cloud.google.com/sdk/gcloud/reference/beta/ai/custom-jobs/stream-logs)æ¥æµå¼ä¼ è¾“æ—¥å¿—ä»¥ç›‘æ§ä½œä¸šè¿›åº¦ï¼š\n",
    "\n",
    "```\n",
    "gcloud ai custom-jobs stream-logs <job_id> --region=$REGION\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06eb6c334000"
   },
   "source": [
    "æ‚¨å¯ä»¥é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯å†™å…¥GCSçš„æ¨¡å‹æ–‡ä»¶ï¼Œä»¥é€šè¿‡è®­ç»ƒä»£ç æ¥è¿è¡Œæ¨¡å‹ï¼š\n",
    "\n",
    "```\n",
    "!gsutil ls -l $JOB_DIR/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c170d386492b"
   },
   "source": [
    "åœ¨Vertex AIè®­ç»ƒä¸­ä½¿ç”¨è‡ªå®šä¹‰å®¹å™¨è¿è¡Œè‡ªå®šä¹‰ä½œä¸š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "035227b6e581"
   },
   "source": [
    "è¦åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰å®¹å™¨çš„åŸ¹è®­å·¥ä½œï¼Œæ‚¨éœ€è¦å®šä¹‰ä¸€ä¸ª `Dockerfile` æ¥å®‰è£…æˆ–æ·»åŠ è®­ç»ƒå·¥ä½œæ‰€éœ€çš„ä¾èµ–é¡¹ã€‚ç„¶åï¼Œæ‚¨éœ€è¦åœ¨æœ¬åœ°æ„å»ºå’Œæµ‹è¯• Docker é•œåƒä»¥è¿›è¡ŒéªŒè¯ï¼Œå°†é•œåƒæ¨é€åˆ°å®¹å™¨æ³¨å†Œè¡¨ï¼Œå¹¶æäº¤ä¸€ä¸ªè‡ªå®šä¹‰ä½œä¸šåˆ° Vertex AI è®­ç»ƒæœåŠ¡ã€‚\n",
    "\n",
    "![åœ¨ Vertex AI ä¸Šä½¿ç”¨è‡ªå®šä¹‰å®¹å™¨è¿›è¡Œè®­ç»ƒ](./images/training-with-custom-containers-on-vertex-training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95ea5367dc42"
   },
   "source": [
    "ä½¿ç”¨Dockerfileå’Œè®­ç»ƒä»£ç ä»¥åŠä¾èµ–é¡¹æ„å»ºæ‚¨çš„å®¹å™¨\n",
    "\n",
    "åœ¨å…ˆå‰çš„éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†è®­ç»ƒåº”ç”¨ç¨‹åºä»£ç å’Œä¾èµ–é¡¹åŒ…è£…ä¸º Python æºåˆ†å‘åŒ…ã€‚æ‰“åŒ…è®­ç»ƒåº”ç”¨ç¨‹åºå’Œä¾èµ–é¡¹çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ Dockerfile åˆ›å»ºè‡ªå®šä¹‰å®¹å™¨ã€‚æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª Dockerfileï¼Œä½¿ç”¨ç”± Vertex AI æä¾›çš„é¢„æ„å»ºçš„ PyTorch å®¹å™¨æ˜ åƒä½œä¸ºåŸºæœ¬æ˜ åƒï¼Œå®‰è£…ä¾èµ–é¡¹ - `transformers`ã€`datasets`ã€`tqdm` å’Œ `cloudml-hypertune`ï¼Œå¹¶å¤åˆ¶è®­ç»ƒåº”ç”¨ç¨‹åºä»£ç ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59cf98db5792"
   },
   "outputs": [],
   "source": [
    "%%writefile ./custom_container/Dockerfile\n",
    "\n",
    "# Use pytorch GPU base image\n",
    "FROM us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.1-10:latest\n",
    "\n",
    "# set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Install required packages\n",
    "RUN pip install google-cloud-storage transformers datasets tqdm cloudml-hypertune\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY ./trainer/__init__.py /app/trainer/__init__.py\n",
    "COPY ./trainer/experiment.py /app/trainer/experiment.py\n",
    "COPY ./trainer/utils.py /app/trainer/utils.py\n",
    "COPY ./trainer/metadata.py /app/trainer/metadata.py\n",
    "COPY ./trainer/model.py /app/trainer/model.py\n",
    "COPY ./trainer/task.py /app/trainer/task.py\n",
    "\n",
    "# Set up the entry point to invoke the trainer.\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1f8d15e545e7"
   },
   "source": [
    "æ„å»ºé•œåƒå¹¶æ ‡è®°å®¹å™¨æ³¨å†Œè¡¨è·¯å¾„ï¼ˆgcr.ioï¼‰ï¼Œä»¥ä¾¿æ¨é€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03442268f05d"
   },
   "outputs": [],
   "source": [
    "CUSTOM_TRAIN_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/pytorch_gpu_train_{APP_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99d59a1f072c"
   },
   "outputs": [],
   "source": [
    "!cd ./custom_container/ && docker build -f Dockerfile -t $CUSTOM_TRAIN_IMAGE_URI ../python_package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "169b86d50c45"
   },
   "source": [
    "#### *[å¯é€‰]* **ä½¿ç”¨è‡ªå®šä¹‰å®¹å™¨åœ¨æœ¬åœ°è¿è¡Œè®­ç»ƒä»»åŠ¡**\n",
    "\n",
    "ä»¥åˆ†ç¦»æ¨¡å¼åœ¨æœ¬åœ°è¿è¡Œå®¹å™¨è¿›è¡Œæµ‹è¯•ã€‚åœ¨å¸¦æœ‰GPUçš„æœºå™¨ä¸Šè¿è¡Œæ—¶ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`--gpus all`å‘½ä»¤è¡Œæ ‡å¿—ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1361941a46d9"
   },
   "outputs": [],
   "source": [
    "!docker run --gpus all -it --rm $CUSTOM_TRAIN_IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1873a991a40f"
   },
   "source": [
    "åœ¨Vertex AIä¸Šè¿è¡Œè‡ªå®šä¹‰å®¹å™¨çš„è®­ç»ƒä½œä¸š\n",
    "\n",
    "åœ¨å°†è®­ç»ƒä½œä¸šæäº¤åˆ°Vertex AIä¹‹å‰ï¼Œå°†è‡ªå®šä¹‰å®¹å™¨é•œåƒæ¨é€åˆ°Google Cloudå®¹å™¨æ³¨å†Œè¡¨ï¼Œç„¶åæäº¤è®­ç»ƒä½œä¸šç»™Vertex AIã€‚\n",
    "\n",
    "æ³¨æ„ï¼š[å®¹å™¨æ³¨å†Œè¡¨](https://cloud.google.com/container-registry)æ˜¯ä¸€ä¸ªä¸­å¤®ä»“åº“ï¼Œç”¨äºå­˜å‚¨ã€ç®¡ç†å’Œä¿æŠ¤æ‚¨çš„Dockerå®¹å™¨é•œåƒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5e11e1319b6"
   },
   "source": [
    "å°†å®¹å™¨æ¨é€åˆ°å®¹å™¨æ³¨å†Œè¡¨\n",
    "\n",
    "å°†å¸¦æœ‰è®­ç»ƒåº”ç”¨ç¨‹åºä»£ç å’Œä¾èµ–é¡¹çš„å®¹å™¨é•œåƒæ¨é€åˆ°æ‚¨çš„å®¹å™¨æ³¨å†Œè¡¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11fbe35013f9"
   },
   "outputs": [],
   "source": [
    "!docker push $CUSTOM_TRAIN_IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d157a91a792"
   },
   "source": [
    "éªŒè¯å®¹å™¨æ³¨å†Œè¡¨ä¸­çš„è‡ªå®šä¹‰å®¹å™¨é•œåƒ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a23a4c447117"
   },
   "outputs": [],
   "source": [
    "!gcloud container images describe $CUSTOM_TRAIN_IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a23e5e34bea9"
   },
   "source": [
    "åˆå§‹åŒ– Python çš„ Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52f180952ca0"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abf1fa4085cb"
   },
   "source": [
    "é…ç½®å¹¶æäº¤è‡ªå®šä¹‰ä½œä¸šåˆ° Vertex AI è®­ç»ƒæœåŠ¡\n",
    "\n",
    "ä½¿ç”¨åŒ…å«è®­ç»ƒä»£ç å’Œå…¶ä»–ä¾èµ–é¡¹çš„[è‡ªå®šä¹‰å®¹å™¨](https://cloud.google.com/vertex-ai/docs/training/create-custom-container)å›¾åƒé…ç½®ä¸€ä¸ª[è‡ªå®šä¹‰ä½œä¸š](https://cloud.google.com/vertex-ai/docs/training/create-custom-job)\n",
    "\n",
    "**æ³¨æ„:** å½“ä½¿ç”¨ Vertex AI SDK for Python æäº¤è®­ç»ƒä½œä¸šæ—¶ï¼Œå®ƒä¼šåˆ›å»ºä¸€ä¸ª[è®­ç»ƒç®¡é“](https://cloud.google.com/vertex-ai/docs/training/create-training-pipeline)ï¼Œè¯¥ç®¡é“å¯åŠ¨è‡ªå®šä¹‰ä½œä¸šåœ¨ Vertex AI è®­ç»ƒä¸Šè¿›è¡Œè®­ç»ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5e048cc0500"
   },
   "outputs": [],
   "source": [
    "JOB_NAME = f\"{APP_NAME}-pytorch-cstm-cntr-{get_timestamp()}\"\n",
    "\n",
    "print(f\"APP_NAME={APP_NAME}\")\n",
    "print(f\"CUSTOM_TRAIN_IMAGE_URI={CUSTOM_TRAIN_IMAGE_URI}\")\n",
    "print(f\"JOB_NAME={JOB_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6946d8ad77f6"
   },
   "outputs": [],
   "source": [
    "# configure the job with container image spec\n",
    "job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=f\"{JOB_NAME}\", container_uri=f\"{CUSTOM_TRAIN_IMAGE_URI}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7a24d15e8e9"
   },
   "outputs": [],
   "source": [
    "# define training code arguments\n",
    "training_args = [\"--num-epochs\", \"2\", \"--model-name\", \"finetuned-bert-classifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7459d3261450"
   },
   "outputs": [],
   "source": [
    "# submit the custom job to Vertex AI training service\n",
    "model = job.run(\n",
    "    replica_count=1,\n",
    "    machine_type=\"n1-standard-8\",\n",
    "    accelerator_type=\"NVIDIA_TESLA_V100\",\n",
    "    accelerator_count=1,\n",
    "    args=training_args,\n",
    "    sync=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d694283ad14c"
   },
   "source": [
    "ç›‘æ§è‡ªå®šä¹‰ä½œä¸šçš„è¿›åº¦\n",
    "\n",
    "æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹é“¾æ¥ç›‘æ§ä»äº‘æ§åˆ¶å°å¯åŠ¨çš„è‡ªå®šä¹‰ä½œä¸š[è¿™é‡Œ](https://console.cloud.google.com/vertex-ai/training/training-pipelines/)æˆ–ä½¿ç”¨gcloud CLIå‘½ä»¤[`gcloud beta ai custom-jobs stream-logs`](https://cloud.google.com/sdk/gcloud/reference/beta/ai/custom-jobs/stream-logs)\n",
    "\n",
    "![åœ¨ Vertex AI è®­ç»ƒä¸­ç›‘æ§è‡ªå®šä¹‰ä½œä¸šè¿›åº¦](./images/vertex-training-monitor-custom-job-container.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17d146293583"
   },
   "source": [
    "##### ***ã€å¯é€‰ã€‘*** **ä½¿ç”¨gcloud CLIæäº¤è‡ªå®šä¹‰å®¹å™¨çš„è‡ªå®šä¹‰ä½œä¸š**\n",
    "æ‚¨å¯ä»¥ä½¿ç”¨ [`gcloud beta ai custom-jobs create`](https://cloud.google.com/sdk/gcloud/reference/beta/ai/custom-jobs/create) å‘½ä»¤å’Œè‡ªå®šä¹‰å®¹å™¨è§„èŒƒå°†è®­ç»ƒä½œä¸šæäº¤ç»™Vertex AIè®­ç»ƒæœåŠ¡ã€‚`gcloud`å‘½ä»¤æäº¤è®­ç»ƒä½œä¸šå¹¶å¯åŠ¨å…·æœ‰æŒ‡å®šè‡ªå®šä¹‰å®¹å™¨é•œåƒçš„å·¥ä½œæ± ã€‚\n",
    "\n",
    "```\n",
    "gcloud beta ai custom-jobs create \\\n",
    "    --display-name=${JOB_NAME} \\\n",
    "    --region ${REGION} \\\n",
    "    --worker-pool-spec=replica-count=1,machine-type='n1-standard-8',accelerator-type='NVIDIA_TESLA_V100',accelerator-count=1,container-image-uri=${CUSTOM_TRAIN_IMAGE_URI} \\\n",
    "    --args=\"--model-name\",\"finetuned-bert-classifier\",\"--job-dir\",$JOB_DIR\n",
    "```\n",
    "\n",
    "- `worker-pool-spec` å‚æ•°å®šä¹‰äº†è‡ªå®šä¹‰ä½œä¸šä½¿ç”¨çš„å·¥ä½œæ± é…ç½®ã€‚ä»¥ä¸‹æ˜¯`worker-pool-spec`ä¸­çš„å­—æ®µï¼š\n",
    "    - å°†`container-image-uri`è®¾ç½®ä¸ºç”¨äºè®­ç»ƒçš„æ¨é€åˆ°Google Cloudå®¹å™¨æ³¨å†Œè¡¨çš„è‡ªå®šä¹‰å®¹å™¨é•œåƒ\n",
    "    - è®¾ç½®`accelerator-type`å’Œ`machine-type`ä»¥è®¾ç½®æ‰§è¡Œåº”ç”¨ç¨‹åºçš„è®¡ç®—ç±»å‹\n",
    "\n",
    "è¯·å‚é˜…[æ–‡æ¡£](https://cloud.google.com/sdk/gcloud/reference/beta/ai/custom-jobs/create#--args)è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚\n",
    "\n",
    "ä½äº`./custom_container/scripts/train-cloud.sh`çš„è„šæœ¬åŒ…å«äº†å¯åŠ¨è‡ªå®šä¹‰ä½œä¸šå’Œç›‘è§†æ—¥å¿—çš„`gcloud`å‘½ä»¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45c0f675d26a"
   },
   "outputs": [],
   "source": [
    "!cd custom_container && ./scripts/train-cloud.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69d723da4f80"
   },
   "source": [
    "é™¤äº†äº‘æ§åˆ¶å°ä¹‹å¤–ï¼Œæ‚¨è¿˜å¯ä»¥é€šè¿‡ä½¿ç”¨[gcloud CLI](https://cloud.google.com/sdk/gcloud/reference/beta/ai/custom-jobs/stream-logs)é€šè¿‡ä¼ é€’ä½œä¸šIDæ¥é€šè¿‡æµå¼æ—¥å¿—ç›‘æ§ä½œä¸šè¿›åº¦ï¼š\n",
    "\n",
    "```\n",
    "gcloud ai custom-jobs stream-logs <job_id> --region=$REGION\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cffb0f2e5d4a"
   },
   "source": [
    "æ‚¨å¯ä»¥é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥éªŒè¯å†™å…¥GCSçš„æ¨¡å‹æ–‡ä»¶ï¼š\n",
    "\n",
    "```\n",
    "!gsutil ls -l $JOB_DIR/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "409c7472fd4f"
   },
   "source": [
    "è¶…å‚æ•°è°ƒæ•´"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba6122f929e3"
   },
   "source": [
    "ç”¨äºå¾®è°ƒå˜å‹å™¨æ¨¡å‹ä»¥è¿›è¡Œæƒ…æ„Ÿåˆ†æä»»åŠ¡çš„è®­ç»ƒåº”ç”¨ç¨‹åºä»£ç ä½¿ç”¨è¶…å‚æ•°ï¼Œä¾‹å¦‚å­¦ä¹ ç‡å’Œæƒé‡è¡°å‡ã€‚è¿™äº›è¶…å‚æ•°æ§åˆ¶è®­ç»ƒç®—æ³•çš„è¡Œä¸ºï¼Œå¹¶å¯ä»¥å¯¹ç”Ÿæˆçš„æ¨¡å‹çš„æ€§èƒ½äº§ç”Ÿæ˜¾è‘—å½±å“ã€‚ç¬”è®°æœ¬çš„è¿™ä¸€éƒ¨åˆ†å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨Vertex AIè®­ç»ƒæœåŠ¡è‡ªåŠ¨è°ƒæ•´è¿™äº›è¶…å‚æ•°ã€‚\n",
    "\n",
    "æˆ‘ä»¬é€šè¿‡å°†è®­ç»ƒåº”ç”¨ç¨‹åºä»£ç å’Œä¾èµ–é¡¹æ‰“åŒ…åˆ°Dockerå®¹å™¨ä¸­ï¼Œå¹¶å°†å®¹å™¨æ¨é€åˆ°Googleå®¹å™¨æ³¨å†Œè¡¨ï¼Œç±»ä¼¼äºåœ¨Vertex AIä¸Šè¿è¡Œè‡ªå®šä¹‰å®¹å™¨è¿›è¡ŒCustom Jobï¼Œå‘Vertex AI TrainingæœåŠ¡æäº¤[è¶…å‚æ•°è°ƒæ•´ä½œä¸š](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview)ã€‚\n",
    "\n",
    "![åœ¨Vertex AI Trainingä¸Šä½¿ç”¨è‡ªå®šä¹‰å®¹å™¨è¿›è¡Œè¶…å‚æ•°è°ƒæ•´](./images/hp-tuning-with-custom-containers-on-vertex-training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1570be63a7c"
   },
   "source": [
    "åœ¨Vertex AIä¸­ï¼Œè¶…å‚æ•°è°ƒæ•´æ˜¯å¦‚ä½•å·¥ä½œçš„å‘¢ï¼Ÿ\n",
    "\n",
    "ä»¥ä¸‹æ˜¯åœ¨Vertex AIåŸ¹è®­æœåŠ¡ä¸Šè¿è¡Œè¶…å‚æ•°è°ƒæ•´ä½œä¸šæ¶‰åŠçš„é«˜çº§æ­¥éª¤ï¼š\n",
    "\n",
    "- æ‚¨å®šä¹‰è¦è°ƒæ•´æ¨¡å‹çš„è¶…å‚æ•°ï¼Œä»¥åŠè¦ä¼˜åŒ–çš„åº¦é‡ï¼ˆæˆ–ç›®æ ‡ï¼‰\n",
    "- Vertex AIä½¿ç”¨æ‚¨æŒ‡å®šçš„è¶…å‚æ•°å’Œé™åˆ¶è¿è¡Œå¤šä¸ªè®­ç»ƒåº”ç”¨ç¨‹åºçš„è¯•éªŒ-è¦è¿è¡Œçš„æœ€å¤§è¯•éªŒæ¬¡æ•°å’Œå¹¶è¡Œè¯•éªŒæ¬¡æ•°ã€‚ \n",
    "- Vertex AIè·Ÿè¸ªæ¯ä¸ªè¯•éªŒçš„ç»“æœï¼Œå¹¶ä¸ºåç»­è¯•éªŒè¿›è¡Œè°ƒæ•´ã€‚è¿™éœ€è¦æ‚¨çš„è®­ç»ƒåº”ç”¨ç¨‹åºä½¿ç”¨PythonåŒ…[`cloudml-hypertune`](https://github.com/GoogleCloudPlatform/cloudml-hypertune)å‘Vertex AIæŠ¥å‘ŠæŒ‡æ ‡ã€‚ \n",
    "- ä½œä¸šå®Œæˆåï¼Œæ ¹æ®æ‚¨é…ç½®çš„æ ‡å‡†è·å–æ‰€æœ‰è¯•éªŒçš„æ‘˜è¦ï¼Œè¯¥æ‘˜è¦åŸºäºæœ€æœ‰æ•ˆçš„å€¼é…ç½®ã€‚\n",
    "\n",
    "è¯·å‚è€ƒ[Vertex AIæ–‡æ¡£](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview)äº†è§£å¦‚ä½•é…ç½®å’Œé€‰æ‹©ç”¨äºè°ƒæ•´çš„è¶…å‚æ•°ï¼Œé…ç½®è°ƒæ•´ç­–ç•¥ä»¥åŠVertex AIå¦‚ä½•ä¼˜åŒ–è¶…å‚æ•°è°ƒæ•´ä½œä¸šã€‚é»˜è®¤çš„è°ƒæ•´ç­–ç•¥ä½¿ç”¨å…ˆå‰è¯•éªŒçš„ç»“æœæ¥æŒ‡å¯¼åç»­è¯•éªŒä¸­å€¼çš„åˆ†é…ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4dc37f4aab3"
   },
   "source": [
    "### ç”¨äºè¶…å‚æ•°è°ƒæ•´çš„è®­ç»ƒåº”ç”¨ä»£ç æ›´æ”¹\n",
    "\n",
    "åœ¨Vertex AIä¸­è¿›è¡Œè¶…å‚æ•°è°ƒæ•´æœ‰ä¸€äº›ç‰¹å®šè¦æ±‚ï¼š\n",
    "\n",
    "1. è¦å°†è¶…å‚æ•°å€¼ä¼ é€’ç»™è®­ç»ƒä»£ç ï¼Œæ‚¨éœ€è¦åœ¨ä¸»è®­ç»ƒæ¨¡å—ä¸­ä¸ºæ¯ä¸ªè°ƒæ•´çš„è¶…å‚æ•°å®šä¹‰ä¸€ä¸ªå‘½ä»¤è¡Œå‚æ•°ã€‚ä½¿ç”¨è¿™äº›å‚æ•°ä¸­ä¼ é€’çš„å€¼æ¥è®¾ç½®è®­ç»ƒåº”ç”¨ç¨‹åºä»£ç ä¸­ç›¸åº”çš„è¶…å‚æ•°ã€‚\n",
    "1. æ‚¨å¿…é¡»å°†è®­ç»ƒåº”ç”¨ç¨‹åºçš„æŒ‡æ ‡ä¼ é€’ç»™Vertex AIä»¥è¯„ä¼°è¯•éªŒçš„æœ‰æ•ˆæ€§ã€‚æ‚¨å¯ä»¥ä½¿ç”¨`cloudml-hypertune` PythonåŒ…æ¥æŠ¥å‘ŠæŒ‡æ ‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4b0331ad2e11"
   },
   "source": [
    "å…ˆå‰ï¼Œåœ¨åŸ¹è®­åº”ç”¨ç¨‹åºä»£ç ä¸­ï¼Œæˆ‘ä»¬å¯¹transformeræ¨¡å‹è¿›è¡Œå¾®è°ƒä»¥è¿›è¡Œæƒ…æ„Ÿåˆ†æä»»åŠ¡ï¼Œä½¿ç”¨è¶…å‚æ•°ä½œä¸ºè®­ç»ƒå‚æ•°ï¼ˆ`training_args`ï¼‰å®ä¾‹åŒ–[`Trainer`](https://huggingface.co/transformers/main_classes/trainer.html)ã€‚\n",
    "\n",
    "è¿™äº›è¶…å‚æ•°ä½œä¸ºå‘½ä»¤è¡Œå‚æ•°ä¼ é€’ç»™åŸ¹è®­æ¨¡å—`trainer.task`ï¼Œç„¶åä¼ é€’ç»™`training_args`ã€‚è¯·å‚è€ƒ`./python_package/trainer`æ¨¡å—æŸ¥çœ‹åŸ¹è®­åº”ç”¨ç¨‹åºä»£ç ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16fb8c85a170"
   },
   "source": [
    "å¯ç”¨è¶…å‚æ•°è°ƒæ•´æ—¶ï¼Œä¸ºäº†å‘Vertex AIæŠ¥å‘Šåº¦é‡æ ‡å‡†ï¼Œæˆ‘ä»¬åœ¨è¯„ä¼°é˜¶æ®µä¹‹åè°ƒç”¨ [`cloudml-hypertune` Python åŒ…](https://github.com/GoogleCloudPlatform/cloudml-hypertune)ã€‚æ­¤åŒ…è¢«æ·»åŠ ä¸º `trainer` çš„ [callback](https://huggingface.co/transformers/main_classes/callback.html#transformers.trainer_callback.TrainerCallback)ã€‚`trainer` å¯¹è±¡å°†ç”±ä¸Šä¸€æ¬¡è¯„ä¼°é˜¶æ®µè®¡ç®—çš„åº¦é‡ä¼ é€’ç»™callbackï¼Œä»¥ä¾¿ç”±`hypertune`åº“æŠ¥å‘Šç»™Vertex AIç”¨äºè¯„ä¼°è¯•éªŒã€‚\n",
    "\n",
    "```python\n",
    "# æ·»åŠ ç”¨äºæŠ¥å‘Šåº¦é‡çš„è¶…å‚æ•°è°ƒæ•´å›è°ƒå‡½æ•°\n",
    "if args.hp_tune == \"y\":\n",
    "    trainer.add_callback(HPTuneCallback(\"accuracy\", \"eval_accuracy\"))\n",
    "\n",
    "class HPTuneCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    ä¸€ä¸ªè‡ªå®šä¹‰çš„å›è°ƒç±»ï¼Œç”¨äºåœ¨æ¯ä¸ªå‘¨æœŸæœ«å‘è¶…è°ƒå™¨æŠ¥å‘Šåº¦é‡æ ‡å‡†ã€‚\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, metric_tag, metric_value):\n",
    "        super(HPTuneCallback, self).__init__()\n",
    "        self.metric_tag = metric_tag\n",
    "        self.metric_value = metric_value\n",
    "        self.hpt = hypertune.HyperTune()\n",
    "        \n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        print(f\"HP metric {self.metric_tag}={kwargs['metrics'][self.metric_value]}\")\n",
    "        self.hpt.report_hyperparameter_tuning_metric(\n",
    "            hyperparameter_metric_tag=self.metric_tag,\n",
    "            metric_value=kwargs['metrics'][self.metric_value],\n",
    "            global_step=state.epoch)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9d284f3599d"
   },
   "source": [
    "åœ¨Vertex AIä¸Šè¿è¡Œè¶…å‚æ•°è°ƒæ•´ä½œä¸š\n",
    "\n",
    "åœ¨å°†è¶…å‚æ•°è°ƒæ•´ä½œä¸šæäº¤ç»™Vertex AIä¹‹å‰ï¼Œå°†å¸¦æœ‰è®­ç»ƒåº”ç”¨ç¨‹åºçš„è‡ªå®šä¹‰å®¹å™¨æ˜ åƒæ¨é€åˆ°Google Cloudå®¹å™¨æ³¨å†Œè¡¨ï¼Œç„¶åæäº¤ä½œä¸šç»™Vertex AIã€‚æˆ‘ä»¬å°†ä½¿ç”¨ç”¨äºåœ¨Vertex AIè®­ç»ƒæœåŠ¡ä¸Šè¿è¡Œè‡ªå®šä¹‰ä½œä¸šçš„ç›¸åŒæ˜ åƒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ab9c7321d2f"
   },
   "source": [
    "éªŒè¯å®¹å™¨æ³¨å†Œè¡¨ä¸­çš„è‡ªå®šä¹‰å®¹å™¨é•œåƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54c11399e7a9"
   },
   "outputs": [],
   "source": [
    "!gcloud container images describe $CUSTOM_TRAIN_IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f60fab07d67c"
   },
   "source": [
    "åˆå§‹åŒ–Pythonçš„Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7f914ea43ac0"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6652aa63ddff"
   },
   "source": [
    "é…ç½®å¹¶æäº¤è¶…å‚æ•°è°ƒæ•´ä½œä¸šåˆ°Vertex AIåŸ¹è®­æœåŠ¡\n",
    "\n",
    "ä½¿ç”¨å…·æœ‰è®­ç»ƒä»£ç å’Œå…¶ä»–ä¾èµ–é¡¹çš„è‡ªå®šä¹‰å®¹å™¨æ˜ åƒé…ç½®[è¶…å‚æ•°è°ƒæ•´ä½œä¸š](https://cloud.google.com/vertex-ai/docs/training/using-hyperparameter-tuning)ï¼Œå…·ä½“è¯·å‚è€ƒ[æ­¤å¤„](https://cloud.google.com/vertex-ai/docs/training/create-custom-container)ã€‚\n",
    "\n",
    "åœ¨é…ç½®å’Œæäº¤è¶…å‚æ•°è°ƒæ•´ä½œä¸šæ—¶ï¼Œæ‚¨éœ€è¦é™„åŠ ä¸€ä¸ªè‡ªå®šä¹‰ä½œä¸šå®šä¹‰ï¼Œå…¶ä¸­åŒ…æ‹¬å®šä¹‰æœºå™¨ç±»å‹ã€åŠ é€Ÿå™¨å’Œè¡¨ç¤ºè‡ªå®šä¹‰å®¹å™¨çš„å®¹å™¨æ˜ åƒçš„URIçš„å·¥ä½œæ± è§„èŒƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93da68249c07"
   },
   "outputs": [],
   "source": [
    "JOB_NAME = f\"{APP_NAME}-pytorch-hptune-{get_timestamp()}\"\n",
    "\n",
    "print(f\"APP_NAME={APP_NAME}\")\n",
    "print(f\"CUSTOM_TRAIN_IMAGE_URI={CUSTOM_TRAIN_IMAGE_URI}\")\n",
    "print(f\"JOB_NAME={JOB_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d46db3a8b23"
   },
   "source": [
    "ä½¿ç”¨`hp-tune`å‚æ•°è®¾ç½®ä¸º`y`æ¥å®šä¹‰è®­ç»ƒå‚æ•°ï¼Œä»¥ä¾¿è®­ç»ƒåº”ç”¨ç¨‹åºä»£ç å¯ä»¥å‘Vertex AIæŠ¥å‘ŠæŒ‡æ ‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30b206352f6e"
   },
   "outputs": [],
   "source": [
    "training_args = [\n",
    "    \"--num-epochs\",\n",
    "    \"2\",\n",
    "    \"--model-name\",\n",
    "    \"finetuned-bert-classifier\",\n",
    "    \"--hp-tune\",\n",
    "    \"y\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e84606af6ab"
   },
   "source": [
    " ä½¿ç”¨å·¥ä½œæ± è§„èŒƒåˆ›å»ºä¸€ä¸ª CustomJobï¼Œä»¥å®šä¹‰æœºå™¨ç±»å‹ã€åŠ é€Ÿå™¨ä»¥åŠåŒ…å«è®­ç»ƒåº”ç”¨ç¨‹åºä»£ç çš„å®¢æˆ·ç«¯å®¹å™¨è§„èŒƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0456de4efb46"
   },
   "outputs": [],
   "source": [
    "# The spec of the worker pools including machine type and Docker image\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": \"n1-standard-8\",\n",
    "            \"accelerator_type\": \"NVIDIA_TESLA_V100\",\n",
    "            \"accelerator_count\": 1,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\"image_uri\": CUSTOM_TRAIN_IMAGE_URI, \"args\": training_args},\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1339a33f3c3c"
   },
   "outputs": [],
   "source": [
    "custom_job = aiplatform.CustomJob(\n",
    "    display_name=JOB_NAME, worker_pool_specs=worker_pool_specs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "269d6ffa999f"
   },
   "source": [
    "å°†`parameter_spec`å®šä¹‰ä¸ºä¸€ä¸ªPythonå­—å…¸å¯¹è±¡ï¼Œå…¶ä¸­åŒ…å«æœç´¢ç©ºé—´ï¼Œå³è¦æœç´¢å’Œä¼˜åŒ–çš„å‚æ•°ã€‚é”®æ˜¯ä½œä¸ºå‘½ä»¤è¡Œå‚æ•°ä¼ é€’ç»™è®­ç»ƒä»£ç çš„è¶…å‚æ•°åç§°ï¼Œå€¼æ˜¯å‚æ•°è§„èŒƒã€‚è§„èŒƒè¦æ±‚å°†è¶…å‚æ•°æ•°æ®ç±»å‹æŒ‡å®šä¸ºå‚æ•°å€¼è§„èŒƒçš„å®ä¾‹ã€‚\n",
    "\n",
    "è¯·å‚è€ƒ[æ–‡æ¡£](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview#hyperparameters)æœ‰å…³é€‰æ‹©è¦è°ƒæ•´çš„è¶…å‚æ•°ä»¥åŠå¦‚ä½•å®šä¹‰å‚æ•°è§„èŒƒçš„ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4210677c7ec7"
   },
   "outputs": [],
   "source": [
    "# Dictionary representing parameters to optimize.\n",
    "# The dictionary key is the parameter_id, which is passed into your training\n",
    "# job as a command line argument,\n",
    "# And the dictionary value is the parameter specification of the metric.\n",
    "parameter_spec = {\n",
    "    \"learning-rate\": hpt.DoubleParameterSpec(min=1e-6, max=0.001, scale=\"log\"),\n",
    "    \"weight-decay\": hpt.DiscreteParameterSpec(\n",
    "        values=[0.0001, 0.001, 0.01, 0.1], scale=None\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e29058ada6d4"
   },
   "source": [
    "å®šä¹‰`metric_spec`ï¼Œå…¶ä¸­åŒ…å«æŒ‡æ ‡çš„åç§°å’Œç›®æ ‡ä»¥ä¼˜åŒ–æŒ‡æ ‡ã€‚ç›®æ ‡æŒ‡å®šæ‚¨æ˜¯å¦å¸Œæœ›è°ƒæ•´æ¨¡å‹ä»¥æœ€å¤§åŒ–æˆ–æœ€å°åŒ–æ­¤æŒ‡æ ‡çš„å€¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6d50f78b1303"
   },
   "outputs": [],
   "source": [
    "# Dictionary representing metrics to optimize.\n",
    "# The dictionary key is the metric_id, which is reported by your training job,\n",
    "# And the dictionary value is the optimization goal of the metric.\n",
    "metric_spec = {\"accuracy\": \"maximize\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c5215ca590c"
   },
   "source": [
    "ä½¿ç”¨è‡ªå®šä¹‰ä½œä¸šã€æŒ‡æ ‡è§„èŒƒã€å‚æ•°è§„èŒƒå’Œè¯•éªŒé™åˆ¶é…ç½®å¹¶æäº¤è¶…å‚æ•°è°ƒæ•´ä½œä¸šã€‚\n",
    "\n",
    "- **`max_trial_count`**ï¼šæœåŠ¡è¿è¡Œçš„æœ€å¤§è¯•éªŒæ¬¡æ•°ã€‚æˆ‘ä»¬å»ºè®®ä»è¾ƒå°çš„å€¼å¼€å§‹ï¼Œä»¥ä¾¿äº†è§£æ‰€é€‰æ‹©çš„è¶…å‚æ•°å¯¹ç»“æœçš„å½±å“ï¼Œç„¶åå†é€æ¸å¢åŠ ã€‚\n",
    "- **`parallel_trial_count`**ï¼šå¹¶è¡Œè¿è¡Œçš„è¯•éªŒæ•°é‡ã€‚æˆ‘ä»¬å»ºè®®ä»è¾ƒå°çš„å€¼å¼€å§‹ï¼Œå› ä¸ºVertex AIä¼šä½¿ç”¨å…ˆå‰è¯•éªŒçš„ç»“æœæ¥æŒ‡å¯¼åç»­è¯•éªŒä¸­æ•°å€¼çš„åˆ†é…ã€‚å¤§é‡å¹¶è¡Œè¯•éªŒæ„å‘³ç€è¿™äº›è¯•éªŒå°†åœ¨æ²¡æœ‰è¿›è¡Œä¸­çš„ä»»ä½•è¯•éªŒç»“æœçš„æƒ…å†µä¸‹å¼€å§‹ã€‚\n",
    "- **`search_algorithm`**ï¼šä¸ºç ”ç©¶æŒ‡å®šçš„æœç´¢ç®—æ³•ã€‚å¦‚æœæ‚¨æ²¡æœ‰æŒ‡å®šç®—æ³•ï¼ŒVertex AI é»˜è®¤åº”ç”¨è´å¶æ–¯ä¼˜åŒ–æ¥æ‰¾åˆ°åœ¨å‚æ•°ç©ºé—´ä¸­æœç´¢æœ€ä¼˜è§£ã€‚\n",
    "\n",
    "è¯·å‚è€ƒ[æ–‡æ¡£](https://cloud.google.com/vertex-ai/docs/training/using-hyperparameter-tuning#configuration)äº†è§£è¶…å‚æ•°è®­ç»ƒä½œä¸šçš„é…ç½®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8d8088bfa3ad"
   },
   "outputs": [],
   "source": [
    "hp_job = aiplatform.HyperparameterTuningJob(\n",
    "    display_name=JOB_NAME,\n",
    "    custom_job=custom_job,\n",
    "    metric_spec=metric_spec,\n",
    "    parameter_spec=parameter_spec,\n",
    "    max_trial_count=5,\n",
    "    parallel_trial_count=2,\n",
    "    search_algorithm=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4f07757c0a4"
   },
   "outputs": [],
   "source": [
    "model = hp_job.run(sync=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d07c7cb26ad8"
   },
   "source": [
    "ç›‘è§†è‡ªå®šä¹‰ä½œä¸šçš„è¿›åº¦\n",
    "\n",
    "æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹é“¾æ¥ç›‘è§†ä»Cloud Consoleå¯åŠ¨çš„è¶…å‚æ•°è°ƒæ•´ä½œä¸š[è¿™é‡Œ](https://console.cloud.google.com/vertex-ai/training/hyperparameter-tuning-jobs/)ï¼Œæˆ–è€…ä½¿ç”¨gcloud CLIå‘½ä»¤ [`gcloud beta ai custom-jobs stream-logs`](https://cloud.google.com/sdk/gcloud/reference/beta/ai/custom-jobs/stream-logs)\n",
    "\n",
    "![åœ¨Vertex AI Trainingä¸­ç›‘è§†è¶…å‚æ•°è°ƒæ•´ä½œä¸šçš„è¿›å±•](./images/vertex-training-monitor-hptuning-job-container.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba934b434f03"
   },
   "source": [
    "å·¥ä½œå®Œæˆåï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹å’Œæ ¼å¼åŒ–è¶…å‚æ•°è°ƒæ•´è¯•éªŒï¼ˆç”±Vertex AIè®­ç»ƒæœåŠ¡è¿è¡Œï¼‰çš„ç»“æœä½œä¸ºPandasæ•°æ®å¸§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9b5abf9ca2d7"
   },
   "outputs": [],
   "source": [
    "def get_trials_as_df(trials):\n",
    "    results = []\n",
    "    for trial in trials:\n",
    "        row = {}\n",
    "        t = MessageToDict(trial._pb)\n",
    "        # print(t)\n",
    "        row[\"Trial ID\"], row[\"Status\"], row[\"Start time\"], row[\"End time\"] = (\n",
    "            t[\"id\"],\n",
    "            t[\"state\"],\n",
    "            t[\"startTime\"],\n",
    "            t.get(\"endTime\", None),\n",
    "        )\n",
    "\n",
    "        for param in t[\"parameters\"]:\n",
    "            row[param[\"parameterId\"]] = param[\"value\"]\n",
    "\n",
    "        if t[\"state\"] == \"SUCCEEDED\":\n",
    "            row[\"Training step\"] = t[\"finalMeasurement\"][\"stepCount\"]\n",
    "            for metric in t[\"finalMeasurement\"][\"metrics\"]:\n",
    "                row[metric[\"metricId\"]] = metric[\"value\"]\n",
    "        results.append(row)\n",
    "\n",
    "    _df = pd.DataFrame(results)\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "972f23712ce4"
   },
   "outputs": [],
   "source": [
    "df_trials = get_trials_as_df(hp_job.trials)\n",
    "df_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dbccb2b7d32"
   },
   "source": [
    "ç°åœ¨ï¼Œæ‚¨å¯ä»¥ä»è¯•éªŒç»“æœä¸­é€‰æ‹©è¡¨ç°æœ€å¥½çš„è¯•éªŒéƒ¨ç½²åˆ° Vertex AI é¢„æµ‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c32f8a0a9c76"
   },
   "outputs": [],
   "source": [
    "# get trial id of the best run from the Trials\n",
    "best_trial_id = df_trials.loc[df_trials[\"accuracy\"].idxmax()][\"Trial ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8057eebb32e9"
   },
   "outputs": [],
   "source": [
    "# get base output directory where artifacts are saved\n",
    "base_output_dir = MessageToDict(hp_job._gca_resource._pb)[\"trialJobSpec\"][\n",
    "    \"baseOutputDirectory\"\n",
    "][\"outputUriPrefix\"]\n",
    "\n",
    "# get the model artifacts of the best trial id\n",
    "best_model_artifact_uri = f\"{base_output_dir}/{best_trial_id}\"\n",
    "\n",
    "print(\n",
    "    f\"Model artifacts from the Hyperparameter Tuning Job with bbest trial id {best_trial_id} are located at {best_model_artifact_uri}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c120990dfa7e"
   },
   "source": [
    "æ‚¨å¯ä»¥é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥éªŒè¯å†™å…¥GCSçš„æ¨¡å‹æ–‡ä»¶ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbac4a0c28a5"
   },
   "outputs": [],
   "source": [
    "!gsutil ls -r $best_model_artifact_uri/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b43f9a01162"
   },
   "source": [
    "##### **[å¯é€‰]** ä½¿ç”¨ gcloud CLI æäº¤è¶…å‚æ•°è°ƒæ•´ä½œä¸š\n",
    "æ‚¨å¯ä»¥ä½¿ç”¨[`gcloud beta ai hp-tuning-jobs create`](https://cloud.google.com/sdk/gcloud/reference/beta/ai/hp-tuning-jobs/create)å‘½ä»¤å°†è¶…å‚æ•°è°ƒæ•´ä½œä¸šæäº¤ç»™Vertex AIè®­ç»ƒæœåŠ¡ã€‚`gcloud`å‘½ä»¤å°†æäº¤è¶…å‚æ•°è°ƒæ•´ä½œä¸šå¹¶æ ¹æ®è‡ªå®šä¹‰å®¹å™¨æ˜ åƒã€è¯•éªŒæ•°é‡å’Œè®¾ç½®çš„æ ‡å‡†å¯åŠ¨å¤šä¸ªè¯•éªŒå·¥ä½œæ± ã€‚è¯¥å‘½ä»¤éœ€è¦å°†è¶…å‚æ•°è°ƒæ•´ä½œä¸šé…ç½®æä¾›ä¸ºYAMLæ ¼å¼çš„é…ç½®æ–‡ä»¶ï¼ŒåŒ…å«ä½œä¸šåç§°ã€‚\n",
    "\n",
    "ä»¥ä¸‹æ˜¯å¦‚ä½•ä½¿ç”¨`gcloud`CLIåœ¨Vertex AIä¸Šæäº¤è¶…å‚æ•°è°ƒæ•´ä½œä¸šçš„ç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39a793062138"
   },
   "outputs": [],
   "source": [
    "%%bash -s $BUCKET_NAME $APP_NAME\n",
    "\n",
    "# ========================================================\n",
    "# set job parameters\n",
    "# ========================================================\n",
    "# PROJECT_ID: Change to your project id\n",
    "PROJECT_ID=$(gcloud config list --format 'value(core.project)')\n",
    "        \n",
    "# set job display name\n",
    "JOB_PREFIX=\"finetuned-bert-classifier\"\n",
    "JOB_NAME=${JOB_PREFIX}-pytorch-hptune-$(date +%Y%m%d%H%M%S)\n",
    "echo \"Launching hyperparameter tuning job with display name as \"$JOB_NAME\n",
    "\n",
    "# BUCKET_NAME is a required parameter to run the cell.\n",
    "BUCKET_NAME=$1\n",
    "\n",
    "# APP_NAME: get application name\n",
    "APP_NAME=$2\n",
    "\n",
    "# JOB_DIR: Where to store prepared package and upload output model.\n",
    "JOB_DIR=${BUCKET_NAME}/${JOB_PREFIX}/model/${JOB_NAME}\n",
    "\n",
    "# custom container image URI\n",
    "CUSTOM_TRAIN_IMAGE_URI='gcr.io/'${PROJECT_ID}'/pytorch_gpu_train_'${APP_NAME}\n",
    "\n",
    "# ========================================================\n",
    "# create hyperparameter tuning configuration file\n",
    "# ========================================================\n",
    "cat << EOF > ./python_package/hptuning_job.yaml\n",
    "\n",
    "studySpec:\n",
    "  metrics:\n",
    "  - metricId: accuracy\n",
    "    goal: MAXIMIZE\n",
    "  parameters:\n",
    "  - parameterId: learning-rate\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.000001\n",
    "      maxValue: 0.001\n",
    "  - parameterId: weight-decay\n",
    "    scaleType: SCALE_TYPE_UNSPECIFIED\n",
    "    discreteValueSpec:\n",
    "      values: [\n",
    "          0.0001, \n",
    "          0.001, \n",
    "          0.01, \n",
    "          0.1\n",
    "      ]\n",
    "  measurementSelectionType: BEST_MEASUREMENT\n",
    "trialJobSpec:\n",
    "  workerPoolSpecs:\n",
    "  - machineSpec:\n",
    "      machineType: n1-standard-8\n",
    "      acceleratorType: NVIDIA_TESLA_V100\n",
    "      acceleratorCount: 1  \n",
    "    replicaCount: 1\n",
    "    containerSpec:\n",
    "      imageUri: $CUSTOM_TRAIN_IMAGE_URI\n",
    "      args: [\"--num-epochs\", \"2\", \"--model-name\", \"finetuned-bert-classifier\", \"--hp-tune\", \"y\"]\n",
    "  baseOutputDirectory: \n",
    "    outputUriPrefix: $JOB_DIR/\n",
    "EOF\n",
    "\n",
    "# ========================================================\n",
    "# submit hyperparameter tuning job\n",
    "# ========================================================\n",
    "gcloud beta ai hp-tuning-jobs create \\\n",
    "   --config ./python_package/hptuning_job.yaml \\\n",
    "   --display-name $JOB_NAME \\\n",
    "   --algorithm algorithm-unspecified \\\n",
    "   --max-trial-count 5 \\\n",
    "   --parallel-trial-count 2 \\\n",
    "   --region=us-central1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4685723ceaf"
   },
   "source": [
    "éƒ¨ç½²\n",
    "\n",
    "åœ¨[Vertex AI Predictions](https://cloud.google.com/vertex-ai/docs/predictions/getting-predictions)ä¸Šéƒ¨ç½²PyTorchæ¨¡å‹éœ€è¦ä½¿ç”¨ä¸€ä¸ªè‡ªå®šä¹‰å®¹å™¨æ¥æä¾›åœ¨çº¿é¢„æµ‹ã€‚æ‚¨å°†éƒ¨ç½²ä¸€ä¸ªè¿è¡Œ[PyTorchçš„TorchServe](https://pytorch.org/serve/)å·¥å…·çš„å®¹å™¨ï¼Œä»¥ä¾¿ä»Hugging Face Transformers Fine-Tuned Transformeræ¨¡å‹å¯¹æƒ…æ„Ÿåˆ†æä»»åŠ¡è¿›è¡Œé¢„æµ‹ã€‚ç„¶åæ‚¨å¯ä»¥ä½¿ç”¨Vertex AI Predictionsæ¥å¯¹è¾“å…¥æ–‡æœ¬çš„æƒ…æ„Ÿè¿›è¡Œåˆ†ç±»ã€‚\n",
    "\n",
    "### ä½¿ç”¨è‡ªå®šä¹‰å®¹å™¨åœ¨Vertex AI Predictionsä¸Šéƒ¨ç½²æ¨¡å‹\n",
    "\n",
    "è¦ä½¿ç”¨è‡ªå®šä¹‰å®¹å™¨æä¾›PyTorchæ¨¡å‹çš„é¢„æµ‹ï¼Œæ‚¨å¿…é¡»æä¾›ä¸€ä¸ªDockerå®¹å™¨æ˜ åƒç»™Vertex AIï¼Œè¯¥å®¹å™¨å¯ä»¥è¿è¡Œä¸€ä¸ªHTTPæœåŠ¡å™¨ï¼Œä¾‹å¦‚è¿™ç§æƒ…å†µä¸‹çš„TorchServeã€‚è¯·å‚è€ƒ[æ–‡æ¡£](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements)ï¼Œå…¶ä¸­æè¿°äº†ä¸Vertex AI Predictionså…¼å®¹çš„å®¹å™¨æ˜ åƒçš„è¦æ±‚ã€‚\n",
    "\n",
    "![åœ¨Vertex AI Predictionsä¸Šä½¿ç”¨è‡ªå®šä¹‰å®¹å™¨æä¾›PyTorchæ¨¡å‹çš„é¢„æµ‹](./images/serve-pytorch-model-on-vertex-predictions-with-custom-containers.png)\n",
    "\n",
    "åŸºæœ¬ä¸Šï¼Œè¦åœ¨Vertex AI Predictionsä¸Šéƒ¨ç½²PyTorchæ¨¡å‹ï¼Œä»¥ä¸‹æ˜¯æ­¥éª¤ï¼š\n",
    "\n",
    "1. æ‰“åŒ…ç»è¿‡è®­ç»ƒçš„æ¨¡å‹å·¥ä»¶ï¼ŒåŒ…æ‹¬[é»˜è®¤](https://pytorch.org/serve/#default-handlers)æˆ–[è‡ªå®šä¹‰](https://pytorch.org/serve/custom_service.html)å¤„ç†ç¨‹åºï¼Œé€šè¿‡ä½¿ç”¨[Torchæ¨¡å‹å­˜æ¡£](https://github.com/pytorch/serve/tree/master/model-archiver)åˆ›å»ºä¸€ä¸ªå­˜æ¡£æ–‡ä»¶\n",
    "2. æ„å»ºä¸€ä¸ª[å…¼å®¹Vertex AI Predictions](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements)çš„è‡ªå®šä¹‰å®¹å™¨ï¼Œä»¥ä½¿ç”¨Torchserveæä¾›æ¨¡å‹æœåŠ¡\n",
    "3. å°†å¸¦æœ‰è‡ªå®šä¹‰å®¹å™¨æ˜ åƒçš„æ¨¡å‹ä¸Šä¼ ä¸ºVertex AIæ¨¡å‹èµ„æºä»¥æä¾›é¢„æµ‹\n",
    "4. åˆ›å»ºä¸€ä¸ªVertex AIç«¯ç‚¹å’Œ[éƒ¨ç½²æ¨¡å‹](https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api)èµ„æº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c931da77e57"
   },
   "source": [
    "åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰æ¨¡å‹å¤„ç†ç¨‹åºæ¥å¤„ç†é¢„æµ‹è¯·æ±‚\n",
    "\n",
    "å½“ä½¿ç”¨ç»è¿‡å¾®è°ƒçš„å˜å‹å™¨æ¨¡å‹æ¥é¢„æµ‹è¾“å…¥æ–‡æœ¬çš„æƒ…ç»ªæ—¶ï¼Œéœ€è¦å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œå¹¶é€šè¿‡æ·»åŠ åç§°ï¼ˆç§¯æ/æ¶ˆæï¼‰åˆ°ç›®æ ‡æ ‡ç­¾ï¼ˆ1/0ï¼‰ä»¥åŠæ¦‚ç‡ï¼ˆæˆ–ç½®ä¿¡åº¦ï¼‰è¿›è¡Œåå¤„ç†ã€‚æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰å¤„ç†ç¨‹åºè„šæœ¬ï¼Œè¯¥è„šæœ¬ä¸æ¨¡å‹å·¥ä»¶æ‰“åŒ…åœ¨ä¸€èµ·ï¼Œå½“TorchServeè¿è¡Œæ—¶æ‰§è¡Œè¯¥ä»£ç ã€‚\n",
    "\n",
    "è‡ªå®šä¹‰å¤„ç†ç¨‹åºè„šæœ¬æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š\n",
    "\n",
    "- åœ¨å°†è¾“å…¥æ–‡æœ¬å‘é€åˆ°æ¨¡å‹ä»¥è¿›è¡Œæ¨ç†ä¹‹å‰å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†\n",
    "- è‡ªå®šä¹‰è°ƒç”¨æ¨¡å‹è¿›è¡Œæ¨ç†çš„æ–¹å¼\n",
    "- åœ¨å°†æ¨¡å‹çš„è¾“å‡ºåå¤„ç†åå‘é€å›å“åº”\n",
    "\n",
    "è¯·å‚è€ƒ[TorchServeæ–‡æ¡£](https://pytorch.org/serve/custom_service.html)æ¥å®šä¹‰è‡ªå®šä¹‰å¤„ç†ç¨‹åºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ceb881740d6"
   },
   "outputs": [],
   "source": [
    "%%writefile predictor/custom_handler.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class TransformersClassifierHandler(BaseHandler):\n",
    "    \"\"\"\n",
    "    The handler takes an input string and returns the classification text \n",
    "    based on the serialized transformers checkpoint.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(TransformersClassifierHandler, self).__init__()\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, ctx):\n",
    "        \"\"\" Loads the model.pt file and initialized the model object.\n",
    "        Instantiates Tokenizer for preprocessor to use\n",
    "        Loads labels to name mapping file for post-processing inference response\n",
    "        \"\"\"\n",
    "        self.manifest = ctx.manifest\n",
    "\n",
    "        properties = ctx.system_properties\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        self.device = torch.device(\"cuda:\" + str(properties.get(\"gpu_id\")) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Read model serialize/pt file\n",
    "        serialized_file = self.manifest[\"model\"][\"serializedFile\"]\n",
    "        model_pt_path = os.path.join(model_dir, serialized_file)\n",
    "        if not os.path.isfile(model_pt_path):\n",
    "            raise RuntimeError(\"Missing the model.pt or pytorch_model.bin file\")\n",
    "        \n",
    "        # Load model\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        logger.debug('Transformer model from path {0} loaded successfully'.format(model_dir))\n",
    "        \n",
    "        # Ensure to use the same tokenizer used during training\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "        # Read the mapping file, index to object name\n",
    "        mapping_file_path = os.path.join(model_dir, \"index_to_name.json\")\n",
    "\n",
    "        if os.path.isfile(mapping_file_path):\n",
    "            with open(mapping_file_path) as f:\n",
    "                self.mapping = json.load(f)\n",
    "        else:\n",
    "            logger.warning('Missing the index_to_name.json file. Inference output will default.')\n",
    "            self.mapping = {\"0\": \"Negative\",  \"1\": \"Positive\"}\n",
    "\n",
    "        self.initialized = True\n",
    "\n",
    "    def preprocess(self, data):\n",
    "        \"\"\" Preprocessing input request by tokenizing\n",
    "            Extend with your own preprocessing steps as needed\n",
    "        \"\"\"\n",
    "        text = data[0].get(\"data\")\n",
    "        if text is None:\n",
    "            text = data[0].get(\"body\")\n",
    "        sentences = text.decode('utf-8')\n",
    "        logger.info(\"Received text: '%s'\", sentences)\n",
    "\n",
    "        # Tokenize the texts\n",
    "        tokenizer_args = ((sentences,))\n",
    "        inputs = self.tokenizer(*tokenizer_args,\n",
    "                                padding='max_length',\n",
    "                                max_length=128,\n",
    "                                truncation=True,\n",
    "                                return_tensors = \"pt\")\n",
    "        return inputs\n",
    "\n",
    "    def inference(self, inputs):\n",
    "        \"\"\" Predict the class of a text using a trained transformer model.\n",
    "        \"\"\"\n",
    "        prediction = self.model(inputs['input_ids'].to(self.device))[0].argmax().item()\n",
    "\n",
    "        if self.mapping:\n",
    "            prediction = self.mapping[str(prediction)]\n",
    "\n",
    "        logger.info(\"Model predicted: '%s'\", prediction)\n",
    "        return [prediction]\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        return inference_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f32fe0d49feb"
   },
   "source": [
    "ç”Ÿæˆç›®æ ‡æ ‡ç­¾ä»¥å‘½åæ–‡ä»¶ *[å¯é€‰]*\n",
    "\n",
    "åœ¨è‡ªå®šä¹‰å¤„ç†ç¨‹åºä¸­ï¼Œæˆ‘ä»¬å¼•ç”¨äº†ä¸€ä¸ªç›®æ ‡æ ‡ç­¾ä¸å…¶æœ‰æ„ä¹‰åç§°ä¹‹é—´çš„æ˜ å°„æ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶å°†ç”¨äºæ ¼å¼åŒ–é¢„æµ‹å“åº”ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ç›®æ ‡æ ‡ç­¾\"0\"æ˜ å°„ä¸º\"Negative\"ï¼Œå°†\"1\"æ˜ å°„ä¸º\"Positive\"ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1be04c0f8960"
   },
   "outputs": [],
   "source": [
    "%%writefile ./predictor/index_to_name.json\n",
    "\n",
    "{\n",
    "    \"0\": \"Negative\", \n",
    "    \"1\": \"Positive\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3feca8d40a3"
   },
   "source": [
    "#### **åˆ›å»ºè‡ªå®šä¹‰å®¹å™¨æ˜ åƒä»¥æä¾›é¢„æµ‹**\n",
    "\n",
    "æˆ‘ä»¬å°†ä½¿ç”¨Cloud Buildæ¥åˆ›å»ºå¸¦æœ‰ä»¥ä¸‹æ„å»ºæ­¥éª¤çš„è‡ªå®šä¹‰å®¹å™¨æ˜ åƒï¼š\n",
    "\n",
    "##### **ä¸‹è½½æ¨¡å‹å·¥ä»¶**\n",
    "\n",
    "ä»Cloud Storageä¸‹è½½ä½œä¸ºè®­ç»ƒï¼ˆæˆ–è¶…å‚æ•°è°ƒæ•´ï¼‰ä»»åŠ¡çš„ä¸€éƒ¨åˆ†ä¿å­˜çš„æ¨¡å‹å·¥ä»¶åˆ°æœ¬åœ°ç›®å½•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6966da1a55a5"
   },
   "outputs": [],
   "source": [
    "GCS_MODEL_ARTIFACTS_URI = best_model_artifact_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "560170b3b7d9"
   },
   "source": [
    "åœ¨äº‘å­˜å‚¨æ¡¶ä¸­éªŒè¯æ¨¡å‹æ–‡ä»¶artifactã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "216c2d276daa"
   },
   "outputs": [],
   "source": [
    "!gsutil ls -r $GCS_MODEL_ARTIFACTS_URI/model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a112fd084cf4"
   },
   "source": [
    "ä»äº‘å­˜å‚¨å¤åˆ¶æ–‡ä»¶åˆ°æœ¬åœ°ç›®å½•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82e7e1a28c92"
   },
   "outputs": [],
   "source": [
    "!gsutil -m cp -r $GCS_MODEL_ARTIFACTS_URI/model/ ./predictor/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0302ecd8df0c"
   },
   "outputs": [],
   "source": [
    "!ls -ltrR ./predictor/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b44d55f7be1"
   },
   "source": [
    "æ„å»ºå®¹å™¨é•œåƒ\n",
    "\n",
    "åˆ›å»ºä¸€ä¸ªä»¥TorchServeä¸ºåŸºç¡€é•œåƒçš„Dockerfileï¼š\n",
    "\n",
    "- **`RUN`**ï¼šå®‰è£…ä¾èµ–é¡¹ï¼Œå¦‚`transformers`\n",
    "- **`COPY`**ï¼šå°†æ¨¡å‹æ–‡ä»¶æ·»åŠ åˆ°å®¹å™¨é•œåƒçš„`/home/model-server/`ç›®å½•ä¸­\n",
    "- **`COPY`**ï¼šå°†è‡ªå®šä¹‰å¤„ç†ç¨‹åºè„šæœ¬æ·»åŠ åˆ°å®¹å™¨é•œåƒçš„`/home/model-server/`ç›®å½•ä¸­\n",
    "- **`RUN`**ï¼šåˆ›å»º`/home/model-server/config.properties`æ¥å®šä¹‰æœåŠ¡é…ç½®ï¼ˆå¥åº·å’Œé¢„æµ‹ç›‘å¬ç«¯å£ï¼‰\n",
    "- **`RUN`**ï¼šè¿è¡Œ[Torchæ¨¡å‹æ‰“åŒ…å™¨](https://pytorch.org/serve/model-archiver.html)æ¥ä»å¤åˆ¶åˆ°é•œåƒ`/home/model-server/`ä¸­çš„æ–‡ä»¶åˆ›å»ºä¸€ä¸ªæ¨¡å‹å­˜æ¡£æ–‡ä»¶ã€‚æ¨¡å‹å­˜æ¡£æ–‡ä»¶ä¿å­˜åœ¨`/home/model-server/model-store/`ä¸­ï¼Œåç§°ä¸`<model-name>.mar`ç›¸åŒ\n",
    "- **`CMD`**ï¼šå¯åŠ¨Torchserve HTTPæœåŠ¡å™¨ï¼Œå¼•ç”¨é…ç½®å±æ€§å¹¶å¯ç”¨è¯¥æ¨¡å‹çš„æœåŠ¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54acc94e5949"
   },
   "outputs": [],
   "source": [
    "%%bash -s $APP_NAME\n",
    "\n",
    "APP_NAME=$1\n",
    "\n",
    "cat << EOF > ./predictor/Dockerfile\n",
    "\n",
    "FROM pytorch/torchserve:latest-cpu\n",
    "\n",
    "# install dependencies\n",
    "RUN python3 -m pip install --upgrade pip\n",
    "RUN pip3 install transformers\n",
    "\n",
    "USER model-server\n",
    "\n",
    "# copy model artifacts, custom handler and other dependencies\n",
    "COPY ./custom_handler.py /home/model-server/\n",
    "COPY ./index_to_name.json /home/model-server/\n",
    "COPY ./model/$APP_NAME/ /home/model-server/\n",
    "\n",
    "# create torchserve configuration file\n",
    "USER root\n",
    "RUN printf \"\\nservice_envelope=json\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /home/model-server/config.properties\n",
    "USER model-server\n",
    "\n",
    "# expose health and prediction listener ports from the image\n",
    "EXPOSE 7080\n",
    "EXPOSE 7081\n",
    "\n",
    "# create model archive file packaging model artifacts and dependencies\n",
    "RUN torch-model-archiver -f \\\n",
    "  --model-name=$APP_NAME \\\n",
    "  --version=1.0 \\\n",
    "  --serialized-file=/home/model-server/pytorch_model.bin \\\n",
    "  --handler=/home/model-server/custom_handler.py \\\n",
    "  --extra-files \"/home/model-server/config.json,/home/model-server/tokenizer.json,/home/model-server/training_args.bin,/home/model-server/tokenizer_config.json,/home/model-server/special_tokens_map.json,/home/model-server/vocab.txt,/home/model-server/index_to_name.json\" \\\n",
    "  --export-path=/home/model-server/model-store\n",
    "\n",
    "# run Torchserve HTTP serve to respond to prediction requests\n",
    "CMD [\"torchserve\", \\\n",
    "     \"--start\", \\\n",
    "     \"--ts-config=/home/model-server/config.properties\", \\\n",
    "     \"--models\", \\\n",
    "     \"$APP_NAME=$APP_NAME.mar\", \\\n",
    "     \"--model-store\", \\\n",
    "     \"/home/model-server/model-store\"]\n",
    "EOF\n",
    "\n",
    "echo \"Writing ./predictor/Dockerfile\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8878a9e37fe"
   },
   "source": [
    "æ„å»ºå¸¦æœ‰å®¹å™¨æ³¨å†Œè¡¨ï¼ˆgcr.ioï¼‰è·¯å¾„æ ‡è®°çš„Dockeré•œåƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d2d6b9a4857c"
   },
   "outputs": [],
   "source": [
    "CUSTOM_PREDICTOR_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/pytorch_predict_{APP_NAME}\"\n",
    "print(f\"CUSTOM_PREDICTOR_IMAGE_URI = {CUSTOM_PREDICTOR_IMAGE_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ac17dec3371"
   },
   "outputs": [],
   "source": [
    "!docker build \\\n",
    "  --tag=$CUSTOM_PREDICTOR_IMAGE_URI \\\n",
    "  ./predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5e13aeb92678"
   },
   "source": [
    "åœ¨å°†å®¹å™¨æ˜ åƒæ¨é€åˆ°å®¹å™¨æ³¨å†Œè¡¨ä»¥åœ¨ Vertex AI é¢„æµ‹ä¸­ä½¿ç”¨ä¹‹å‰ï¼Œæ‚¨å¯ä»¥åœ¨æœ¬åœ°ç¯å¢ƒä¸­å°†å…¶ä½œä¸ºå®¹å™¨è¿è¡Œï¼Œä»¥éªŒè¯æœåŠ¡å™¨æ˜¯å¦æŒ‰é¢„æœŸå·¥ä½œã€‚ã€å¯é€‰ã€‘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaf5bb210eb9"
   },
   "source": [
    "è¿è¡Œå®¹å™¨å›¾åƒä½œä¸ºæœ¬åœ°å®¹å™¨ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5b848c5fec2f"
   },
   "outputs": [],
   "source": [
    "!docker stop local_bert_classifier\n",
    "!docker run -t -d --rm -p 7080:7080 --name=local_bert_classifier $CUSTOM_PREDICTOR_IMAGE_URI\n",
    "!sleep 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a63999a79fea"
   },
   "source": [
    "å‘é€å®¹å™¨çš„æœåŠ¡å™¨å¥åº·æ£€æŸ¥ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6499006af599"
   },
   "outputs": [],
   "source": [
    "!curl http://localhost:7080/ping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a45d57cf5ba"
   },
   "source": [
    "å¦‚æœæˆåŠŸï¼ŒæœåŠ¡å™¨ä¼šè¿”å›ä»¥ä¸‹å“åº”ï¼š\n",
    "\n",
    "```\n",
    "{\n",
    "  \"status\": \"Healthy\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6413202bfeb8"
   },
   "source": [
    "3. è¦å‘å®¹å™¨çš„æœåŠ¡å™¨å‘é€é¢„æµ‹è¯·æ±‚ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "246d76732fcb"
   },
   "outputs": [],
   "source": [
    "%%bash -s $APP_NAME\n",
    "\n",
    "APP_NAME=$1\n",
    "\n",
    "cat > ./predictor/instances.json <<END\n",
    "{ \n",
    "   \"instances\": [\n",
    "     { \n",
    "       \"data\": {\n",
    "         \"b64\": \"$(echo 'Take away the CGI and the A-list cast and you end up with film with less punch.' | base64 --wrap=0)\"\n",
    "       }\n",
    "     }\n",
    "   ]\n",
    "}\n",
    "END\n",
    "\n",
    "curl -s -X POST \\\n",
    "  -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "  -d @./predictor/instances.json \\\n",
    "  http://localhost:7080/predictions/$APP_NAME/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d34a279f7fe7"
   },
   "source": [
    "è¿™ä¸ªè¯·æ±‚ä½¿ç”¨ä¸€ä¸ªæµ‹è¯•å¥å­ã€‚å¦‚æœæˆåŠŸï¼ŒæœåŠ¡å™¨ä»¥ä»¥ä¸‹æ ¼å¼è¿”å›é¢„æµ‹ï¼š\n",
    "\n",
    "```\n",
    "    {\"predictions\": [\"Negative\"]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ac697916268"
   },
   "source": [
    "4. è¦åœæ­¢å®¹å™¨ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0a116f4fa88c"
   },
   "outputs": [],
   "source": [
    "!docker stop local_bert_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69477b3a00c0"
   },
   "source": [
    "éƒ¨ç½²æœåŠ¡å®¹å™¨åˆ°Vertex AIé¢„æµ‹\n",
    "\n",
    "æˆ‘ä»¬åœ¨Vertex AIä¸Šåˆ›å»ºä¸€ä¸ªæ¨¡å‹èµ„æºå¹¶å°†æ¨¡å‹éƒ¨ç½²åˆ°Vertex AIç«¯ç‚¹ã€‚åœ¨ä½¿ç”¨æ¨¡å‹ä¹‹å‰ï¼Œæ‚¨å¿…é¡»å°†æ¨¡å‹éƒ¨ç½²åˆ°ä¸€ä¸ªç«¯ç‚¹ã€‚éƒ¨ç½²çš„æ¨¡å‹ä¼šè¿è¡Œè‡ªå®šä¹‰å®¹å™¨é•œåƒæ¥æä¾›é¢„æµ‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "650995567bb1"
   },
   "source": [
    "å°†servingå®¹å™¨æ¨é€åˆ°å®¹å™¨æ³¨å†Œè¡¨ä¸­\n",
    "\n",
    "å°†åŒ…å«æ¨æ–­ä»£ç å’Œä¾èµ–é¡¹çš„å®¹å™¨é•œåƒæ¨é€åˆ°æ‚¨çš„å®¹å™¨æ³¨å†Œè¡¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56a927f34d2a"
   },
   "outputs": [],
   "source": [
    "!docker push $CUSTOM_PREDICTOR_IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3da91e19af4"
   },
   "source": [
    "åˆå§‹åŒ–Pythonçš„Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e0857c467ef"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a8e5f9ef00b"
   },
   "source": [
    "ä½¿ç”¨è‡ªå®šä¹‰servingå®¹å™¨åˆ›å»ºæ¨¡å‹èµ„æº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad5f86202958"
   },
   "outputs": [],
   "source": [
    "VERSION = 1\n",
    "model_display_name = f\"{APP_NAME}-v{VERSION}\"\n",
    "model_description = \"PyTorch based text classifier with custom container\"\n",
    "\n",
    "MODEL_NAME = APP_NAME\n",
    "health_route = \"/ping\"\n",
    "predict_route = f\"/predictions/{MODEL_NAME}\"\n",
    "serving_container_ports = [7080]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7fb34080960"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=model_display_name,\n",
    "    description=model_description,\n",
    "    serving_container_image_uri=CUSTOM_PREDICTOR_IMAGE_URI,\n",
    "    serving_container_predict_route=predict_route,\n",
    "    serving_container_health_route=health_route,\n",
    "    serving_container_ports=serving_container_ports,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85134f5adfa5"
   },
   "source": [
    "æœ‰å…³ä¸Šä¼ æˆ–å¯¼å…¥æ¨¡å‹çš„æ›´å¤šä¸Šä¸‹æ–‡ï¼Œè¯·å‚è€ƒ[æ–‡æ¡£](https://cloud.google.com/vertex-ai/docs/general/import-model)ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e12774f0dc68"
   },
   "source": [
    "ä¸ºå…·æœ‰è‡ªå®šä¹‰å®¹å™¨çš„æ¨¡å‹åˆ›å»ºä¸€ä¸ªç«¯ç‚¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0bf59607969"
   },
   "outputs": [],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "endpoint = aiplatform.Endpoint.create(display_name=endpoint_display_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba9826243edf"
   },
   "source": [
    "éƒ¨ç½²æ¨¡å‹åˆ°ç«¯ç‚¹\n",
    "\n",
    "éƒ¨ç½²æ¨¡å‹ä¼šå°†ç‰©ç†èµ„æºä¸æ¨¡å‹å…³è”èµ·æ¥ï¼Œä½¿å…¶èƒ½å¤Ÿä»¥ä½å»¶è¿Ÿæä¾›åœ¨çº¿é¢„æµ‹ã€‚\n",
    "\n",
    "**æ³¨æ„ï¼š** è¿™ä¸€æ­¥éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´æ¥éƒ¨ç½²èµ„æºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8e36ccbc24b4"
   },
   "outputs": [],
   "source": [
    "traffic_percentage = 100\n",
    "machine_type = \"n1-standard-4\"\n",
    "deployed_model_display_name = model_display_name\n",
    "min_replica_count = 1\n",
    "max_replica_count = 3\n",
    "sync = True\n",
    "\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=deployed_model_display_name,\n",
    "    machine_type=machine_type,\n",
    "    traffic_percentage=traffic_percentage,\n",
    "    sync=sync,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc4673478269"
   },
   "source": [
    "ä½¿ç”¨Vertex AI SDKè°ƒç”¨éƒ¨ç½²çš„æ¨¡å‹çš„ç«¯ç‚¹è¿›è¡Œé¢„æµ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fcbf1497407"
   },
   "source": [
    "è·å–ç«¯ç‚¹ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52362d052767"
   },
   "outputs": [],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "filter = f'display_name=\"{endpoint_display_name}\"'\n",
    "\n",
    "for endpoint_info in aiplatform.Endpoint.list(filter=filter):\n",
    "    print(\n",
    "        f\"Endpoint display name = {endpoint_info.display_name} resource id ={endpoint_info.resource_name} \"\n",
    "    )\n",
    "\n",
    "endpoint = aiplatform.Endpoint(endpoint_info.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "376e74fdbd95"
   },
   "outputs": [],
   "source": [
    "endpoint.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1f454fff5e7d"
   },
   "source": [
    "##### **ä¸ºåœ¨çº¿é¢„æµ‹æ ¼å¼åŒ–è¾“å…¥**\n",
    "\n",
    "æ­¤ç¬”è®°æœ¬ä½¿ç”¨[Torchserveçš„KServeåŸºäºæ¨ç†API](https://pytorch.org/serve/inference_api.html#kserve-inference-api)ï¼Œè¯¥APIä¹Ÿæ˜¯[Vertex AI Predictionså…¼å®¹æ ¼å¼](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#prediction)ã€‚ å¯¹äºåœ¨çº¿é¢„æµ‹è¯·æ±‚ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ–¹å¼å°†é¢„æµ‹è¾“å…¥å®ä¾‹æ ¼å¼åŒ–ä¸ºå¸¦æœ‰base64ç¼–ç çš„JSONï¼š\n",
    "\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"data\": {\n",
    "            \"b64\": \"<base64ç¼–ç å­—ç¬¦ä¸²>\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "646e9dfe8add"
   },
   "source": [
    "å®šä¹‰æ ·æœ¬æ–‡æœ¬ä»¥æµ‹è¯•é¢„æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edc4658b2df1"
   },
   "outputs": [],
   "source": [
    "test_instances = [\n",
    "    b\"Jaw dropping visual affects and action! One of the best I have seen to date.\",\n",
    "    b\"Take away the CGI and the A-list cast and you end up with film with less punch.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52303da7c048"
   },
   "source": [
    "å‘é€åœ¨çº¿é¢„æµ‹è¯·æ±‚\n",
    "\n",
    "æ ¼å¼åŒ–è¾“å…¥æ–‡æœ¬å­—ç¬¦ä¸²ï¼Œä½¿ç”¨æ ¼å¼åŒ–çš„è¾“å…¥è¯·æ±‚è°ƒç”¨é¢„æµ‹ç»ˆç«¯ç‚¹ï¼Œå¹¶è·å–å“åº”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5808801dbcb"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 100)\n",
    "for instance in test_instances:\n",
    "    print(f\"Input text: \\n\\t{instance.decode('utf-8')}\\n\")\n",
    "    b64_encoded = base64.b64encode(instance)\n",
    "    test_instance = [{\"data\": {\"b64\": f\"{str(b64_encoded.decode('utf-8'))}\"}}]\n",
    "    print(f\"Formatted input: \\n{json.dumps(test_instance, indent=4)}\\n\")\n",
    "    prediction = endpoint.predict(instances=test_instance)\n",
    "    print(f\"Prediction response: \\n\\t{prediction}\")\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21664e69720a"
   },
   "source": [
    "**[å¯é€‰]** **ä½¿ç”¨gcloud CLIå‘å‡ºé¢„æµ‹è¯·æ±‚**\n",
    "\n",
    "æ‚¨ä¹Ÿå¯ä»¥è°ƒç”¨Vertex AIç»ˆç«¯èŠ‚ç‚¹æ¥ä½¿ç”¨[`gcloud beta ai endpoints predict`](https://cloud.google.com/sdk/gcloud/reference/beta/ai/endpoints/predict)è¿›è¡Œé¢„æµ‹ã€‚\n",
    "\n",
    "ä»¥ä¸‹ä»£ç å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨`gcloud` CLIå‘Vertex AIç»ˆç«¯èŠ‚ç‚¹å‘å‡ºé¢„æµ‹è¯·æ±‚ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bb062d3e7a8"
   },
   "outputs": [],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "950c04742e87"
   },
   "outputs": [],
   "source": [
    "%%bash -s $REGION $endpoint_display_name\n",
    "\n",
    "REGION=$1\n",
    "endpoint_display_name=$2\n",
    "\n",
    "# get endpoint id\n",
    "echo \"REGION = ${REGION}\"\n",
    "echo \"ENDPOINT DISPLAY NAME = ${endpoint_display_name}\"\n",
    "endpoint_id=$(gcloud beta ai endpoints list --region ${REGION} --filter \"display_name=${endpoint_display_name}\" --format \"value(ENDPOINT_ID)\")\n",
    "echo \"ENDPOINT_ID = ${endpoint_id}\"\n",
    "\n",
    "# call prediction endpoint\n",
    "input_text=\"Take away the CGI and the A-list cast and you end up with film with less punch.\"\n",
    "echo \"INPUT TEXT = ${input_text}\"\n",
    "\n",
    "prediction=$(\n",
    "echo \"\"\"\n",
    "{ \n",
    "   \"instances\": [\n",
    "     { \n",
    "       \"data\": {\n",
    "         \"b64\": \"$(echo ${input_text} | base64 --wrap=0)\"\n",
    "       }\n",
    "     }\n",
    "   ]\n",
    "}\n",
    "\"\"\" | gcloud beta ai endpoints predict ${endpoint_id} --region=$REGION --json-request -)\n",
    "\n",
    "echo \"PREDICTION RESPONSE = ${prediction}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e636b52e5913"
   },
   "source": [
    "æ•´ç†æ¸…ç†\n",
    "\n",
    "### æ•´ç†æ¸…ç†è®­ç»ƒå’Œéƒ¨ç½²èµ„æº\n",
    "\n",
    "è¦æ¸…ç†æœ¬ç¬”è®°ä¸­ä½¿ç”¨çš„æ‰€æœ‰è°·æ­Œäº‘èµ„æºï¼Œæ‚¨å¯ä»¥[åˆ é™¤ç”¨äºæœ¬æ•™ç¨‹çš„è°·æ­Œäº‘é¡¹ç›®](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)ã€‚\n",
    "\n",
    "å¦åˆ™ï¼Œæ‚¨å¯ä»¥åˆ é™¤æœ¬æ•™ç¨‹ä¸­åˆ›å»ºçš„å„ä¸ªèµ„æºï¼š\n",
    "\n",
    "- è®­ç»ƒä½œä¸š\n",
    "- æ¨¡å‹\n",
    "- ç«¯ç‚¹\n",
    "- äº‘å­˜å‚¨æ¡¶\n",
    "- å®¹å™¨é•œåƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b89f5a348d1"
   },
   "source": [
    "ä¸ºè¦åˆ é™¤çš„èµ„æºç±»å‹è®¾ç½®æ ‡å¿—ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26ee41d02418"
   },
   "outputs": [],
   "source": [
    "delete_custom_job = False\n",
    "delete_hp_tuning_job = False\n",
    "delete_endpoint = True\n",
    "delete_model = False\n",
    "delete_bucket = False\n",
    "delete_image = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa19a6540bd2"
   },
   "source": [
    "å®šä¹‰ä½œä¸šã€æ¨¡å‹å’Œç«¯ç‚¹çš„å®¢æˆ·ç«¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7f5f8dbd8cb6"
   },
   "outputs": [],
   "source": [
    "# API Endpoint\n",
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "\n",
    "# Vertex AI location root path for your dataset, model and endpoint resources\n",
    "PARENT = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "\n",
    "client_options = {\"api_endpoint\": API_ENDPOINT}\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6e41b7b75ef6"
   },
   "outputs": [],
   "source": [
    "# functions to create client\n",
    "def create_job_client():\n",
    "    client = aip.JobServiceClient(client_options=client_options)\n",
    "    return client\n",
    "\n",
    "\n",
    "def create_model_client():\n",
    "    client = aip.ModelServiceClient(client_options=client_options)\n",
    "    return client\n",
    "\n",
    "\n",
    "def create_endpoint_client():\n",
    "    client = aip.EndpointServiceClient(client_options=client_options)\n",
    "    return client\n",
    "\n",
    "\n",
    "clients = {}\n",
    "clients[\"job\"] = create_job_client()\n",
    "clients[\"model\"] = create_model_client()\n",
    "clients[\"endpoint\"] = create_endpoint_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c41b12064678"
   },
   "source": [
    "åœ¨ç¬”è®°æœ¬ä¸­å®šä¹‰å‡½æ•°æ¥åˆ—å‡ºä»¥`APP_NAME`å¼€å¤´çš„å·¥ä½œã€æ¨¡å‹å’Œç«¯ç‚¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9a450d8eea2"
   },
   "outputs": [],
   "source": [
    "def list_custom_jobs():\n",
    "    client = clients[\"job\"]\n",
    "    jobs = []\n",
    "    response = client.list_custom_jobs(parent=PARENT)\n",
    "    for row in response:\n",
    "        _row = MessageToDict(row._pb)\n",
    "        if _row[\"displayName\"].startswith(APP_NAME):\n",
    "            jobs.append((_row[\"name\"], _row[\"displayName\"]))\n",
    "    return jobs\n",
    "\n",
    "\n",
    "def list_hp_tuning_jobs():\n",
    "    client = clients[\"job\"]\n",
    "    jobs = []\n",
    "    response = client.list_hyperparameter_tuning_jobs(parent=PARENT)\n",
    "    for row in response:\n",
    "        _row = MessageToDict(row._pb)\n",
    "        if _row[\"displayName\"].startswith(APP_NAME):\n",
    "            jobs.append((_row[\"name\"], _row[\"displayName\"]))\n",
    "    return jobs\n",
    "\n",
    "\n",
    "def list_models():\n",
    "    client = clients[\"model\"]\n",
    "    models = []\n",
    "    response = client.list_models(parent=PARENT)\n",
    "    for row in response:\n",
    "        _row = MessageToDict(row._pb)\n",
    "        if _row[\"displayName\"].startswith(APP_NAME):\n",
    "            models.append((_row[\"name\"], _row[\"displayName\"]))\n",
    "    return models\n",
    "\n",
    "\n",
    "def list_endpoints():\n",
    "    client = clients[\"endpoint\"]\n",
    "    endpoints = []\n",
    "    response = client.list_endpoints(parent=PARENT)\n",
    "    for row in response:\n",
    "        _row = MessageToDict(row._pb)\n",
    "        if _row[\"displayName\"].startswith(APP_NAME):\n",
    "            print(_row)\n",
    "            endpoints.append((_row[\"name\"], _row[\"displayName\"]))\n",
    "    return endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1281b5fe9222"
   },
   "source": [
    "åˆ é™¤è‡ªå®šä¹‰è®­ç»ƒä½œä¸š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "944b5ec4694c"
   },
   "outputs": [],
   "source": [
    "# Delete the custom training using the Vertex AI fully qualified identifier for the custom training\n",
    "try:\n",
    "    if delete_custom_job:\n",
    "        custom_jobs = list_custom_jobs()\n",
    "        for job_id, job_name in custom_jobs:\n",
    "            print(f\"Deleting job {job_id} [{job_name}]\")\n",
    "            clients[\"job\"].delete_custom_job(name=job_id)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd76a52356ec"
   },
   "source": [
    "åˆ é™¤è¶…å‚æ•°è°ƒæ•´ä½œä¸š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b65e57c07b43"
   },
   "outputs": [],
   "source": [
    "# Delete the hyperparameter tuning jobs using the Vertex AI fully qualified identifier for the hyperparameter tuning job\n",
    "try:\n",
    "    if delete_hp_tuning_job:\n",
    "        hp_tuning_jobs = list_hp_tuning_jobs()\n",
    "        for job_id, job_name in hp_tuning_jobs:\n",
    "            print(f\"Deleting job {job_id} [{job_name}]\")\n",
    "            clients[\"job\"].delete_hyperparameter_tuning_job(name=job_id)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc21008bb215"
   },
   "source": [
    "å–æ¶ˆéƒ¨ç½²æ¨¡å‹å’Œåˆ é™¤ç«¯ç‚¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51684df7dc6b"
   },
   "outputs": [],
   "source": [
    "# Delete the endpoint using the Vertex AI fully qualified identifier for the endpoint\n",
    "try:\n",
    "    if delete_endpoint:\n",
    "        endpoints = list_endpoints()\n",
    "        for endpoint_id, endpoint_name in endpoints:\n",
    "            endpoint = aiplatform.Endpoint(endpoint_id)\n",
    "            # undeploy models from the endpoint\n",
    "            print(f\"Undeploying all deployed models from the endpoint {endpoint_name}\")\n",
    "            endpoint.undeploy_all(sync=True)\n",
    "            # deleting endpoint\n",
    "            print(f\"Deleting endpoint {endpoint_id} [{endpoint_name}]\")\n",
    "            clients[\"endpoint\"].delete_endpoint(name=endpoint_id)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a6719f8f8a2"
   },
   "source": [
    "åˆ é™¤æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "087a5322f387"
   },
   "outputs": [],
   "source": [
    "# Delete the model using the Vertex AI fully qualified identifier for the model\n",
    "try:\n",
    "    models = list_models()\n",
    "    for model_id, model_name in models:\n",
    "        print(f\"Deleting model {model_id} [{model_name}]\")\n",
    "        clients[\"model\"].delete_model(name=model_id)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "938a7cd172ab"
   },
   "source": [
    "åˆ é™¤æš‚å­˜æ¡¶ä¸­çš„å†…å®¹\n",
    "\n",
    "---\n",
    "\n",
    "***æ³¨æ„ï¼šæ­¤äº‘å­˜å‚¨æ¡¶ä¸­çš„æ‰€æœ‰å†…å®¹å°†è¢«åˆ é™¤ã€‚è¯·è°¨æ…è¿è¡Œã€‚***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a50bd867c02d"
   },
   "outputs": [],
   "source": [
    "if delete_bucket and \"BUCKET_NAME\" in globals():\n",
    "    print(f\"Deleting all contents from the bucket {BUCKET_NAME}\")\n",
    "\n",
    "    shell_output = ! gsutil du -as $BUCKET_NAME\n",
    "    print(\n",
    "        f\"Size of the bucket {BUCKET_NAME} before deleting = {shell_output[0].split()[0]} bytes\"\n",
    "    )\n",
    "\n",
    "    # uncomment below line to delete contents of the bucket\n",
    "    # ! gsutil rm -r $BUCKET_NAME\n",
    "\n",
    "    shell_output = ! gsutil du -as $BUCKET_NAME\n",
    "    if float(shell_output[0].split()[0]) > 0:\n",
    "        print(\n",
    "            \"PLEASE UNCOMMENT LINE TO DELETE BUCKET. CONTENT FROM THE BUCKET NOT DELETED\"\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"Size of the bucket {BUCKET_NAME} after deleting = {shell_output[0].split()[0]} bytes\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afd19ee7efa7"
   },
   "source": [
    "åˆ é™¤å®¹å™¨æ³¨å†Œè¡¨ä¸­çš„å›¾åƒ\n",
    "\n",
    "ä»æ³¨å†Œè¡¨ä¸­åˆ é™¤æœ¬æ•™ç¨‹ä¸­ç”±å˜é‡ `APP_NAME` å®šä¹‰å‰ç¼€æ‰€åˆ›å»ºçš„æ‰€æœ‰å®¹å™¨å›¾åƒã€‚æ‰€æœ‰å…³è”çš„æ ‡ç­¾ä¹Ÿå°†è¢«åˆ é™¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d45ec639148b"
   },
   "outputs": [],
   "source": [
    "gcr_images = !gcloud container images list --repository=gcr.io/$PROJECT_ID --filter=\"name~\"$APP_NAME\n",
    "\n",
    "if delete_image:\n",
    "    for image in gcr_images:\n",
    "        if image != \"NAME\":  # skip header line\n",
    "            print(f\"Deleting image {image} including all tags\")\n",
    "            !gcloud container images delete $image --force-delete-tags --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3541e1629c02"
   },
   "source": [
    "### æ¸…ç†ç¬”è®°æœ¬ç¯å¢ƒ\n",
    "\n",
    "åœ¨å®éªŒå®Œæˆåï¼Œæ‚¨å¯ä»¥é€‰æ‹©[åœæ­¢](https://cloud.google.com/ai-platform/notebooks/docs/shut-down)æˆ–è€…åˆ é™¤ AI ç¬”è®°æœ¬å®ä¾‹ï¼Œä»¥é¿å…äº§ç”Ÿä»»ä½•è´¹ç”¨ã€‚å¦‚æœæ‚¨æƒ³ä¿å­˜æ‚¨çš„å·¥ä½œï¼Œå¯ä»¥é€‰æ‹©åœæ­¢å®ä¾‹ã€‚\n",
    "\n",
    "```\n",
    "# åœæ­¢ç¬”è®°æœ¬å®ä¾‹\n",
    "gcloud notebooks instances stop example-instance --location=us-central1-a\n",
    "\n",
    "\n",
    "# åˆ é™¤ç¬”è®°æœ¬å®ä¾‹\n",
    "gcloud notebooks instances delete example-instance --location=us-central1-a\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "n9qywopnIrJH",
    "545PP3o8IrJV",
    "7k8ge1L1IrJk"
   ],
   "name": "pytorch-text-classification-vertex-ai-train-tune-deploy.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
