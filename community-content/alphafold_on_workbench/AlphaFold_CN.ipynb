{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pc5-mbsX9PZC"
   },
   "source": [
    "# 在 Vertex AI Workbench 上使用 AlphaFold\n",
    "\n",
    "[Vertex AI Workbench](https://cloud.google.com/vertex-ai/docs/workbench) 提供了一个端到端的基于笔记本的生产环境，可以预先配置运行 AlphaFold 所需的运行时依赖项。通过 [用户管理的笔记本](https://cloud.google.com/vertex-ai/docs/workbench/user-managed/introduction)，您可以配置 GPU 加速器来运行使用 Tensorflow 的 AlphaFold，而无需安装和管理驱动程序或 JupyterLab 实例。这个笔记本允许您使用 AlphaFold v2.1.0 的略简化版本轻松预测蛋白质的结构。\n",
    "\n",
    "## ![](https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/community-content/alphafold_on_workbench/vertexai_40.png) [在 Vertex AI Workbench 中启动此笔记本](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://github.com/GoogleCloudPlatform/vertex-ai-samples/raw/main/community-content/alphafold_on_workbench/AlphaFold.ipynb)\n",
    "\n",
    "**与 AlphaFold v2.1.0 的差异**\n",
    "\n",
    "与 AlphaFold v2.1.0 相比，这个笔记本不使用**模板（同源结构）**，而是使用 [BFD 数据库](https://bfd.mmseqs.com/) 的一部分。我们已经验证了这些变化在数千个最近的 PDB 结构上。虽然在许多目标上准确性将接近完整的 AlphaFold 系统，但由于 MSA 较小且缺少模板，少数目标的准确性会大幅下降。为了获得最佳可靠性，我们建议使用 [完整的开源 AlphaFold](https://github.com/deepmind/alphafold/)，或者 [AlphaFold 蛋白质结构数据库](https://alphafold.ebi.ac.uk/)。\n",
    "\n",
    "**与本地 AlphaFold 安装相比，此笔记本对于多聚体的平均准确性存在一定下降，对于完整的多聚体准确性，强烈建议在本地运行 [AlphaFold](https://github.com/deepmind/alphafold#running-alphafold)。** 此外，AlphaFold-Multimer 需要为复合物中的每个唯一序列搜索 MSA，因此速度相对较慢。如果由于多聚体 MSA 搜索缓慢导致笔记本超时，我们建议在本地运行 AlphaFold。\n",
    "\n",
    "请注意，这个笔记本是一个早期访问的原型，不是一个成品。它仅用于理论建模，使用时应谨慎。\n",
    "\n",
    "**引用此工作**\n",
    "\n",
    "任何披露使用此笔记本的研究结果的出版物应该[引用](https://github.com/deepmind/alphafold/#citing-this-work) [AlphaFold 论文](https://doi.org/10.1038/s41586-021-03819-2)。\n",
    "\n",
    "**许可证**\n",
    "\n",
    "这个 Colab 使用了[AlphaFold 模型参数](https://github.com/deepmind/alphafold/#model-parameters-license)，这些参数受 Creative Commons Attribution 4.0 International ([CC BY 4.0](https://creativecommons.org/licenses/by/4.0/legalcode)) 许可证的约束。Colab 本身是根据[Apache 2.0 许可证](https://www.apache.org/licenses/LICENSE-2.0)提供的。请查看下面的完整许可声明。\n",
    "\n",
    "**更多信息**\n",
    "\n",
    "您可以在以下论文中找到有关 AlphaFold 如何工作的更多信息：\n",
    "\n",
    "* [AlphaFold 方法论文](https://www.nature.com/articles/s41586-021-03819-2)\n",
    "* [AlphaFold 对人类蛋白质组预测的论文](https://www.nature.com/articles/s41586-021-03828-1)\n",
    "* [AlphaFold-Multimer 论文](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v1)\n",
    "\n",
    "有关如何解释 AlphaFold 预测的常见问题，请参阅[这里](https://alphafold.ebi.ac.uk/faq)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7a02613eb1a"
   },
   "source": [
    "## 下载AlphaFold数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "collapsed": true,
    "id": "woIxeCPygt7K",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import alphafold.common\n",
    "import tqdm.notebook\n",
    "from IPython.utils import io\n",
    "\n",
    "TQDM_BAR_FORMAT = (\n",
    "    \"{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]\"\n",
    ")\n",
    "\n",
    "SOURCE_URL = (\n",
    "    \"https://storage.googleapis.com/alphafold/alphafold_params_colab_2022-01-19.tar\"\n",
    ")\n",
    "PARAMS_DIR = \"alphafold/data/params\"\n",
    "PARAMS_PATH = os.path.join(PARAMS_DIR, os.path.basename(SOURCE_URL))\n",
    "ALPHAFOLD_COMMON_DIR = os.path.dirname(alphafold.common.__file__)\n",
    "\n",
    "try:\n",
    "    with tqdm.notebook.tqdm(total=100, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
    "        with io.capture_output() as captured:\n",
    "\n",
    "            # Download and store stereo_chemical_props.txt\n",
    "            !mkdir -p ~/content/alphafold/alphafold/common\n",
    "            !mkdir -p /opt/conda/lib/python3.7/site-packages/alphafold/common/\n",
    "            !wget -q -P ~/content/alphafold/alphafold/common https://git.scicore.unibas.ch/schwede/openstructure/-/raw/7102c63615b64735c4941278d92b554ec94415f8/modules/mol/alg/src/stereo_chemical_props.txt\n",
    "            pbar.update(18)\n",
    "            !cp -f ~/content/alphafold/alphafold/common/stereo_chemical_props.txt \"{ALPHAFOLD_COMMON_DIR}\"\n",
    "\n",
    "            # Download alphafold_params_colab_2021-10-27.tar\n",
    "            !mkdir --parents \"{PARAMS_DIR}\"\n",
    "            !wget -O \"{PARAMS_PATH}\" \"{SOURCE_URL}\"\n",
    "            pbar.update(27)\n",
    "\n",
    "            # Un-tar alphafold_params_colab_2021-10-27.tar\n",
    "            !tar --extract --verbose --file=\"{PARAMS_PATH}\" --directory=\"{PARAMS_DIR}\" --preserve-permissions\n",
    "            # !rm \"{PARAMS_PATH}\"\n",
    "            pbar.update(55)\n",
    "\n",
    "except subprocess.CalledProcessError:\n",
    "    print(captured)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8926b7d5529"
   },
   "source": [
    "配置GPU加速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "collapsed": true,
    "id": "VzJ5iMjTtoZw",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Confirm accelerator configuration\n",
    "import jax\n",
    "\n",
    "if jax.local_devices()[0].platform == \"tpu\":\n",
    "    raise RuntimeError(\n",
    "        \"TPU runtime not supported. Please configure GPU acceleration on the VM.\"\n",
    "    )\n",
    "elif jax.local_devices()[0].platform == \"cpu\":\n",
    "    print(\n",
    "        \"CPU-only runtime is not recommended, because prediction execution will be slow. For better performance, consider GPU acceleration on the VM.\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"Running with {jax.local_devices()[0].device_kind} GPU\")\n",
    "\n",
    "# Make sure all necessary environment variables are set.\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_FORCE_UNIFIED_MEMORY\"] = \"1\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4JpOs6oA-QS"
   },
   "source": [
    "## 进行预测\n",
    "\n",
    "请将您的蛋白质序列粘贴到下面的文本框中，然后通过“运行”>“运行所选单元格及以下所有单元格”来运行剩余单元格。您也可以通过按左侧的“播放”按钮逐个运行单元格。\n",
    "\n",
    "请注意，根据蛋白质长度和所分配的 GPU 类型，搜索数据库和实际预测可能需要一些时间，从几分钟到几小时不等（请参阅下面的常见问题解答）。\n",
    "\n",
    "开始之前，请输入要折叠的氨基酸序列⬇️\n",
    "\n",
    "如果您只输入一个序列，则将使用单体模型。如果输入多个序列，则将使用多聚体模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b310d44229d0"
   },
   "outputs": [],
   "source": [
    "# Input sequences (type: str)\n",
    "sequence_1 = \"MAAHKGAEHHHKAAEHHEQAAKHHHAAAEHHEKGEHEQAAHHADTAYAHHKHAEEHAAQAAKHDAEHHAPKPH\"\n",
    "sequence_2 = \"\"\n",
    "sequence_3 = \"\"\n",
    "sequence_4 = \"\"\n",
    "sequence_5 = \"\"\n",
    "sequence_6 = \"\"\n",
    "sequence_7 = \"\"\n",
    "sequence_8 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "collapsed": true,
    "id": "rowN0bVYLe9n",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from alphafold.notebooks import notebook_utils\n",
    "\n",
    "input_sequences = (\n",
    "    sequence_1,\n",
    "    sequence_2,\n",
    "    sequence_3,\n",
    "    sequence_4,\n",
    "    sequence_5,\n",
    "    sequence_6,\n",
    "    sequence_7,\n",
    "    sequence_8,\n",
    ")\n",
    "\n",
    "# If folding a complex target and all the input sequences are\n",
    "# prokaryotic then set `is_prokaryotic` to `True`. Set to `False`\n",
    "# otherwise or if the origin is unknown.\n",
    "\n",
    "is_prokaryote = False  # @param {type:\"boolean\"}\n",
    "\n",
    "MIN_SINGLE_SEQUENCE_LENGTH = 16\n",
    "MAX_SINGLE_SEQUENCE_LENGTH = 2500\n",
    "MAX_MULTIMER_LENGTH = 2500\n",
    "\n",
    "# Validate the input.\n",
    "sequences, model_type_to_use = notebook_utils.validate_input(\n",
    "    input_sequences=input_sequences,\n",
    "    min_length=MIN_SINGLE_SEQUENCE_LENGTH,\n",
    "    max_length=MAX_SINGLE_SEQUENCE_LENGTH,\n",
    "    max_multimer_length=MAX_MULTIMER_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "db551d4877ea"
   },
   "source": [
    "## 在基因数据库中搜索\n",
    "\n",
    "一旦执行了这个单元格，你将会看到关于多重序列比对（MSA）的统计信息，这些信息将会被AlphaFold使用。特别地，你将会看到每个残基在MSA中被相似序列覆盖的程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "collapsed": true,
    "id": "2tTeTTsLKPjB",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "import random\n",
    "from concurrent import futures\n",
    "from urllib import request\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import py3Dmol\n",
    "from alphafold.common import protein\n",
    "from alphafold.data import (feature_processing, msa_pairing, pipeline,\n",
    "                            pipeline_multimer)\n",
    "from alphafold.data.tools import jackhmmer\n",
    "from alphafold.model import config, data, model\n",
    "from alphafold.relax import relax, utils\n",
    "from IPython import display\n",
    "from ipywidgets import GridspecLayout, Output\n",
    "\n",
    "# Color bands for visualizing plddt\n",
    "PLDDT_BANDS = [\n",
    "    (0, 50, \"#FF7D45\"),\n",
    "    (50, 70, \"#FFDB13\"),\n",
    "    (70, 90, \"#65CBF3\"),\n",
    "    (90, 100, \"#0053D6\"),\n",
    "]\n",
    "\n",
    "# --- Find the closest source ---\n",
    "test_url_pattern = (\n",
    "    \"https://storage.googleapis.com/alphafold-colab{:s}/latest/uniref90_2021_03.fasta.1\"\n",
    ")\n",
    "ex = futures.ThreadPoolExecutor(3)\n",
    "\n",
    "\n",
    "def fetch(source):\n",
    "    request.urlretrieve(test_url_pattern.format(source))\n",
    "    return source\n",
    "\n",
    "\n",
    "fs = [ex.submit(fetch, source) for source in [\"\", \"-europe\", \"-asia\"]]\n",
    "source = None\n",
    "for f in futures.as_completed(fs):\n",
    "    source = f.result()\n",
    "    ex.shutdown()\n",
    "    break\n",
    "\n",
    "JACKHMMER_BINARY_PATH = \"/usr/bin/jackhmmer\"\n",
    "DB_ROOT_PATH = f\"https://storage.googleapis.com/alphafold-colab{source}/latest/\"\n",
    "# The z_value is the number of sequences in a database.\n",
    "MSA_DATABASES = [\n",
    "    {\n",
    "        \"db_name\": \"uniref90\",\n",
    "        \"db_path\": f\"{DB_ROOT_PATH}uniref90_2021_03.fasta\",\n",
    "        \"num_streamed_chunks\": 59,\n",
    "        \"z_value\": 135_301_051,\n",
    "    },\n",
    "    {\n",
    "        \"db_name\": \"smallbfd\",\n",
    "        \"db_path\": f\"{DB_ROOT_PATH}bfd-first_non_consensus_sequences.fasta\",\n",
    "        \"num_streamed_chunks\": 17,\n",
    "        \"z_value\": 65_984_053,\n",
    "    },\n",
    "    {\n",
    "        \"db_name\": \"mgnify\",\n",
    "        \"db_path\": f\"{DB_ROOT_PATH}mgy_clusters_2019_05.fasta\",\n",
    "        \"num_streamed_chunks\": 71,\n",
    "        \"z_value\": 304_820_129,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Search UniProt and construct the all_seq features only for heteromers, not homomers.\n",
    "if model_type_to_use == notebook_utils.ModelType.MULTIMER and len(set(sequences)) > 1:\n",
    "    MSA_DATABASES.extend(\n",
    "        [\n",
    "            # Swiss-Prot and TrEMBL are concatenated together as UniProt.\n",
    "            {\n",
    "                \"db_name\": \"uniprot\",\n",
    "                \"db_path\": f\"{DB_ROOT_PATH}uniprot_2021_03.fasta\",\n",
    "                \"num_streamed_chunks\": 98,\n",
    "                \"z_value\": 219_174_961 + 565_254,\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "TOTAL_JACKHMMER_CHUNKS = sum(cfg[\"num_streamed_chunks\"] for cfg in MSA_DATABASES)\n",
    "\n",
    "MAX_HITS = {\n",
    "    \"uniref90\": 10_000,\n",
    "    \"smallbfd\": 5_000,\n",
    "    \"mgnify\": 501,\n",
    "    \"uniprot\": 50_000,\n",
    "}\n",
    "\n",
    "\n",
    "def get_msa(fasta_path):\n",
    "    \"\"\"Searches for MSA for the given sequence using chunked Jackhmmer search.\"\"\"\n",
    "\n",
    "    # Run the search against chunks of genetic databases.\n",
    "    raw_msa_results = collections.defaultdict(list)\n",
    "    with tqdm.notebook.tqdm(\n",
    "        total=TOTAL_JACKHMMER_CHUNKS, bar_format=TQDM_BAR_FORMAT\n",
    "    ) as pbar:\n",
    "\n",
    "        def jackhmmer_chunk_callback(i):\n",
    "            pbar.update(n=1)\n",
    "\n",
    "        for db_config in MSA_DATABASES:\n",
    "            db_name = db_config[\"db_name\"]\n",
    "            pbar.set_description(f\"Searching {db_name}\")\n",
    "            jackhmmer_runner = jackhmmer.Jackhmmer(\n",
    "                binary_path=JACKHMMER_BINARY_PATH,\n",
    "                database_path=db_config[\"db_path\"],\n",
    "                get_tblout=True,\n",
    "                num_streamed_chunks=db_config[\"num_streamed_chunks\"],\n",
    "                streaming_callback=jackhmmer_chunk_callback,\n",
    "                z_value=db_config[\"z_value\"],\n",
    "            )\n",
    "            # Group the results by database name.\n",
    "            raw_msa_results[db_name].extend(jackhmmer_runner.query(fasta_path))\n",
    "\n",
    "    return raw_msa_results\n",
    "\n",
    "\n",
    "features_for_chain = {}\n",
    "raw_msa_results_for_sequence = {}\n",
    "for sequence_index, sequence in enumerate(sequences, start=1):\n",
    "    print(f\"\\nGetting MSA for sequence {sequence_index}\")\n",
    "\n",
    "    fasta_path = f\"target_{sequence_index}.fasta\"\n",
    "    with open(fasta_path, \"wt\") as f:\n",
    "        f.write(f\">query\\n{sequence}\")\n",
    "\n",
    "    # Don't do redundant work for multiple copies of the same chain in the multimer.\n",
    "    if sequence not in raw_msa_results_for_sequence:\n",
    "        raw_msa_results = get_msa(fasta_path=fasta_path)\n",
    "        raw_msa_results_for_sequence[sequence] = raw_msa_results\n",
    "    else:\n",
    "        raw_msa_results = copy.deepcopy(raw_msa_results_for_sequence[sequence])\n",
    "\n",
    "    # Extract the MSAs from the Stockholm files.\n",
    "    # NB: deduplication happens later in pipeline.make_msa_features.\n",
    "    single_chain_msas = []\n",
    "    uniprot_msa = None\n",
    "    for db_name, db_results in raw_msa_results.items():\n",
    "        merged_msa = notebook_utils.merge_chunked_msa(\n",
    "            results=db_results, max_hits=MAX_HITS.get(db_name)\n",
    "        )\n",
    "        if merged_msa.sequences and db_name != \"uniprot\":\n",
    "            single_chain_msas.append(merged_msa)\n",
    "            msa_size = len(set(merged_msa.sequences))\n",
    "            print(\n",
    "                f\"{msa_size} unique sequences found in {db_name} for sequence {sequence_index}\"\n",
    "            )\n",
    "        elif merged_msa.sequences and db_name == \"uniprot\":\n",
    "            uniprot_msa = merged_msa\n",
    "\n",
    "    notebook_utils.show_msa_info(\n",
    "        single_chain_msas=single_chain_msas, sequence_index=sequence_index\n",
    "    )\n",
    "\n",
    "    # Turn the raw data into model features.\n",
    "    feature_dict = {}\n",
    "    feature_dict.update(\n",
    "        pipeline.make_sequence_features(\n",
    "            sequence=sequence, description=\"query\", num_res=len(sequence)\n",
    "        )\n",
    "    )\n",
    "    feature_dict.update(pipeline.make_msa_features(msas=single_chain_msas))\n",
    "    # We don't use templates in AlphaFold notebook, add only empty placeholder features.\n",
    "    feature_dict.update(\n",
    "        notebook_utils.empty_placeholder_template_features(\n",
    "            num_templates=0, num_res=len(sequence)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Construct the all_seq features only for heteromers, not homomers.\n",
    "    if (\n",
    "        model_type_to_use == notebook_utils.ModelType.MULTIMER\n",
    "        and len(set(sequences)) > 1\n",
    "    ):\n",
    "        valid_feats = msa_pairing.MSA_FEATURES + (\n",
    "            \"msa_uniprot_accession_identifiers\",\n",
    "            \"msa_species_identifiers\",\n",
    "        )\n",
    "        all_seq_features = {\n",
    "            f\"{k}_all_seq\": v\n",
    "            for k, v in pipeline.make_msa_features([uniprot_msa]).items()\n",
    "            if k in valid_feats\n",
    "        }\n",
    "        feature_dict.update(all_seq_features)\n",
    "\n",
    "    features_for_chain[protein.PDB_CHAIN_IDS[sequence_index - 1]] = feature_dict\n",
    "\n",
    "\n",
    "# Do further feature post-processing depending on the model type.\n",
    "if model_type_to_use == notebook_utils.ModelType.MONOMER:\n",
    "    np_example = features_for_chain[protein.PDB_CHAIN_IDS[0]]\n",
    "\n",
    "elif model_type_to_use == notebook_utils.ModelType.MULTIMER:\n",
    "    all_chain_features = {}\n",
    "    for chain_id, chain_features in features_for_chain.items():\n",
    "        all_chain_features[chain_id] = pipeline_multimer.convert_monomer_features(\n",
    "            chain_features, chain_id\n",
    "        )\n",
    "\n",
    "    all_chain_features = pipeline_multimer.add_assembly_features(all_chain_features)\n",
    "\n",
    "    np_example = feature_processing.pair_and_merge(\n",
    "        all_chain_features=all_chain_features, is_prokaryote=is_prokaryote\n",
    "    )\n",
    "\n",
    "    # Pad MSA to avoid zero-sized extra_msa.\n",
    "    np_example = pipeline_multimer.pad_msa(np_example, min_num_seq=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9640643486bd"
   },
   "source": [
    "## 运行AlphaFold\n",
    "\n",
    "执行此单元格后，将在VM上保存一个名为“prediction.zip”的压缩文件，其中包含获得的预测结果，并可在边栏中下载到您的计算机上。如果您在松弛阶段遇到问题，您可以在下方禁用它。警告：这意味着预测结果可能具有令人分心的小立体化违规。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "collapsed": true,
    "id": "XUo6foMQxwS2",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "run_relax = True\n",
    "\n",
    "# --- Run the model ---\n",
    "if model_type_to_use == notebook_utils.ModelType.MONOMER:\n",
    "    model_names = config.MODEL_PRESETS[\"monomer\"] + (\"model_2_ptm\",)\n",
    "elif model_type_to_use == notebook_utils.ModelType.MULTIMER:\n",
    "    model_names = config.MODEL_PRESETS[\"multimer\"]\n",
    "\n",
    "output_dir = \"prediction\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "plddts = {}\n",
    "ranking_confidences = {}\n",
    "pae_outputs = {}\n",
    "unrelaxed_proteins = {}\n",
    "\n",
    "with tqdm.notebook.tqdm(total=len(model_names) + 1, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
    "    for model_name in model_names:\n",
    "        pbar.set_description(f\"Running {model_name}\")\n",
    "\n",
    "        cfg = config.model_config(model_name)\n",
    "        if model_type_to_use == notebook_utils.ModelType.MONOMER:\n",
    "            cfg.data.eval.num_ensemble = 1\n",
    "        elif model_type_to_use == notebook_utils.ModelType.MULTIMER:\n",
    "            cfg.model.num_ensemble_eval = 1\n",
    "        params = data.get_model_haiku_params(model_name, \"./alphafold/data\")\n",
    "        model_runner = model.RunModel(cfg, params)\n",
    "        processed_feature_dict = model_runner.process_features(\n",
    "            np_example, random_seed=0\n",
    "        )\n",
    "        prediction = model_runner.predict(\n",
    "            processed_feature_dict, random_seed=random.randrange(sys.maxsize)\n",
    "        )\n",
    "\n",
    "        mean_plddt = prediction[\"plddt\"].mean()\n",
    "\n",
    "        if model_type_to_use == notebook_utils.ModelType.MONOMER:\n",
    "            if \"predicted_aligned_error\" in prediction:\n",
    "                pae_outputs[model_name] = (\n",
    "                    prediction[\"predicted_aligned_error\"],\n",
    "                    prediction[\"max_predicted_aligned_error\"],\n",
    "                )\n",
    "            else:\n",
    "                # Monomer models are sorted by mean pLDDT. Do not put monomer pTM models here as they\n",
    "                # should never get selected.\n",
    "                ranking_confidences[model_name] = prediction[\"ranking_confidence\"]\n",
    "                plddts[model_name] = prediction[\"plddt\"]\n",
    "        elif model_type_to_use == notebook_utils.ModelType.MULTIMER:\n",
    "            # Multimer models are sorted by pTM+ipTM.\n",
    "            ranking_confidences[model_name] = prediction[\"ranking_confidence\"]\n",
    "            plddts[model_name] = prediction[\"plddt\"]\n",
    "            pae_outputs[model_name] = (\n",
    "                prediction[\"predicted_aligned_error\"],\n",
    "                prediction[\"max_predicted_aligned_error\"],\n",
    "            )\n",
    "\n",
    "        # Set the b-factors to the per-residue plddt.\n",
    "        final_atom_mask = prediction[\"structure_module\"][\"final_atom_mask\"]\n",
    "        b_factors = prediction[\"plddt\"][:, None] * final_atom_mask\n",
    "        unrelaxed_protein = protein.from_prediction(\n",
    "            processed_feature_dict,\n",
    "            prediction,\n",
    "            b_factors=b_factors,\n",
    "            remove_leading_feature_dimension=(\n",
    "                model_type_to_use == notebook_utils.ModelType.MONOMER\n",
    "            ),\n",
    "        )\n",
    "        unrelaxed_proteins[model_name] = unrelaxed_protein\n",
    "\n",
    "        # Delete unused outputs to save memory.\n",
    "        del model_runner\n",
    "        del params\n",
    "        del prediction\n",
    "        pbar.update(n=1)\n",
    "\n",
    "    # --- AMBER relax the best model ---\n",
    "\n",
    "    # Find the best model according to the mean pLDDT.\n",
    "    best_model_name = max(\n",
    "        ranking_confidences.keys(), key=lambda x: ranking_confidences[x]\n",
    "    )\n",
    "\n",
    "    if run_relax:\n",
    "        pbar.set_description(\"AMBER relaxation\")\n",
    "        amber_relaxer = relax.AmberRelaxation(\n",
    "            max_iterations=0,\n",
    "            tolerance=2.39,\n",
    "            stiffness=10.0,\n",
    "            exclude_residues=[],\n",
    "            max_outer_iterations=3,\n",
    "        )\n",
    "        relaxed_pdb, _, _ = amber_relaxer.process(\n",
    "            prot=unrelaxed_proteins[best_model_name]\n",
    "        )\n",
    "    else:\n",
    "        print(\"Warning: Running without the relaxation stage.\")\n",
    "        relaxed_pdb = protein.to_pdb(unrelaxed_proteins[best_model_name])\n",
    "    pbar.update(n=1)  # Finished AMBER relax.\n",
    "\n",
    "# Construct multiclass b-factors to indicate confidence bands\n",
    "# 0=very low, 1=low, 2=confident, 3=very high\n",
    "banded_b_factors = []\n",
    "for plddt in plddts[best_model_name]:\n",
    "    for idx, (min_val, max_val, _) in enumerate(PLDDT_BANDS):\n",
    "        if plddt >= min_val and plddt <= max_val:\n",
    "            banded_b_factors.append(idx)\n",
    "            break\n",
    "banded_b_factors = np.array(banded_b_factors)[:, None] * final_atom_mask\n",
    "to_visualize_pdb = utils.overwrite_b_factors(relaxed_pdb, banded_b_factors)\n",
    "\n",
    "\n",
    "# Write out the prediction\n",
    "pred_output_path = os.path.join(output_dir, \"selected_prediction.pdb\")\n",
    "with open(pred_output_path, \"w\") as f:\n",
    "    f.write(relaxed_pdb)\n",
    "\n",
    "\n",
    "# --- Visualise the prediction & confidence ---\n",
    "show_sidechains = True\n",
    "\n",
    "\n",
    "def plot_plddt_legend():\n",
    "    \"\"\"Plots the legend for pLDDT.\"\"\"\n",
    "    thresh = [\n",
    "        \"Very low (pLDDT < 50)\",\n",
    "        \"Low (70 > pLDDT > 50)\",\n",
    "        \"Confident (90 > pLDDT > 70)\",\n",
    "        \"Very high (pLDDT > 90)\",\n",
    "    ]\n",
    "\n",
    "    colors = [x[2] for x in PLDDT_BANDS]\n",
    "\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    for c in colors:\n",
    "        plt.bar(0, 0, color=c)\n",
    "    plt.legend(thresh, frameon=False, loc=\"center\", fontsize=20)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    plt.title(\"Model Confidence\", fontsize=20, pad=20)\n",
    "    return plt\n",
    "\n",
    "\n",
    "# Show the structure coloured by chain if the multimer model has been used.\n",
    "if model_type_to_use == notebook_utils.ModelType.MULTIMER:\n",
    "    multichain_view = py3Dmol.view(width=800, height=600)\n",
    "    multichain_view.addModelsAsFrames(to_visualize_pdb)\n",
    "    multichain_style = {\"cartoon\": {\"colorscheme\": \"chain\"}}\n",
    "    multichain_view.setStyle({\"model\": -1}, multichain_style)\n",
    "    multichain_view.zoomTo()\n",
    "    multichain_view.show()\n",
    "\n",
    "# Color the structure by per-residue pLDDT\n",
    "color_map = {i: bands[2] for i, bands in enumerate(PLDDT_BANDS)}\n",
    "view = py3Dmol.view(width=800, height=600)\n",
    "view.addModelsAsFrames(to_visualize_pdb)\n",
    "style = {\"cartoon\": {\"colorscheme\": {\"prop\": \"b\", \"map\": color_map}}}\n",
    "if show_sidechains:\n",
    "    style[\"stick\"] = {}\n",
    "view.setStyle({\"model\": -1}, style)\n",
    "view.zoomTo()\n",
    "\n",
    "grid = GridspecLayout(1, 2)\n",
    "out = Output()\n",
    "with out:\n",
    "    view.show()\n",
    "grid[0, 0] = out\n",
    "\n",
    "out = Output()\n",
    "with out:\n",
    "    plot_plddt_legend().show()\n",
    "grid[0, 1] = out\n",
    "\n",
    "display.display(grid)\n",
    "\n",
    "# Display pLDDT and predicted aligned error (if output by the model).\n",
    "if pae_outputs:\n",
    "    num_plots = 2\n",
    "else:\n",
    "    num_plots = 1\n",
    "\n",
    "plt.figure(figsize=[8 * num_plots, 6])\n",
    "plt.subplot(1, num_plots, 1)\n",
    "plt.plot(plddts[best_model_name])\n",
    "plt.title(\"Predicted LDDT\")\n",
    "plt.xlabel(\"Residue\")\n",
    "plt.ylabel(\"pLDDT\")\n",
    "\n",
    "if num_plots == 2:\n",
    "    plt.subplot(1, 2, 2)\n",
    "    pae, max_pae = list(pae_outputs.values())[0]\n",
    "    plt.imshow(pae, vmin=0.0, vmax=max_pae, cmap=\"Greens_r\")\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Display lines at chain boundaries.\n",
    "    best_unrelaxed_prot = unrelaxed_proteins[best_model_name]\n",
    "    total_num_res = best_unrelaxed_prot.residue_index.shape[-1]\n",
    "    chain_ids = best_unrelaxed_prot.chain_index\n",
    "    for chain_boundary in np.nonzero(chain_ids[:-1] - chain_ids[1:]):\n",
    "        if chain_boundary.size:\n",
    "            plt.plot([0, total_num_res], [chain_boundary, chain_boundary], color=\"red\")\n",
    "            plt.plot([chain_boundary, chain_boundary], [0, total_num_res], color=\"red\")\n",
    "\n",
    "    plt.title(\"Predicted Aligned Error\")\n",
    "    plt.xlabel(\"Scored residue\")\n",
    "    plt.ylabel(\"Aligned residue\")\n",
    "\n",
    "# Save the predicted aligned error (if it exists).\n",
    "pae_output_path = os.path.join(output_dir, \"predicted_aligned_error.json\")\n",
    "if pae_outputs:\n",
    "    # Save predicted aligned error in the same format as the AF EMBL DB.\n",
    "    pae_data = notebook_utils.get_pae_json(pae=pae, max_pae=max_pae.item())\n",
    "    with open(pae_output_path, \"w\") as f:\n",
    "        f.write(pae_data)\n",
    "\n",
    "!zip -q -r {output_dir}.zip {output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUQAn5LYC5n4"
   },
   "source": [
    "### 解释预测\n",
    "\n",
    "通常预测的LDDT（pLDDT）最适用于领域内的置信度，而预测的对齐误差（PAE）最适用于确定领域间或链间的置信度。\n",
    "\n",
    "请参阅[AlphaFold方法论文](https://www.nature.com/articles/s41586-021-03819-2)，[人类蛋白质组的AlphaFold预测论文](https://www.nature.com/articles/s41586-021-03828-1)，以及[AlphaFold-Multimer论文](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v1)，以及我们的[常见问题解答](https://alphafold.ebi.ac.uk/faq)以了解如何解释AlphaFold的预测结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeb2z8DIA4om"
   },
   "source": [
    "## 常见问题解答和故障排除\n",
    "\n",
    "\n",
    "*   如何为我的蛋白质获取预测的蛋白质结构？\n",
    "    *   将笔记本连接到Jupyter内核“Python 3（ipykernel）”。\n",
    "    *   将您的蛋白质的氨基酸序列（不包括任何标题）粘贴到“Making a Prediction”中的变量sequence_1中。\n",
    "    *   运行笔记本中的所有单元格，可以逐个运行，也可以通过“Kernel” / “Restart Kernel and Run All Cells...”来运行。\n",
    "    *   一旦所有单元格都被执行，预测的蛋白质结构将被下载。注意：这可能需要几分钟到几小时 - 请参见下文。\n",
    "*   这需要多长时间？\n",
    "    *   对基因数据库的搜索可能需要几分钟到几小时。\n",
    "    *   运行AlphaFold并生成预测可能需要几分钟到几小时，具体取决于您的蛋白质长度以及您的VM可以访问的GPU类型。\n",
    "*   我的笔记本似乎不再做任何事情，我应该怎么办？\n",
    "    *   有些步骤可能需要几分钟到几小时才能完成。\n",
    "    *   如果什么都没发生或者收到错误消息，请尝试通过“Kernel” / “Restart Kernel and Run All Cells...”重新启动您的笔记本运行时。\n",
    "    *   如果这种方法不起作用，请尝试重置您的GCloud Console中的虚拟机（“Compute Engine” / “VM Instances”）。\n",
    "*   这和AlphaFold的开源版本有什么区别？\n",
    "    *   这个笔记本版本的AlphaFold只搜索BFD数据集的选定部分，目前不使用模板，因此与AlphaFold的完整版本相比，其准确性降低，完整版本描述在[AlphaFold论文](https://doi.org/10.1038/s41586-021-03819-2)和[Github存储库](https://github.com/deepmind/alphafold/)中（完整版本可通过推断脚本获得）。\n",
    "*   我收到了一个“笔记本需要高RAM”的警告，我该怎么办？\n",
    "    *   在“Compute Engine” / “VM Instances”控制台菜单中，您可以重新配置主机VM设置。请参阅[更改已停止实例的VM实例的机器类型](https://cloud.google.com/compute/docs/instances/changing-machine-type-of-stopped-instance)获取说明。\n",
    "*   这个工具会在我的电脑上安装什么吗？\n",
    "    *   不会，一切都在您的Google Cloud项目中的VM实例中进行。\n",
    "*   我应该如何分享反馈和错误报告？\n",
    "    *   请将任何反馈和错误报告作为[问题](https://github.com/GoogleCloudPlatform/vertex-ai-samples/issues)在Github上分享。\n",
    "\n",
    "\n",
    "## 相关工作\n",
    "\n",
    "请查看社区提供的这些Colab笔记本（请注意，这些笔记本可能与我们验证的AlphaFold系统有所不同，我们无法保证其准确性）：\n",
    "\n",
    "*   由Sergey Ovchinnikov、Milot Mirdita和Martin Steinegger提供的[ColabFold AlphaFold2笔记本](https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/AlphaFold2.ipynb)，它使用在Södinglab托管的API，基于MMseqs2服务器进行多序列对齐创建。（[Mirdita等人2019，生物信息学](https://academic.oup.com/bioinformatics/article/35/16/2856/5280135)）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfPhvYgKC81B"
   },
   "source": [
    "# 许可和免责声明\n",
    "\n",
    "这不是一个官方支持的谷歌产品。\n",
    "\n",
    "此笔记本和其他提供的信息仅用于理论建模，使用时应谨慎。它以“原样”提供，不提供任何明示或暗示的任何形式的保证。信息并非用作专业医疗建议，诊断或治疗的替代，并不构成医疗或其他专业建议。\n",
    "\n",
    "版权所有 2021 DeepMind Technologies Limited。\n",
    "\n",
    "## AlphaFold 代码许可\n",
    "\n",
    "根据Apache 许可证，第2版许可（“许可证”）授权；您不能在不遵守许可证的情况下使用此文件。您可以在 https://www.apache.org/licenses/LICENSE-2.0 获取许可证的副本。\n",
    "\n",
    "除非适用法律要求或书面同意，根据许可证分发的软件以“原样”分发，不提供任何形式的保证或条件，无论是明示的还是暗示的。请查看许可证以获取管理权限和限制的具体语言。\n",
    "\n",
    "## 模型参数许可\n",
    "\n",
    "AlphaFold 参数根据知识共享署名4.0国际（CC BY 4.0）许可协议提供。详细信息请参阅：https://creativecommons.org/licenses/by/4.0/legalcode\n",
    "\n",
    "## 第三方软件\n",
    "\n",
    "在 AlphaFold 读我档案的[致谢部分](https://github.com/deepmind/alphafold/#acknowledgements)中提到的第三方软件、库或代码的使用可能受到单独的条款和条件或许可证规定的约束。您使用第三方软件、库或代码受到这些条款的约束，您应在使用之前检查您是否能够遵守任何适用的限制或条款和条件。\n",
    "\n",
    "## 镜像数据库\n",
    "\n",
    "以下数据库由 DeepMind 镜像，可在以下位置引用：\n",
    "- UniProt：v2021\\_03（未修改），由The UniProt Consortium 提供，根据[知识共享署名-非商业性使用-NoDerivatives 4.0国际许可](http://creativecommons.org/licenses/by-nd/4.0/)提供。\n",
    "- UniRef90：v2021\\_03（未修改），由The UniProt Consortium 提供，根据[知识共享署名-非商业性使用-NoDerivatives 4.0国际许可](http://creativecommons.org/licenses/by-nd/4.0/)提供。\n",
    "- MGnify：v2019\\_05（未修改），由Mitchell AL等人提供，免除所有版权限制，并根据[CC0 1.0通用（CC0 1.0）公共领域奉献](https://creativecommons.org/publicdomain/zero/1.0/)完全和免费提供，供非商业和商业使用。\n",
    "- BFD：（已修改），由Steinegger M.和Söding J. 提供，由 DeepMind 修改，根据[知识共享署名-相同方式共享 4.0 国际许可协议](https://creativecommons.org/licenses/by/4.0/)提供。有关详细信息，请参阅[AlphaFold 蛋白质组学论文](https://www.nature.com/articles/s41586-021-03828-1)的方法部分。"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AlphaFold.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
