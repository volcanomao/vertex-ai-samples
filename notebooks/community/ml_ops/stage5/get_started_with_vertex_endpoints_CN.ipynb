{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "# GCP上的端到端机器学习：MLOps阶段5：部署：使用Vertex AI端点开始\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage5/get_started_with_vertex_endpoints.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage5/get_started_with_vertex_endpoints.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage5/get_started_with_vertex_endpoints.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>         \n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何使用Vertex AI SDK来创建和使用“Vertex AI 终端节点”资源来为模型提供服务。Vertex AI 终端节点提供了将服务二进制文件和服务基础设施虚拟化的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9402cfbdc2d"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用`Vertex AI Endpoint`资源。\n",
    "\n",
    "本教程使用以下 Google Cloud ML 服务和资源：\n",
    "\n",
    "- `Vertex AI Endpoints`\n",
    "- `Vertex AI Models`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 创建一个`Endpoint`资源。\n",
    "- 列出所有的`Endpoint`资源。\n",
    "- 根据查询过滤器列出`Endpoint`资源。\n",
    "- 配置一个`Model`资源的serving二进制文件，用于部署到一个`Endpoint`资源。\n",
    "- 将单个`Model`资源部署到一个`Endpoint`资源。\n",
    "- 获取已部署的`Model`资源的部署设置。\n",
    "- 配置自动缩放。\n",
    "- 将多个`Model`资源部署到一个`Endpoint`资源，并配置流量分担。\n",
    "- 动态更改`Endpoint`资源的流量分担。\n",
    "- 从一个`Endpoint`资源中取消部署一个单个`Model`资源。\n",
    "- 从一个`Endpoint`资源中取消部署所有的`Model`资源。\n",
    "- 删除一个`Endpoint`资源。\n",
    "- 在流水线中：创建一个`Endpoint`资源并将一个现有的`Model`资源部署到`Endpoint`资源。\n",
    "- 在流水线中：将一个现有的`Model`资源部署到一个现有的`Endpoint`资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:iris,lcn"
   },
   "source": [
    "数据集\n",
    "\n",
    "本教程使用了来自TensorFlow Hub的预训练图像分类模型，该模型是在ImageNet数据集上训练的。\n",
    "\n",
    "了解更多有关[ResNet V2预训练模型](https://tfhub.dev/google/imagenet/resnet_v2_101/classification/5)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "### 成本\n",
    "\n",
    "此教程使用谷歌云的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* 云存储\n",
    "\n",
    "了解[Vertex AI\n",
    "定价](https://cloud.google.com/vertex-ai/pricing)和[云存储\n",
    "定价](https://cloud.google.com/storage/pricing)，并使用[Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "根据您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip"
   },
   "source": [
    "安装以下软件包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "! pip3 install --upgrade google-cloud-aiplatform $USER_FLAG -q\n",
    "! pip3 install --upgrade google-cloud-pipeline-components $USER_FLAG -q\n",
    "! pip3 install tensorflow-hub $USER_FLAG -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhq5zEbGg0XX"
   },
   "source": [
    "### 重启内核\n",
    "\n",
    "在安装了额外的包之后，您需要重启笔记本内核，以便它能够找到这些包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzrelQZ22IZj"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### GPU 运行时\n",
    "\n",
    "*如果可以的话，请确保在 GPU 运行时下运行此笔记本。在 Colab 中，选择* **Runtime > Change Runtime Type > GPU**\n",
    "\n",
    "### 设置 Google Cloud 项目\n",
    "\n",
    "**以下步骤是必需的，无论您使用何种笔记本环境。**\n",
    "\n",
    "1. [选择或创建一个 Google Cloud 项目](https://console.cloud.google.com/cloud-resource-manager)。当您第一次创建帐户时，您将获得 $300 的免费信用用于计算/存储成本。\n",
    "\n",
    "2. [确保您的项目已启用计费。](https://cloud.google.com/billing/docs/how-to/modify-project)\n",
    "\n",
    "3. [启用以下 API: Vertex AI APIs, Compute Engine APIs, and Cloud Storage.](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component,storage-component.googleapis.com)\n",
    "\n",
    "4. 如果您在本地运行此笔记本，您需要安装[Cloud SDK]((https://cloud.google.com/sdk))。\n",
    "\n",
    "5. 在下面的单元格中输入您的项目 ID。然后运行该单元格，确保 Cloud SDK 使用正确的项目来运行此笔记本中的所有命令。\n",
    "\n",
    "**注意**: Jupyter 运行以 `!` 为前缀的行作为 shell 命令，并插值以 `$` 为前缀的 Python 变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用 `gcloud` 获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 区域\n",
    "\n",
    "您还可以更改`REGION`变量，该变量用于整个笔记本的操作。以下是Vertex AI支持的区域。我们建议您选择距离您最近的区域。\n",
    "\n",
    "- 美洲: `us-central1`\n",
    "- 欧洲: `europe-west4`\n",
    "- 亚太: `asia-east1`\n",
    "\n",
    "您可能不应该使用多区域存储桶进行Vertex AI训练。并非所有区域均为所有Vertex AI服务提供支持。\n",
    "\n",
    "了解有关[Vertex AI区域](https://cloud.google.com/vertex-ai/docs/general/locations)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "时间戳\n",
    "\n",
    "如果您在直播教程会话中，您可能会使用共享测试账号或项目。为了避免在创建的资源中用户之间发生命名冲突，您必须为每个实例会话创建一个时间戳，并将时间戳追加到您在本教程中创建的资源名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "timestamp"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 验证您的Google Cloud帐户\n",
    "\n",
    "**如果您正在使用Vertex AI Workbench笔记本**，则您的环境已经通过身份验证。\n",
    "\n",
    "**如果您正在使用Colab**，请运行下面的单元格，并在提示时按照说明通过oAuth验证您的帐户。\n",
    "\n",
    "**否则**，请按照以下步骤操作：\n",
    "\n",
    "在Cloud Console中，转到[创建服务帐户密钥](https://console.cloud.google.com/apis/credentials/serviceaccountkey)页面。\n",
    "\n",
    "**点击创建服务帐户**。\n",
    "\n",
    "在**服务帐户名称**字段中，输入一个名称，然后点击**创建**。\n",
    "\n",
    "在**授予此服务帐户访问权限的项目**部分，点击角色下拉列表。在过滤框中输入“Vertex”，然后选择**Vertex管理员**。在过滤框中输入“Storage对象管理员”，然后选择**Storage对象管理员**。\n",
    "\n",
    "点击创建。一个包含您密钥的JSON文件将下载到您的本地环境。\n",
    "\n",
    "在下面的单元格中，将您的服务帐户密钥路径输入为GOOGLE_APPLICATION_CREDENTIALS变量，并运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcp_authenticate"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "创建一个云存储存储桶\n",
    "\n",
    "**无论您使用的是哪个笔记本环境，都需要执行以下步骤。**\n",
    "\n",
    "当您初始化用于 Python 的 Vertex AI SDK 时，您需要指定一个云存储暂存桶。暂存桶是您的数据集和模型资源在会话之间保留的位置。\n",
    "\n",
    "请在下方设置您的云存储存储桶的名称。存储桶的名称必须在全局范围内在所有谷歌云项目中是唯一的，包括您组织之外的项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"[your-bucket-name]\":\n",
    "    BUCKET_NAME = PROJECT_ID + \"aip-\" + TIMESTAMP\n",
    "    BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有在您的存储桶不存在时才运行以下单元格来创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "最后，通过检查Cloud Storage桶的内容来验证访问权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。\n",
    "### 导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "### 初始化用于 Python 的 Vertex AI SDK\n",
    "\n",
    "为您的项目和相应的存储桶初始化 Python 版本的 Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "source": [
    "设置硬件加速器\n",
    "\n",
    "您可以为训练和预测设置硬件加速器。\n",
    "\n",
    "将变量`DEPLOY_GPU/DEPLOY_NGPU`设置为使用支持 GPU 的容器映像，并为虚拟机实例（VM）分配的 GPU 数量。例如，要使用一个GPU容器映像，并为每个VM分配4个 Nvidia Telsa K80 GPU，您需要指定:\n",
    "\n",
    "    (aip.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
    "\n",
    "否则，指定`(None, None)`以使用一个容器映像在CPU上运行。\n",
    "\n",
    "了解更多关于[您区域的硬件加速器支持](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)。\n",
    "\n",
    "*注意*: 2.3 之前的 TF 发布版本因 GPU 支持而无法加载此教程中的自定义模型。这是一个已知问题，在 TF 2.3 中已修复。这是由生成在服务功能中的静态图运算导致的。如果您在自己的自定义模型中遇到此问题，请使用支持 GPU 的 TF 2.3 容器映像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_DEPLOY_GPU\"):\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (\n",
    "        aip.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "        int(os.getenv(\"IS_TESTING_DEPLOY_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction"
   },
   "source": [
    "设置预构建的容器\n",
    "\n",
    "设置用于预测的预构建Docker容器镜像。\n",
    "\n",
    "有关最新列表，请参阅[用于预测的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:training,prediction"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TF\"):\n",
    "    TF = os.getenv(\"IS_TESTING_TF\")\n",
    "else:\n",
    "    TF = \"2.5\".replace(\".\", \"-\")\n",
    "\n",
    "if TF[0] == \"2\":\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf2-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf2-cpu.{}\".format(TF)\n",
    "else:\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "\n",
    "DEPLOY_IMAGE = \"{}-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], DEPLOY_VERSION\n",
    ")\n",
    "\n",
    "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU, DEPLOY_NGPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于预测的机器类型。\n",
    "\n",
    "- 设置变量`DEPLOY_COMPUTE`以配置用于预测的虚拟机的计算资源。\n",
    "- `机器类型`\n",
    "   - `n1-standard`：每个虚拟CPU 3.75GB内存。\n",
    "   - `n1-highmem`：每个虚拟CPU 6.5GB内存。\n",
    "   - `n1-highcpu`：每个虚拟CPU 0.9GB内存。\n",
    "- `vCPUs`：\\ [2、4、8、16、32、64、96 \\]的数量。\n",
    "\n",
    "*注意：您也可以使用n2和e2机器类型进行训练和部署，但它们不支持GPU*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_DEPLOY_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_DEPLOY_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8128b8ff025"
   },
   "source": [
    "从TensorFlow Hub获取预训练模型\n",
    "\n",
    "为了演示目的，本教程使用了来自TensorFlow Hub（TFHub）的预训练模型，然后将其上传到“Vertex AI Model”资源中。一旦您拥有了“Vertex AI Model”资源，就可以将模型部署到“Vertex AI Endpoint”资源中。\n",
    "\n",
    "### 下载预训练模型\n",
    "\n",
    "首先，您需要从TensorFlow Hub下载预训练模型。该模型将作为一个TF.Keras层进行下载。在本例中，为了完成模型，您将使用下载的TFHub模型创建一个`Sequential()`模型，并指定模型的输入形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c55fa4c826f7"
   },
   "outputs": [],
   "source": [
    "tfhub_model = tf.keras.Sequential(\n",
    "    [hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_101/classification/5\")]\n",
    ")\n",
    "\n",
    "tfhub_model.build([None, 224, 224, 3])\n",
    "\n",
    "tfhub_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63de49055083"
   },
   "source": [
    "### 保存模型工件\n",
    "\n",
    "在这一点上，模型已经加载到内存中。接下来，您需要将模型工件保存到云存储位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64618c713db9"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = BUCKET_URI + \"/model\"\n",
    "tfhub_model.save(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8ce91147c93"
   },
   "source": [
    "### 将TensorFlow Hub模型上传到“Vertex AI Model”资源\n",
    "\n",
    "最后，您将来自TFHub模型的模型文件上传到“Vertex AI Model”资源。\n",
    "\n",
    "*注意：*当您将模型文件上传到“Vertex Model”资源时，您需要指定相应的部署容器镜像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad61e1429512"
   },
   "outputs": [],
   "source": [
    "model = aip.Model.upload(\n",
    "    display_name=\"example_\" + TIMESTAMP,\n",
    "    artifact_uri=MODEL_DIR,\n",
    "    serving_container_image_uri=DEPLOY_IMAGE,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "628de0914ba1"
   },
   "source": [
    "## 创建 `Endpoint` 资源\n",
    "\n",
    "您可以使用 `Endpoint.create()` 方法创建一个 `Endpoint` 资源。至少，您需要为端点指定显示名称。可选地，您可以指定项目和位置（区域）；否则，设置会继承您在使用 `init()` 方法初始化 Vertex AI SDK 时设置的值。\n",
    "\n",
    "在这个例子中，指定了以下参数：\n",
    "\n",
    "- `display_name`：`Endpoint` 资源的可读名称。\n",
    "- `project`：您的项目 ID。\n",
    "- `location`：您的区域。\n",
    "- `labels`：（可选）以键值对形式定义的用于 `Endpoint` 的用户自定义元数据。\n",
    "\n",
    "该方法返回一个 `Endpoint` 对象。\n",
    "\n",
    "了解更多关于 [Vertex AI Endpoints](https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ea443f9593b"
   },
   "outputs": [],
   "source": [
    "endpoint = aip.Endpoint.create(\n",
    "    display_name=\"example_\" + TIMESTAMP,\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    labels={\"your_key\": \"your_value\"},\n",
    ")\n",
    "\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15d2ebdb1a03"
   },
   "source": [
    "获取“Endpoint”资源的详细信息\n",
    "\n",
    "您可以使用属性“gca_resource”获取“Endpoint”对象的基础详细信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddb9410f2570"
   },
   "outputs": [],
   "source": [
    "print(endpoint.gca_resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97a8be4c9b43"
   },
   "source": [
    "### 列出`端点`\n",
    "\n",
    "方法 `Endpoint.list()` 将返回您的项目所有`端点`资源的列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fbf34c5dccf"
   },
   "outputs": [],
   "source": [
    "endpoints = aip.Endpoint.list()\n",
    "print(len(endpoints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fe21bfa19cb"
   },
   "source": [
    "### 使用过滤器列出`Endpoints`\n",
    "\n",
    "您可以使用参数`filter`来缩小从`list()`方法返回的`Endpoint`资源。 参数的格式如下：\n",
    "\n",
    "    filter='<endpoint-property>=<value>[AND <endpoint-property>=<value>, ...]'\n",
    "    \n",
    "在这个例子中，您可以根据单个`Endpoint`属性`display_name`进行过滤。\n",
    "\n",
    "如果`list()`方法返回多个`Endpoints`，您可以使用参数`order_by`对它们进行排序。 参数的格式如下：\n",
    "\n",
    "    order_by='<endpoint-property?'\n",
    "    \n",
    "在这个例子中，您通过`Endpoint`属性`create_time`对返回的列表进行排序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dde741d7e5cd"
   },
   "outputs": [],
   "source": [
    "aip.Endpoint.list(filter=\"display_name=example_\" + TIMESTAMP, order_by=\"create_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ca3fa3f6a894"
   },
   "source": [
    "## 将`Model`资源部署到`Endpoint`资源。\n",
    "\n",
    "您可以将一个或多个`Vertex AI Model`资源实例部署到同一个端点上。每个部署的`Vertex AI Model`资源都将拥有自己的用于服务二进制文件的部署容器。\n",
    "\n",
    "*注意：* 在这个例子中，您在上传模型文件到`Vertex AI Model`资源的前一步中指定了TFHub模型的部署容器。\n",
    "\n",
    "### 部署单个`Endpoint`资源\n",
    "\n",
    "在下一个例子中，您将一个`Vertex AI Model`资源部署到一个`Vertex AI Endpoint`资源中。`Vertex AI Model`资源已经为它定义了部署容器镜像。要部署，您需要指定以下额外的配置设置：\n",
    "\n",
    "- 机器类型。\n",
    "- GPU的类型和数量（如果有）。\n",
    "- 静态、手动或自动扩展的VM实例。\n",
    "\n",
    "在这个例子中，您以最少的指定参数部署模型，如下：\n",
    "\n",
    "- `model`：`Model`资源。\n",
    "- `deployed_model_displayed_name`：部署模型实例的人类可读的名称。\n",
    "- `machine_type`：每个VM实例的机器类型。\n",
    "\n",
    "由于资源预设要求，这可能需要几分钟时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e93b034a72f"
   },
   "outputs": [],
   "source": [
    "response = endpoint.deploy(\n",
    "    model=model,\n",
    "    deployed_model_display_name=\"example_\" + TIMESTAMP,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    ")\n",
    "\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1ae5a228adb"
   },
   "source": [
    "获取部署模型的信息\n",
    "\n",
    "您可以从`Endpoint`资源配置数据`gca_resource.deployed_models`中获取部署模型的部署设置。在这个例子中，只有一个模型被部署 -- 因此引用了下标`[0]`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5864deb1fd90"
   },
   "outputs": [],
   "source": [
    "print(endpoint.gca_resource.deployed_models[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cf4e3ce528b"
   },
   "source": [
    "### 从 `Endpoint` 资源中撤销 `Model` 资源\n",
    "\n",
    "当一个 `Model` 资源被部署到一个 `Endpoint` 资源时，已部署的 `Model` 资源实例会被分配一个 ID -- 通常称为已部署的模型 ID。\n",
    "\n",
    "您可以使用 `undeploy()` 方法撤销特定的 `Model` 资源实例，具有以下参数：\n",
    "\n",
    "- `deployed_model_id`：已部署模型分配的ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69557a907de7"
   },
   "outputs": [],
   "source": [
    "deployed_model_id = endpoint.gca_resource.deployed_models[0].id\n",
    "print(deployed_model_id)\n",
    "\n",
    "endpoint.undeploy(deployed_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1d2930d207c"
   },
   "source": [
    "## 配置 GPU 资源和扩展规模\n",
    "\n",
    "在下一个示例中，您还可以为硬件加速器（GPU）和 VM 实例数量配置部署的模型，具有以下附加参数：\n",
    "\n",
    "- `accelerator_type`：硬件加速器（GPU）的类型。\n",
    "- `accelerator_count`：每个 VM 实例的硬件加速器数量。\n",
    "- `min_replica_count`：自动扩展的最小 VM 实例数。*注意：* 必须至少为一。\n",
    "- `max_replica_count`：自动扩展的最大 VM 实例数。\n",
    "\n",
    "`Vertex AI Endpoints` 支持以下类型的扩展规模。\n",
    "\n",
    "- 单个实例：最小和最大复制计数均设置为 1。\n",
    "- 手动扩展：最小和最大复制计数设置为大于 1 的相同值。在这种情况下，(最大) VM 实例数量在启动时配置并保持恒定。\n",
    "- 自动扩展：最大复制计数大于最小复制计数。在启动时，将配置最小数量的 VM 实例，并根据负载情况动态增加到最大复制计数，然后再减少至最小复制计数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e976cbb58988"
   },
   "outputs": [],
   "source": [
    "MIN_NODES = 1\n",
    "MAX_NODES = 2\n",
    "\n",
    "\n",
    "response = endpoint.deploy(\n",
    "    model=model,\n",
    "    deployed_model_display_name=\"example_\" + TIMESTAMP,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    accelerator_type=DEPLOY_GPU,\n",
    "    accelerator_count=DEPLOY_NGPU,\n",
    "    min_replica_count=MIN_NODES,\n",
    "    max_replica_count=MAX_NODES,\n",
    ")\n",
    "\n",
    "deployed_model_id = endpoint.gca_resource.deployed_models[0].id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "805028a58684"
   },
   "source": [
    "### 将多个 `Model` 资源部署到一个 `Endpoint` 资源\n",
    "\n",
    "一个 `Endpoint` 资源可以有多个部署的模型。当向一个 `Endpoint` 发送预测请求时，它将根据负载均衡路由到其中一个部署的模型。在同一个 `Endpoint` 资源上部署的所有模型必须是同质的 -- 即，具有相同的输入向量和输出。\n",
    "\n",
    "当您将多个 `Model` 资源部署到一个 `Endpoint` 时，你需要指定如何在不同部署的 `Model` 资源之间分配预测流量。一个常见的用法是进行 `金丝雀发布`，其中有一个新的生产版本的模型，并逐步将其推出 -- 观察对新模型没有负面影响。\n",
    "\n",
    "参数 `traffic_split` 的格式如下：\n",
    "\n",
    "{ \"0\": 百分比, deploy_model_id: 百分比, ... }\n",
    "\n",
    "键 \"0\" 是要部署的模型。在这个例子中，它将占到 10%。每个后续的键/值对都指的是现有部署模型，其中键是部署模型的ID，值是该模型的新百分比。所有值必须加起来等于 100（100%）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0abec0bf236"
   },
   "outputs": [],
   "source": [
    "response = endpoint.deploy(\n",
    "    model=model,\n",
    "    deployed_model_display_name=\"example_\" + TIMESTAMP,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    traffic_split={\"0\": 10, deployed_model_id: 90},\n",
    ")\n",
    "\n",
    "print(endpoint.gca_resource.deployed_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "968938d30a69"
   },
   "source": [
    "调整流量分流\n",
    "\n",
    "目前，在SDK中不支持重新配置流量分流（但将来会支持）。您可以使用GAPIC API接口动态重新配置流量分流。动态重新配置流量分流的一个示例是逐步推出金丝雀版本。\n",
    "\n",
    "要实现这一点，您需要：\n",
    "\n",
    "1. 使用调用`gapic.EndpointServiceClient()`创建客户端接口\n",
    "2. 使用方法`get_endpoint()`获取相应端点的GAPIC对象\n",
    "3. 更新内存中的GAPIC端点对象中的流量分流\n",
    "4. 使用方法`update_endpoint()`来动态更新负载均衡器上`Endpoint`资源的流量分流设置。\n",
    "\n",
    "#### 创建客户端接口\n",
    "\n",
    "首先，创建GAPIC客户端接口。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a214c49d5924"
   },
   "outputs": [],
   "source": [
    "# API service endpoint\n",
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "\n",
    "# Vertex location root path for your dataset, model and endpoint resources\n",
    "PARENT = \"projects/\" + PROJECT_ID + \"/locations/\" + REGION\n",
    "\n",
    "# client options same for all services\n",
    "client_options = {\"api_endpoint\": API_ENDPOINT}\n",
    "\n",
    "\n",
    "def create_endpoint_client():\n",
    "    client = aip.gapic.EndpointServiceClient(client_options=client_options)\n",
    "    return client\n",
    "\n",
    "\n",
    "clients = {}\n",
    "clients[\"endpoint\"] = create_endpoint_client()\n",
    "\n",
    "traffic_split = endpoint.traffic_split\n",
    "print(traffic_split)\n",
    "new_traffic_split = {}\n",
    "for key, value in traffic_split.items():\n",
    "    if value == 90:\n",
    "        value = 80\n",
    "    else:\n",
    "        value = 20\n",
    "    new_traffic_split[key] = value\n",
    "print(new_traffic_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bc8decee6e5"
   },
   "source": [
    "更新流量分配\n",
    "\n",
    "接下来，您可以在内存中的GAPIC端点上设置新的流量分配，然后使用`update_endpoint()`方法将其推送到`Endpoint`资源上的负载均衡器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1792092972a5"
   },
   "outputs": [],
   "source": [
    "from google.protobuf.field_mask_pb2 import FieldMask\n",
    "\n",
    "gapic_endpoint = clients[\"endpoint\"].get_endpoint(name=endpoint.resource_name)\n",
    "\n",
    "gapic_endpoint.traffic_split = new_traffic_split\n",
    "gapic_endpoint.deployed_models = []\n",
    "\n",
    "clients[\"endpoint\"].update_endpoint(\n",
    "    endpoint=gapic_endpoint, update_mask=FieldMask(paths=[\"traffic_split\"])\n",
    ")\n",
    "\n",
    "# refetch the endpoint\n",
    "gapic_endpoint = clients[\"endpoint\"].get_endpoint(name=endpoint.resource_name)\n",
    "print(gapic_endpoint.traffic_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6ad5bae1489"
   },
   "source": [
    "### 从一个`Endpoint`资源中撤销一个单独的`Model`资源。\n",
    "\n",
    "接下来，您可以从一个具有多个部署的`Model`实例的`Endpoint`资源中撤销一个`Model`实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ee048ee9157"
   },
   "outputs": [],
   "source": [
    "model_0 = endpoint.gca_resource.deployed_models[0].id\n",
    "model_1 = endpoint.gca_resource.deployed_models[1].id\n",
    "\n",
    "endpoint.undeploy(model_0)\n",
    "print(endpoint.gca_resource.deployed_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d89e913932a"
   },
   "source": [
    "最后，您可以使用 `undeploy_all()` 方法从 `Endpoint` 资源中取消部署所有 `Model` 实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09ff279b71ec"
   },
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64b75c0a6f8e"
   },
   "source": [
    "### 删除一个`Endpoint`资源\n",
    "\n",
    "如果`Endpoint`资源没有部署的模型，可以使用`delete()`方法删除该资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d54790378636"
   },
   "outputs": [],
   "source": [
    "endpoint.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fc5f996f599"
   },
   "source": [
    "## `终端点`作为`Vertex AI Pipeline`的一部分\n",
    "\n",
    "接下来的部分演示了如何在`Vertex AI Pipeline`中使用`终端点`资源。\n",
    "\n",
    "### 在管道中创建`终端点`\n",
    "\n",
    "在这个管道中，您将创建一个`终端点`资源，然后将一个`模型`资源部署到`终端点`资源上。要部署的`模型`资源是您之前作为`模型`资源导入的现有TFHub模型。操作步骤如下：\n",
    "\n",
    "- 对于管道参数，传递现有`模型`资源的资源名称。\n",
    "- 使用`GetVertexModelOp()`组件为模型创建一个`VertexModel`管道工件。\n",
    "- 创建一个`终端点`资源。\n",
    "- 使用`VertexModel`管道工件，将`模型`资源部署到`终端点`资源上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e17eda0f7369"
   },
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import Artifact, Output, component\n",
    "\n",
    "PIPELINE_ROOT = \"{}/pipeline_root/endpoint_example\".format(BUCKET_URI)\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"create-endpoint-deploy-model\",\n",
    "    description=\"create an endpoint and deploy a model\",\n",
    ")\n",
    "def pipeline(\n",
    "    display_name: str,\n",
    "    resource_name: str,\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION,\n",
    "):\n",
    "    from google_cloud_pipeline_components.experimental.evaluation import \\\n",
    "        GetVertexModelOp\n",
    "    from google_cloud_pipeline_components.v1.endpoint import (EndpointCreateOp,\n",
    "                                                              ModelDeployOp)\n",
    "\n",
    "    model = GetVertexModelOp(model_resource_name=resource_name)\n",
    "\n",
    "    endpoint_op = EndpointCreateOp(\n",
    "        project=project,\n",
    "        location=region,\n",
    "        display_name=display_name,\n",
    "    )\n",
    "\n",
    "    _ = ModelDeployOp(\n",
    "        model=model.outputs[\"model\"],\n",
    "        endpoint=endpoint_op.outputs[\"endpoint\"],\n",
    "        dedicated_resources_min_replica_count=1,\n",
    "        dedicated_resources_max_replica_count=1,\n",
    "        dedicated_resources_machine_type=DEPLOY_COMPUTE,\n",
    "    )\n",
    "\n",
    "\n",
    "try:\n",
    "    compiler.Compiler().compile(\n",
    "        pipeline_func=pipeline, package_path=\"create_endpoint_and_deploy_model.json\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "306485da9ea0"
   },
   "source": [
    "### 执行管道\n",
    "\n",
    "接下来执行管道。管道接受以下参数，这些参数作为字典`parameter_values`传递：\n",
    "\n",
    "- `display_name`：生成的Vertex AI资源的显示名称。\n",
    "- `resource_name`：现有`Model`资源的资源名称。\n",
    "- `project`：项目ID。\n",
    "- `region`：地区。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56991772e65a"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    pipeline = aip.PipelineJob(\n",
    "        display_name=\"create-endpoint-deploy-pipeline\",\n",
    "        template_path=\"create_endpoint_and_deploy_model.json\",\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        parameter_values={\n",
    "            \"display_name\": \"create_endpoint_and_deploy_model_\" + TIMESTAMP,\n",
    "            \"resource_name\": model.resource_name,\n",
    "            \"project\": PROJECT_ID,\n",
    "            \"region\": REGION,\n",
    "        },\n",
    "        enable_caching=False,\n",
    "    )\n",
    "\n",
    "    pipeline.run()\n",
    "\n",
    "    ! rm -f create_endpoint_and_deploy_model.json\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view_pipeline_results:custom,icn"
   },
   "source": [
    "查看管道结果\n",
    "\n",
    "最后，您将查看管道中每个任务的工件输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c29a34da7df3"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def print_pipeline_output(job, output_task_name):\n",
    "    PROJECT_NUMBER = job.gca_resource.name.split(\"/\")[1]\n",
    "    print(PROJECT_NUMBER)\n",
    "\n",
    "    JOB_ID = job.name\n",
    "    print(JOB_ID)\n",
    "    for _ in range(len(job.gca_resource.job_detail.task_details)):\n",
    "        TASK_ID = job.gca_resource.job_detail.task_details[_].task_id\n",
    "        EXECUTE_OUTPUT = (\n",
    "            PIPELINE_ROOT\n",
    "            + \"/\"\n",
    "            + PROJECT_NUMBER\n",
    "            + \"/\"\n",
    "            + JOB_ID\n",
    "            + \"/\"\n",
    "            + output_task_name\n",
    "            + \"_\"\n",
    "            + str(TASK_ID)\n",
    "            + \"/executor_output.json\"\n",
    "        )\n",
    "        GCP_RESOURCES = (\n",
    "            PIPELINE_ROOT\n",
    "            + \"/\"\n",
    "            + PROJECT_NUMBER\n",
    "            + \"/\"\n",
    "            + JOB_ID\n",
    "            + \"/\"\n",
    "            + output_task_name\n",
    "            + \"_\"\n",
    "            + str(TASK_ID)\n",
    "            + \"/gcp_resources\"\n",
    "        )\n",
    "        EVAL_METRICS = (\n",
    "            PIPELINE_ROOT\n",
    "            + \"/\"\n",
    "            + PROJECT_NUMBER\n",
    "            + \"/\"\n",
    "            + JOB_ID\n",
    "            + \"/\"\n",
    "            + output_task_name\n",
    "            + \"_\"\n",
    "            + str(TASK_ID)\n",
    "            + \"/evaluation_metrics\"\n",
    "        )\n",
    "        if tf.io.gfile.exists(EXECUTE_OUTPUT):\n",
    "            ! gsutil cat $EXECUTE_OUTPUT\n",
    "            return EXECUTE_OUTPUT\n",
    "        elif tf.io.gfile.exists(GCP_RESOURCES):\n",
    "            ! gsutil cat $GCP_RESOURCES\n",
    "            return GCP_RESOURCES\n",
    "        elif tf.io.gfile.exists(EVAL_METRICS):\n",
    "            ! gsutil cat $EVAL_METRICS\n",
    "            return EVAL_METRICS\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "try:\n",
    "    print(\"endpoint-create\")\n",
    "    artifacts = print_pipeline_output(pipeline, \"endpoint-create\")\n",
    "    print(\"\\n\\n\")\n",
    "    output = !gsutil cat $artifacts\n",
    "    output = json.loads(output[0])\n",
    "    endpoint_id = output[\"artifacts\"][\"endpoint\"][\"artifacts\"][0][\"metadata\"][\n",
    "        \"resourceName\"\n",
    "    ]\n",
    "    print(\"model-deploy\")\n",
    "    artifacts = print_pipeline_output(pipeline, \"model-deploy\")\n",
    "    print(\"\\n\\n\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8b32877af1c"
   },
   "source": [
    "清理管道资源\n",
    "\n",
    "删除为此示例创建的所有`Vertex AI`资源，除了在下一个示例中使用的`Endpoint`资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7c9af9d370e"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    endpoint = aip.Endpoint(endpoint_id)\n",
    "    endpoint.undeploy_all()\n",
    "\n",
    "    pipeline.delete()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aa975a64792"
   },
   "source": [
    "### 将现有的`Endpoint`传递到管道中\n",
    "\n",
    "在这个管道中，您将一个`Model`资源部署到`Endpoint`资源中。要部署的`Model`资源是您之前导入为`Model`资源的现有TFHub模型。`Endpoint`资源是先前管道示例中的现有`Endpoint`。步骤如下：\n",
    "\n",
    "- 对于管道参数，请传递现有`Model`和`Endpoint`资源的资源名称和资源URI。\n",
    "- 使用`importer_node()`组件为该模型创建一个`VertexModel`管道工件。\n",
    "- 使用`GetVertexModelOp()`组件为该模型创建一个`VertexModel`管道工件。\n",
    "- 使用`VertexModel`和`VertexEndpoint`管道工件，将`Model`资源部署到`Endpoint`资源中。\n",
    "\n",
    "*注意:* 该示例目前由内部问题阻止：b/219835305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "910c4046993d"
   },
   "outputs": [],
   "source": [
    "PIPELINE_ROOT = \"{}/pipeline_root/endpoint_example_2\".format(BUCKET_URI)\n",
    "\n",
    "\n",
    "# (WORKAROUND  b/219835305)\n",
    "@component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"],\n",
    ")\n",
    "def return_unmanaged_endpoint(resource_name: str, endpoint: Output[Artifact]):\n",
    "\n",
    "    endpoint.metadata[\"resourceName\"] = resource_name\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"deploy-model-existing-endpoint\",\n",
    "    description=\"deploy a model to an existing endpoint\",\n",
    ")\n",
    "def pipeline(\n",
    "    display_name: str,\n",
    "    model_resource_name: str,\n",
    "    endpoint_resource_uri: str,\n",
    "    endpoint_resource_name: str,\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION,\n",
    "):\n",
    "    from google_cloud_pipeline_components.experimental.evaluation import \\\n",
    "        GetVertexModelOp\n",
    "    from google_cloud_pipeline_components.v1.endpoint import ModelDeployOp\n",
    "\n",
    "    # Desired sequence: blocked by b/219835305\n",
    "    \"\"\"\n",
    "    from kfp.v2.components import importer_node\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    \"\"\"\n",
    "\n",
    "    model = GetVertexModelOp(model_resource_name=model_resource_name)\n",
    "\n",
    "    # Desired sequence: blocked by b/219835305\n",
    "    \"\"\"\n",
    "    endpoint = importer_node.importer(\n",
    "        artifact_uri=endpoint_resource_uri,\n",
    "        artifact_class=artifact_types.VertexEndpoint,\n",
    "        metadata={\"resourceName\": endpoint_resource_name},\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    # (WORKAROUND  b/219835305)\n",
    "    endpoint = return_unmanaged_endpoint(resource_name=endpoint_resource_name)\n",
    "\n",
    "    _ = ModelDeployOp(\n",
    "        model=model.outputs[\"model\"],\n",
    "        endpoint=endpoint.outputs[\"endpoint\"],\n",
    "        dedicated_resources_min_replica_count=1,\n",
    "        dedicated_resources_max_replica_count=1,\n",
    "        dedicated_resources_machine_type=DEPLOY_COMPUTE,\n",
    "    )\n",
    "\n",
    "\n",
    "try:\n",
    "    compiler.Compiler().compile(\n",
    "        pipeline_func=pipeline, package_path=\"deploy_model_existing_endpoint.json\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a672bc448095"
   },
   "source": [
    "### 执行流水线\n",
    "\n",
    "接下来，您执行流水线。流水线接受以下参数，这些参数作为字典`parameter_values`传递：\n",
    "\n",
    "- `display_name`：生成的Vertex AI资源的显示名称。\n",
    "- `model_resource_name`：现有`Model`资源的资源名称。\n",
    "- `endpoint_resource_name`：现有`Endpoint`资源的资源名称。\n",
    "- `endpoint_resource_uri`：现有`Endpoint`资源的资源URI。\n",
    "- `project`：项目ID。\n",
    "- `region`：地区。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68591a3ddad4"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    pipeline = aip.PipelineJob(\n",
    "        display_name=\"deploy-model-existing-endpoint\",\n",
    "        template_path=\"deploy_model_existing_endpoint.json\",\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        parameter_values={\n",
    "            \"display_name\": \"deploy_model_existing_endpoint_\" + TIMESTAMP,\n",
    "            \"model_resource_name\": model.resource_name,\n",
    "            \"endpoint_resource_name\": endpoint.resource_name,\n",
    "            \"endpoint_resource_uri\": \"https://us-central1-aiplatform.googleapis.com/v1/\"\n",
    "            + endpoint.resource_name,\n",
    "            \"project\": PROJECT_ID,\n",
    "            \"region\": REGION,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    pipeline.run()\n",
    "\n",
    "    ! rm -f deploy_model_existing_endpoint.json\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view_pipeline_results:custom,icn"
   },
   "source": [
    "查看管道结果\n",
    "\n",
    "最后，您将查看管道中每个任务的工件输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f91799c572a8"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"model-deploy\")\n",
    "    artifacts = print_pipeline_output(pipeline, \"model-deploy\")\n",
    "    print(\"\\n\\n\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6b1260a969e"
   },
   "source": [
    "清理管道资源\n",
    "\n",
    "删除为此示例创建的所有`Vertex AI`资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cc890855b55a"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    endpoint.undeploy_all()\n",
    "    endpoint.delete()\n",
    "    pipeline.delete()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## 清理工作\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于本教程的[Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "delete_bucket = False\n",
    "delete_model = True\n",
    "\n",
    "if delete_model:\n",
    "    try:\n",
    "        model.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -rf {BUCKET_URI}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "get_started_with_vertex_endpoints.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
