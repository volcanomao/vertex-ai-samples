{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "# GCP上的E2E ML: MLOps阶段5：部署：使用Vertex AI终结点和共享VM开始\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage5/get_started_with_vertex_endpoint_and_shared_vm.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "        <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage5/get_started_with_vertex_endpoint_and_shared_vm.ipynb\">\n",
    "        <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "        </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage5/get_started_with_vertex_endpoint_and_shared_vm.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI工作台中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:mlops"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示如何在Google Cloud上使用Vertex AI进行端到端MLOps生产操作。本教程涵盖第5阶段：部署：使用终端点和共享虚拟机开始托管模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:mlops,stage2,get_started_automl_training"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用部署资源池来部署模型。部署资源池提供了在同一个（共享的）虚拟机上托管多个模型的能力。\n",
    "\n",
    "部署资源池将模型部署组合在一起，共享虚拟机内的资源。在部署资源池内可以部署多个端点在同一个虚拟机上。每个端点可以拥有一个或多个部署的模型。给定端点的部署模型可以归为相同或不同的部署资源池。\n",
    "\n",
    "本教程使用以下 Google Cloud ML 服务：\n",
    "\n",
    "- `Vertex AI Training`\n",
    "- `Vertex AI Model` 资源\n",
    "- `Vertex AI Endpoint` 资源\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 上传一个预训练的图像分类模型作为 `Model` 资源（模型A）。\n",
    "- 上传一个预训练的文本句子编码器模型作为 `Model` 资源（模型B）。\n",
    "- 创建一个共享的虚拟机部署资源池。\n",
    "- 列出共享的虚拟机部署资源池。\n",
    "- 创建两个 `Endpoint` 资源。\n",
    "- 使用部署资源池将第一个模型（模型A）部署到第一个 `Endpoint` 资源。\n",
    "- 使用部署资源池将第二个模型（模型B）部署到第二个 `Endpoint` 资源。\n",
    "- 使用第一个部署的模型（模型A）进行预测请求。\n",
    "- 使用第二个部署的模型（模型B）进行预测请求。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:flowers,icn"
   },
   "source": [
    "### 模型\n",
    "\n",
    "本教程使用的预训练模型来自[TensorFlow Hub](https://tfhub.dev/) 仓库：\n",
    "\n",
    "- [图像分类](https://tfhub.dev/google/imagenet/inception_v3/classification/5): 使用ImageNet进行训练。\n",
    "- [文本句子编码器](https://tfhub.dev/google/universal-sentence-encoder/4): 谷歌的通用句子编码器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb3451ce8e47"
   },
   "source": [
    "成本\n",
    "本教程使用Google Cloud的计费组件：\n",
    "\n",
    "- Vertex AI\n",
    "- Cloud Storage\n",
    "\n",
    "了解[Vertex AI定价](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage定价](https://cloud.google.com/storage/pricing)，并使用[定价计算器](https://cloud.google.com/products/calculator/)根据您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_mlops"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装执行这个笔记本所需要的软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_mlops"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "# Install the packages\n",
    "\n",
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                         tensorflow \\\n",
    "                         tensorflow-hub $USER_FLAG -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "重新启动内核\n",
    "\n",
    "安装完额外的软件包后，您需要重新启动笔记本内核，以便它能够找到这些软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "restart"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id"
   },
   "source": [
    "## 在开始之前\n",
    "\n",
    "### 设置您的谷歌云项目\n",
    "\n",
    "**无论您使用什么笔记本环境，都需要执行以下步骤。**\n",
    "\n",
    "1. [选择或创建一个谷歌云项目](https://console.cloud.google.com/cloud-resource-manager)。当您第一次创建账户时，您将获得300美元的免费信用额度，可用于支付计算/存储成本。\n",
    "\n",
    "1. [确保为您的项目启用了计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "1. [启用 Vertex AI、Compute Engine 和 Cloud Storage API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component,storage_component)。\n",
    "\n",
    "1. 如果您在本地运行此笔记本，您需要安装[Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "1. 在下面的单元格中输入您的项目ID。然后运行该单元格，确保Cloud SDK在此笔记本中的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter会将以`!`为前缀的行视为shell命令，并将以`$`为前缀的Python变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56d591439df1"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用`gcloud`来获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "区域\n",
    "\n",
    "您还可以更改“REGION”变量，这个变量用于整个笔记本的操作。下面是Vertex AI支持的区域。我们建议您选择离您最近的区域。\n",
    "\n",
    "- 美洲: `us-central1`\n",
    "- 欧洲: `europe-west4`\n",
    "- 亚太: `asia-east1`\n",
    "\n",
    "您可能不能使用多区域存储桶来训练Vertex AI。并非所有区域都支持所有Vertex AI服务。\n",
    "\n",
    "了解更多关于[Vertex AI区域](https://cloud.google.com/vertex-ai/docs/general/locations)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "UUID\n",
    "\n",
    "如果你正在进行实时教程会话，你可能正在使用共享的测试账户或项目。为了避免用户在创建的资源之间发生名称冲突，你需要为每个实例会话创建一个 UUID，并将其附加在你在本教程中创建的资源名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84Vdv7R-QEH6"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ffa6b6c7cdb"
   },
   "source": [
    "### 验证您的Google Cloud帐户\n",
    "\n",
    "**如果您正在使用Vertex AI Workbench笔记本**，您的环境已经通过身份验证。跳过此步骤。\n",
    "\n",
    "**如果您正在使用Colab**，运行下面的单元格，并按照提示进行身份验证。\n",
    "\n",
    "**否则**，请按照以下步骤操作：\n",
    "\n",
    "在Cloud Console中，转到[创建服务帐号密钥](https://console.cloud.google.com/apis/credentials/serviceaccountkey)页面。\n",
    "\n",
    "1. **单击创建服务帐号**。\n",
    "\n",
    "2. 在**服务帐号名称**字段中输入名称，然后单击**创建**。\n",
    "\n",
    "3. 在**授予此服务帐号对项目的访问权限**部分，单击角色下拉列表。在过滤框中输入“Vertex AI”，并选择**Vertex AI管理员**。在过滤框中输入“Storage Object Admin”，并选择**Storage Object Admin**。\n",
    "\n",
    "4. 单击创建。包含您密钥的JSON文件将下载到您的本地环境。\n",
    "\n",
    "5. 在下面的单元格中将您的服务帐号密钥路径输入为GOOGLE_APPLICATION_CREDENTIALS变量，然后运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b72272258fc"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "**无论您使用的是什么笔记本环境，以下步骤都是必须的。**\n",
    "\n",
    "当您初始化用于 Python 的 Vertex SDK 时，您需要指定一个云存储的暂存桶。暂存桶是您的数据集和模型资源在会话间保留的地方。\n",
    "\n",
    "请在下面设定您的云存储桶的名称。存储桶的名称必须在所有谷歌云项目中具有全局唯一性，包括您的组织之外的项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_URI == \"\" or BUCKET_URI is None or BUCKET_URI == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_NAME = PROJECT_ID + \"aip-\" + UUID\n",
    "    BUCKET_URI = \"gs://\" + BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有当您的存储桶尚不存在时，才能运行以下单元格来创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "最后，通过检查其内容来验证对您的云存储桶的访问权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。\n",
    "### 导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "import google.cloud.aiplatform_v1beta1 as aip_beta\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "### 初始化Python的Vertex AI SDK\n",
    "\n",
    "为您的项目和相应的存储桶初始化Python的Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aip_constants:fs"
   },
   "source": [
    "### Vertex AI常量\n",
    "\n",
    "设置以下常量以用于Vertex AI：\n",
    "\n",
    "- `API_ENDPOINT`：Vertex AI API服务端点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aip_constants:fs"
   },
   "outputs": [],
   "source": [
    "# API service endpoint\n",
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "\n",
    "# Vertex location root path for your dataset, model and endpoint resources\n",
    "PARENT = \"projects/\" + PROJECT_ID + \"/locations/\" + REGION\n",
    "\n",
    "# client options same for all services\n",
    "client_options = {\"api_endpoint\": API_ENDPOINT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "source": [
    "设置硬件加速器\n",
    "\n",
    "您可以为训练和预测设置硬件加速器。\n",
    "\n",
    "设置变量`DEPLOY_GPU/DEPLOY_NGPU`以使用支持 GPU 的容器映像，并指定分配给虚拟机（VM）实例的 GPU 数量。例如，要使用一个拥有 4 个 Nvidia Telsa K80 GPU 的容器映像分配给每个 VM，您可以指定：\n",
    "\n",
    "    (aip.gapic.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
    "\n",
    "否则，指定`(None, None)`来使用一个在 CPU 上运行的容器映像。\n",
    "\n",
    "了解更多关于[您地区的硬件加速器支持](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)的信息。\n",
    "\n",
    "*注意*：TF 2.3 之前的 GPU 支持版本在此教程中无法加载自定义模型。这是一个已知问题，在 TF 2.3 中已修复。这是由于在服务功能中生成的静态图操作。如果您在自定义模型上遇到了此问题，请使用支持 GPU 的 TF 2.3 容器映像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_DEPLOY_GPU\"):\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (\n",
    "        aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "        int(os.getenv(\"IS_TESTING_DEPLOY_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction"
   },
   "source": [
    "设置预构建的容器\n",
    "\n",
    "设置用于预测的预构建Docker容器图像。\n",
    "\n",
    "有关最新列表，请参阅[用于预测的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:training,prediction"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TF\"):\n",
    "    TF = os.getenv(\"IS_TESTING_TF\")\n",
    "else:\n",
    "    TF = \"2.5\".replace(\".\", \"-\")\n",
    "\n",
    "if TF[0] == \"2\":\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf2-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf2-cpu.{}\".format(TF)\n",
    "else:\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "\n",
    "DEPLOY_IMAGE = \"{}-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], DEPLOY_VERSION\n",
    ")\n",
    "\n",
    "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU, DEPLOY_NGPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于预测的机器类型。\n",
    "\n",
    "- 将变量`DEPLOY_COMPUTE`设置为配置用于预测的VM的计算资源。\n",
    "- `机器类型`\n",
    "     - `n1-standard`：每个vCPU 3.75GB的内存。\n",
    "     - `n1-highmem`：每个vCPU 6.5GB的内存\n",
    "     - `n1-highcpu`：每个vCPU 0.9GB的内存\n",
    "- `vCPUs`：\\[2, 4, 8, 16, 32, 64, 96 \\]个的数量\n",
    "\n",
    "*注意：您也可以使用n2和e2机器类型进行训练和部署，但它们不支持GPU*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_DEPLOY_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_DEPLOY_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8128b8ff025"
   },
   "source": [
    "从 TensorFlow Hub 获取预训练模型\n",
    "\n",
    "为了演示目的，本教程使用来自TensorFlow Hub（TFHub）的预训练模型，然后将其上传到“Vertex AI Model”资源。一旦有了“Vertex AI Model”资源，模型就可以部署到“Vertex AI Endpoint”资源。\n",
    "\n",
    "### 下载预训练的图像分类模型\n",
    "\n",
    "首先，从TensorFlow Hub下载预训练的图像分类模型。该模型以TF.Keras层的形式被下载。为了完成模型，例如，在这个例子中，您创建一个`Sequential()`模型，其中TFHub模型被指定为一层，并指定输入形状。下载的模型在ImageNet上进行了预训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "249bd746def6"
   },
   "outputs": [],
   "source": [
    "tfhub_model_icn = tf.keras.Sequential(\n",
    "    [hub.KerasLayer(\"https://tfhub.dev/google/imagenet/inception_v3/classification/5\")]\n",
    ")\n",
    "tfhub_model_icn.build([None, 224, 224, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63de49055083"
   },
   "source": [
    "### 保存模型工件\n",
    "\n",
    "此时，模型位于内存中。接下来，您将模型工件保存到云存储位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64618c713db9"
   },
   "outputs": [],
   "source": [
    "MODEL_ICN_DIR = BUCKET_URI + \"/model_icn\"\n",
    "tfhub_model_icn.save(MODEL_ICN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "how_serving_function_works"
   },
   "source": [
    "## 上传模型进行服务\n",
    "\n",
    "接下来，您将上传您的TFHub图像分类模型到Vertex AI的`Model`服务，该服务将为您的模型创建一个Vertex AI的`Model`资源。在上传过程中，您需要定义一个serving函数来将数据转换为您的模型所期望的格式。如果您发送编码数据到Vertex AI，您的serving函数将确保数据在传递到模型之前在模型服务器上被解码。\n",
    "\n",
    "### serving函数如何工作\n",
    "\n",
    "当您向在线预测服务器发送请求时，该请求将由HTTP服务器接收。HTTP服务器从HTTP请求内容体中提取预测请求。提取的预测请求被转发到serving函数。对于Google预构建的预测容器，请求内容以`tf.string`的形式传递给serving函数。\n",
    "\n",
    "serving函数由两部分组成：\n",
    "\n",
    "- `预处理函数`：\n",
    "  - 将输入（`tf.string`）转换为底层模型（动态图）期望的输入形状和数据类型。\n",
    "  - 执行与训练底层模型期间相同的数据预处理 -- 例如，归一化，缩放等。\n",
    "- `后处理函数`：\n",
    "  - 将模型输出转换为接收应用程序预期的格式 -- 例如，压缩输出。\n",
    "  - 打包输出供接收应用程序使用 -- 例如，添加标题，制作JSON对象等。\n",
    "\n",
    "预处理和后处理函数均转换为与模型融合在一起的静态图。从底层模型输出传递给后处理函数。后处理函数将转换/打包后的输出传递回HTTP服务器。HTTP服务器将输出作为HTTP响应内容返回。\n",
    "\n",
    "在为TF.Keras模型构建serving函数时需要考虑的一个因素是它们作为静态图运行。这意味着您不能使用需要动态图的TF图操作。如果这样做，您将在编译serving函数时遇到错误，并指出您正在使用不受支持的EagerTensor。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "serving_function_image:post"
   },
   "source": [
    "### 图像数据的服务功能\n",
    "\n",
    "### 预处理\n",
    "\n",
    "为了将图像传递给预测服务，您需要将压缩（例如 JPEG）图像字节编码为 base 64 格式，以便在网络上传输二进制数据时使内容免受修改。由于部署的模型期望输入数据是原始（未压缩）字节，您需要确保将 base 64 编码的数据转换回原始字节，然后进行预处理以匹配模型的输入要求，然后将其作为输入传递给部署的模型。\n",
    "\n",
    "为了解决这个问题，您需要定义一个服务函数（`serving_fn`）并将其附加到模型作为预处理步骤。添加一个 `@tf.function` 装饰器，使服务函数与底层模型融合在一起（而不是在 CPU 上游处理）。\n",
    "\n",
    "当您发送预测或解释请求时，请求的内容被 base 64 解码为一个 Tensorflow 字符串（`tf.string`），然后传递给服务函数（`serving_fn`）。服务函数将 `tf.string` 预处理为原始（未压缩）的 numpy 字节（`preprocess_fn`）以满足模型的输入要求：\n",
    "\n",
    "- `io.decode_jpeg` - 解压缩 JPG 图像，返回一个具有三个通道（RGB）的 Tensorflow 张量。\n",
    "- `image.convert_image_dtype` - 将整数像素值更改为 32 位浮点数，并将像素数据重新缩放在 0 和 1 之间。\n",
    "- `image.resize` - 将图像调整大小以匹配模型的输入形状。\n",
    "\n",
    "此时，数据可以通过一个具体函数传递给模型（`m_call`）。服务函数是一个静态图，而模型是一个动态图。具体函数执行将输入数据从服务函数传递到模型，并将预测结果从模型传递回服务函数的任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "serving_function_image"
   },
   "outputs": [],
   "source": [
    "CONCRETE_INPUT = \"numpy_inputs\"\n",
    "\n",
    "\n",
    "def _preprocess(bytes_input):\n",
    "    decoded = tf.io.decode_jpeg(bytes_input, channels=3)\n",
    "    decoded = tf.image.convert_image_dtype(decoded, tf.float32)\n",
    "    resized = tf.image.resize(decoded, size=(224, 224))\n",
    "    return resized\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "def preprocess_fn(bytes_inputs):\n",
    "    decoded_images = tf.map_fn(\n",
    "        _preprocess, bytes_inputs, dtype=tf.float32, back_prop=False\n",
    "    )\n",
    "    return {\n",
    "        CONCRETE_INPUT: decoded_images\n",
    "    }  # User needs to make sure the key matches model's input\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "def serving_fn(bytes_inputs):\n",
    "    images = preprocess_fn(bytes_inputs)\n",
    "    prob = m_call(**images)\n",
    "    return prob\n",
    "\n",
    "\n",
    "m_call = tf.function(tfhub_model_icn.call).get_concrete_function(\n",
    "    [tf.TensorSpec(shape=[None, 224, 224, 3], dtype=tf.float32, name=CONCRETE_INPUT)]\n",
    ")\n",
    "\n",
    "tf.saved_model.save(\n",
    "    tfhub_model_icn, MODEL_ICN_DIR, signatures={\"serving_default\": serving_fn}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "serving_function_signature:image"
   },
   "source": [
    "获取服务函数签名\n",
    "\n",
    "您可以通过重新加载模型到内存，并查询每个层对应的签名来获取您模型的输入和输出层的签名。\n",
    "\n",
    "对于您的目的，您需要服务函数的签名。为什么？好吧，当我们将数据作为 HTTP 请求包发送进行预测时，图像数据是 base64 编码的，而我们的 TF.Keras 模型需要 numpy 输入。您的服务函数将执行将 base64 转换为 numpy 数组的操作。\n",
    "\n",
    "在进行预测请求时，您需要将请求路由到服务函数，而不是模型，因此您需要知道服务函数的输入层名称 -- 这将在您之后进行预测请求时使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "serving_function_signature:image"
   },
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(MODEL_ICN_DIR)\n",
    "\n",
    "serving_input_icn = list(\n",
    "    loaded.signatures[\"serving_default\"].structured_input_signature[1].keys()\n",
    ")[0]\n",
    "print(\"Serving function input:\", serving_input_icn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8ce91147c93"
   },
   "source": [
    "### 将TensorFlow Hub模型上传到`Vertex AI Model`资源\n",
    "\n",
    "最后，您将TFHub模型和服务函数的模型工件上传到`Vertex AI Model`资源中。\n",
    "\n",
    "*注意:* 当您将模型工件上传到`Vertex AI Model`资源时，您需要指定相应的部署容器镜像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad61e1429512"
   },
   "outputs": [],
   "source": [
    "model_icn = aiplatform.Model.upload(\n",
    "    display_name=\"icn_\" + UUID,\n",
    "    artifact_uri=MODEL_ICN_DIR,\n",
    "    serving_container_image_uri=DEPLOY_IMAGE,\n",
    ")\n",
    "\n",
    "print(model_icn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e893c95868b"
   },
   "source": [
    "### 下载预训练的句子编码器模型\n",
    "\n",
    "接下来，您可以从TensorFlow Hub下载预训练的文本句子编码器模型。该模型将作为一个TF.Keras层进行下载。为了完成这个模型，在本例中，您可以使用下载的TFHub模型作为一个层来创建一个`Sequential()`模型，并指定输入形状给模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3760344b764"
   },
   "outputs": [],
   "source": [
    "tfhub_model_use = tf.keras.Sequential(\n",
    "    [hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\")]\n",
    ")\n",
    "\n",
    "# force the model to build\n",
    "tfhub_model_use.predict([\"foo\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63de49055083"
   },
   "source": [
    "### 保存模型工件\n",
    "\n",
    "在这一点上，模型已经加载到内存中。接下来，您将模型工件保存到云存储位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64618c713db9"
   },
   "outputs": [],
   "source": [
    "MODEL_USE_DIR = BUCKET_URI + \"/model_use\"\n",
    "tfhub_model_use.save(MODEL_USE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "serving_function_signature:image"
   },
   "source": [
    "获取serving函数的签名\n",
    "\n",
    "您可以通过重新加载模型到内存中，并查询每个层对应的签名来获取模型的输入和输出层的签名。\n",
    "\n",
    "对于您的目的，您需要serving函数的签名。\n",
    "\n",
    "在进行预测请求时，您需要将请求路由到serving函数而不是模型，因此您需要知道serving函数的输入层名称 -- 这将在您进行预测请求时使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "serving_function_signature:image"
   },
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(MODEL_USE_DIR)\n",
    "\n",
    "serving_input_use = list(\n",
    "    loaded.signatures[\"serving_default\"].structured_input_signature[1].keys()\n",
    ")[0]\n",
    "print(\"Serving function input:\", serving_input_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8ce91147c93"
   },
   "source": [
    "将TensorFlow Hub模型上传到 `Vertex AI Model` 资源中\n",
    "\n",
    "最后，您将TFHub模型和服务功能中的模型构件上传到 `Vertex AI Model` 资源中。\n",
    "\n",
    "*注意:* 当您将模型构件上传到 `Vertex AI Model` 资源时，您需指定相应的部署容器镜像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad61e1429512"
   },
   "outputs": [],
   "source": [
    "model_use = aiplatform.Model.upload(\n",
    "    display_name=\"icn_\" + UUID,\n",
    "    artifact_uri=MODEL_USE_DIR,\n",
    "    serving_container_image_uri=DEPLOY_IMAGE,\n",
    ")\n",
    "\n",
    "print(model_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gk9tr92tSh-f"
   },
   "source": [
    "## 创建部署资源池\n",
    "\n",
    "目前，创建部署资源池只能通过基于REST的API（如CURL）和GAPIC API（Python）进行支持。\n",
    "\n",
    "使用 `create_deployment_resource_pool` API 来创建一个资源池，具备以下配置：\n",
    "\n",
    "- `dedicated_resources`：为共享虚拟机分配的计算（硬件）资源。\n",
    "- `min_replica_count`：自动扩展，计算节点的最小数量。\n",
    "- `max_replica_count`：自动扩展，计算节点的最大数量。\n",
    "\n",
    "了解更多有关[部署资源池](https://googleapis.dev/python/aiplatform/latest/aiplatform_v1beta1/deployment_resource_pool_service.html)的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90c51b6cf34a"
   },
   "outputs": [],
   "source": [
    "DEPLOYMENT_RESOURCE_POOL_ID = f\"shared-vm-{UUID}\"  # @param {type: \"string\"}\n",
    "MIN_NODES = 1\n",
    "MAX_NODES = 2\n",
    "\n",
    "# Initialize request argument(s)\n",
    "deployment_resource_pool = aip_beta.DeploymentResourcePool()\n",
    "deployment_resource_pool.dedicated_resources.min_replica_count = MIN_NODES\n",
    "deployment_resource_pool.dedicated_resources.max_replica_count = MAX_NODES\n",
    "deployment_resource_pool.dedicated_resources.machine_spec.machine_type = DEPLOY_COMPUTE\n",
    "if DEPLOY_NGPU:\n",
    "    deployment_resource_pool.dedicated_resources.machine_spec.accelerator_type = DEPLOY_GPU\n",
    "    deployment_resource_pool.dedicated_resources.machine_spec.accelerator_count = DEPLOY_NGPU\n",
    "\n",
    "request = aip_beta.CreateDeploymentResourcePoolRequest(\n",
    "    parent=f\"projects/{PROJECT_ID}/locations/{REGION}\",\n",
    "    deployment_resource_pool=deployment_resource_pool,\n",
    "    deployment_resource_pool_id=DEPLOYMENT_RESOURCE_POOL_ID,\n",
    ")\n",
    "\n",
    "pool_client = aip_beta.services.deployment_resource_pool_service.DeploymentResourcePoolServiceClient(\n",
    "    client_options=client_options\n",
    ")\n",
    "\n",
    "op = pool_client.create_deployment_resource_pool(request=request)\n",
    "print(op)\n",
    "\n",
    "result = op.result()\n",
    "print(result)\n",
    "\n",
    "deployment_pool_id = result.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WP4WV_bZzDh"
   },
   "source": [
    "## 获取部署资源池\n",
    "\n",
    "使用`GetDeploymentResourcePool` API来查看您创建的部署资源池。\n",
    "\n",
    "了解更多关于 [获取部署资源池](https://googleapis.dev/python/aiplatform/latest/aiplatform_v1beta1/deployment_resource_pool_service.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b740253903c0"
   },
   "outputs": [],
   "source": [
    "response = pool_client.get_deployment_resource_pool(name=deployment_pool_id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBQyGl-7aaZC"
   },
   "source": [
    "列出所有部署资源池\n",
    "\n",
    "使用 `ListDeploymentResourcePools` API 列出所有部署资源池。\n",
    "\n",
    "了解更多关于[列出部署资源池](https://googleapis.dev/python/aiplatform/latest/aiplatform_v1beta1/deployment_resource_pool_service.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ebfd007bff2"
   },
   "outputs": [],
   "source": [
    "pools = pool_client.list_deployment_resource_pools(\n",
    "    parent=f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    ")\n",
    "for pool in pools:\n",
    "    print(pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "628de0914ba1"
   },
   "source": [
    "## 创建两个`Endpoint`资源\n",
    "\n",
    "接下来，您可以使用`Endpoint.create()`方法创建两个`Endpoint`资源。至少，您需要指定端点的显示名称。可选地，您也可以指定项目和位置（地区），否则这些设置将继承您使用`init()`方法初始化Vertex AI SDK时设置的值。\n",
    "\n",
    "在本例中，指定了以下参数：\n",
    "\n",
    "- `display_name`：`Endpoint`资源的可读名称。\n",
    "\n",
    "此方法将返回一个`Endpoint`对象。\n",
    "\n",
    "了解更多关于[Vertex AI端点](https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ea443f9593b"
   },
   "outputs": [],
   "source": [
    "endpoint_icn = aiplatform.Endpoint.create(display_name=\"icn_\" + UUID)\n",
    "\n",
    "print(endpoint_icn)\n",
    "\n",
    "endpoint_use = aiplatform.Endpoint.create(display_name=\"use_\" + UUID)\n",
    "\n",
    "print(endpoint_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azXkQSkjb3tv"
   },
   "source": [
    "## 在部署资源池中部署模型\n",
    "\n",
    "在创建了一个模型和一个终端之后，您可以使用 DeployModel API 进行部署。在下面的 CURL 命令示例中，注意您是如何指定 DeployedModel 的 `shared_resources` 为创建的资源池的部署资源名称。\n",
    "\n",
    "相同部署资源池的模型部署可以同时启动。\n",
    "\n",
    "### 部署图像分类模型\n",
    "\n",
    "接下来，您可以将图像分类模型部署到一个 `Endpoint` ，使用您的部署资源池。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEcQp8eUdHok"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "SHARED_RESOURCE = \"projects/{project_id}/locations/{region}/deploymentResourcePools/{deployment_resource_pool_id}\".format(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    "    deployment_resource_pool_id=DEPLOYMENT_RESOURCE_POOL_ID,\n",
    ")\n",
    "\n",
    "DEPLOY_MODEL_PAYLOAD = {\n",
    "    \"deployedModel\": {\n",
    "        \"model\": model_icn.resource_name,\n",
    "        \"shared_resources\": SHARED_RESOURCE,\n",
    "    },\n",
    "    \"trafficSplit\": {\"0\": 100},\n",
    "}\n",
    "DEPLOY_MODEL_REQUEST = json.dumps(DEPLOY_MODEL_PAYLOAD)\n",
    "pp.pprint(\"DEPLOY_MODEL_REQUEST: \" + DEPLOY_MODEL_REQUEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92c2036684b3"
   },
   "outputs": [],
   "source": [
    "ENDPOINT_ID = endpoint_icn.name\n",
    "\n",
    "output = ! curl -X POST \\\n",
    " -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    " -H \"Content-Type: application/json\" \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1beta1/projects/{PROJECT_ID}/locations/{REGION}/endpoints/{ENDPOINT_ID}:deployModel \\\n",
    "-d '{DEPLOY_MODEL_REQUEST}'\n",
    "\n",
    "for line in output:\n",
    "    if '\"name\"' in line:\n",
    "        operation_id = line.split(\":\")[-1].strip()[:-1]\n",
    "        break\n",
    "print(operation_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5053c9db02a"
   },
   "source": [
    "等待部署完成\n",
    "\n",
    "接下来，您将查询操作的状态，等待操作状态'完成'设置为'true'。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "563db25caa5c"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "done = False\n",
    "while done != '\"done\": true':\n",
    "    status = ! curl -X GET \\\n",
    " -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    " -H \"Content-Type: application/json\" \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1beta1/{operation_id}\n",
    "    for line in status:\n",
    "        if '\"done\"' in line.strip():\n",
    "            done = line.strip()[0:-1]\n",
    "    print(\"DONE status:\", done)\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68ceccf7a8a7"
   },
   "source": [
    "部署文本句子编码器模型\n",
    "\n",
    "接下来，您将使用您的部署资源池将文本句子编码器模型部署到一个“终端节点”上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEcQp8eUdHok"
   },
   "outputs": [],
   "source": [
    "DEPLOY_MODEL_PAYLOAD = {\n",
    "    \"deployedModel\": {\n",
    "        \"model\": model_use.resource_name,\n",
    "        \"shared_resources\": SHARED_RESOURCE,\n",
    "    },\n",
    "    \"trafficSplit\": {\"0\": 100},\n",
    "}\n",
    "DEPLOY_MODEL_REQUEST = json.dumps(DEPLOY_MODEL_PAYLOAD)\n",
    "pp.pprint(\"DEPLOY_MODEL_REQUEST: \" + DEPLOY_MODEL_REQUEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "288acc79c173"
   },
   "outputs": [],
   "source": [
    "ENDPOINT_ID = endpoint_use.name\n",
    "\n",
    "output = ! curl -X POST \\\n",
    " -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    " -H \"Content-Type: application/json\" \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1beta1/projects/{PROJECT_ID}/locations/{REGION}/endpoints/{ENDPOINT_ID}:deployModel \\\n",
    "-d '{DEPLOY_MODEL_REQUEST}'\n",
    "\n",
    "for line in output:\n",
    "    if '\"name\"' in line:\n",
    "        operation_id = line.split(\":\")[-1].strip()[:-1]\n",
    "        break\n",
    "print(operation_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87ba1aa4e0b0"
   },
   "source": [
    "等待部署完成\n",
    "\n",
    "接下来，您将查询操作的状态，等待操作状态`完成`被设置为`true`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5b075d6ec099"
   },
   "outputs": [],
   "source": [
    "done = False\n",
    "while done != '\"done\": true':\n",
    "    status = ! curl -X GET \\\n",
    " -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    " -H \"Content-Type: application/json\" \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1beta1/{operation_id}\n",
    "    for line in status:\n",
    "        if '\"done\"' in line.strip():\n",
    "            done = line.strip()[0:-1]\n",
    "    print(\"DONE status:\", done)\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52248c450776"
   },
   "source": [
    "获取端点的部署细节\n",
    "\n",
    "列出在端点上部署的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3b768614e7c6"
   },
   "outputs": [],
   "source": [
    "print(endpoint_icn.list_models())\n",
    "print(endpoint_use.list_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "033a5bfb969c"
   },
   "source": [
    "### 创建图像分类模型的测试示例\n",
    "\n",
    "接下来，您要测试已部署的图像分类模型。首先，您需要为提供功能对测试数据进行编码，格式如下：\n",
    "\n",
    "`{ serving_input: { 'b64': base64编码的字节 } }`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54947579cdf7"
   },
   "outputs": [],
   "source": [
    "! gsutil cp gs://cloud-ml-data/img/flower_photos/daisy/100080576_f52e8ee070_n.jpg test.jpg\n",
    "\n",
    "import base64\n",
    "\n",
    "with open(\"test.jpg\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "b64str = base64.b64encode(data).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdf3dd237d32"
   },
   "source": [
    "### 为图像分类模型进行预测请求\n",
    "\n",
    "最终，您会发起一个预测请求。由于该模型是在ImageNet上训练的，预测将返回相应1000个类别的概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "predict_request:mbsdk,custom,icn"
   },
   "outputs": [],
   "source": [
    "# The format of each instance should conform to the deployed model's prediction input schema.\n",
    "instances = [{serving_input_icn: {\"b64\": b64str}}]\n",
    "\n",
    "prediction = endpoint_icn.predict(instances=instances)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "033a5bfb969c"
   },
   "source": [
    "### 创建测试示例文本句编码器模型\n",
    "\n",
    "接下来，您将测试已部署的文本句编码器模型。首先，您需要对用于服务功能的测试数据进行编码，其格式为：\n",
    "\n",
    "`\"word1 word2 ... wordN\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3dd85e9ce024"
   },
   "outputs": [],
   "source": [
    "instance = \"the brown fox jumped over the laxy dog\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3185c34f59c"
   },
   "source": [
    "### 为文本句子编码模型发起预测请求\n",
    "\n",
    "最终，您发起一个预测请求。预测将返回一个包含500个元素的嵌入向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96877270ec07"
   },
   "outputs": [],
   "source": [
    "endpoint_use.predict([instance])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "source": [
    "解除部署模型\n",
    "\n",
    "当您完成预测后，您需要从`Endpoint`资源中解除部署模型。这将取消所有计算资源并终止已部署模型的计费。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint_icn.undeploy_all()\n",
    "endpoint_use.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "source": [
    "删除`Model`资源\n",
    "\n",
    "`delete()`方法将删除模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "model_icn.delete()\n",
    "model_use.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "source": [
    "删除`Endpoint`资源\n",
    "\n",
    "方法'delete()'将删除该端点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint_icn.delete()\n",
    "endpoint_use.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3baa3a7496e"
   },
   "source": [
    "删除`DeploymentResourcePool`\n",
    "\n",
    "方法 'delete_deployment_resource_pool()' 将删除您的部署资源池。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b76a4de1e57e"
   },
   "outputs": [],
   "source": [
    "response = pool_client.delete_deployment_resource_pool(name=deployment_pool_id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup"
   },
   "source": [
    "进行清理\n",
    "\n",
    "要清理在此项目中使用的所有Google Cloud资源，您可以[删除用于本教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup"
   },
   "outputs": [],
   "source": [
    "# Set this to true only if you'd like to delete your bucket\n",
    "delete_bucket = False\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI\n",
    "\n",
    "!rm -f test.jpg"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_with_vertex_endpoint_and_shared_vm.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
