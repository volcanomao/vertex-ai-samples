{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "# GCP上的E2E ML：MLOps第2阶段：实验：开始使用Vertex AI Vizier\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_vizier.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "        <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_vizier.ipynb\">\n",
    "        <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab上运行\n",
    "        </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage2/get_started_vertex_vizier.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>           \n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:mlops"
   },
   "source": [
    "## 概览\n",
    "\n",
    "本教程演示了如何在Google Cloud上使用Vertex AI进行端到端的生产MLOps。本教程涵盖了第二阶段：实验：开始使用Vertex AI Vizier。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:mlops,stage2,get_started_vertex_vizier"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何在使用`Vertex AI`进行训练时使用`Vertex AI Vizier`。\n",
    "\n",
    "本教程使用以下Google Cloud ML服务：\n",
    "\n",
    "- `Vertex AI Training`\n",
    "- `Vertex AI Hyperparameter Tuning`\n",
    "- `Vertex AI Vizier`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 使用随机算法进行超参数调整。\n",
    "- 使用Vizier（贝叶斯）算法进行超参数调整。\n",
    "- 为Vizier研究建议试验并更新结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "recommendation:mlops,stage2,vertex,vizier"
   },
   "source": [
    "###建议\n",
    "\n",
    "在Google Cloud上进行端到端的MLOps时，以下是在何时使用Vertex AI Vizier进行超参数调整的最佳实践：\n",
    "\n",
    "**网格搜索**\n",
    "\n",
    "您有少量的离散值组合。例如，您有以下两个超参数和离散值：\n",
    "\n",
    "- batch size：\\[16, 32, 64\\]\n",
    "- lr：\\[0.001, 0.01, 0.1\\]\n",
    "\n",
    "组合的总数为9（3 x 3）。\n",
    "\n",
    "**随机搜索**\n",
    "\n",
    "您有一小组超参数，其中至少有一个是连续值。例如，您有以下两个超参数和范围：\n",
    "\n",
    "- batch size：\\[16, 32, 64\\]\n",
    "- lr：0.001 .. 0.1\n",
    "\n",
    "**Vizier搜索**\n",
    "\n",
    "您可以是以下情况之一：\n",
    "\n",
    "- 有大量的超参数和离散值\n",
    "- 巨大的连续搜索空间\n",
    "- 多个目标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:custom,boston,lrg"
   },
   "source": [
    "数据集\n",
    "\n",
    "本教程使用的数据集是[波士顿房价数据集](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)。本教程中使用的数据集版本已经内置在TensorFlow中。训练好的模型用于预测房屋的中位价格，单位为1千美元。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c480fc50ec3c"
   },
   "source": [
    "成本\n",
    "\n",
    "本教程使用Google Cloud的可计费组件：\n",
    "\n",
    "- Vertex AI\n",
    "- 云存储\n",
    "\n",
    "了解[Vertex AI价格](https://cloud.google.com/vertex-ai/pricing)和[云存储价格](https://cloud.google.com/storage/pricing)，并使用[Pricing Calculator](https://cloud.google.com/products/calculator/)根据您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_mlops"
   },
   "source": [
    "安装所需的软件包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fd00fa70a2a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "! pip3 install --upgrade $USER_FLAG -q google-cloud-aiplatform \\\n",
    "                                       google-vizier==0.0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "重新启动内核\n",
    "\n",
    "安装了额外的软件包后，您需要重新启动笔记本内核，这样它就能找到这些软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "restart"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2721ef0202d9"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### 设置你的谷歌云项目\n",
    "\n",
    "**无论你使用什么笔记本环境，以下步骤都是必需的。**\n",
    "\n",
    "1. [选择或创建一个谷歌云项目](https://console.cloud.google.com/cloud-resource-manager)。当你第一次创建一个帐户时，你会获得一个$300的免费学分用于支付计算/存储费用。\n",
    "\n",
    "1. [确保为你的项目启用了结算功能](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "1. [启用Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。 \n",
    "\n",
    "1. 如果你是在本地运行这个笔记本，你需要安装[Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "1. 在下面的单元格中输入你的项目ID。然后运行该单元格确保Cloud SDK 对这个笔记本中的所有命令使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter会将以`！`为前缀的行作为shell命令运行，并且会将以`$`为前缀的Python变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id"
   },
   "source": [
    "**设置您的项目ID**\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以尝试使用 `gcloud` 来获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "区域\n",
    "\n",
    "您还可以更改 `REGION` 变量，该变量在笔记本的其余部分中使用。以下是 Vertex AI 支持的区域。我们建议您选择离您最近的区域。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太地区：`asia-east1`\n",
    "\n",
    "您可能无法在 Vertex AI 上使用多区域存储桶进行训练。并非所有区域都支持所有 Vertex AI 服务。\n",
    "\n",
    "了解更多关于 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type:\"string\"}\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06571eb4063b"
   },
   "source": [
    "UUID\n",
    "\n",
    "如果您正在进行现场教程会话，您可能正在使用共享的测试账户或项目。为了避免用户在创建的资源之间出现名称冲突，您可以为每个实例会话创建一个UUID，并将其附加到您在本教程中创建资源的名称后面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e166d927e36"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 验证您的Google Cloud账户\n",
    "\n",
    "**如果您正在使用Vertex AI Workbench笔记本**，您的环境已经完成了身份验证。\n",
    "\n",
    "**如果您正在使用Colab**，运行下面的单元格，并且按照提示进行身份验证，通过oAuth认证您的账户。\n",
    "\n",
    "**否则**，请按照以下步骤操作：\n",
    "\n",
    "在Cloud控制台中，转到[创建服务账户密钥](https://console.cloud.google.com/apis/credentials/serviceaccountkey)页面。\n",
    "\n",
    "**点击创建服务账户**。\n",
    "\n",
    "在**服务账户名称**字段中输入一个名称，点击**创建**。\n",
    "\n",
    "在**授予此服务账户对项目的访问权限**部分，点击角色下拉列表。在筛选框中输入\"Vertex\"，并选择**Vertex管理员**。在筛选框中输入\"Storage Object Admin\"，并选择**存储对象管理员**。\n",
    "\n",
    "点击创建。一个包含您密钥的JSON文件将下载到本地环境。\n",
    "\n",
    "在下面的单元格中将您的服务账户密钥的路径输入为GOOGLE_APPLICATION_CREDENTIALS变量，然后运行此单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcp_authenticate"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = False\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        IS_COLAB = True\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "**无论您使用的笔记本环境如何，都需要按照以下步骤操作。**\n",
    "\n",
    "当您初始化用于 Python 的 Vertex SDK 时，需要指定一个云存储暂存桶。暂存桶是您的数据集和模型资源所关联的所有数据在会话之间保留的地方。\n",
    "\n",
    "请在下面设置您的云存储桶的名称。存储桶的名称必须在所有 Google Cloud 项目中全局唯一，包括您组织之外的项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = \"gs://[your-bucket-name]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_URI == \"\" or BUCKET_URI is None or BUCKET_URI == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_URI = \"gs://\" + PROJECT_ID + \"aip-\" + UUID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有你的存储桶尚不存在：运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "最后，通过检查云存储桶的内容来验证对其的访问权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。\n",
    "### 导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip\n",
    "from google.cloud.aiplatform.vizier import Study, pyvizier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "### 初始化用于 Python 的 Vertex AI SDK\n",
    "\n",
    "为您的项目和相应的存储桶初始化用于 Python 的 Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,mbsdk"
   },
   "source": [
    "#### 设置硬件加速器\n",
    "\n",
    "您可以为训练设置硬件加速器。\n",
    "\n",
    "将变量`TRAIN_GPU / TRAIN_NGPU`设置为使用支持 GPU 的容器映像和分配给虚拟机（VM）实例的 GPU 数量。例如，要使用一个 GPU 容器映像，为每个 VM 分配 4 个 Nvidia Telsa K80 GPU，您应该指定：\n",
    "\n",
    "    (aip.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
    "\n",
    "否则，请指定`(None, None)`以使用一个在 CPU 上运行的容器映像。\n",
    "\n",
    "了解更多信息，请前往[这里](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)查看您所在地区的硬件加速器支持。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accelerators:training,mbsdk"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TRAIN_GPU\"):\n",
    "    TRAIN_GPU, TRAIN_NGPU = (\n",
    "        aip.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "        int(os.getenv(\"IS_TESTING_TRAIN_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    TRAIN_GPU, TRAIN_NGPU = (aip.gapic.AcceleratorType.NVIDIA_TESLA_K80, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training"
   },
   "source": [
    "设置预建立的容器\n",
    "\n",
    "设置用于训练的预建立的Docker容器镜像。\n",
    "\n",
    "- 将变量`TF`设置为容器镜像的TensorFlow版本。例如，`2-1`表示版本2.1，`1-15`表示版本1.15。以下列表显示了一些可用的预建立图像：\n",
    "\n",
    "要获取最新列表，请参阅[用于训练的预建立容器](https://cloud.google.com/ai-platform-unified/docs/training/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:training"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TF\"):\n",
    "    TF = os.getenv(\"IS_TESTING_TF\")\n",
    "else:\n",
    "    TF = \"2.5\".replace(\".\", \"-\")\n",
    "\n",
    "if TF[0] == \"2\":\n",
    "    if TRAIN_GPU:\n",
    "        TRAIN_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        TRAIN_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "else:\n",
    "    if TRAIN_GPU:\n",
    "        TRAIN_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        TRAIN_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "\n",
    "TRAIN_IMAGE = \"{}-docker.pkg.dev/vertex-ai/training/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], TRAIN_VERSION\n",
    ")\n",
    "\n",
    "print(\"Training:\", TRAIN_IMAGE, TRAIN_GPU, TRAIN_NGPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于训练的机器类型。\n",
    "\n",
    "- 将变量`TRAIN_COMPUTE`设置为配置用于训练的虚拟机的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`：每个vCPU 3.75GB内存。\n",
    "     - `n1-highmem`：每个vCPU 6.5GB内存。\n",
    "     - `n1-highcpu`：每个vCPU 0.9GB内存。\n",
    " - `vCPUs`：数量为\\[2, 4, 8, 16, 32, 64, 96\\]\n",
    "\n",
    "*注意：以下不支持用于训练：*\n",
    "\n",
    " - `standard`：2个vCPUs\n",
    " - `highcpu`：2、4和8个vCPUs\n",
    "\n",
    "*注意：您还可以使用n2和e2机器类型进行训练和部署，但它们不支持GPU*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TRAIN_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_TRAIN_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vizier_intro"
   },
   "source": [
    "## 独立的Vertex AI Vizer服务\n",
    "\n",
    "`Vizier`服务可以作为一个独立的服务，用于选择试验的下一组参数。\n",
    "\n",
    "*注意：* 该服务不执行试验。您需要自己创建试验和执行。\n",
    "\n",
    "了解更多关于[Vizier的使用](https://cloud.google.com/vertex-ai/docs/vizier/using-vizier)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpt_intro"
   },
   "source": [
    "## Vertex AI超参数调整服务\n",
    "\n",
    "以下示例演示了如何使用Vertex AI超参数调整服务和 `random` 搜索算法设置、执行和评估试验。\n",
    "\n",
    "了解有关[超参数调整概述](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview)的更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_training_package"
   },
   "source": [
    "### 检查超参数调整包\n",
    "\n",
    "#### 包布局\n",
    "\n",
    "在开始超参数调整之前，你将看看一个Python包是如何为自定义超参数调整工作而组装的。解压后，包含以下目录/文件布局。\n",
    "\n",
    "- PKG-INFO\n",
    "- README.md\n",
    "- setup.cfg\n",
    "- setup.py\n",
    "- trainer\n",
    "  - \\_\\_init\\_\\_.py\n",
    "  - task.py\n",
    "\n",
    "文件 `setup.cfg` 和 `setup.py` 是将包安装到Docker镜像操作环境的说明。\n",
    "\n",
    "文件 `trainer/task.py` 是执行自定义超参数调整工作的Python脚本。 *注意*，当我们在工作池规范中提到它时，我们用点(`trainer.task`)替代了目录斜杠，并去掉了文件后缀(`.py`)。\n",
    "\n",
    "#### 包装配\n",
    "\n",
    "在下面的单元格中，您将组装训练包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "examine_training_package"
   },
   "outputs": [],
   "source": [
    "# Make folder for Python hyperparameter tuning script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\nsetuptools.setup(\\n\\n    install_requires=[\\n\\n        'tensorflow==2.5.0',\\n\\n        'tensorflow_datasets==1.3.0',\\n\\n    ],\\n\\n    packages=setuptools.find_packages())\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\nName: Boston Housing tabular regression\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration hyperparameter tuning script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taskpy_contents:hpt,boston"
   },
   "source": [
    "#### Task.py 内容\n",
    "\n",
    "在下一个单元格中，您可以编写超参数调优脚本 task.py 的内容。我不会详细讨论，只是让您浏览一下。总结如下：\n",
    "\n",
    "- 解析当前试验的超参数设置的命令行参数。\n",
    "- 从命令行中获取保存模型文件的目录（`--model_dir`），如果没有指定，则从环境变量 `AIP_MODEL_DIR` 中获取。\n",
    "- 下载并预处理波士顿房价数据集。\n",
    "- 构建一个 DNN 模型。\n",
    "- 在模型的构建和编译过程中使用每个密集层的单元数和学习率超参数值。\n",
    "- 定义一个回调函数 `HPTCallback`，在每个 epoch 结束时获取验证损失（`on_epoch_end()`）并通过 `hpt.report_hyperparameter_tuning_metric()` 报告给超参数调优服务。\n",
    "- 使用 `fit()` 方法训练模型，并指定一个回调函数，将验证损失报告给超参数调优服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taskpy_contents:hpt,boston"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "# Custom Training for Boston Housing\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from hypertune import HyperTune\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model-dir', dest='model_dir',\n",
    "                    default=os.getenv('AIP_MODEL_DIR'), type=str, help='Model dir.')\n",
    "parser.add_argument('--lr', dest='lr',\n",
    "                    default=0.001, type=float,\n",
    "                    help='Learning rate.')\n",
    "parser.add_argument('--decay', dest='decay',\n",
    "                    default=0.98, type=float,\n",
    "                    help='Decay rate')\n",
    "parser.add_argument('--units', dest='units',\n",
    "                    default=64, type=int,\n",
    "                    help='Number of units.')\n",
    "parser.add_argument('--epochs', dest='epochs',\n",
    "                    default=20, type=int,\n",
    "                    help='Number of epochs.')\n",
    "parser.add_argument('--steps', dest='steps',\n",
    "                    default=200, type=int,\n",
    "                    help='Number of steps per epoch.')\n",
    "parser.add_argument('--param-file', dest='param_file',\n",
    "                    default='/tmp/param.txt', type=str,\n",
    "                    help='Output file for parameters')\n",
    "parser.add_argument('--distribute', dest='distribute', type=str, default='single',\n",
    "                    help='distributed training strategy')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print('Python Version = {}'.format(sys.version))\n",
    "print('TensorFlow Version = {}'.format(tf.__version__))\n",
    "print('TF_CONFIG = {}'.format(os.environ.get('TF_CONFIG', 'Not found')))\n",
    "\n",
    "\n",
    "def make_dataset():\n",
    "\n",
    "  # Scaling Boston Housing data features\n",
    "  def scale(feature):\n",
    "    max = np.max(feature)\n",
    "    feature = (feature / max).astype(np.float)\n",
    "    return feature, max\n",
    "\n",
    "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
    "  )\n",
    "  params = []\n",
    "  for _ in range(13):\n",
    "    x_train[_], max = scale(x_train[_])\n",
    "    x_test[_], _ = scale(x_test[_])\n",
    "    params.append(max)\n",
    "\n",
    "  # store the normalization (max) value for each feature\n",
    "  with tf.io.gfile.GFile(args.param_file, 'w') as f:\n",
    "    f.write(str(params))\n",
    "  return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "# Build the Keras model\n",
    "def build_and_compile_dnn_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(args.units, activation='relu', input_shape=(13,)),\n",
    "      tf.keras.layers.Dense(args.units, activation='relu'),\n",
    "      tf.keras.layers.Dense(1, activation='linear')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss='mse',\n",
    "      optimizer=tf.keras.optimizers.RMSprop(learning_rate=args.lr, decay=args.decay))\n",
    "  return model\n",
    "\n",
    "\n",
    "model = build_and_compile_dnn_model()\n",
    "\n",
    "# Instantiate the HyperTune reporting object\n",
    "hpt = HyperTune()\n",
    "\n",
    "# Reporting callback\n",
    "class HPTCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global hpt\n",
    "        hpt.report_hyperparameter_tuning_metric(\n",
    "        hyperparameter_metric_tag='val_loss',\n",
    "        metric_value=logs['val_loss'],\n",
    "        global_step=epoch)\n",
    "\n",
    "# Train the model\n",
    "BATCH_SIZE = 16\n",
    "(x_train, y_train), (x_test, y_test) = make_dataset()\n",
    "model.fit(x_train, y_train, epochs=args.epochs, batch_size=BATCH_SIZE, validation_split=0.1, callbacks=[HPTCallback()])\n",
    "model.save(args.model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tarball_training_script"
   },
   "source": [
    "将超参数调整脚本存储在您的云存储桶中\n",
    "\n",
    "接下来，将超参数调整文件夹打包成压缩的 tar 文件，然后将其存储在您的云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tarball_training_script"
   },
   "outputs": [],
   "source": [
    "! rm -f custom.tar custom.tar.gz\n",
    "! tar cvf custom.tar custom\n",
    "! gzip custom.tar\n",
    "! gsutil cp custom.tar.gz $BUCKET_URI/trainer_boston.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_custom_job_machine_specification"
   },
   "source": [
    "### 准备您的机器规格\n",
    "\n",
    "现在为您的自定义超参数调整作业定义机器规格。这会告诉 Vertex 需要为超参数调整提供什么类型的机器实例。\n",
    "- `machine_type`：要提供的GCP实例类型 -- 例如，n1-standard-8。\n",
    "- `accelerator_type`：硬件加速器的类型，如果有的话。在这个教程中，如果您之前设置了变量`TRAIN_GPU != None`，则表示您正在使用GPU；否则您将使用CPU。\n",
    "- `accelerator_count`：加速器的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_custom_job_machine_specification"
   },
   "outputs": [],
   "source": [
    "if TRAIN_GPU:\n",
    "    machine_spec = {\n",
    "        \"machine_type\": TRAIN_COMPUTE,\n",
    "        \"accelerator_type\": TRAIN_GPU,\n",
    "        \"accelerator_count\": TRAIN_NGPU,\n",
    "    }\n",
    "else:\n",
    "    machine_spec = {\"machine_type\": TRAIN_COMPUTE, \"accelerator_count\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_custom_job_disk_specification"
   },
   "source": [
    "### 准备您的磁盘规格\n",
    "\n",
    "（可选）现在为您的定制超参数调整作业定义磁盘规格。这告诉Vertex每个机器实例为超参数调整提供什么类型和大小的磁盘。\n",
    "\n",
    "- `boot_disk_type`：SSD或标准。SSD 更快，标准更便宜。默认为SSD。\n",
    "- `boot_disk_size_gb`：磁盘大小（GB）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_custom_job_disk_specification"
   },
   "outputs": [],
   "source": [
    "DISK_TYPE = \"pd-ssd\"  # [ pd-ssd, pd-standard]\n",
    "DISK_SIZE = 200  # GB\n",
    "\n",
    "disk_spec = {\"boot_disk_type\": DISK_TYPE, \"boot_disk_size_gb\": DISK_SIZE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_custom_job_worker_pool_specification:prebuilt_container"
   },
   "source": [
    "### 定义工作池规范\n",
    "\n",
    "接下来，您需要定义自定义超参数调整作业的工作池规范。工作池规范将包括以下内容：\n",
    "\n",
    "- `replica_count`：要配置的此机器类型的实例数。\n",
    "- `machine_spec`：硬件规范。\n",
    "- `disk_spec`：（可选）磁盘存储规范。\n",
    "\n",
    "- `python_package`：要安装在VM实例上的Python训练包以及要调用的Python模块，以及Python模块的命令行参数。\n",
    "\n",
    "现在让我们更深入了解Python包规范：\n",
    "\n",
    "- `executor_image_spec`：这是为您的自定义超参数调整作业配置的Docker镜像。\n",
    "\n",
    "- `package_uris`：这是您的Python训练包的位置（URI）列表，需要安装在配置实例上。这些位置需要在Cloud Storage存储桶中。这些可以是单个Python文件或整个包的zip（存档）。在后一种情况下，作业服务将解压（解档）内容到Docker镜像中。\n",
    "\n",
    "- `python_module`：要调用以运行自定义超参数调整作业的Python模块（脚本）。在本示例中，您将调用`trainer.task.py` - 请注意，不需要附加`.py`后缀。\n",
    "\n",
    "- `args`：要传递给相应Python模块的命令行参数。在本示例中，您将设置：\n",
    "   - `\"--model-dir=\" + MODEL_DIR`：存储模型工件的Cloud Storage位置。有两种方法可以告诉超参数调整脚本在哪里保存模型工件：\n",
    "      - 直接：将Cloud Storage位置作为命令行参数传递给您的训练脚本（设置变量`DIRECT = True`），或\n",
    "      - 间接：服务将Cloud Storage位置作为环境变量`AIP_MODEL_DIR`传递给您的训练脚本（设置变量`DIRECT = False`）。在这种情况下，您需要在作业规范中告诉服务模型工件位置。\n",
    "   - `\"--epochs=\" + EPOCHS`：训练的时期数。\n",
    "   - `\"--steps=\" + STEPS`：每个时期的步骤（批次）数。\n",
    "   - `\"--distribute=\" + TRAIN_STRATEGY\"`：用于单个或分布式超参数调整的超参数调整分发策略。\n",
    "      - `\"single\"`：单个设备。\n",
    "      - `\"mirror\"`：单个计算实例上的所有GPU设备。\n",
    "      - `\"multi\"`：所有计算实例上的所有GPU设备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_custom_job_worker_pool_specification:prebuilt_container"
   },
   "outputs": [],
   "source": [
    "JOB_NAME = \"custom_job_\" + UUID\n",
    "MODEL_DIR = \"{}/{}\".format(BUCKET_URI, JOB_NAME)\n",
    "\n",
    "if not TRAIN_NGPU or TRAIN_NGPU < 2:\n",
    "    TRAIN_STRATEGY = \"single\"\n",
    "else:\n",
    "    TRAIN_STRATEGY = \"mirror\"\n",
    "\n",
    "EPOCHS = 20\n",
    "STEPS = 100\n",
    "\n",
    "DIRECT = False\n",
    "if DIRECT:\n",
    "    CMDARGS = [\n",
    "        \"--model-dir=\" + MODEL_DIR,\n",
    "        \"--epochs=\" + str(EPOCHS),\n",
    "        \"--steps=\" + str(STEPS),\n",
    "        \"--distribute=\" + TRAIN_STRATEGY,\n",
    "    ]\n",
    "else:\n",
    "    CMDARGS = [\n",
    "        \"--epochs=\" + str(EPOCHS),\n",
    "        \"--steps=\" + str(STEPS),\n",
    "        \"--distribute=\" + TRAIN_STRATEGY,\n",
    "    ]\n",
    "\n",
    "worker_pool_spec = [\n",
    "    {\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": machine_spec,\n",
    "        \"disk_spec\": disk_spec,\n",
    "        \"python_package_spec\": {\n",
    "            \"executor_image_uri\": TRAIN_IMAGE,\n",
    "            \"package_uris\": [BUCKET_URI + \"/trainer_boston.tar.gz\"],\n",
    "            \"python_module\": \"trainer.task\",\n",
    "            \"args\": CMDARGS,\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_job:mbsdk"
   },
   "source": [
    "创建自定义作业\n",
    "\n",
    "使用`CustomJob`类来创建一个自定义作业，比如用于超参数调整，具有以下参数：\n",
    "\n",
    "- `display_name`：自定义作业的人类可读名称。\n",
    "- `worker_pool_specs`：相应虚拟机实例的规范。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_custom_job:mbsdk"
   },
   "outputs": [],
   "source": [
    "job = aip.CustomJob(display_name=\"boston_\" + UUID, worker_pool_specs=worker_pool_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_hpt_job:mbsdk"
   },
   "source": [
    "## 创建超参数调整作业\n",
    "\n",
    "使用`HyperparameterTuningJob`类创建一个超参数调整作业，具有以下参数：\n",
    "\n",
    "- `display_name`：自定义作业的可读名称。\n",
    "- `custom_job`：此自定义作业中的工作池规范适用于所有试验中创建的CustomJobs。\n",
    "- `metrics_spec`：要优化的度量。字典键是度量id，由您的训练作业报告，字典值是优化度量的目标（`最小化`或`最大化`）。\n",
    "- `parameter_spec`：要优化的参数。字典键是度量id，作为命令行关键字参数传递给您的训练作业，字典值是度量的参数规范。\n",
    "- `search_algorithm`：要使用的搜索算法：`grid`，`random`和`None`。如果指定`None`，则使用`Vizier`服务（贝叶斯）。\n",
    "- `max_trial_count`：要执行的最大试验次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_hpt_job:mbsdk"
   },
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "\n",
    "hpt_job = aip.HyperparameterTuningJob(\n",
    "    display_name=\"boston_\" + UUID,\n",
    "    custom_job=job,\n",
    "    metric_spec={\n",
    "        \"val_loss\": \"minimize\",\n",
    "    },\n",
    "    parameter_spec={\n",
    "        \"lr\": hpt.DoubleParameterSpec(min=0.001, max=0.1, scale=\"log\"),\n",
    "        \"units\": hpt.IntegerParameterSpec(min=4, max=128, scale=\"linear\"),\n",
    "    },\n",
    "    search_algorithm=\"random\",\n",
    "    max_trial_count=6,\n",
    "    parallel_trial_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_hpt_job:mbsdk"
   },
   "source": [
    "运行超参数调整作业\n",
    "\n",
    "使用`run()`方法执行超参数调整作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_hpt_job:mbsdk"
   },
   "outputs": [],
   "source": [
    "hpt_job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpt_trial_results:mbsdk"
   },
   "source": [
    "显示超参数调整作业试验结果\n",
    "\n",
    "在超参数调整作业完成之后，属性`trials`将返回每次试验的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpt_trial_results:mbsdk"
   },
   "outputs": [],
   "source": [
    "print(hpt_job.trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "best_trial:mbsdk"
   },
   "source": [
    "现在看看哪个试验是最好的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "best_trial:mbsdk"
   },
   "outputs": [],
   "source": [
    "best = (None, None, None, 0.0)\n",
    "for trial in hpt_job.trials:\n",
    "    # Keep track of the best outcome\n",
    "    if float(trial.final_measurement.metrics[0].value) > best[3]:\n",
    "        try:\n",
    "            best = (\n",
    "                trial.id,\n",
    "                float(trial.parameters[0].value),\n",
    "                float(trial.parameters[1].value),\n",
    "                float(trial.final_measurement.metrics[0].value),\n",
    "            )\n",
    "        except:\n",
    "            best = (\n",
    "                trial.id,\n",
    "                float(trial.parameters[0].value),\n",
    "                None,\n",
    "                float(trial.final_measurement.metrics[0].value),\n",
    "            )\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_best_model"
   },
   "source": [
    "获得最佳模型\n",
    "\n",
    "如果您使用了让服务告诉调整脚本在哪里保存模型工件的方法（`DIRECT = False`），那么最佳模型的模型工件将保存在：\n",
    "\n",
    "    MODEL_DIR/<best_trial_id>/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_best_model"
   },
   "outputs": [],
   "source": [
    "BEST_MODEL_DIR = MODEL_DIR + \"/\" + best[0] + \"/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "delete_hpt_job"
   },
   "source": [
    "### 删除超参数调优作业\n",
    "\n",
    "方法'delete（）'将删除超参数调优作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "delete_hpt_job"
   },
   "outputs": [],
   "source": [
    "hpt_job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpt_vizier_intro"
   },
   "source": [
    "## Vertex AI超参数调整和Vertex AI Vizer服务的结合\n",
    "\n",
    "以下示例演示了如何使用Vertex AI超参数调整服务和`Vizier`搜索服务设置、执行和评估试验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_job:mbsdk"
   },
   "source": [
    "## 创建自定义作业\n",
    "\n",
    "使用`CustomJob`类来创建自定义作业，例如用于超参数调整，具有以下参数：\n",
    "\n",
    "- `display_name`：自定义作业的人类可读名称。\n",
    "- `worker_pool_specs`：对应虚拟机实例的规格。\n",
    "- `base_output_dir`：用于存储模型工件的 Cloud Storage 位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_custom_job:mbsdk"
   },
   "outputs": [],
   "source": [
    "job = aip.CustomJob(\n",
    "    display_name=\"boston_\" + UUID,\n",
    "    worker_pool_specs=worker_pool_spec,\n",
    "    base_output_dir=MODEL_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_hpt_job:mbsdk,vizier"
   },
   "source": [
    "## 创建超参数调整作业\n",
    "\n",
    "使用类`HyperparameterTuningJob`来创建一个超参数调整作业，其中包括以下参数：\n",
    "\n",
    "- `display_name`: 用于自定义作业的人类可读名称。\n",
    "- `custom_job`: 此自定义作业中的工作池规范适用于所有试验中创建的CustomJobs。\n",
    "- `metrics_spec`: 要优化的指标。字典键是metric_id，由您的训练作业报告，字典值是指标的优化目标('minimize'或'maximize')。\n",
    "- `parameter_spec`: 要优化的参数。字典键是metric_id，作为命令行关键字参数传递给您的训练作业，字典值是指标的参数规范。\n",
    "- `search_algorithm`: 要使用的搜索算法：`grid`、`random`和`None`。如果指定了`None`，则会使用`Vizier`服务（贝叶斯）。\n",
    "- `max_trial_count`: 要执行的最大试验次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_hpt_job:mbsdk,vizier"
   },
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "\n",
    "hpt_job = aip.HyperparameterTuningJob(\n",
    "    display_name=\"boston_\" + UUID,\n",
    "    custom_job=job,\n",
    "    metric_spec={\n",
    "        \"val_loss\": \"minimize\",\n",
    "    },\n",
    "    parameter_spec={\n",
    "        \"lr\": hpt.DoubleParameterSpec(min=0.0001, max=0.1, scale=\"log\"),\n",
    "        \"units\": hpt.IntegerParameterSpec(min=4, max=512, scale=\"linear\"),\n",
    "    },\n",
    "    search_algorithm=None,\n",
    "    max_trial_count=12,\n",
    "    parallel_trial_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_hpt_job:mbsdk"
   },
   "source": [
    "使用`run()`方法执行超参数调整作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_hpt_job:mbsdk"
   },
   "outputs": [],
   "source": [
    "hpt_job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpt_trial_results:mbsdk"
   },
   "source": [
    "### 显示超参数调整工作试验结果\n",
    "\n",
    "在超参数调整工作完成后，属性`trials`将返回每次试验的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpt_trial_results:mbsdk"
   },
   "outputs": [],
   "source": [
    "print(hpt_job.trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "best_trial:mbsdk"
   },
   "source": [
    "现在看看哪个试验是最好的：### 最佳试验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "best_trial:mbsdk"
   },
   "outputs": [],
   "source": [
    "best = (None, None, None, 0.0)\n",
    "for trial in hpt_job.trials:\n",
    "    # Keep track of the best outcome\n",
    "    if float(trial.final_measurement.metrics[0].value) > best[3]:\n",
    "        try:\n",
    "            best = (\n",
    "                trial.id,\n",
    "                float(trial.parameters[0].value),\n",
    "                float(trial.parameters[1].value),\n",
    "                float(trial.final_measurement.metrics[0].value),\n",
    "            )\n",
    "        except:\n",
    "            best = (\n",
    "                trial.id,\n",
    "                float(trial.parameters[0].value),\n",
    "                None,\n",
    "                float(trial.final_measurement.metrics[0].value),\n",
    "            )\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_best_model"
   },
   "source": [
    "获取最佳模型\n",
    "\n",
    "如果您使用了让服务告诉调整脚本在哪里保存模型工件的方法（`DIRECT = False`），那么最佳模型的模型工件将保存在：\n",
    "\n",
    "    MODEL_DIR/<best_trial_id>/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_best_model"
   },
   "outputs": [],
   "source": [
    "BEST_MODEL_DIR = MODEL_DIR + \"/\" + best[0] + \"/model\"\n",
    "\n",
    "! gsutil ls {BEST_MODEL_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "delete_hpt_job"
   },
   "source": [
    "删除超参数调整作业\n",
    "\n",
    "方法'delete()'将删除超参数调整作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "delete_hpt_job"
   },
   "outputs": [],
   "source": [
    "hpt_job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vizier_intro"
   },
   "source": [
    "## 独立的 Vertex AI 视觉服务\n",
    "\n",
    "`Vizier` 服务可作为独立服务用于选择试验的下一组参数。\n",
    "\n",
    "*注意:* 该服务不执行试验。您需要自行创建试验和执行。\n",
    "\n",
    "了解更多关于 [使用 Vizier](https://cloud.google.com/vertex-ai/docs/vizier/using-vizier)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vizier_client"
   },
   "source": [
    "### 指定用于建议试验参数的算法\n",
    "\n",
    "首先，创建一个`StudyConfig`，并指定用于建议下一个试验的算法。\n",
    "\n",
    "    GRID_SEARCH：网格搜索\n",
    "    RANDOM_SEARCH：随机搜索\n",
    "    ALGORITHM_UNSPECIFIED：Vizier 贝叶斯算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7dd26490358"
   },
   "outputs": [],
   "source": [
    "problem = pyvizier.StudyConfig()\n",
    "problem.algorithm = pyvizier.Algorithm.RANDOM_SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_vizier_study"
   },
   "source": [
    "### 创建一个研究\n",
    "\n",
    "一项研究是一系列实验或试验，帮助您优化超参数或参数。\n",
    "\n",
    "在下面的例子中，目标是最大化 y = x^2，其中 x 的范围在 \\[-10, 10\\]。这个例子只有一个参数，并使用一个易于计算的函数来演示如何使用Vizier。\n",
    "\n",
    "首先，您需要将要最小化或最大化的指标作为列表指定给 `metric_information` 属性。然后使用 `add_XXX_params()` 方法为相应的数据类型指定研究的参数：\n",
    "\n",
    "    - add_bool_param\n",
    "    - add_categorical_param\n",
    "    - add_discrete_param\n",
    "    - add_float_param\n",
    "    - add_int_param\n",
    "\n",
    "您可以使用 `create_or_load()` 方法来创建这项研究。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_vizier_study"
   },
   "outputs": [],
   "source": [
    "STUDY_DISPLAY_NAME = \"xpow2\" + UUID\n",
    "\n",
    "problem.metric_information.append(\n",
    "    pyvizier.MetricInformation(name=\"y\", goal=pyvizier.ObjectiveMetricGoal.MAXIMIZE)\n",
    ")\n",
    "\n",
    "params = problem.search_space.select_root()\n",
    "params.add_float_param(\"x\", -10.0, 10.0, scale_type=pyvizier.ScaleType.LINEAR)\n",
    "\n",
    "study = Study.create_or_load(display_name=STUDY_DISPLAY_NAME, problem=problem)\n",
    "\n",
    "STUDY_NAME = study.name\n",
    "print(\"STUDY_NAME: {}\".format(STUDY_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_vizier_study"
   },
   "source": [
    "### 获取大臣研究\n",
    "\n",
    "您可以使用方法`list()`来获取研究。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_vizier_study"
   },
   "outputs": [],
   "source": [
    "studies = Study.list()\n",
    "print(studies[0].gca_resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vizier_suggest_trial"
   },
   "source": [
    "获取建议试验\n",
    "\n",
    "接下来，使用方法`suggest()`查询Vizier服务获取建议试验，使用以下键/值对：\n",
    "\n",
    "- `count`: 要建议的试验数量。\n",
    "\n",
    "这个调用是一个长时间运行的操作。响应对象的`result()`方法将等待调用完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11ff2c4562cb"
   },
   "outputs": [],
   "source": [
    "SUGGEST_COUNT = 1\n",
    "\n",
    "trials = study.suggest(count=SUGGEST_COUNT)\n",
    "\n",
    "print(trials)\n",
    "\n",
    "# Get the trial ID of the first trial\n",
    "TRIAL_ID = trials[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_vizier_trial"
   },
   "source": [
    "### 评估结果\n",
    "在收到您的试验建议之后，评估每个试验并将每个结果记录为一个测量值。\n",
    "\n",
    "例如，如果您要优化的函数是y = x^2，那么您可以使用试验中建议的x值来评估该函数。使用建议值为0.1，该函数计算结果为y = 0.1 * 0.1，结果为0.01。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vizier_add_measurement"
   },
   "source": [
    "### 添加测量\n",
    "\n",
    "在评估您的试验建议并获取测量结果后，将该测量结果添加到您的试验中。\n",
    "\n",
    "使用以下指令来存储您的测量结果并发送请求。在本例中，将RESULT替换为测量结果。如果您要优化的函数是y = x^2，并且建议的x值为0.1，则结果为0.01。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vizier_add_measurement"
   },
   "outputs": [],
   "source": [
    "RESULT = 0.01\n",
    "\n",
    "measurement = pyvizier.Measurement()\n",
    "measurement.metrics[\"y\"] = RESULT\n",
    "\n",
    "trials[0].add_measurement(measurement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vizier_delete_study"
   },
   "source": [
    "删除大臣研究\n",
    "\n",
    "方法 'delete()' 将删除该研究。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vizier_delete_study"
   },
   "outputs": [],
   "source": [
    "study.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于本教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在本教程中创建的各个资源：\n",
    "\n",
    "- Cloud Storage 存储桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "outputs": [],
   "source": [
    "delete_bucket = False\n",
    "\n",
    "if os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_vertex_vizier.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
