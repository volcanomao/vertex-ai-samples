{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "# 在 GCP 上进行的 E2E 机器学习：MLOps 阶段 2：实验：开始使用 Vertex AI Training 进行 R 的训练\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training_r.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "        <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training_r.ipynb\">\n",
    "        <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "        </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage2/get_started_vertex_training_r.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在 Vertex AI Workbench 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:mlops"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何在 Google Cloud 上生产环境中使用 Vertex AI 进行端到端 MLOps。本教程涵盖了第二阶段：实验阶段：使用 Vertex AI Training for R 入门。请注意，此笔记本应仅在 R 笔记本图像（例如，R4.1）中运行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:mlops,stage2,get_started_vertex_training_r"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用`Vertex AI Training`来训练一个自定义的 R 模型。\n",
    "\n",
    "此教程使用以下谷歌云 ML 服务:\n",
    "\n",
    "- `Vertex AI Training`\n",
    "- `Vertex AI Model`资源\n",
    "\n",
    "执行的步骤包括:\n",
    "\n",
    "- 在笔记本中使用 %%R 魔术命令本地训练一个 R 模型\n",
    "- 创建一个包含训练好的 R 模型和服务功能的部署镜像\n",
    "- 在本地测试部署镜像\n",
    "- 为带有嵌入式 R 模型的部署镜像创建一个`Vertex AI Model`资源\n",
    "- 将带有嵌入式 R 模型的部署镜像部署到`Vertex AI Endpoint`资源\n",
    "- 使用带有嵌入式 R 模型的部署镜像进行测试\n",
    "- 创建一个从 R 到 Python 的训练包\n",
    "- 为训练模型创建一个训练镜像\n",
    "- 使用带有 R 到 Python 训练包的 `Vertex AI Training` 服务来训练一个 R 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:r,iris,lcn"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是内置于 R 包中的鸢尾花数据集。该数据集不需要任何特征工程。训练的模型预测鸢尾花的类型，属于三种品种中的一种：山鸢尾、维吉尼亚鸢尾或变色鸢尾。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c997d8d92ce"
   },
   "source": [
    "### 成本\n",
    "\n",
    "本教程使用Google Cloud的收费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI定价](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage定价](https://cloud.google.com/storage/pricing)，并使用[Pricing Calculator](https://cloud.google.com/products/calculator/)根据您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_mlops"
   },
   "source": [
    "## 安装步骤\n",
    "\n",
    "安装执行这个笔记本所需的软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fd00fa70a2a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "! pip3 install --upgrade google-cloud-aiplatform[tensorboard] $USER_FLAG -q\n",
    "! pip3 install --upgrade rpy2 $USER_FLAG -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### 重新启动内核\n",
    "\n",
    "安装了额外的软件包后，您需要重新启动笔记本内核，以便它能找到这些软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "restart"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e3cab0cc491"
   },
   "source": [
    "在你开始之前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be929e7b4d76"
   },
   "source": [
    "### 设置您的 Google Cloud 项目\n",
    "\n",
    "**无论您使用的是哪种笔记本环境，都需要按照以下步骤操作。**\n",
    "\n",
    "1. [选择或创建 Google Cloud 项目](https://console.cloud.google.com/cloud-resource-manager)。当您第一次创建帐户时，您将获得一笔 300 美元的免费信用额用于支付计算/存储成本。\n",
    "\n",
    "1. [确保您的项目已启用计费功能](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "1. [启用 Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。\n",
    "\n",
    "1. 如果您在本地运行此笔记本，您需要安装 [Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "1. 在下面的单元格中输入您的项目 ID。然后运行该单元格，确保 Cloud SDK 在此笔记本的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter 运行以 `!` 开头的行作为 shell 命令，并将以 `$` 开头的 Python 变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id"
   },
   "source": [
    "#### 设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用`gcloud`来获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "区域\n",
    "\n",
    "您还可以更改“REGION”变量，该变量用于笔记本其余部分的操作。以下是支持Vertex AI的区域。我们建议您选择最接近您的区域。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太地区：`asia-east1`\n",
    "\n",
    "您可能无法使用多区域存储桶来训练Vertex AI。并非所有区域都支持所有Vertex AI服务。\n",
    "\n",
    "了解更多关于[Vertex AI区域](https://cloud.google.com/vertex-ai/docs/general/locations)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type:\"string\"}\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "时间戳\n",
    "\n",
    "如果您正在参加实时教程会话，您可能正在使用共享的测试帐户或项目。为了避免用户在创建的资源上出现名称冲突，您可以为每个实例会话创建一个时间戳，并将时间戳附加到您在本教程中创建的资源名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "timestamp"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ffa6b6c7cdb"
   },
   "source": [
    "### 认证您的Google Cloud账户\n",
    "\n",
    "**如果您正在使用Vertex AI Workbench笔记本**，您的环境已经经过身份验证。请跳过此步骤。\n",
    "\n",
    "**如果您正在使用Colab**，运行下面的单元格，并按提示进行身份验证，通过oAuth验证您的账户。\n",
    "\n",
    "**否则**，请按照以下步骤操作：\n",
    "\n",
    "在Cloud控制台中，转到[创建服务账号密钥](https://console.cloud.google.com/apis/credentials/serviceaccountkey)页面。\n",
    "\n",
    "1. **点击创建服务账号**。\n",
    "\n",
    "2. 在**服务账号名称**字段中输入名称，并点击**创建**。\n",
    "\n",
    "3. 在**向此服务账号授予权限给项目**部分，点击角色下拉列表。在筛选框中输入“Vertex AI”，选择**Vertex AI管理员**。在筛选框中输入“存储对象管理员”，选择**存储对象管理员**。\n",
    "\n",
    "4. 点击创建。一个包含您的密钥的JSON文件将下载到您的本地环境中。\n",
    "\n",
    "5. 在下面的单元格中以GOOGLE_APPLICATION_CREDENTIALS变量的形式输入您的服务账号密钥的路径，然后运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b72272258fc"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = False\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        IS_COLAB = True\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "**无论您使用的是哪种笔记本环境，都需要按照以下步骤操作。**\n",
    "\n",
    "在初始化用于Python的Vertex AI SDK时，您需要指定一个云存储临时存储桶。这个临时存储桶是您数据集和模型资源相关数据在会话间保留的地方。\n",
    "\n",
    "请在下方设置您的云存储桶的名称。存储桶的名称在所有谷歌云项目中必须是全局唯一的，包括您组织之外的谷歌云项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = \"gs://[your-bucket-name]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_URI == \"\" or BUCKET_URI is None or BUCKET_URI == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_URI = \"gs://\" + PROJECT_ID + \"aip-\" + TIMESTAMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有当您的存储桶尚不存在时：运行以下单元格以创建您的云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "最后，通过检查其内容来验证对云存储桶的访问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。\n",
    "### 导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "import google.cloud.aiplatform as aip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "### 初始化用于 Python 的 Vertex AI SDK\n",
    "\n",
    "为您的项目和相应的存储桶初始化用于 Python 的 Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "source": [
    "设置硬件加速器\n",
    "\n",
    "您可以为训练和预测设置硬件加速器。\n",
    "\n",
    "将变量`TRAIN_GPU/TRAIN_NGPU`和`DEPLOY_GPU/DEPLOY_NGPU`设置为使用支持GPU的容器映像以及分配给虚拟机（VM）实例的GPU数量。例如，要使用一个GPU容器映像，并为每个VM分配4个Nvidia Telsa K80 GPU，您可以指定：\n",
    "\n",
    "    (aip.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
    "\n",
    "\n",
    "否则，指定`(None, None)`以在CPU上运行容器映像。\n",
    "\n",
    "了解更多关于[您地区的硬件加速器支持](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)。\n",
    "\n",
    "*注意*：TF 2.3之前的GPU支持版本在加载此教程中的自定义模型时将无法运行。这是一个已知问题，在TF 2.3中已修复。这是由于在服务函数中生成静态图操作。如果在自己的自定义模型中遇到此问题，请使用支持GPU的TF 2.3容器映像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TRAIN_GPU\"):\n",
    "    TRAIN_GPU, TRAIN_NGPU = (\n",
    "        aip.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "        int(os.getenv(\"IS_TESTING_TRAIN_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    TRAIN_GPU, TRAIN_NGPU = (None, None)\n",
    "\n",
    "if os.getenv(\"IS_TESTING_DEPLOY_GPU\"):\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (\n",
    "        aip.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "        int(os.getenv(\"IS_TESTING_DEPLOY_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training,prediction"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于训练和预测的机器类型。\n",
    "\n",
    "- 设置变量`TRAIN_COMPUTE`和`DEPLOY_COMPUTE`以配置用于训练和预测的虚拟机的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`：每个vCPU 3.75GB的内存。\n",
    "     - `n1-highmem`：每个vCPU 6.5GB的内存。\n",
    "     - `n1-highcpu`：每个vCPU 0.9GB的内存。\n",
    " - `vCPUs`：\\[2, 4, 8, 16, 32, 64, 96 \\]个CPU核心\n",
    "\n",
    "*注意：以下不支持用于训练:*\n",
    "\n",
    " - `standard`：2个vCPUs\n",
    " - `highcpu`：2、4和8个vCPUs\n",
    "\n",
    "*注意：您也可以使用n2和e2机器类型进行训练和部署，但它们不支持GPU。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training,prediction"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TRAIN_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_TRAIN_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)\n",
    "\n",
    "if os.getenv(\"IS_TESTING_DEPLOY_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_DEPLOY_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_intro"
   },
   "source": [
    "## R培训简介\n",
    "\n",
    "### 训练一个R模型\n",
    "\n",
    "您可以在本地训练模型，也可以使用`Vertex AI Training`服务。在后一种情况下，您需要将R到Python解析器`rpy2`安装到您的训练实例（例如，setup.py），并使用R到Python解析器`rpy2`执行R训练脚本。\n",
    "\n",
    "### 部署一个R模型\n",
    "\n",
    "在`Vertex AI Prediction`服务上部署一个R模型需要使用一个定制的容器来提供在线预测。在本教程中，您将部署一个运行plumber R包的容器，以提供来自训练模型工件的预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_ipython"
   },
   "source": [
    "### 载入 R 笔记本解释器\n",
    "\n",
    "载入模块 `rpy2.ipython` 将在您的笔记本中添加对 %R 和 %RR 魔法单元的支持。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_ipython"
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_install:randomForest"
   },
   "source": [
    "### 安装和引入一些额外的R包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_install:randomForest"
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "install.packages(c(\"randomForest\", \"plumber\"), repos = \"http://cran.us.r-project.org\")\n",
    "\n",
    "library(ggplot2)\n",
    "library(randomForest)\n",
    "library(plumber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick_peek:r"
   },
   "source": [
    "快速查看您的数据\n",
    "\n",
    "本教程使用了内置在R软件包中的鸢尾花数据集的版本。\n",
    "\n",
    "首先，快速查看数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quick_peek:r"
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "head(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom_dir"
   },
   "outputs": [],
   "source": [
    "# Make folder for R\n",
    "! rm -rf deploy custom\n",
    "! mkdir deploy custom custom/trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "locally_train:r,iris"
   },
   "source": [
    "### 在本地训练一个R模型\n",
    "\n",
    "首先，您在本地训练这个R模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "locally_train:r,iris"
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# train model\n",
    "model = randomForest(Species ~ ., data = iris)\n",
    "# save model\n",
    "save(model, file = \"deploy/model.RData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "serving_script_r"
   },
   "source": [
    "### 提供脚本\n",
    "\n",
    "您创建了一个用于提供预测的 R 脚本。此脚本执行以下操作：\n",
    "\n",
    "- 从输入请求的 HTTP 主体中提取预测请求数值。\n",
    "- 为 R 模型构建一个预测请求。\n",
    "- 将预测请求提交给 R 模型。\n",
    "- 返回预测结果。\n",
    "\n",
    "*注意*：Plumber 使用注释“注解”在函数上面定义 Web 服务。当您将文件输入 Plumber 时，您将获得一个可运行的 Web 服务，其他系统可以通过网络与之交互。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "serving_script_r"
   },
   "outputs": [],
   "source": [
    "%%writefile deploy/serving.R\n",
    "# serving.R\n",
    "\n",
    "library(\"randomForest\")\n",
    "\n",
    "#* Health check\n",
    "#* @get /ping\n",
    "#* @serializer unboxedJSON\n",
    "function() {\n",
    "    list(status = \"OK\")\n",
    "}\n",
    "\n",
    "#* @apiTitle flower classifier\n",
    "#* @param petal_length\n",
    "#* @param petal_width\n",
    "#* @param sepal_length\n",
    "#* @param sepal_width\n",
    "#* @post /classify\n",
    "function (req)\n",
    "{\n",
    "    instances <- as.data.frame(jsonlite::fromJSON(req$postBody))\n",
    "    results <- list()\n",
    "\n",
    "    load(\"./model.RData\")\n",
    "\n",
    "    for(i in 1:nrow(instances)) {       # for-loop over columns\n",
    "        petal_length <- instances[i, \"instances.petal_length\"]\n",
    "        petal_width <- instances[i, \"instances.petal_width\"]\n",
    "        sepal_length <- instances[i, \"instances.sepal_length\"]\n",
    "        sepal_width <- instances[i, \"instances.sepal_width\"]\n",
    "        test = c(sepal_length, sepal_width, petal_length, petal_width)\n",
    "        test = sapply(test, as.numeric)\n",
    "        test = data.frame(matrix(test, ncol = 4))\n",
    "        colnames(test) = colnames(iris[, 1:4])\n",
    "        results <- append(results, predict(model, test))\n",
    "    }\n",
    "\n",
    "    list(predictions = results)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "start_server_r"
   },
   "source": [
    "#### 运行R服务器的脚本\n",
    "\n",
    "接下来，您需要创建一个运行服务器的文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "start_server_r"
   },
   "outputs": [],
   "source": [
    "%%writefile deploy/startServer.R\n",
    "library(plumber)\n",
    "pr <- plumb(\"serving.R\")\n",
    "pr$run(host = \"0.0.0.0\", port = 7080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "docker_write,prediction,r"
   },
   "source": [
    "### 为预测创建 R 容器\n",
    "\n",
    "目前，Vertex AI 没有预定义的容器可以用于部署 R 模型进行预测。没关系，您可以自己组装一个定制的容器。在本教程中，您可以按照以下步骤从一个 Docker 镜像构建一个部署容器：\n",
    "\n",
    "- 设置由 RStudio 提供的基础镜像（rstudio/plumber）。\n",
    "- 将模型工件和服务脚本打包到一个 Docker 镜像中。\n",
    "- 在端口 7080 上启动服务脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "docker_write,prediction,r"
   },
   "outputs": [],
   "source": [
    "%%writefile deploy/Dockerfile\n",
    "\n",
    "FROM rstudio/plumber\n",
    "\n",
    "# install random forest\n",
    "RUN R -e 'install.packages(c(\"randomForest\"), repos = \"https://cran.rstudio.com/\")'\n",
    "\n",
    "# Copy model and script\n",
    "RUN mkdir /app\n",
    "COPY model.RData /app\n",
    "COPY serving.R /app\n",
    "COPY startServer.R /app\n",
    "WORKDIR /app\n",
    "\n",
    "# plumber & run server\n",
    "EXPOSE 7080\n",
    "\n",
    "ENTRYPOINT [\"R\", \"-f\", \"/app/startServer.R\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "docker_push,prediction,r"
   },
   "outputs": [],
   "source": [
    "DEPLOY_IMAGE = f\"gcr.io/{PROJECT_ID}/r-predict-iris\"\n",
    "print(DEPLOY_IMAGE)\n",
    "\n",
    "! docker build --tag=$DEPLOY_IMAGE ./deploy\n",
    "\n",
    "! docker push $DEPLOY_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_docker_locally:launch,r"
   },
   "source": [
    "### 本地测试Docker镜像\n",
    "\n",
    "接下来，您可以本地测试已经创建好的用于提供预测服务的Docker镜像。\n",
    "\n",
    "#### 启动服务二进制文件\n",
    "\n",
    "首先，启动服务二进制文件，监听端口7080，并进行健康检查。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_docker_locally:launch,r"
   },
   "outputs": [],
   "source": [
    "! docker stop local_iris 2>/dev/null\n",
    "! docker run -t -d --rm -p 7080:7080 --name=local_iris $DEPLOY_IMAGE\n",
    "! sleep 10\n",
    "! curl http://localhost:7080/ping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_docker_locally:predict,r"
   },
   "source": [
    "发送预测请求\n",
    "\n",
    "接下来，您将向您本地启动的服务器二进制文件发送一个预测请求。之后，您将关闭启动的服务器二进制文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_docker_locally:predict,r"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > ./deploy/instances.json <<END\n",
    "{\n",
    "  \"instances\": [{\n",
    "      \"sepal_width\": 1,\n",
    "      \"sepal_length\": 2,\n",
    "      \"petal_width\": 3,\n",
    "      \"petal_length\": 1\n",
    "    },\n",
    "    {\n",
    "      \"sepal_width\": 4,\n",
    "      \"sepal_length\": 2,\n",
    "      \"petal_width\": 1,\n",
    "      \"petal_length\": 1\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "END\n",
    "\n",
    "curl -s -X POST \\\n",
    "  -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "  -d @./deploy/instances.json \\\n",
    "  http://localhost:7080/classify\n",
    "\n",
    "docker stop local_iris 1>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_model,r"
   },
   "source": [
    "### 将一个 R 模型上传至 `Vertex AI Model` 资源\n",
    "\n",
    "接下来，将 R 模型上传到 Vertex AI Model 资源，具有以下参数：\n",
    "\n",
    "- `display_name`：模型资源的可读名称。\n",
    "- `serving_container_image_uri`：包含部署二进制文件和 R 模型的部署镜像。\n",
    "- `serving_container_predict_route`：用于预测请求的 URI 端点。\n",
    "- `serving_container_health_route`：用于健康检测 ping 的 URI 端点。\n",
    "- `serving_container_ports`：用于监听预测/健康请求的端口列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_model,r"
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"iris_\" + TIMESTAMP\n",
    "health_route = \"/ping\"\n",
    "predict_route = \"/classify\"\n",
    "serving_container_ports = [7080]\n",
    "\n",
    "model = aip.Model.upload(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    serving_container_image_uri=DEPLOY_IMAGE,\n",
    "    serving_container_predict_route=predict_route,\n",
    "    serving_container_health_route=health_route,\n",
    "    serving_container_ports=serving_container_ports,\n",
    ")\n",
    "\n",
    "model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:mbsdk,all"
   },
   "source": [
    "## 部署模型\n",
    "\n",
    "接下来，部署您的模型以进行在线预测。要部署模型，您需要调用`deploy`方法，并提供以下参数：\n",
    "\n",
    "- `deployed_model_display_name`：部署模型的人类可读名称。\n",
    "- `traffic_split`：端点上流量的百分比将流向该模型，可以指定为一个或多个键/值对的字典。\n",
    "如果只有一个模型，那么指定为{ \"0\": 100 }，其中\"0\"是指上传的这个模型，100表示100%的流量。\n",
    "如果端点上存在其他模型，需要分配流量，则使用model_id来指定为{ \"0\": percent, model_id: percent, ... }，其中model_id是已部署到端点的现有模型的模型ID。这些百分比必须加起来等于100。\n",
    "- `machine_type`：用于训练的机器类型。\n",
    "- `accelerator_type`：硬件加速器类型。\n",
    "- `accelerator_count`：要附加到工作副本的加速器数量。\n",
    "- `starting_replica_count`：最初要预留的计算实例数。\n",
    "- `max_replica_count`：要扩展到的最大计算实例数。在本教程中，只预留一个实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy_model:mbsdk,all"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_NAME = \"iris-\" + TIMESTAMP\n",
    "\n",
    "TRAFFIC_SPLIT = {\"0\": 100}\n",
    "\n",
    "MIN_NODES = 1\n",
    "MAX_NODES = 1\n",
    "\n",
    "if DEPLOY_GPU:\n",
    "    endpoint = model.deploy(\n",
    "        deployed_model_display_name=DEPLOYED_NAME,\n",
    "        traffic_split=TRAFFIC_SPLIT,\n",
    "        machine_type=DEPLOY_COMPUTE,\n",
    "        accelerator_type=DEPLOY_GPU.name,\n",
    "        accelerator_count=DEPLOY_NGPU,\n",
    "        min_replica_count=MIN_NODES,\n",
    "        max_replica_count=MAX_NODES,\n",
    "    )\n",
    "else:\n",
    "    endpoint = model.deploy(\n",
    "        deployed_model_display_name=DEPLOYED_NAME,\n",
    "        traffic_split=TRAFFIC_SPLIT,\n",
    "        machine_type=DEPLOY_COMPUTE,\n",
    "        min_replica_count=MIN_NODES,\n",
    "        max_replica_count=MAX_NODES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_deployed_model:iris"
   },
   "source": [
    "### 进行测试预测\n",
    "\n",
    "接下来，您可以通过发送合成数据来测试已部署的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_deployed_model:iris"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    INSTANCES = [\n",
    "        {\"sepal_width\": 1, \"sepal_length\": 2, \"petal_width\": 3, \"petal_length\": 1},\n",
    "        {\"sepal_width\": 4, \"sepal_length\": 2, \"petal_width\": 1, \"petal_length\": 1},\n",
    "    ]\n",
    "\n",
    "    prediction = endpoint.predict(instances=INSTANCES)\n",
    "\n",
    "    print(prediction)\n",
    "except:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "source": [
    "撤销模型\n",
    "\n",
    "当您完成预测后，您可以从“端点”资源中撤销模型。这将取消所有计算资源，并停止对部署模型的计费。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "source": [
    "删除端点\n",
    "\n",
    "方法“delete()”将删除端点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "source": [
    "删除模型\n",
    "\n",
    "方法'delete（）'将会删除模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taskpy_contents:iris,r"
   },
   "source": [
    "### 为 Python/R 培训包创建任务脚本\n",
    "\n",
    "接下来，您需要为培训包创建 `task.py` 脚本。一些重要的步骤包括：\n",
    "\n",
    "- 命令行参数：\n",
    "    - `model-dir`：保存训练模型的位置。在使用 Vertex AI 自定义训练时，该位置将在环境变量 `AIP_MODEL_DIR` 中指定。\n",
    "\n",
    "- 培训：\n",
    "    - 使用 R 到 Python 解释器来运行 R 培训脚本。\n",
    "\n",
    "- 模型工件保存：\n",
    "    - 在由 `model-dir` 指定的 Cloud 存储位置保存模型工件。\n",
    "    - *注意*：GCSFuse（`/gcs`）用于在 Cloud 存储存储桶上执行文件系统操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taskpy_contents:iris,r"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import rpy2\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "# import rpy2's package module\n",
    "import rpy2.robjects.packages as rpackages\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model-dir', dest='model_dir',\n",
    "                    default=os.getenv('AIP_MODEL_DIR'), type=str, help='Model dir.')\n",
    "args = parser.parse_args()\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# import R's utility package\n",
    "randomForest = rpackages.importr('randomForest')\n",
    "\n",
    "# train the model\n",
    "logging.info(\"Model training started ...\")\n",
    "rpy2.robjects.r('''\n",
    "    # train model\n",
    "    model = randomForest(Species ~ ., data = iris)\n",
    "    # save model\n",
    "    save(model, file = \"model.RData\")\n",
    "'''\n",
    ")\n",
    "logging.info(\"Model training completed ...\")\n",
    "\n",
    "# GCSFuse conversion\n",
    "gs_prefix = 'gs://'\n",
    "gcsfuse_prefix = '/gcs/'\n",
    "if args.model_dir.startswith(gs_prefix):\n",
    "    args.model_dir = args.model_dir.replace(gs_prefix, gcsfuse_prefix)\n",
    "    dirpath = os.path.split(args.model_dir)[0]\n",
    "    if not os.path.isdir(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "# Upload the saved model file to Cloud Storage\n",
    "gcs_model_path = os.path.join(args.model_dir, 'model.RData')\n",
    "logging.info(\"Saving model artifacts to {}\". format(gcs_model_path))\n",
    "with open(\"model.RData\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "with open(gcs_model_path, \"wb\") as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "docker_write,training,r"
   },
   "source": [
    "为训练创建 R 容器\n",
    "\n",
    "目前，Vertex AI 没有用于训练 R 模型的预定义容器。没问题，您可以自己组装自定义容器。在本教程中，您可以按照以下步骤从 Docker 镜像构建部署容器：\n",
    "\n",
    "- 将基本镜像设置为 TensorFlow 深度学习镜像\n",
    "- 安装 R-to-Python 包和其他 R 工具\n",
    "- 安装云存储包\n",
    "- 将模型内容和服务脚本打包到 Docker 镜像中。\n",
    "- 在容器中设置入口点以运行训练包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "docker_write,training,r"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/Dockerfile\n",
    "\n",
    "FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-3\n",
    "\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends build-essential r-base r-cran-randomforest python3.6 python3-pip python3-setuptools python3-dev\n",
    "RUN pip install google-cloud-storage\n",
    "RUN pip install rpy2\n",
    "\n",
    "# install random forest\n",
    "RUN R -e 'install.packages(c(\"randomForest\"), repos = \"https://cran.rstudio.com/\")'\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY trainer /trainer\n",
    "\n",
    "# Sets up the entry point to invoke the trainer.\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "docker_push,training,r"
   },
   "outputs": [],
   "source": [
    "TRAIN_IMAGE = f\"gcr.io/{PROJECT_ID}/r-train-iris\"\n",
    "print(TRAIN_IMAGE)\n",
    "\n",
    "! docker build --tag=$TRAIN_IMAGE ./custom\n",
    "\n",
    "! docker push $TRAIN_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_container_training_job:mbsdk,no_model"
   },
   "source": [
    "### 创建和运行自定义训练任务\n",
    "\n",
    "要训练一个自定义模型，您需要执行两个步骤：1）创建一个自定义训练任务，2）运行这个任务。\n",
    "\n",
    "#### 创建自定义训练任务\n",
    "\n",
    "使用`CustomTrainingJob`类创建一个自定义训练任务，包括以下参数：\n",
    "\n",
    "- `display_name`：自定义训练任务的可读名称。\n",
    "- `container_uri`：训练容器镜像。\n",
    "- `command`：在容器内调用的命令（例如解释器）和脚本。\n",
    "\n",
    "*注意：* 在容器内可以覆盖命令和脚本的调用方式（即 ENTRYPOINT）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_custom_container_training_job:mbsdk,no_model"
   },
   "outputs": [],
   "source": [
    "job = aip.CustomContainerTrainingJob(\n",
    "    display_name=\"iris_\" + TIMESTAMP,\n",
    "    container_uri=TRAIN_IMAGE,\n",
    "    command=[\"python3\", \"trainer/task.py\"],\n",
    ")\n",
    "\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_custom_container_training_job:r"
   },
   "source": [
    "运行自定义容器训练任务\n",
    "\n",
    "接下来，通过调用`run()`方法运行自定义任务来启动训练任务。参数与运行自定义训练任务时相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_custom_container_training_job:r"
   },
   "outputs": [],
   "source": [
    "CMDARGS = [\"--model-dir=\" + BUCKET_URI]\n",
    "\n",
    "job.run(args=CMDARGS, replica_count=1, machine_type=TRAIN_COMPUTE, sync=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "delete_job"
   },
   "source": [
    "删除自定义训练作业\n",
    "\n",
    "训练作业完成后，您可以使用`delete()`方法删除训练作业。在完成之前，可以使用`cancel()`方法取消训练作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "delete_job"
   },
   "outputs": [],
   "source": [
    "job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理本项目中使用的所有Google Cloud资源，您可以删除用于教程的[Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在本教程中创建的个别资源：\n",
    "\n",
    "- 模型（已在先前单元格中删除）\n",
    "- 端点（已在先前单元格中删除）\n",
    "- 自定义作业（已在先前单元格中删除）\n",
    "- 云存储桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "outputs": [],
   "source": [
    "delete_bucket = False\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_vertex_training_r.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
