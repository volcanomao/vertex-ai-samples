{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "# 在GCP上的端到端机器学习：MLOps阶段2：实验：开始使用AutoML训练\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_automl_training.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_automl_training.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage2/get_started_automl_training.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:mlops"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何在Google Cloud上使用Vertex AI进行端到端MLOps生产。本教程涵盖了第2阶段：实验：开始使用AutoML训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:mlops,stage2,get_started_automl_training"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用 `AutoML` 在 `Vertex AI` 上进行训练。\n",
    "\n",
    "该教程使用以下谷歌云ML服务：\n",
    "\n",
    "- `AutoML 训练`\n",
    "- `Vertex AI 数据集`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 训练图像模型\n",
    "- 将图像模型导出为边缘模型\n",
    "- 训练表格模型\n",
    "- 将表格模型导出为云模型\n",
    "- 训练文本模型\n",
    "- 训练视频模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "recommendation:mlops,stage2,automl,training"
   },
   "source": [
    "### 推荐\n",
    "\n",
    "在 Google Cloud 上进行端到端 MLOps 时，在何时使用 AutoML 时，以下是最佳实践：\n",
    "\n",
    "* **您只有有限数量的训练数据**\n",
    "\n",
    "* **在尝试自定义模型之前，您想建立一个基准度量**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:flowers,icn"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "#### 图像\n",
    "\n",
    "本教程中使用的图像数据集是来自[TensorFlow数据集](https://www.tensorflow.org/datasets/catalog/overview)的[花卉数据集](https://www.tensorflow.org/datasets/catalog/tf_flowers)。本教程中的数据集版本存储在公共云存储桶中。训练的模型可以预测给定图像中的花卉类型，包括五种花卉：雏菊、蒲公英、玫瑰、向日葵或郁金香。\n",
    "\n",
    "#### 表格\n",
    "\n",
    "本教程中使用的表格数据集是来自[Google BigQuery公共数据集](https://cloud.google.com/bigquery/public-data)的GSOD数据集。在本教程中使用的数据集版本仅使用年份、月份和日期这些字段来预测平均每日温度（mean_temp）的值。\n",
    "\n",
    "#### 文本\n",
    "\n",
    "本教程中使用的文本数据集是来自[Kaggle数据集](https://www.kaggle.com/ritresearch/happydb)的[Happy Moments数据集](https://www.kaggle.com/ritresearch/happydb)。在本教程中使用的数据集版本存储在公共云存储桶中。\n",
    "\n",
    "#### 视频\n",
    "\n",
    "本教程中使用的视频数据集是来自[MIT](http://cbcl.mit.edu/publications/ps/Kuehne_etal_iccv11.pdf)的[人体运动数据集](https://todo)中的高尔夫挥杆识别部分。在本教程中使用的数据集版本存储在公共云存储桶中。训练的模型可以预测高尔夫挥杆开始的起始帧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb3451ce8e47"
   },
   "source": [
    "### 费用\n",
    "本教程使用 Google Cloud 的可计费组件：\n",
    "\n",
    "- Vertex AI\n",
    "- 云存储\n",
    "\n",
    "了解 [Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing) 和 [云存储价格](https://cloud.google.com/storage/pricing)，并使用 [定价计算器](https://cloud.google.com/products/calculator/) 基于您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_mlops"
   },
   "source": [
    "安装执行此笔记本所需的软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_mlops"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "# Install the packages\n",
    "\n",
    "! pip3 install --upgrade google-cloud-aiplatform $USER_FLAG -q\n",
    "! pip3 install --upgrade google-cloud-storage $USER_FLAG -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "重新启动核心\n",
    "\n",
    "安装了额外的包之后，您需要重新启动笔记本核心，以便它可以找到这些包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "restart"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id"
   },
   "source": [
    "## 在开始之前\n",
    "\n",
    "### 设置您的 Google Cloud 项目\n",
    "\n",
    "**无论您使用的是哪种笔记本环境，以下步骤都是必需的。**\n",
    "\n",
    "1. [选择或创建一个 Google Cloud 项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建一个账户时，您将获得 $300 的免费信用额度，用于支付计算/存储成本。\n",
    "\n",
    "1. [确保您的项目已启用计费功能](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "1. [启用 Vertex AI、Compute Engine 和 Cloud Storage APIs](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component,storage_component)。\n",
    "\n",
    "1. 如果您是在本地运行这个笔记本，您需要安装 [Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "1. 在下面的单元格中输入您的项目 ID。然后运行该单元格，确保 Cloud SDK 对本笔记本中的所有命令使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter 运行以 `!` 为前缀的行作为 shell 命令，并且它会将以 `$` 为前缀的 Python 变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aee4379e8e5"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用 `gcloud` 获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "区域\n",
    "\n",
    "您还可以更改“REGION”变量，该变量用于笔记本的其余部分操作。以下是支持Vertex AI的区域。我们建议您选择最靠近您的区域。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太：`asia-east1`\n",
    "\n",
    "您可能不能使用多区域存储桶进行Vertex AI的训练。并非所有区域都支持所有的Vertex AI服务。\n",
    "\n",
    "了解有关[Vertex AI区域](https://cloud.google.com/vertex-ai/docs/general/locations)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "时间戳\n",
    "\n",
    "如果您正在进行实时教程会话，您可能正在使用共享测试帐户或项目。为避免用户在创建的资源之间发生名称冲突，您为每个实例会话创建一个时间戳，并将时间戳附加到您在此教程中创建的资源的名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "timestamp"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ffa6b6c7cdb"
   },
   "source": [
    "### 验证您的 Google Cloud 帐号\n",
    "\n",
    "**如果您正在使用 Vertex AI Workbench 笔记本**，则您的环境已经通过验证。跳过此步骤。\n",
    "\n",
    "**如果您正在使用 Colab**，运行下面的单元格，并按照提示进行身份验证，通过 oAuth 认证您的帐号。\n",
    "\n",
    "**否则**，请按照以下步骤操作：\n",
    "\n",
    "在 Cloud 控制台中，转到 [创建服务帐号密钥](https://console.cloud.google.com/apis/credentials/serviceaccountkey) 页面。\n",
    "\n",
    "1. **点击创建服务帐号**。\n",
    "\n",
    "2. 在 **服务帐号名称** 栏中输入一个名称，然后点击 **创建**。\n",
    "\n",
    "3. 在 **将此服务帐号授权给项目** 部分，点击角色下拉列表。在过滤框中输入 \"Vertex AI\"，选择 **Vertex AI 管理员**。在过滤框中输入 \"Storage Object Admin\"，选择 **存储对象管理员**。\n",
    "\n",
    "4. 点击创建。一个包含您的密钥的 JSON 文件将下载到您的本地环境中。\n",
    "\n",
    "5. 将您的服务帐号密钥路径作为 GOOGLE_APPLICATION_CREDENTIALS 变量输入到下面的单元格中，并运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b72272258fc"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = False\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        IS_COLAB = True\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "**无论你使用什么笔记本环境，以下步骤都是必须的。**\n",
    "\n",
    "在初始化用于 Python 的 Vertex SDK 时，您需要指定一个云存储临时桶。这个临时桶是您数据集和模型资源相关数据在不同会话之间保留的地方。\n",
    "\n",
    "在下面设置您的云存储桶的名称。云存储桶的命名必须在所有 Google Cloud 项目中全局唯一，包括您组织之外的项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_URI == \"\" or BUCKET_URI is None or BUCKET_URI == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_NAME = PROJECT_ID + \"aip-\" + TIMESTAMP\n",
    "    BUCKET_URI = \"gs://\" + BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有在您的存储桶不存在时才运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "最后，通过检查内容来验证对您的云存储桶的访问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在整个教程中使用的变量。\n",
    "### 导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "### 初始化 Vertex AI SDK for Python\n",
    "\n",
    "为您的项目和相应的存储桶初始化 Vertex AI SDK for Python。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "automl_training_intro"
   },
   "source": [
    "## 自动机器学习训练任务\n",
    "\n",
    "自动机器学习可以用来自动训练各种图像模型类型。自动机器学习自动化以下过程：\n",
    "\n",
    "- 数据集预处理\n",
    "- 特征工程\n",
    "- 数据喂养\n",
    "- 模型架构选择\n",
    "- 超参数调整\n",
    "- 训练模型\n",
    "\n",
    "了解更多关于[Vertex AI for AutoML 用户](https://cloud.google.com/vertex-ai/docs/start/automl-users) 的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "automl_image_intro"
   },
   "source": [
    "自动机器学习图像模型\n",
    "\n",
    "AutoML可以训练以下类型的图像模型：\n",
    "\n",
    "- 分类\n",
    "- 目标检测\n",
    "- 分割\n",
    "\n",
    "模型可以训练用于部署到云端，也可以导出到边缘设备。\n",
    "\n",
    "了解更多关于[AutoML模型类型](https://cloud.google.com/vertex-ai/docs/start/automl-model-types)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_preparation:image,u_dataset"
   },
   "source": [
    "数据准备\n",
    "\n",
    "用于图像的Vertex `Dataset`资源对您的数据有一些要求：\n",
    "\n",
    "- 图像必须存储在Cloud Storage存储桶中。\n",
    "- 每个图像文件必须是图像格式（PNG，JPEG，BMP，...）。\n",
    "- 必须在您的Cloud Storage存储桶中存储一个包含每个图像的路径和标签的索引文件。\n",
    "- 索引文件必须是CSV或JSONL格式。\n",
    "\n",
    "了解更多关于[准备图像数据](https://cloud.google.com/vertex-ai/docs/datasets/prepare-image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_import_format:icn,u_dataset,csv"
   },
   "source": [
    "CSV\n",
    "\n",
    "对于图像分类，CSV索引文件具有以下要求：\n",
    "\n",
    "- 没有标题。\n",
    "- 第一列是图像的云存储路径。\n",
    "- 第二列是标签。\n",
    "- 任何剩余的列都是用于多标签图像分类的附加标签。\n",
    "\n",
    "对于图像目标检测，CSV索引文件具有以下要求：\n",
    "\n",
    "- 没有标题。\n",
    "- 第一列是图像的云存储路径。\n",
    "- 第二列是标签。\n",
    "- 第三/第四列是边界框的左上角。坐标已归一化，介于0和1之间。\n",
    "- 第五/第六/第七列未使用，应为0。\n",
    "- 第八/第九列是边界框的右下角。\n",
    "\n",
    "ML_USE\n",
    "\n",
    "在数据集用于训练时，每行可能额外指定将数据项指定为哪种拆分；否则，数据集将被随机拆分：80/10/10。\n",
    "\n",
    "`ml_use` 分配由列的指定分配指定 -- 作为第一列。该值可以是以下之一：training、test 或 validation。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_import_format:isg,u_dataset,jsonl"
   },
   "source": [
    "JSONL\n",
    "\n",
    "对于图像分类，JSONL索引文件具有以下要求：\n",
    "\n",
    "- 每个数据项都是单独的JSON对象，放在单独的一行上。\n",
    "- 键/值对`image_gcs_uri`是图像的云存储路径。\n",
    "- 键/值对`display_name`是图像的标签。\n",
    "\n",
    "    { 'image_gcs_uri': image, \n",
    "      'classification_annotations': \n",
    "          { 'display_name': label\n",
    "          }\n",
    "    }\n",
    "    \n",
    "对于多标签，标签被指定为`display_name`键/值对的列表：\n",
    "\n",
    "    { 'image_gcs_uri': image, \n",
    "      'classification_annotations': [\n",
    "          { 'display_name': label1\n",
    "          },\n",
    "          { 'display_name': labelN\n",
    "          },\n",
    "       ]\n",
    "    }\n",
    "    \n",
    "对于目标检测，JSONL索引文件具有以下要求：\n",
    "\n",
    "- 每个数据项都是单独的JSON对象，放在单独的一行上。\n",
    "- 键/值对`image_gcs_uri`是图像的云存储路径。\n",
    "- 键/值对`bounding_box_annotations`是一个列表：\n",
    "    - `display_name`：物体的标签\n",
    "    - `x_min`、`y_min`、`x_max`、`y_max`：边界框的坐标\n",
    "\n",
    "{\n",
    "  \"image_gcs_uri\": image,\n",
    "  \"bounding_box_annotations\": [\n",
    "    {\n",
    "      \"display_name\": label,\n",
    "      \"x_min\": \"X_MIN\",\n",
    "      \"y_min\": \"Y_MIN\",\n",
    "      \"x_max\": \"X_MAX\",\n",
    "      \"y_max\": \"Y_MAX\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"display_name\": \"OBJECT2_LABEL\",\n",
    "      \"x_min\": \"X_MIN\",\n",
    "      \"y_min\": \"Y_MIN\",\n",
    "      \"x_max\": \"X_MAX\",\n",
    "      \"y_max\": \"Y_MAX\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "对于图像分割，JSONL索引文件具有以下要求：\n",
    "\n",
    "- 每个数据项都是单独的JSON对象，放在单独的一行上。\n",
    "- 键/值对`image_gcs_uri`是图像的云存储路径。\n",
    "- 键/值对`category_mask_uri`是mask图像的云存储路径，格式为PNG。\n",
    "- 键/值对`annotation_spec_colors`是一个列表，将mask颜色映射到一个标签。\n",
    "  - 键/值对`display_name`是像素颜色mask的标签。\n",
    "  - 键/值对`color`是对应标签的mask的RGB归一化像素值（在0和1之间）。\n",
    "\n",
    "    { 'image_gcs_uri': image, \n",
    "      'segmentation_annotations': { 'category_mask_uri': mask_image, 'annotation_spec_colors' : [ \n",
    "          { 'display_name': label, 'color': {\"red\": value, \"blue\": value, \"green\": value} }, ...\n",
    "      ] \n",
    "    }\n",
    "    \n",
    "ML_USE\n",
    "\n",
    "每个JSONL对象还可以指定在拆分数据集进行训练时将数据项分配给哪个拆分；否则，随机拆分数据集: 80/10/10。\n",
    "\n",
    "\"data_item_resource_labels\": {\n",
    "      \"aiplatform.googleapis.com/ml_use\": \"training|test|validation\"\n",
    "    }\n",
    "\n",
    "*注意*：字典键字段也可以使用驼峰命名。例如，'image_gcs_uri'也可以是'imageGcsUri'。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_file:u_dataset,csv"
   },
   "source": [
    "云存储训练数据的位置。\n",
    "\n",
    "现在将变量`IMPORT_FILE`设置为云存储中CSV索引文件的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:flowers,csv,icn"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = (\n",
    "    \"gs://cloud-samples-data/vision/automl_classification/flowers/all_data_v2.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick_peek:csv"
   },
   "source": [
    "快速查看您的数据\n",
    "\n",
    "本教程使用存储在公共云存储桶中的Happy Moments数据集的一个版本，并使用CSV索引文件。\n",
    "\n",
    "首先快速查看数据。通过计算CSV索引文件中的行数（`wc -l`）来计算示例的数量，然后查看前几行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quick_peek:csv"
   },
   "outputs": [],
   "source": [
    "FILE = IMPORT_FILE\n",
    "\n",
    "count = ! gsutil cat $FILE | wc -l\n",
    "print(\"Number of Examples\", int(count[0]))\n",
    "\n",
    "print(\"First 10 rows\")\n",
    "! gsutil cat $FILE | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_dataset:image,icn"
   },
   "source": [
    "### 创建数据集\n",
    "\n",
    "接下来，使用 `ImageDataset` 类的 `create` 方法创建 `Dataset` 资源，该方法需要以下参数：\n",
    "\n",
    "- `display_name`：`Dataset` 资源的可读名称。\n",
    "- `gcs_source`：一个或多个数据集索引文件列表，用于将数据项导入 `Dataset` 资源。\n",
    "- `import_schema_uri`：数据项的数据标记模式：\n",
    "  - `single_label`：二进制和多类分类\n",
    "  - `multi_label`：多标签多类分类\n",
    "  - `bounding_box`：目标检测\n",
    "  - `image_segmentation`：分割\n",
    "\n",
    "了解更多关于 [ImageDataset](https://cloud.google.com/vertex-ai/docs/datasets/prepare-image)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataset:image,icn"
   },
   "outputs": [],
   "source": [
    "dataset = aiplatform.ImageDataset.create(\n",
    "    display_name=\"flowers_\" + TIMESTAMP,\n",
    "    gcs_source=[IMPORT_FILE],\n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.image.single_label_classification,\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_automl_pipeline:image,edge,icn"
   },
   "source": [
    "### 创建和运行训练流水线\n",
    "\n",
    "要训练一个AutoML模型，您需要执行两个步骤：1) 创建一个训练流水线，和 2) 运行这个流水线。\n",
    "\n",
    "#### 创建训练流水线\n",
    "\n",
    "使用`AutoMLImageTrainingJob`类来创建一个AutoML训练流水线，需要以下参数：\n",
    "\n",
    "- `display_name`：`TrainingJob`资源的人类可读名称。\n",
    "- `prediction_type`：要为模型训练的任务类型。\n",
    "  - `classification`：图像分类模型。\n",
    "  - `object_detection`：图像目标检测模型。\n",
    "- `multi_label`：如果是分类任务，是单标签（`False`）还是多标签（`True`）。\n",
    "- `model_type`：部署模型的类型。\n",
    "  - `CLOUD`：在Google Cloud上部署\n",
    "  - `CLOUD_HIGH_ACCURACY_1`：优化精度，适用于在Google Cloud上部署\n",
    "  - `CLOUD_LOW_LATENCY_`：优化延迟，适用于在Google Cloud上部署\n",
    "  - `MOBILE_TF_VERSATILE_1`：在边缘设备上部署\n",
    "  - `MOBILE_TF_HIGH_ACCURACY_1`：优化精度，适用于在边缘设备上部署\n",
    "  - `MOBILE_TF_LOW_LATENCY_1`：优化延迟，适用于在边缘设备上部署\n",
    "- `base_model`：（可选）从现有的`Model`资源进行迁移学习—仅支持图像分类。\n",
    "\n",
    "实例化的对象是用于训练作业的DAG（有向无环图）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_automl_pipeline:image,edge,icn"
   },
   "outputs": [],
   "source": [
    "dag = aiplatform.AutoMLImageTrainingJob(\n",
    "    display_name=\"flowers_\" + TIMESTAMP,\n",
    "    prediction_type=\"classification\",\n",
    "    multi_label=False,\n",
    "    model_type=\"MOBILE_TF_LOW_LATENCY_1\",\n",
    "    base_model=None,\n",
    ")\n",
    "\n",
    "print(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_automl_pipeline:image"
   },
   "source": [
    "#### 运行训练流水线\n",
    "\n",
    "接下来，通过调用方法 `run` 来运行创建的DAG，以启动训练作业，并使用以下参数：\n",
    "\n",
    "- `dataset`：用于训练模型的 `Dataset` 资源。\n",
    "- `model_display_name`：训练模型的可读名称。\n",
    "- `training_fraction_split`：用于训练的数据集百分比。\n",
    "- `test_fraction_split`：用于测试（留置数据）的数据集百分比。\n",
    "- `validation_fraction_split`：用于验证的数据集百分比。\n",
    "- `budget_milli_node_hours`：（可选）以毫节点小时（1000 = 节点小时）为单位指定的最大训练时间。\n",
    "- `disable_early_stopping`：如果为 `True`，则在服务认为无法进一步提高模型目标测量之前，可能会在使用整个预算之前完成训练。\n",
    "\n",
    "完成 `run` 方法后，将返回 `Model` 资源。\n",
    "\n",
    "训练流水线的执行将需要超过30分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_automl_pipeline:image"
   },
   "outputs": [],
   "source": [
    "model = dag.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"flowers_\" + TIMESTAMP,\n",
    "    training_fraction_split=0.8,\n",
    "    validation_fraction_split=0.1,\n",
    "    test_fraction_split=0.1,\n",
    "    budget_milli_node_hours=8000,\n",
    "    disable_early_stopping=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "source": [
    "## 查看模型评估分数\n",
    "\n",
    "在模型训练完成后，您可以使用`list_model_evaluations()`方法查看其评估分数。该方法将返回每个评估切片的迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "model_evaluations = model.list_model_evaluations()\n",
    "\n",
    "for model_evaluation in model_evaluations:\n",
    "    print(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:mbsdk,automatic"
   },
   "source": [
    "部署模型\n",
    "\n",
    "接下来，部署您的模型用于在线预测。要部署模型，请调用 `deploy` 方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy_model:mbsdk,automatic"
   },
   "outputs": [],
   "source": [
    "endpoint = model.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_prediction"
   },
   "source": [
    "发送一个在线预测请求\n",
    "\n",
    "向您部署的模型发送一个在线预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_test_item"
   },
   "source": [
    "获取测试项目\n",
    "\n",
    "您将使用数据集中的一个任意示例作为测试项目。不必担心该示例很可能在训练模型时已经被使用过。您只需看看如何进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_test_item:automl,icn,csv"
   },
   "outputs": [],
   "source": [
    "test_item = !gsutil cat $IMPORT_FILE | head -n1\n",
    "if len(str(test_item[0]).split(\",\")) == 3:\n",
    "    _, test_item, test_label = str(test_item[0]).split(\",\")\n",
    "else:\n",
    "    test_item, test_label = str(test_item[0]).split(\",\")\n",
    "\n",
    "print(test_item, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "predict_request:mbsdk,icn"
   },
   "source": [
    "### 进行预测\n",
    "\n",
    "现在您的`Model`资源已部署到`Endpoint`资源上，您可以通过向Endpoint资源发送预测请求来进行在线预测。\n",
    "\n",
    "#### 请求\n",
    "\n",
    "在这个例子中，由于您的测试项目位于公共Cloud Storage存储桶中，您需要将其复制到您的存储桶中，并使用`Cloud Storage SDK`读取图像的内容。为了将测试数据传递给预测服务，您需要将字节编码为base64，这样可以使内容在网络上传输二进制数据时不易被修改。\n",
    "\n",
    "每个实例的格式为：\n",
    "\n",
    "    { 'content': { 'b64': base64编码的字节 } }\n",
    "\n",
    "由于`predict()`方法可以接受多个项目（实例），请将您的单个测试项目作为一个测试项目的列表发送。\n",
    "\n",
    "#### 响应\n",
    "\n",
    "`predict()`调用的响应是一个Python字典，包含以下条目：\n",
    "\n",
    "- `ids`：每个预测请求的内部分配的唯一标识符。\n",
    "- `displayNames`：每个类标签的类名。\n",
    "- `confidences`：每个类标签的预测置信度，介于0和1之间。\n",
    "- `deployed_model_id`：执行预测的部署的Model资源的Vertex AI标识符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1c1d53e89beb"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "# Copy the test image to the Cloud storage bucket as \"test.jpg\"\n",
    "test_image_local = \"{}/test.jpg\".format(BUCKET_URI)\n",
    "! gsutil cp $test_item $test_image_local\n",
    "\n",
    "# Download the test image in bytes format\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "bucket = storage_client.bucket(bucket_name=BUCKET_NAME)\n",
    "test_content = bucket.get_blob(\"test.jpg\").download_as_bytes()\n",
    "\n",
    "# The format of each instance should conform to the deployed model's prediction input schema.\n",
    "instances = [{\"content\": base64.b64encode(test_content).decode(\"utf-8\")}]\n",
    "\n",
    "prediction = endpoint.predict(instances=instances)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b1b67898533"
   },
   "source": [
    "#### 使用[GFile](https://www.tensorflow.org/api_docs/python/tf/io/gfile/GFile)的替代方法\n",
    "\n",
    "另外，可以使用tensorflow-io库中的[GFile](https://www.tensorflow.org/api_docs/python/tf/io/gfile/GFile)方法直接从云存储中读取数据。以下代码段执行相同的操作：\n",
    "\n",
    "```\n",
    "import base64\n",
    "import tensorflow as tf\n",
    "\n",
    "# 使用GFile读取测试文件\n",
    "with tf.io.gfile.GFile(test_item, \"rb\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# 每个实例的格式应符合部署模型的预测输入模式\n",
    "instances = [{\"content\": base64.b64encode(content).decode(\"utf-8\")}]\n",
    "\n",
    "prediction = endpoint.predict(instances=instances)\n",
    "\n",
    "print(prediction)\n",
    "```\n",
    "然而，`tf.io.gfile.GFile`支持多种文件系统实现，包括本地文件、Google Cloud存储（使用gs://前缀）和HDFS（使用hdfs://前缀）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "source": [
    "取消部署模型\n",
    "\n",
    "当您完成预测时，需要从`端点`资源中取消部署模型。这将取消所有计算资源，并停止为已部署的模型结算费用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export_model:mbsdk,image"
   },
   "source": [
    "## 导出为Edge模型\n",
    "\n",
    "您可以将AutoML云模型导出为`Edge`模型，然后将其自定义部署到边缘设备或本地下载。使用`export_model()`方法将模型导出到Cloud Storage，需要传入以下参数：\n",
    "\n",
    "- `artifact_destination`：用于存储SavedFormat模型文件的Cloud Storage位置。\n",
    "- `export_format_id`：要保存模型格式的格式。对于AutoML云，只有一个选项：\n",
    "   - `tf-saved-model`：用于部署到容器的TensorFlow SavedFormat。\n",
    "   - `tflite`：用于部署到边缘或移动设备的TensorFlow Lite。\n",
    "   - `edgetpu-tflite`：用于TPU的TensorFlow Lite。\n",
    "   - `tf-js`：用于网络客户端的TensorFlow。\n",
    "   - `coral-ml`：用于Coral设备。\n",
    "\n",
    "- `sync`：是否以同步或异步方式执行操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_model:mbsdk,image"
   },
   "outputs": [],
   "source": [
    "response = model.export_model(\n",
    "    artifact_destination=BUCKET_URI, export_format_id=\"tflite\", sync=True\n",
    ")\n",
    "\n",
    "model_package = response[\"artifactOutputUri\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "source": [
    "删除模型\n",
    "\n",
    "方法'delete()'将删除模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "source": [
    "删除数据集\n",
    "\n",
    "方法'delete()'会删除数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "dataset.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "source": [
    "删除该端点\n",
    "\n",
    "方法 'delete()' 将删除该端点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "automl_tabular_intro"
   },
   "source": [
    "自动机器学习表格模型\n",
    "\n",
    "自动机器学习可以训练以下类型的表格模型：\n",
    "\n",
    "- 分类\n",
    "- 回归\n",
    "- 预测\n",
    "\n",
    "一个模型可以被训练以便自动部署到云端，或者导出以便手动部署到云端。\n",
    "\n",
    "了解更多关于 [AutoML 模型类型](https://cloud.google.com/vertex-ai/docs/start/automl-model-types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_preparation:tabular,u_dataset"
   },
   "source": [
    "### 数据准备\n",
    "\n",
    "对于表格数据，Vertex AI的`Dataset`资源有一些要求。\n",
    "\n",
    "- 必须在CSV文件或BigQuery表中。\n",
    "\n",
    "了解更多关于[准备表格数据](https://cloud.google.com/vertex-ai/docs/datasets/prepare-tabular)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_import_format:lbn,u_dataset,csv"
   },
   "source": [
    "#### CSV\n",
    "\n",
    "对于表格模型，CSV文件有一些要求：\n",
    "\n",
    "- 第一行必须是标题 -- 请注意，这与图片、文本和视频不同，这些类型的要求是没有标题。\n",
    "- 除了一个列是特征之外，所有其他列都是特征。\n",
    "- 一个列是标签，您在随后创建训练流水线时将指定。\n",
    "\n",
    "##### ML_USE\n",
    "\n",
    "每行可能还可以指定在数据集进行训练拆分时将数据分配给哪个拆分；否则，数据集将被随机分割为80/10/10。\n",
    "\n",
    "`ml_use`指定是通过在列前添加一个用于指定分配的列来指定的 -- 作为第一列。值可以是以下之一：training, test, or validation。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_file:u_dataset,bq"
   },
   "source": [
    "请将BigQuery培训数据的位置设为`IMPORT_FILE`变量的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:gsod,bq,lrg"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = \"bq://bigquery-public-data.samples.gsod\"\n",
    "BQ_TABLE = \"bigquery-public-data.samples.gsod\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_dataset:tabular,bq,lrg"
   },
   "source": [
    "### 创建数据集\n",
    "\n",
    "#### BigQuery 输入数据\n",
    "\n",
    "接下来，使用 `TabularDataset` 类的 `create` 方法为 `Dataset` 资源创建数据集，其中包括以下参数：\n",
    "\n",
    "- `display_name`：`Dataset` 资源的可读名称。\n",
    "- `bq_source`：将数据项从 BigQuery 表导入到 `Dataset` 资源中。\n",
    "- `labels`：用户定义的元数据。在此示例中，您会存储包含用户定义数据的 Cloud Storage 存储桶的位置。\n",
    "\n",
    "了解有关[从 BigQuery 表中创建 TabularDataset](https://cloud.google.com/vertex-ai/docs/datasets/create-dataset-api#aiplatform_create_dataset_tabular_bigquery_sample-python)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataset:tabular,bq,lrg"
   },
   "outputs": [],
   "source": [
    "dataset = aiplatform.TabularDataset.create(\n",
    "    display_name=\"gsod_\" + TIMESTAMP,\n",
    "    bq_source=[IMPORT_FILE],\n",
    "    labels={\"user_metadata\": BUCKET_NAME},\n",
    ")\n",
    "\n",
    "label_column = \"mean_temp\"\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_transformations:gsod"
   },
   "outputs": [],
   "source": [
    "TRANSFORMATIONS = [\n",
    "    {\"auto\": {\"column_name\": \"year\"}},\n",
    "    {\"auto\": {\"column_name\": \"month\"}},\n",
    "    {\"auto\": {\"column_name\": \"day\"}},\n",
    "]\n",
    "\n",
    "label_column = \"mean_temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_automl_pipeline:tabular,lrg,transformations"
   },
   "source": [
    "### 创建和运行训练管道\n",
    "\n",
    "要训练一个AutoML模型，您需要执行两个步骤：1) 创建一个训练管道，2) 运行该管道。\n",
    "\n",
    "#### 创建训练管道\n",
    "\n",
    "使用`AutoMLTabularTrainingJob`类创建一个AutoML训练管道，使用以下参数：\n",
    "\n",
    "- `display_name`：`TrainingJob`资源的人类可读名称。\n",
    "- `optimization_prediction_type`：为模型训练指定的任务类型。\n",
    "  - `classification`：一个表格分类模型。\n",
    "  - `regression`：一个表格回归模型。\n",
    "- `column_transformations`：（可选）应用于输入列的转换。\n",
    "- `optimization_objective`：最小化或最大化的优化目标。\n",
    "  - 二分类：\n",
    "    - `minimize-log-loss`\n",
    "    - `maximize-au-roc`\n",
    "    - `maximize-au-prc`\n",
    "    - `maximize-precision-at-recall`\n",
    "    - `maximize-recall-at-precision`\n",
    "  - 多类别分类：\n",
    "    - `minimize-log-loss`\n",
    "  - 回归：\n",
    "    - `minimize-rmse`\n",
    "    - `minimize-mae`\n",
    "    - `minimize-rmsle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_automl_pipeline:tabular,lrg,transformations"
   },
   "outputs": [],
   "source": [
    "dag = aiplatform.AutoMLTabularTrainingJob(\n",
    "    display_name=\"gsod_\" + TIMESTAMP,\n",
    "    optimization_prediction_type=\"regression\",\n",
    "    optimization_objective=\"minimize-rmse\",\n",
    "    column_transformations=TRANSFORMATIONS,\n",
    ")\n",
    "\n",
    "print(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_automl_pipeline:tabular"
   },
   "source": [
    "运行训练管道\n",
    "\n",
    "接下来，您可以通过调用`run`方法来运行创建的DAG，以启动训练作业，以下是参数：\n",
    "\n",
    "- `dataset`：用于训练模型的`Dataset`资源。\n",
    "- `model_display_name`：训练模型的人类可读名称。\n",
    "- `training_fraction_split`：用于训练的数据集百分比。\n",
    "- `test_fraction_split`：用于测试（留出数据）的数据集百分比。\n",
    "- `validation_fraction_split`：用于验证的数据集百分比。\n",
    "- `target_column`：要作为标签进行训练的列名。\n",
    "- `budget_milli_node_hours`：（可选）以毫小时为单位指定的最大训练时间（1000 = 小时）。\n",
    "- `disable_early_stopping`：如果为`True`，则在服务认为无法进一步改进模型目标测量之前，训练可能会在使用整个预算之前完成。\n",
    "\n",
    "`run`方法完成后会返回`Model`资源。\n",
    "\n",
    "执行训练管道将需要超过30分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_automl_pipeline:tabular"
   },
   "outputs": [],
   "source": [
    "model = dag.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"gsod_\" + TIMESTAMP,\n",
    "    training_fraction_split=0.8,\n",
    "    validation_fraction_split=0.1,\n",
    "    test_fraction_split=0.1,\n",
    "    budget_milli_node_hours=8000,\n",
    "    disable_early_stopping=False,\n",
    "    target_column=\"mean_temp\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "source": [
    "## 回顾模型评估分数\n",
    "\n",
    "在模型训练完成后，您可以使用`list_model_evaluations()`方法回顾其评估分数。该方法将为每个评估切片返回一个迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "model_evaluations = model.list_model_evaluations()\n",
    "\n",
    "for model_evaluation in model_evaluations:\n",
    "    print(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:mbsdk,dedicated"
   },
   "source": [
    "部署模型\n",
    "\n",
    "接下来，为在线预测部署您的模型。要部署模型，您需要调用 `deploy` 方法，并提供以下参数：\n",
    "\n",
    "- `machine_type`：计算机类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy_model:mbsdk,dedicated"
   },
   "outputs": [],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "source": [
    "### 下线模型\n",
    "\n",
    "当您完成预测时，您需要将模型从“端点”资源中下线。这将取消所有计算资源并终止部署模型的计费。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export_model:mbsdk,tabular"
   },
   "source": [
    "将云模型导出\n",
    "\n",
    "您可以将AutoML云模型导出为TensorFlow SavedFormat模型，然后可以自定义部署到云存储或本地下载。使用`export_model()`方法将模型导出到云存储，该方法接受以下参数：\n",
    "\n",
    "- `artifact_destination`：保存SavedFormat模型工件的Cloud Storage位置。\n",
    "- `export_format_id`：保存模型格式的格式。对于AutoML云，只有一个选项：\n",
    "   - `tf-saved-model`：TensorFlow SavedFormat\n",
    "- `sync`：是否同步或异步执行操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_model:mbsdk,tabular"
   },
   "outputs": [],
   "source": [
    "response = model.export_model(\n",
    "    artifact_destination=BUCKET_URI, export_format_id=\"tf-saved-model\", sync=True\n",
    ")\n",
    "\n",
    "model_package = response[\"artifactOutputUri\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "source": [
    "删除模型\n",
    "\n",
    "方法 'delete()' 将删除模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "source": [
    "删除数据集\n",
    "\n",
    "方法'delete（）'将删除数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "dataset.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "source": [
    "删除端点\n",
    "\n",
    "方法 'delete()' 将删除端点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "automl_text_intro"
   },
   "source": [
    "AutoML可以训练以下类型的文本模型：\n",
    "\n",
    "- 分类\n",
    "- 情感分析\n",
    "- 实体提取\n",
    "\n",
    "了解更多关于[AutoML模型类型](https://cloud.google.com/vertex-ai/docs/start/automl-model-types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_preparation:text,u_dataset"
   },
   "source": [
    "数据准备\n",
    "\n",
    "对于文本，Vertex AI的“数据集”资源有一些要求。\n",
    "\n",
    "- 文本示例必须存储在CSV或JSONL文件中。\n",
    "\n",
    "了解更多关于[准备文本数据](https://cloud.google.com/vertex-ai/docs/datasets/prepare-text)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_import_format:tcn,u_dataset,csv"
   },
   "source": [
    "#### CSV\n",
    "\n",
    "对于文本分类，CSV文件有一些要求：\n",
    "\n",
    "- 没有标题。\n",
    "- 第一列是文本示例或云存储中文本文件的路径（.txt后缀）。\n",
    "- 第二列是标签。\n",
    "- 任何剩余的列都是用于多标签文本分类的附加标签。\n",
    "\n",
    "对于文本情感分析，CSV文件有一些要求：\n",
    "\n",
    "- 没有标题。\n",
    "- 第一列是文本示例或云存储中文本文件的路径（.txt后缀）。\n",
    "- 第二列是情感值。\n",
    "- 第三列是最大可能的情感值。\n",
    "\n",
    "##### ML_USE\n",
    "\n",
    "当数据集进行训练集分割时，每一行可能会指定将数据项目分配给哪个分割；否则，数据集将被随机分割：80/10/10。\n",
    "\n",
    "`ml_use`分配是通过在第一列之前添加一个列来指定的。值可以是以下之一：training，test或validation。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "766c838de8a0"
   },
   "source": [
    "JSONL \n",
    "\n",
    "对于文本分类，JSONL文件有几个要求：\n",
    "\n",
    "- 每个数据项是一个独立的JSON对象，位于单独的一行。\n",
    "- 键/值对`text_gcs_uri`是文本文件在Cloud Storage中的路径。\n",
    "- 键/值对`text_content`是指定文本的另一种方式，以内联方式表示。\n",
    "- 键/值对`display_name`是文本的标签。\n",
    "\n",
    "{\n",
    "  \"classification_annotation\": {\n",
    "    \"display_name\": label\n",
    "  },\n",
    "  \"text_content\": text\n",
    "}\n",
    "{\n",
    "  \"classification_annotation\": {\n",
    "    \"display_name\": label\n",
    "  },\n",
    "  \"text_gcs_uri\": \"gcs_uri_to_file\"\n",
    "}\n",
    "\n",
    "对于多标签，标签被指定为`display_name`键/值对的列表：\n",
    "\n",
    "      'classification_annotations': [\n",
    "          { 'display_name': label1\n",
    "          },\n",
    "          { 'display_name': labelN\n",
    "          },\n",
    "       ]\n",
    "\n",
    "对于文本情感分析，JSONL文件有几个要求：\n",
    "\n",
    "- 每个数据项是一个独立的JSON对象，位于单独的一行。\n",
    "- 键/值对`text_gcs_uri`是文本文件在Cloud Storage中的路径。\n",
    "- 键/值对`text_content`是指定文本的另一种方式，以内联方式表示。\n",
    "- 键/值对`sentiment`是情感值，为大于0的整数值。\n",
    "- 键/值对`sentiment_max`是情感的最大可能值。\n",
    "\n",
    "{\n",
    "  \"sentiment_annotation\": {\n",
    "    \"sentiment\": number,\n",
    "    \"sentiment_max\": number\n",
    "  },\n",
    "  \"text_content\": text,\n",
    "}\n",
    "{\n",
    "  \"sentiment_annotation\": {\n",
    "    \"sentiment\": number,\n",
    "    \"sentiment_max\": number\n",
    "  },\n",
    "  \"text_gcs_uri\": \"gcs_uri_to_file\"\n",
    "}\n",
    "\n",
    "\n",
    "对于文本实体提取，JSONL文件还有一些要求：\n",
    "\n",
    "- 每个数据项是一个独立的JSON对象，位于单独的一行。\n",
    "- 键/值对`text_gcs_uri`是文本文件在Cloud Storage中的路径。\n",
    "- 键/值对`text_content`是指定文本的另一种方式，以内联方式表示。\n",
    "- 键/值对`start_offset`是文本起始字符的偏移量。\n",
    "- 键/值对`end_offset`是文本结束字符的偏移量。\n",
    "- 键/值对`display_name`是文本的标签。\n",
    "\n",
    "{\n",
    "    \"text_segment_annotations\": [\n",
    "      {\n",
    "        \"start_offset\":number,\n",
    "        \"end_offset\":number,\n",
    "        \"display_name\": label\n",
    "      },\n",
    "      ...\n",
    "    ],\n",
    "    \"textContent\": \"inline_text\"\n",
    "}\n",
    "{\n",
    "    \"textSegmentAnnotations\": [\n",
    "      {\n",
    "        \"start_offset\": number,\n",
    "        \"end_offset\": number,\n",
    "        \"displayName\": label\n",
    "      },\n",
    "      ...\n",
    "    ],\n",
    "    \"text_gcs_uri\": \"gcs_uri_to_file\"\n",
    "}\n",
    "\n",
    "ML_USE\n",
    "\n",
    "每个JSONL对象还可以指定将数据项分配给哪个拆分用于训练；否则，数据集将被随机分割：80/10/10。\n",
    "\n",
    "\"data_item_resource_labels\": {\n",
    "      \"aiplatform.googleapis.com/ml_use\": \"training|test|validation\"\n",
    "    }\n",
    "\n",
    "*注意*: 字典键字段也可以选择使用驼峰命名法，例如，'text_gcs_uri'也可以是'textGcsUri'。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_file:u_dataset,csv"
   },
   "source": [
    "云存储训练数据的位置。\n",
    "\n",
    "现在将变量 `IMPORT_FILE` 设置为云存储中CSV索引文件的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:happydb,csv,tcn"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = \"gs://cloud-ml-data/NL-classification/happiness.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick_peek:csv"
   },
   "source": [
    "#### 快速查看您的数据\n",
    "\n",
    "本教程使用存储在公共云存储桶中的Happy Moments数据集版本，使用CSV索引文件。\n",
    "\n",
    "首先快速查看数据。您可以通过计算CSV索引文件中的行数（`wc -l`）来计算示例数量，然后查看前几行数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quick_peek:csv"
   },
   "outputs": [],
   "source": [
    "FILE = IMPORT_FILE\n",
    "\n",
    "count = ! gsutil cat $FILE | wc -l\n",
    "print(\"Number of Examples\", int(count[0]))\n",
    "\n",
    "print(\"First 10 rows\")\n",
    "! gsutil cat $FILE | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_dataset:text,tcn"
   },
   "source": [
    "###创建数据集\n",
    "\n",
    "接下来，使用`TextDataset`类的`create`方法为`Dataset`资源创建数据集，该方法接受以下参数：\n",
    "\n",
    "- `display_name`：`Dataset`资源的可读名称。\n",
    "- `gcs_source`：一个或多个数据集索引文件的列表，用于将数据项导入`Dataset`资源。\n",
    "- `import_schema_uri`：数据项的数据标记模式。\n",
    "  - `single_label`：二元和多类别分类\n",
    "  - `multi_label`：多标签多类别分类\n",
    "  - `sentiment`：情感分析\n",
    "  - `extraction`：实体提取\n",
    "\n",
    "了解更多关于[TextDataset](https://cloud.google.com/vertex-ai/docs/datasets/prepare-text)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataset:text,tcn"
   },
   "outputs": [],
   "source": [
    "dataset = aiplatform.TextDataset.create(\n",
    "    display_name=\"happydb_\" + TIMESTAMP,\n",
    "    gcs_source=[IMPORT_FILE],\n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.text.single_label_classification,\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_automl_pipeline:text,tcn"
   },
   "source": [
    "### 创建和运行训练流水线\n",
    "\n",
    "要训练一个AutoML模型，您需要执行两个步骤：1) 创建一个训练流水线，2) 运行这个流水线。\n",
    "\n",
    "#### 创建训练流水线\n",
    "\n",
    "通过`AutoMLTextTrainingJob`类创建一个AutoML训练流水线，需要提供以下参数：\n",
    "\n",
    "- `display_name`: 用于`TrainingJob`资源的易读名称。\n",
    "- `prediction_type`: 用于训练模型的任务类型。\n",
    "  - `classification`: 文本分类模型。\n",
    "  - `sentiment`: 文本情感分析模型。\n",
    "  - `extraction`: 文本实体提取模型。\n",
    "- `multi_label`: 如果是分类任务，是单标签(False)还是多标签(True)。\n",
    "- `sentiment_max`: 如果是情感分析任务，则是情感值的最大值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_automl_pipeline:text,tcn"
   },
   "outputs": [],
   "source": [
    "dag = aiplatform.AutoMLTextTrainingJob(\n",
    "    display_name=\"happydb_\" + TIMESTAMP,\n",
    "    prediction_type=\"classification\",\n",
    "    multi_label=False,\n",
    ")\n",
    "\n",
    "print(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_automl_pipeline:text"
   },
   "source": [
    "#### 运行训练流水线\n",
    "\n",
    "接下来，您可以通过调用 `run` 方法并传入以下参数来运行创建的DAG以启动训练作业：\n",
    "\n",
    "- `dataset`：用于训练模型的 `Dataset` 资源。\n",
    "- `model_display_name`：训练模型的人类可读名称。\n",
    "- `training_fraction_split`：用于训练的数据集所占比例。\n",
    "- `test_fraction_split`：用于测试（留置数据）的数据集所占比例。\n",
    "- `validation_fraction_split`：用于验证的数据集所占比例。\n",
    "\n",
    "完成后，`run` 方法将返回 `Model` 资源。\n",
    "\n",
    "训练流水线的执行将需要大约> 30分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_automl_pipeline:text"
   },
   "outputs": [],
   "source": [
    "model = dag.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"happydb_\" + TIMESTAMP,\n",
    "    training_fraction_split=0.8,\n",
    "    validation_fraction_split=0.1,\n",
    "    test_fraction_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "source": [
    "##回顾模型评估分数\n",
    "\n",
    "在模型训练完成后，您可以使用 `list_model_evaluations()` 方法回顾它的评估分数。该方法将返回每个评估切片的迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "model_evaluations = model.list_model_evaluations()\n",
    "\n",
    "for model_evaluation in model_evaluations:\n",
    "    print(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:mbsdk,automatic"
   },
   "source": [
    "部署模型\n",
    "\n",
    "接下来，部署您的模型以进行在线预测。要部署模型，您需要调用`deploy`方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy_model:mbsdk,automatic"
   },
   "outputs": [],
   "source": [
    "endpoint = model.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "source": [
    "取消部署模型\n",
    "\n",
    "当您完成预测后，您可以从`Endpoint`资源中取消部署模型。这将取消所有计算资源并停止对部署模型的计费。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "source": [
    "### 删除模型\n",
    "\n",
    "方法 'delete()' 将删除模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "source": [
    "删除数据集\n",
    "\n",
    "方法'delete（）'将删除数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "dataset.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "source": [
    "请删除终端点\n",
    "\n",
    "方法 'delete()' 将删除终端点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "automl_video_intro"
   },
   "source": [
    "自动机器学习视频模型\n",
    "\n",
    "AutoML可以训练以下类型的视频模型：\n",
    "\n",
    "- 分类\n",
    "- 物体跟踪\n",
    "- 动作识别\n",
    "\n",
    "模型可以被训练用于部署到云端，也可以被导出到边缘设备。\n",
    "\n",
    "了解更多关于[AutoML模型类型](https://cloud.google.com/vertex-ai/docs/start/automl-model-types)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_preparation:text,u_dataset"
   },
   "source": [
    "数据准备\n",
    "\n",
    "Vertex AI 用于文本的“数据集”资源对您的文本数据有几个要求。\n",
    "\n",
    "- 文本示例必须存储在 CSV 或 JSONL 文件中。\n",
    "\n",
    "详细了解如何[准备视频数据](https://cloud.google.com/vertex-ai/docs/datasets/prepare-video)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "427212b48840"
   },
   "source": [
    "#### CSV\n",
    "\n",
    "对于视频分类，CSV文件有一些要求：\n",
    "\n",
    "- 没有标题。\n",
    "- 第一列是视频文件的 Cloud Storage 路径。\n",
    "- 第二列是标签。\n",
    "- 第三列是视频中要分类的开始时间（秒）。\n",
    "- 第四列是视频中要分类的结束时间（秒）。\n",
    "\n",
    "对于多标签分类，每个标签是单独的行条目。\n",
    "\n",
    "对于视频对象跟踪，CSV文件有一些要求：\n",
    "\n",
    "- 没有标题。\n",
    "- 第一列是视频文件的 Cloud Storage 路径。\n",
    "- 第二列是标签。\n",
    "- 第三列是未使用的（空白）。\n",
    "- 第四列是视频中开始跟踪对象的时间（秒）。\n",
    "- 第五到八列是要跟踪的对象的顶点。\n",
    "    - x_min\n",
    "    - y_min\n",
    "    - x_max\n",
    "    - y_max\n",
    "\n",
    "对于动作识别，CSV文件有一些要求：\n",
    "\n",
    "- 没有标题。\n",
    "- 每行可以是以下四种格式之一：\n",
    "\n",
    "VIDEO_URI, TIME_SEGMENT_START, TIME_SEGMENT_END, LABEL, ANNOTATION_FRAME_TIMESTAMP\n",
    "\n",
    "VIDEO_URI, , , LABEL, ANNOTATION_FRAME_TIMESTAMP\n",
    "\n",
    "VIDEO_URI, TIME_SEGMENT_START, TIME_SEGMENT_END, LABEL, ANNOTATION_SEGMENT_START, ANNOTATION_SEGMENT_END\n",
    "\n",
    "VIDEO_URI, , , LABEL, ANNOTATION_SEGMENT_START, ANNOTATION_SEGMENT_END\n",
    "\n",
    "\n",
    "##### ML_USE\n",
    "\n",
    "每一行还可以指定在数据集用于训练时要分配给数据项的分割方式；否则，数据集将被随机分割为 80/10/10。\n",
    "\n",
    "`ml_use` 的分配通过在指定分配的列之前添加一列来指定 -- 作为第一列。该值可以是以下之一：training，或 test。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "461301339727"
   },
   "source": [
    "JSONL\n",
    "\n",
    "对于视频分类，CSV文件有一些要求：\n",
    "\n",
    "- 每个数据项是一个单独的JSON对象，放在单独的一行上。\n",
    "- 键/值对`video_gcs_uri`是文本文件的云存储路径。\n",
    "- 键/值对`display_name`是文本的标签。\n",
    "- 键/值对`start_time`是分类的开始时间（秒）。\n",
    "- 键/值对`end_time`是分类的结束时间（秒）。\n",
    "\n",
    "{\n",
    "    \"video_gcs_uri\": video,\n",
    "    \"time_segment_annotations\": [{\n",
    "        \"display_name\": label,\n",
    "        \"start_time\": \"start_time_of_segment\",\n",
    "        \"end_time\": \"end_time_of_segment\"\n",
    "    }]\n",
    "}\n",
    "\n",
    "对于视频对象跟踪，CSV文件有一些要求：\n",
    "\n",
    "- 每个数据项是一个单独的JSON对象，放在单独的一行上。\n",
    "- 键/值对`video_gcs_uri`是文本文件的云存储路径。\n",
    "\n",
    "{\n",
    "    \"video_gcs_uri\": video,\n",
    "    \"temporal_bounding_box_annotations\": [{\n",
    "        \"display_name\": label,\n",
    "        \"x_min\": \"bounding框的最左坐标\",\n",
    "        \"x_max\": \"bounding框的最右坐标\",\n",
    "        \"y_min\": \"bounding框的最上坐标\",\n",
    "        \"y_max\": \"bounding框的最下坐标\",\n",
    "        \"time_offset\": \"检测到对象的时间帧\"\n",
    "    }]\n",
    "}\n",
    "\n",
    "对于视频动作识别，CSV文件有一些要求：\n",
    "\n",
    "- 每个数据项是一个单独的JSON对象，放在单独的一行上。\n",
    "- 键/值对`video_gcs_uri'是文本文件的云存储路径。\n",
    "\n",
    "{\n",
    "  \"video_gcs_uri': video,\n",
    "  \"time_segments\": [{\n",
    "    \"start_time\": \"完全注释段的开始时间\",\n",
    "    \"end_time\": \"段的结束时间\"}],\n",
    "  \"time_segment_annotations\": [{\n",
    "    \"display_name\": label,\n",
    "    \"start_time\": \"段的开始时间\",\n",
    "    \"end_time\": \"段的结束时间\"\n",
    "  }]\n",
    "}\n",
    "\n",
    "ML_USE\n",
    "\n",
    "每个JSONL对象还可以指定将数据项分配到哪个拆分中进行训练；否则，数据集将被随机分割：80/20。\n",
    "\n",
    "\"data_item_resource_labels\": {\n",
    "  \"aiplatform.googleapis.com/ml_use\": \"training|test\"\n",
    "}\n",
    "\n",
    "*注意*：字典键字段也可以使用驼峰命名法。例如，'video_gcs_uri'也可以是'videoGcsUri'。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_file:u_dataset,csv"
   },
   "source": [
    "云存储培训数据的位置。\n",
    "\n",
    "现在将变量`IMPORT_FILE`设置为Cloud Storage中CSV索引文件的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:hmdb,csv,vcn"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = \"gs://automl-video-demo-data/hmdb_split1_5classes_train_inf.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick_peek:csv"
   },
   "source": [
    "快速查看您的数据\n",
    "\n",
    "本教程使用存储在公共云存储桶中的Happy Moments数据集的一个版本，使用CSV索引文件。\n",
    "\n",
    "首先快速查看数据。您可以通过计算CSV索引文件中的行数（`wc -l`）来计算示例数量，然后查看前几行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quick_peek:csv"
   },
   "outputs": [],
   "source": [
    "FILE = IMPORT_FILE\n",
    "\n",
    "count = ! gsutil cat $FILE | wc -l\n",
    "print(\"Number of Examples\", int(count[0]))\n",
    "\n",
    "print(\"First 10 rows\")\n",
    "! gsutil cat $FILE | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_dataset:video,vcn"
   },
   "source": [
    "### 创建数据集\n",
    "\n",
    "接下来，使用`VideoDataset`类的`create`方法创建`Dataset`资源，该方法接受以下参数：\n",
    "\n",
    "- `display_name`：`Dataset`资源的可读名称。\n",
    "- `gcs_source`：一个或多个数据集索引文件的列表，用于将数据项导入`Dataset`资源。\n",
    "- `import_schema_uri`：数据项的数据标记模式。\n",
    "  - `classification`：二元和多类分类\n",
    "  - `object_tracking`：对象追踪\n",
    "  - `action_recognition`：动作识别\n",
    "\n",
    "了解更多关于[VideoDataset](https://cloud.google.com/vertex-ai/docs/datasets/prepare-video)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataset:video,vcn"
   },
   "outputs": [],
   "source": [
    "dataset = aiplatform.VideoDataset.create(\n",
    "    display_name=\"human_motion_\" + TIMESTAMP,\n",
    "    gcs_source=[IMPORT_FILE],\n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.video.classification,\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_automl_pipeline:video,vcn"
   },
   "source": [
    "### 创建并运行训练流程\n",
    "\n",
    "为训练 AutoML 模型，您需要执行两个步骤：1) 创建一个训练流程，2) 运行这个流程。\n",
    "\n",
    "#### 创建训练流程\n",
    "\n",
    "使用 `AutoMLVideoTrainingJob` 类可以创建一个 AutoML 训练流程，具有以下参数：\n",
    "\n",
    "- `display_name`：`TrainingJob` 资源的人类可读名称。\n",
    "- `prediction_type`：为模型训练指定的任务类型。\n",
    "  - `classification`：视频分类模型。\n",
    "  - `object_tracking`：视频目标追踪模型。\n",
    "  - `action_recognition`：视频动作识别模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_automl_pipeline:video,vcn"
   },
   "outputs": [],
   "source": [
    "dag = aiplatform.AutoMLVideoTrainingJob(\n",
    "    display_name=\"human_motion_\" + TIMESTAMP,\n",
    "    prediction_type=\"classification\",\n",
    ")\n",
    "\n",
    "print(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_automl_pipeline:video"
   },
   "source": [
    "#### 运行训练管道\n",
    "\n",
    "接下来，通过调用`run`方法并传入以下参数来运行创建的DAG以开始训练作业：\n",
    "\n",
    "- `dataset`：用于训练模型的`Dataset`资源。\n",
    "- `model_display_name`：训练模型的人类可读名称。\n",
    "- `training_fraction_split`：用于训练的数据集百分比。\n",
    "- `test_fraction_split`：用于测试（留置数据）的数据集百分比。\n",
    "\n",
    "完成`run`方法后，将返回`Model`资源。\n",
    "\n",
    "训练管道的执行将需要超过30分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_automl_pipeline:video"
   },
   "outputs": [],
   "source": [
    "model = dag.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"human_motion_\" + TIMESTAMP,\n",
    "    training_fraction_split=0.8,\n",
    "    test_fraction_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "source": [
    "## 查看模型评估分数\n",
    "\n",
    "在模型训练完成后，您可以使用`list_model_evaluations()`方法查看其评估分数。该方法将为每个评估切片返回一个迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "model_evaluations = model.list_model_evaluations()\n",
    "\n",
    "for model_evaluation in model_evaluations:\n",
    "    print(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "source": [
    "删除模型\n",
    "\n",
    "方法'delete（）'将删除模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "source": [
    "删除数据集\n",
    "\n",
    "方法'delete()'将删除数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "dataset.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以 [删除您用于本教程的Google Cloud 项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup"
   },
   "outputs": [],
   "source": [
    "# Set this to true only if you'd like to delete your bucket\n",
    "delete_bucket = False\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_automl_training.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
