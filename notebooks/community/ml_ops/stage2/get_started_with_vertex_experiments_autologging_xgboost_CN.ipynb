{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# GCP上的端到端机器学习: MLOps阶段2: 使用Vertex AI实验开始自动记录XGBoost模型\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_with_vertex_experiments_autologging_xgboost.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_with_vertex_experiments_autologging_xgboost.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage2/get_started_with_vertex_experiments_autologging_xgboost.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI工作台中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:automl"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何使用DIY代码使用“Vertex AI实验”来实现实验参数和指标的自动记录。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:automl,training,batch_prediction"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何创建一个用于训练XGBoost模型的实验，并使用附带的自助（DIY）代码自动记录参数和指标。\n",
    "\n",
    "该教程使用以下Google Cloud ML服务和资源：\n",
    "\n",
    "- `Vertex AI Experiments`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 构建自助记录代码。\n",
    "- 构建包含自动记录调用的训练包。\n",
    "- 训练模型。\n",
    "- 查看实验。\n",
    "- 删除实验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:custom,boston,lrg"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是来自[TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview)的[Iris数据集](https://www.tensorflow.org/datasets/catalog/iris)。该数据集不需要任何特征工程。本教程中数据集的版本存储在一个公共的云存储桶中。训练好的模型可以预测三种不同种类的鸢尾花品种：山鸢尾(setosa)、维吉尼亚(virginica)或者变色鸢尾(versicolor)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "### 成本\n",
    "\n",
    "本教程使用 Google Cloud 的收费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI 价格定价](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage 价格定价](https://cloud.google.com/storage/pricing)，并使用[Pricing Calculator](https://cloud.google.com/products/calculator/)根据您预期的使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_local"
   },
   "source": [
    "### 设置本地开发环境\n",
    "\n",
    "如果您正在使用Colab或Vertex Workbench AI笔记本，您的环境已经满足运行此笔记本的所有要求。您可以跳过此步骤。\n",
    "\n",
    "否则，请确保您的环境符合此笔记本的要求。您需要以下内容：\n",
    "\n",
    "- 云存储SDK\n",
    "- Git\n",
    "- Python 3\n",
    "- virtualenv\n",
    "- 在使用Python 3的虚拟环境中运行的Jupyter笔记本\n",
    "\n",
    "[设置Python开发环境](https://cloud.google.com/python/setup)和[Jupyter安装指南](https://jupyter.org/install)提供了满足这些要求的详细说明。以下步骤提供了一组简化的说明：\n",
    "\n",
    "1. [安装并初始化SDK](https://cloud.google.com/sdk/docs/)。\n",
    "\n",
    "2. [安装Python 3](https://cloud.google.com/python/setup#installing_python)。\n",
    "\n",
    "3. [安装virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv)并创建一个使用Python 3的虚拟环境。激活虚拟环境。\n",
    "\n",
    "4. 要安装Jupyter，请在终端窗口中运行`pip3 install jupyter`。\n",
    "\n",
    "5. 要启动Jupyter，请在终端窗口中运行`jupyter notebook`。\n",
    "\n",
    "6. 在Jupyter Notebook仪表板中打开此笔记本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装以下包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "! pip3 install --upgrade --quiet {USER_FLAG} google-cloud-aiplatform \\\n",
    "                                             xgboost \\\n",
    "                                             scikit-learn \\\n",
    "                                             numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "重新启动内核\n",
    "\n",
    "安装额外的包后，您需要重新启动笔记本内核，以便它可以找到这些包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "restart"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### GPU 运行时\n",
    "\n",
    "本教程不需要 GPU 运行时。\n",
    "\n",
    "### 设置您的 Google 云项目\n",
    "\n",
    "**无论您的笔记本环境如何，都需要执行以下步骤。**\n",
    "\n",
    "1. [选择或创建 Google 云项目](https://console.cloud.google.com/cloud-resource-manager)。您第一次创建账户时，您将获得 300 美元的免费信用额度用于您的计算/存储成本。\n",
    "\n",
    "2. [确保您的项目已启用计费。](https://cloud.google.com/billing/docs/how-to/modify-project)\n",
    "\n",
    "3. [启用以下 API：Vertex AI API、Compute Engine API 和 Cloud Storage。](https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,compute_component,storage-component.googleapis.com)\n",
    "\n",
    "4. 如果您在本地运行此笔记本，您需要安装 [Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "5. 在下面的单元格中输入您的项目 ID。然后运行该单元格，以确保 Cloud SDK 在此笔记本中的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter 运行以 `!` 为前缀的行作为 shell 命令，并且会插入以 `$` 为前缀的 Python 变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用`gcloud`来获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 区域\n",
    "\n",
    "您还可以更改 `REGION` 变量，该变量用于本笔记本的其余部分操作。以下是 Vertex AI 支持的区域。我们建议您选择最靠近您的区域。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太地区：`asia-east1`\n",
    "\n",
    "您可能不能使用多区域存储桶进行 Vertex AI 训练。并非所有区域都支持所有 Vertex AI 服务。\n",
    "\n",
    "了解更多有关 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "UUID\n",
    "\n",
    "如果您正在进行实时教程会话，您可能正在使用共享测试帐户或项目。为了避免在创建的资源上的用户之间发生名称冲突，您可以为每个实例会话创建一个uuid，并将其附加到您在本教程中创建的资源的名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "timestamp"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 认证您的Google Cloud帐户\n",
    "\n",
    "**如果您正在使用Vertex AI Workbench笔记本**，则您的环境已经经过身份验证。\n",
    "\n",
    "**如果您正在使用Colab**，运行下面的单元格，并按照提示进行身份验证。\n",
    "\n",
    "**否则**，请按照以下步骤进行操作：\n",
    "\n",
    "在Cloud Console中，转到[创建服务帐户密钥](https://console.cloud.google.com/apis/credentials/serviceaccountkey)页面。\n",
    "\n",
    "**单击创建服务帐户**。\n",
    "\n",
    "在**服务帐户名称**字段中输入名称，然后单击**创建**。\n",
    "\n",
    "在**将此服务帐户授予对项目的访问权限**部分，单击角色下拉列表。在筛选框中输入“Vertex”，然后选择**Vertex管理员**。在筛选框中输入“存储对象管理员”，然后选择**存储对象管理员**。\n",
    "\n",
    "单击创建。包含您的密钥的JSON文件将下载到本地环境。\n",
    "\n",
    "在下面的单元格中将服务帐户密钥的路径输入为GOOGLE_APPLICATION_CREDENTIALS变量，然后运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcp_authenticate"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59963fb7178f"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# to suppress lint message (unused)\n",
    "precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "初始化Python的Vertex AI SDK\n",
    "\n",
    "为您的项目和相应的存储桶初始化Python的Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ae8f31c8c617"
   },
   "source": [
    "## 用于自动记录XGBoost模型的DIY代码\n",
    "\n",
    "以下代码实现了XGBoost模型的自动记录。\n",
    "\n",
    "- `autologging()`: 初始化实验并使用堆注入来替换堆上的`xgboost.train()`符号，使用重定向包装函数`VertexXGBtrain`。\n",
    "\n",
    "- `VertexXGBtrain`: 用于XGBoost train()函数的包装函数。自动记录超参数并调用底层函数。\n",
    "\n",
    "- `VertexSKLaccuracy_score`: 用于scikit-learn accuracy_score()函数的包装函数。自动调用底层函数并记录指标结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eb012e5d7ef"
   },
   "outputs": [],
   "source": [
    "def autolog(\n",
    "    project: str = None,\n",
    "    location: str = None,\n",
    "    staging_bucket: str = None,\n",
    "    experiment: str = None,\n",
    "    run: str = None,\n",
    "    framework: str = \"tf\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Enable automatic logging of parameters and metrics in Vertex AI Experiments,\n",
    "    for corresponding framework.\n",
    "\n",
    "        project: The project ID\n",
    "        location : The region\n",
    "        staging_bucket: temporary bucket\n",
    "        experiment: The name of the experiment\n",
    "        run: The name of the run within the experiment\n",
    "        framework: The ML framework for which a model is being trained.\n",
    "    \"\"\"\n",
    "    # autologging\n",
    "    if framework == \"tf\":\n",
    "        try:\n",
    "            globals()[\"Sequential\"] = VertexTFSequential\n",
    "            if \"tf\" in globals():\n",
    "                tf.keras.Sequential = VertexTFSequential\n",
    "            if \"tensorflow\" in globals():\n",
    "                tensorflow.keras.Sequential = VertexTFSequential\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            globals()[\"Model\"] = VertexTFModel\n",
    "            if \"tf\" in globals():\n",
    "                tf.keras.Model = VertexTFModel\n",
    "            if \"tensorflow\" in globals():\n",
    "                tensorflow.keras.Model = VertexTFModel\n",
    "        except:\n",
    "            pass\n",
    "    elif framework == \"xgb\":\n",
    "        global real_xgb_train\n",
    "        global real_accuracy_score, real_precision_score, real_recall_score\n",
    "        import sklearn\n",
    "\n",
    "        try:\n",
    "            if \"xgboost\" in globals():\n",
    "                real_xgb_train = xgboost.train\n",
    "                xgboost.train = VertexXGBtrain\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            if \"xgb\" in globals():\n",
    "                real_xgb_train = xgb.train\n",
    "                xgb.train = VertexXGBtrain\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            global accuracy_score, precision_score, recall_score\n",
    "            if \"accuracy_score\" in globals():\n",
    "                real_accuracy_score = sklearn.metrics.accuracy_score\n",
    "                sklearn.metrics.accuracy_score = VertexSKLaccuracy_score\n",
    "                accuracy_score = VertexSKLaccuracy_score\n",
    "            if \"precision_score\" in globals():\n",
    "                real_precision_score = sklearn.metrics.precision_score\n",
    "                sklearn.metrics.precision_score = VertexSKLprecision_score\n",
    "                precision_score = VertexSKLprecision_score\n",
    "            if \"recall_score\" in globals():\n",
    "                real_recall_score = sklearn.metrics.recall_score\n",
    "                sklearn.metrics.recall_score = VertexSKLrecall_score\n",
    "                recall_score = VertexSKLrecall_score\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if project:\n",
    "        aiplatform.init(\n",
    "            project=project, location=location, staging_bucket=staging_bucket\n",
    "        )\n",
    "\n",
    "    if experiment:\n",
    "        aiplatform.init(experiment=experiment)\n",
    "    if run:\n",
    "        aiplatform.start_run(run)\n",
    "\n",
    "\n",
    "def VertexXGBtrain(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=10,\n",
    "    evals=None,\n",
    "    obj=None,\n",
    "    maximize=None,\n",
    "    early_stopping_rounds=None,\n",
    "    evals_result=None,\n",
    "    verbose_eval=True,\n",
    "    callbacks=None,\n",
    "    custom_metric=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper function for autologging training parameters with Vertex AI Experiments\n",
    "    Args:\n",
    "        same as underlying xgb.train() method\n",
    "    \"\"\"\n",
    "    global real_xgb_train\n",
    "\n",
    "    aiplatform.log_params({\"train.num_boost_round\": int(num_boost_round)})\n",
    "\n",
    "    if params:\n",
    "        if \"booster\" in params:\n",
    "            aiplatform.log_params({\"train.booster\": int(params[\"booster\"])})\n",
    "\n",
    "        # booster parameters\n",
    "        if \"eta\" in params:\n",
    "            aiplatform.log_params({\"train.eta\": int(params[\"eta\"])})\n",
    "        if \"max_depth\" in params:\n",
    "            aiplatform.log_params({\"train.max_depth\": int(params[\"max_depth\"])})\n",
    "        if \"max_leaf_nodes\" in params:\n",
    "            aiplatform.log_params(\n",
    "                {\"train.max_leaf_nodes\": int(params[\"max_leaf_nodes\"])}\n",
    "            )\n",
    "        if \"gamma\" in params:\n",
    "            aiplatform.log_params({\"train.gamma\": int(params[\"gamma\"])})\n",
    "        if \"alpha\" in params:\n",
    "            aiplatform.log_params({\"train.alpha\": int(params[\"alpha\"])})\n",
    "\n",
    "    return real_xgb_train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=evals,\n",
    "        obj=obj,\n",
    "        maximize=maximize,\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=verbose_eval,\n",
    "        callbacks=callbacks,\n",
    "        custom_metric=custom_metric,\n",
    "    )\n",
    "\n",
    "\n",
    "def VertexSKLaccuracy_score(labels, predictions):\n",
    "    \"\"\"\n",
    "    Wrapper function for autologging training metrics with Vertex AI Experiments\n",
    "    Args:\n",
    "        same as underlying accuracy_score function\n",
    "    \"\"\"\n",
    "    global real_accuracy_score\n",
    "    accuracy = real_accuracy_score(labels, predictions)\n",
    "    aiplatform.log_metrics({\"accuracy\": accuracy})\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def VertexSKLprecision_score(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    *,\n",
    "    labels=None,\n",
    "    pos_label=1,\n",
    "    average=\"binary\",\n",
    "    sample_weight=None,\n",
    "    zero_division=\"warn\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper function for autologging training metrics with Vertex AI Experiments\n",
    "    Args:\n",
    "        same as underlying precision_score function\n",
    "    \"\"\"\n",
    "    global real_precision_score\n",
    "    precision = real_precision_score(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=labels,\n",
    "        pos_label=pos_label,\n",
    "        average=average,\n",
    "        sample_weight=sample_weight,\n",
    "        zero_division=zero_division,\n",
    "    )\n",
    "    aiplatform.log_metrics({\"precision\": precision})\n",
    "    return precision\n",
    "\n",
    "\n",
    "def VertexSKLrecall_score(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    *,\n",
    "    labels=None,\n",
    "    pos_label=1,\n",
    "    average=\"binary\",\n",
    "    sample_weight=None,\n",
    "    zero_division=\"warn\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper function for autologging training metrics with Vertex AI Experiments\n",
    "    Args:\n",
    "        same as underlying recall_score function\n",
    "    \"\"\"\n",
    "    global real_recall_score\n",
    "    recall = real_recall_score(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=labels,\n",
    "        pos_label=pos_label,\n",
    "        average=average,\n",
    "        sample_weight=sample_weight,\n",
    "        zero_division=zero_division,\n",
    "    )\n",
    "    aiplatform.log_metrics({\"recall\": recall})\n",
    "    return recall\n",
    "\n",
    "\n",
    "class VertexXGBBooster(xgb.Booster):\n",
    "    \"\"\"\n",
    "    WIP\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params=None, cache=None, model_file=None):\n",
    "        super().__init__(params, cache, model_file)\n",
    "\n",
    "    def boost(\n",
    "        self, dtrain: xgb.core.DMatrix, grad: np.ndarray, hess: np.ndarray\n",
    "    ) -> None:\n",
    "        return super().boost(dtrain, grad, hess)\n",
    "\n",
    "    def eval(\n",
    "        self, data: xgb.core.DMatrix, name: str = \"eval\", iteration: int = 0\n",
    "    ) -> str:\n",
    "        return super().eval(data, name, iteration)\n",
    "\n",
    "    def update(self, dtrain: xgb.core.DMatrix, iteration: int, fobj=None) -> None:\n",
    "        return super().update(dtrain, iteration, fobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce76826902c0"
   },
   "source": [
    "### 使用Vertex AI实验训练XGBoost模型\n",
    "\n",
    "在下面的代码中，您将构建、训练和评估一个XGBoost表格模型。该Python脚本包括以下调用以集成`Vertex AI实验`：\n",
    "\n",
    "- 命令行参数：参数`experiment`和`run`用于传递实验和运行名称。\n",
    "- `autologging()`: 初始化实验并进行堆注入。\n",
    "- `aiplatform.start_execution()`: 初始化用于链接工件的上下文。\n",
    "- `aiplatform.end_run()`: 结束实验。\n",
    "\n",
    "*注意:* 函数`xgb.train`和`accuracy_score`将通过堆注入分别重定向到`VertexXGBtrain`和`VertexSKLaccuracy_score`。当对`train()`和`accuracy()`函数进行后续调用时，它们将作为相应的`VertexXGBtrain`和`VertexSKLaccuracy_score`函数执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiSnFuDoox9W"
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = f\"myexperiment{UUID}\"\n",
    "RUN_NAME = \"run-1\"\n",
    "\n",
    "DATASET_DIR = \"gs://cloud-samples-data/ai-platform/iris\"\n",
    "DATASET_DATA_URL = DATASET_DIR + \"/iris_data.csv\"\n",
    "DATASET_LABELS_URL = DATASET_DIR + \"/iris_target.csv\"\n",
    "\n",
    "BOOSTED_ROUNDS = 20\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import hypertune\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    # gsutil outputs everything to stderr so we need to divert it to stdout.\n",
    "    subprocess.check_call(\n",
    "        [\"gsutil\", \"cp\", DATASET_DATA_URL, \"data.csv\"], stderr=sys.stdout\n",
    "    )\n",
    "    # gsutil outputs everything to stderr so we need to divert it to stdout.\n",
    "    subprocess.check_call(\n",
    "        [\"gsutil\", \"cp\", DATASET_LABELS_URL, \"labels.csv\"], stderr=sys.stdout\n",
    "    )\n",
    "\n",
    "    # Load data into pandas, then use `.values` to get NumPy arrays\n",
    "    data = pd.read_csv(\"data.csv\").values\n",
    "    labels = pd.read_csv(\"labels.csv\").values\n",
    "\n",
    "    # Convert one-column 2D array into 1D array for use with XGBoost\n",
    "    labels = labels.reshape((labels.size,))\n",
    "\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "        data, labels, test_size=0.2, random_state=7\n",
    "    )\n",
    "\n",
    "    # Load data into DMatrix object\n",
    "    dtrain = xgb.DMatrix(train_data, label=train_labels)\n",
    "    return dtrain, test_data, test_labels\n",
    "\n",
    "\n",
    "def train_model(dtrain):\n",
    "    logging.info(\"Start training ...\")\n",
    "    # Train XGBoost model\n",
    "    params = {\"max_depth\": 3, \"objective\": \"multi:softmax\", \"num_class\": 3}\n",
    "    model = xgb.train(params=params, dtrain=dtrain, num_boost_round=BOOSTED_ROUNDS)\n",
    "    logging.info(\"Training completed\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_data, test_labels):\n",
    "    dtest = xgb.DMatrix(test_data)\n",
    "    pred = model.predict(dtest)\n",
    "    predictions = [round(value) for value in pred]\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "    logging.info(f\"Evaluation completed with model accuracy: {accuracy}\")\n",
    "\n",
    "    # report metric for hyperparameter tuning\n",
    "    hpt = hypertune.HyperTune()\n",
    "    hpt.report_hyperparameter_tuning_metric(\n",
    "        hyperparameter_metric_tag=\"accuracy\", metric_value=accuracy\n",
    "    )\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# autologging\n",
    "autolog(experiment=EXPERIMENT_NAME, run=RUN_NAME, framework=\"xgb\")\n",
    "\n",
    "with aiplatform.start_execution(\n",
    "    schema_title=\"system.ContainerExecution\", display_name=\"example_training\"\n",
    ") as execution:\n",
    "    dtrain, test_data, test_labels = get_data()\n",
    "    model = train_model(dtrain)\n",
    "    accuracy = evaluate_model(model, test_data, test_labels)\n",
    "\n",
    "aiplatform.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f40912e6500"
   },
   "source": [
    "获取实验结果\n",
    "\n",
    "接下来，您可以将实验名称作为参数传递给方法`get_experiment_df()`来将实验结果获取为一个 pandas 数据帧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7e9671712230"
   },
   "outputs": [],
   "source": [
    "experiment_df = aiplatform.get_experiment_df()\n",
    "experiment_df = experiment_df[experiment_df.experiment_name == EXPERIMENT_NAME]\n",
    "experiment_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e508c159d712"
   },
   "source": [
    "#### 删除实验\n",
    "\n",
    "由于实验是在训练脚本中创建的，要删除实验，您可以使用`list()`方法获取项目中的所有实验，然后根据实验名称进行筛选。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1a1b5fcbfde0"
   },
   "outputs": [],
   "source": [
    "experiments = aiplatform.Experiment.list()\n",
    "for experiment in experiments:\n",
    "    if experiment.name == EXPERIMENT_NAME:\n",
    "        experiment.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于本教程的[Google Cloud项目]（https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects）。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9eb897e0e728"
   },
   "outputs": [],
   "source": [
    "# There are no resources to cleanup"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_with_vertex_experiments_autologging_xgboost.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
