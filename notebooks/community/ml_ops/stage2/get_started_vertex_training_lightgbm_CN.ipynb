{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f82ca678df6"
   },
   "source": [
    "这个笔记本是从[Rajesh Thallam](https://github.com/RajeshThallam/vertex-ai-labs/blob/main/07-vertex-train-deploy-lightgbm/vertex-train-deploy-lightgbm-model.ipynb)的笔记本的修订版。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# GCP 上的 E2E 机器学习：MLOps 阶段2：实验：使用 Vertex AI Training 开始使用 LightGBM\n",
    "\n",
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training_lightgbm.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training_lightgbm.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      查看 GitHub 上的页面\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage2/get_started_vertex_training_lightgbm.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在 Vertex AI Workbench 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:mlops"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何在Google Cloud上使用Vertex AI进行端到端的MLOps生产环境。本教程涵盖了阶段2：实验阶段：使用Vertex AI 训练LightGBM 模型的入门指南。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:mlops,stage2,get_started_vertex_training_xgboost"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用 `Vertex AI Training` 训练一个 LightGBM 自定义模型。\n",
    "\n",
    "本教程使用以下 Google Cloud ML 服务：\n",
    "\n",
    "- `Vertex AI Training`\n",
    "- `Vertex AI Model` 资源\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 使用 Python 包进行训练。\n",
    "- 使用 GCSFuse 将模型工件保存到 Cloud Storage。\n",
    "- 构建一个 FastAPI 预测服务器。\n",
    "- 构建一个 Dockerfile 部署镜像。\n",
    "- 在本地测试部署镜像。\n",
    "- 创建一个 `Vertex AI Model` 资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:iris,lcn"
   },
   "source": [
    "数据集\n",
    "\n",
    "本教程使用的数据集是来自[TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview)的[Iris数据集](https://www.tensorflow.org/datasets/catalog/iris)。该数据集不需要任何特征工程。本教程中数据集的版本存储在一个公共的云存储桶中。训练好的模型可以预测三种不同种类的鸢尾花品种：山鸢尾(setosa)、弗吉尼亚鸢尾(virginica)和变色鸢尾(versicolor)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de76bb18c85b"
   },
   "source": [
    "### 费用\n",
    "\n",
    "本教程使用Google Cloud的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI价格](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage价格](https://cloud.google.com/storage/pricing)，并使用[Pricing计算器](https://cloud.google.com/products/calculator/)根据您的预期使用量生成费用估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_local"
   },
   "source": [
    "### 设置本地开发环境\n",
    "\n",
    "如果您正在使用Colab或Vertex AI Workbench笔记本，您的环境已满足运行此笔记本的所有要求。您可以跳过此步骤。\n",
    "\n",
    "否则，请确保您的环境满足此笔记本的要求。您需要以下内容：\n",
    "\n",
    "- Cloud Storage SDK\n",
    "- Git\n",
    "- Python 3\n",
    "- virtualenv\n",
    "- 在使用Python 3的虚拟环境中运行的Jupyter笔记本\n",
    "\n",
    "Cloud Storage指南[设置Python开发环境](https://cloud.google.com/python/setup)和[Jupyter安装指南](https://jupyter.org/install)提供满足这些要求的详细说明。以下步骤提供了一套简洁的说明：\n",
    "\n",
    "1. [安装和初始化SDK](https://cloud.google.com/sdk/docs/)。\n",
    "\n",
    "2. [安装Python 3](https://cloud.google.com/python/setup#installing_python)。\n",
    "\n",
    "3. [安装virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv) 并创建一个使用Python 3的虚拟环境。激活虚拟环境。\n",
    "\n",
    "4. 要安装Jupyter，可以在终端shell中运行 `pip3 install jupyter`。\n",
    "\n",
    "5. 要启动Jupyter，可以在终端shell中运行 `jupyter notebook`。\n",
    "\n",
    "6. 在Jupyter Notebook Dashboard中打开这个笔记本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装以下包以执行这个笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "! pip3 install --upgrade google-cloud-aiplatform $USER_FLAG -q\n",
    "! pip3 install -U google-cloud-storage $USER_FLAG -q\n",
    "! pip3 install -U lightgbm $USER_FLAG -q\n",
    "\n",
    "if os.getenv(\"IS_TESTING\"):\n",
    "    ! pip3 install --upgrade tensorflow $USER_FLAG -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "重新启动内核\n",
    "\n",
    "安装了额外的程序包后，您需要重新启动笔记本内核，以便它可以找到这些程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "restart"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### GPU运行时\n",
    "\n",
    "本教程不需要GPU运行时。\n",
    "\n",
    "### 设置您的Google Cloud项目\n",
    "\n",
    "**以下步骤是必需的，无论您的笔记本环境如何。**\n",
    "\n",
    "1. [选择或创建一个Google Cloud项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建帐户时，您将获得$300的免费信用用于计算/存储成本。\n",
    "\n",
    "2. [确保为您的项目启用了计费功能。](https://cloud.google.com/billing/docs/how-to/modify-project)\n",
    "\n",
    "3. [启用以下API：Vertex AI API、Compute Engine API和Cloud Storage。](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component,storage-component.googleapis.com)\n",
    "\n",
    "4. 如果您在本地运行此笔记本，则需要安装 [Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "5. 在下面的单元格中输入您的项目ID。然后运行该单元格，确保Cloud SDK对该笔记本中的所有命令使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter运行以`!`为前缀的行作为shell命令，并插入以`$`为前缀的Python变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用`gcloud`来获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 地区\n",
    "\n",
    "您也可以更改`REGION`变量，该变量用于整个笔记本的操作。以下是Vertex AI支持的地区。我们建议您选择距离您最近的地区。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太：`asia-east1`\n",
    "\n",
    "您可能不能使用多区域存储桶来训练Vertex AI。并非所有地区都支持所有Vertex AI服务。\n",
    "\n",
    "了解更多关于[Vertex AI地区](https://cloud.google.com/vertex-ai/docs/general/locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type:\"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "时间戳\n",
    "\n",
    "如果您正在参加实时教程会议，则可能会使用共享的测试帐户或项目。为避免在创建的资源上发生名称冲突，您为每个实例会话创建一个时间戳，并将时间戳附加到您在本教程中创建的资源的名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "timestamp"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 验证您的谷歌云账户\n",
    "\n",
    "**如果您正在使用Vertex AI Workbench笔记本**，您的环境已经经过验证。请跳过此步骤。\n",
    "\n",
    "**如果您正在使用Colab**，运行下方的单元格，并按照提示进行OAuth验证。\n",
    "\n",
    "**否则**，请按照以下步骤操作：\n",
    "\n",
    "在Cloud控制台中，进入[创建服务账号密钥](https://console.cloud.google.com/apis/credentials/serviceaccountkey)页面。\n",
    "\n",
    "**点击创建服务账号**。\n",
    "\n",
    "在**服务账号名称**字段中输入一个名称，然后点击**创建**。\n",
    "\n",
    "在**将此服务账号授权给项目**部分，点击角色下拉列表。在过滤框中输入\"Vertex\"，并选择**Vertex管理员**。在过滤框中输入\"Storage对象管理员\"，并选择**Storage对象管理员**。\n",
    "\n",
    "点击创建。包含您的密钥的JSON文件将下载到您的本地环境。\n",
    "\n",
    "在下方的单元格中将您的服务账号密钥的路径输入为GOOGLE_APPLICATION_CREDENTIALS变量，并运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcp_authenticate"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "**无论您使用哪种笔记本环境，以下步骤都是必需的。**\n",
    "\n",
    "当您初始化用于 Python 的 Vertex SDK 时，您需要指定一个云存储暂存桶。暂存桶是您的数据集和模型资源关联的所有数据在不同会话之间保留的位置。\n",
    "\n",
    "请在下面设置您的云存储桶的名称。存储桶名称必须在所有谷歌云项目中全局唯一，包括您组织以外的项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"[your-bucket-name]\":\n",
    "    BUCKET_NAME = PROJECT_ID + \"aip-\" + TIMESTAMP\n",
    "    BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只要您的存储桶还不存在：运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "最后，通过检查Cloud Storage存储桶的内容来验证访问权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。\n",
    "### 导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3c0380967f5"
   },
   "outputs": [],
   "source": [
    "print(f\"LightGBM version {lightgbm.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "## 初始化Python的Vertex SDK\n",
    "\n",
    "为您的项目和相应的存储桶初始化Python的Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gar_enable_api"
   },
   "source": [
    "### 启用 Artifact Registry API\n",
    "\n",
    "首先，您必须为您的项目启用 Artifact Registry API 服务。\n",
    "\n",
    "了解有关[启用服务](https://cloud.google.com/artifact-registry/docs/enable-service)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gar_enable_api"
   },
   "outputs": [],
   "source": [
    "! gcloud services enable artifactregistry.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gar_create_repo"
   },
   "source": [
    "### 创建一个私有的Docker仓库\n",
    "\n",
    "你的第一步是在Google Artifact Registry中创建你自己的Docker仓库。\n",
    "\n",
    "1. 运行`gcloud artifacts repositories create`命令来创建一个新的Docker仓库，指定你的地区，并附上描述\"docker repository\"。\n",
    "\n",
    "2. 运行`gcloud artifacts repositories list`命令来验证你的仓库是否已经创建成功。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gar_create_repo"
   },
   "outputs": [],
   "source": [
    "PRIVATE_REPO = \"prediction\"\n",
    "\n",
    "! gcloud artifacts repositories create {PRIVATE_REPO} --repository-format=docker --location={REGION} --description=\"Prediction repository\"\n",
    "\n",
    "! gcloud artifacts repositories list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gar_auth"
   },
   "source": [
    "### 配置私有仓库的身份验证\n",
    "\n",
    "在推送或拉取容器映像之前，请配置Docker使用`gcloud`命令行工具对您所在地区的`Artifact Registry`发出的请求进行身份验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gar_auth"
   },
   "outputs": [],
   "source": [
    "! gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction,xgboost"
   },
   "source": [
    "#### 设置预构建的容器\n",
    "\n",
    "设置用于训练和预测的预构建的 Docker 容器镜像。\n",
    "\n",
    "\n",
    "有关最新列表，请参见[用于训练的预构建容器](https://cloud.google.com/ai-platform-unified/docs/training/pre-built-containers)。\n",
    "\n",
    "\n",
    "有关最新列表，请参见[用于预测的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:training,prediction,xgboost"
   },
   "outputs": [],
   "source": [
    "TRAIN_VERSION = \"scikit-learn-cpu.0-23\"\n",
    "DEPLOY_VERSION = \"lightgbm-cpu\"\n",
    "\n",
    "# prebuilt\n",
    "TRAIN_IMAGE = \"{}-docker.pkg.dev/vertex-ai/training/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], TRAIN_VERSION\n",
    ")\n",
    "\n",
    "DEPLOY_IMAGE = \"{}-docker.pkg.dev/{}/{}/{}:latest\".format(\n",
    "    REGION, PROJECT_ID, PRIVATE_REPO, DEPLOY_VERSION\n",
    ")\n",
    "print(\"Deploy image:\", DEPLOY_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training,prediction"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于训练和预测的机器类型。\n",
    "\n",
    "- 设置变量 `TRAIN_COMPUTE` 和 `DEPLOY_COMPUTE` 来配置用于训练和预测的虚拟机的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`: 每个vCPU 3.75GB的内存。\n",
    "     - `n1-highmem`: 每个vCPU 6.5GB的内存\n",
    "     - `n1-highcpu`: 每个vCPU 0.9GB的内存\n",
    " - `vCPUs`: \\[2, 4, 8, 16, 32, 64, 96 \\]个数\n",
    "\n",
    "*注意：以下机型不支持用于训练*\n",
    "\n",
    " - `标准`: 2个vCPUs\n",
    " - `高CPU`: 2、4和8个vCPUs\n",
    "\n",
    "*注意：您也可以使用n2和e2机型进行训练和部署，但它们不支持GPU。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training,prediction"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TRAIN_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_TRAIN_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)\n",
    "\n",
    "if os.getenv(\"IS_TESTING_DEPLOY_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_DEPLOY_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_training_package:xgboost"
   },
   "source": [
    "### 检查训练包\n",
    "\n",
    "#### 包布局\n",
    "\n",
    "在您开始训练之前，您将查看一个用于定制训练作业的Python包是如何组装的。解压后，该包包含以下目录/文件布局。\n",
    "\n",
    "- PKG-INFO\n",
    "- README.md\n",
    "- setup.cfg\n",
    "- setup.py\n",
    "- trainer\n",
    "  - \\_\\_init\\_\\_.py\n",
    "  - task.py\n",
    "\n",
    "文件`setup.cfg`和`setup.py`是将包安装到Docker映像的操作环境中的指令。\n",
    "\n",
    "文件`trainer/task.py`是执行定制训练作业的Python脚本。*注意*，当我们在工作池规范中引用它时，我们用句点（`trainer.task`）替换目录斜杠，并删除文件后缀（`.py`）。\n",
    "\n",
    "#### 包装配\n",
    "\n",
    "在接下来的单元中，您将组装训练包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4wS4eISox9V"
   },
   "outputs": [],
   "source": [
    "# Make folder for Python training script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\nsetuptools.setup(\\n\\n    install_requires=[\\n\\n'lightgbm'    ],\\n\\n    packages=setuptools.find_packages())\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\nName: Iris tabular classification\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taskpy_contents:iris,xgboost"
   },
   "source": [
    "### 为Python培训包创建任务脚本\n",
    "\n",
    "接下来，您需要为训练包创建`task.py`脚本。一些值得注意的步骤包括：\n",
    "\n",
    "- 命令行参数：\n",
    "    - `model-dir`：保存训练模型的位置。在使用Vertex AI自定义训练时，该位置将在环境变量`AIP_MODEL_DIR`中指定。\n",
    "    \n",
    "- 数据预处理（`get_data()`）：\n",
    "    - 下载数据集并拆分为训练和测试集。\n",
    "    \n",
    "- 训练（`train_model()`）：\n",
    "    - 训练模型。\n",
    "    \n",
    "- 模型结果保存\n",
    "    - 将模型结果和评估指标保存在由`model-dir`指定的云存储位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taskpy_contents:xgboost,iris"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "# Single Instance Training for Iris\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "logging.info(\"Parsing arguments\")\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--model-dir', \n",
    "    dest='model_dir',        \n",
    "    default=os.getenv('AIP_MODEL_DIR'), \n",
    "    type=str, \n",
    "    help='Location to export GCS model')\n",
    "args = parser.parse_args()\n",
    "logging.info(args)\n",
    "\n",
    "def get_data():\n",
    "    # Download data\n",
    "    logging.info(\"Downloading data\")\n",
    "    iris = load_iris()\n",
    "    print(iris.data.shape)\n",
    "\n",
    "    # split data\n",
    "    print(\"Splitting data into test and train\")\n",
    "    x, y = iris.data, iris.target\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=123)\n",
    "\n",
    "    # create dataset for lightgbm\n",
    "    print(\"creating dataset for LightGBM\")\n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)\n",
    "    \n",
    "    return lgb_train, lgb_eval\n",
    "\n",
    "def train_model(lgb_train, lg_eval):\n",
    "    # specify your configurations as a dict\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'metric': {'multi_error'},\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "        'num_class' : 3\n",
    "    }\n",
    "\n",
    "    # train lightgbm model\n",
    "    logging.info('Starting training...')\n",
    "    model = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=20,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    early_stopping_rounds=5)\n",
    "    \n",
    "    return model\n",
    "\n",
    "lgb_train, lgb_eval = get_data()\n",
    "model = train_model(lgb_train, lgb_eval)\n",
    "\n",
    "# GCSFuse conversion\n",
    "gs_prefix = 'gs://'\n",
    "gcsfuse_prefix = '/gcs/'\n",
    "if args.model_dir.startswith(gs_prefix):\n",
    "    args.model_dir = args.model_dir.replace(gs_prefix, gcsfuse_prefix)\n",
    "    dirpath = os.path.split(args.model_dir)[0]\n",
    "    if not os.path.isdir(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "        \n",
    "# save model to file\n",
    "logging.info('Saving model...')\n",
    "model_filename = 'model.txt'\n",
    "gcs_model_path = os.path.join(args.model_dir, model_filename)\n",
    "model.save_model(gcs_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tarball_training_script"
   },
   "source": [
    "将培训脚本存储在您的云存储桶中\n",
    "\n",
    "接下来，将培训文件夹打包成压缩的tar包，然后存储在您的云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnmdycf6ox9X"
   },
   "outputs": [],
   "source": [
    "! rm -f custom.tar custom.tar.gz\n",
    "! tar cvf custom.tar custom\n",
    "! gzip custom.tar\n",
    "! gsutil cp custom.tar.gz $BUCKET_URI/trainer_iris.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_pp_training_job:mbsdk"
   },
   "source": [
    "### 创建和运行自定义训练任务\n",
    "\n",
    "为了训练一个自定义模型，您需要执行两个步骤：1) 创建一个自定义训练任务，2) 运行任务。\n",
    "\n",
    "#### 创建自定义训练任务\n",
    "\n",
    "使用`CustomTrainingJob`类来创建一个自定义训练任务，并指定以下参数：\n",
    "\n",
    "- `display_name`：自定义训练任务的可读名称。\n",
    "- `container_uri`：训练容器镜像。\n",
    "\n",
    "- `python_package_gcs_uri`：Python训练包的位置，以tarball格式存储在云存储中。\n",
    "- `python_module_name`：Python包中训练脚本的相对路径。\n",
    "\n",
    "*注意：* 没有`requirements`参数。您可以在Python包中的`setup.py`脚本中指定任何需求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVEMz1xqox9X"
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"iris_\" + TIMESTAMP\n",
    "\n",
    "job = aiplatform.CustomPythonPackageTrainingJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    python_package_gcs_uri=f\"{BUCKET_URI}/trainer_iris.tar.gz\",\n",
    "    python_module_name=\"trainer.task\",\n",
    "    container_uri=TRAIN_IMAGE,\n",
    "    project=PROJECT_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prepare_custom_cmdargs:iris,xgboost"
   },
   "source": [
    "### 准备您的命令行参数\n",
    "\n",
    "现在为您的自定义训练容器定义命令行参数：\n",
    "\n",
    "- `args`：要传递给作为容器入口点设置的可执行文件的命令行参数。\n",
    "  - `--model-dir`：对于我们的演示，我们使用这个命令行参数来指定存储模型文件的位置。\n",
    "      - 直接：您将Cloud Storage位置作为命令行参数传递给您的训练脚本（设置变量`DIRECT = True`），或\n",
    "      - 间接：服务将Cloud Storage位置作为环境变量`AIP_MODEL_DIR`传递给您的训练脚本（设置变量`DIRECT = False`）。在这种情况下，您需要在作业规范中告诉服务模型文件位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AoUfpBqVox9Y"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = \"{}/{}\".format(BUCKET_URI, TIMESTAMP)\n",
    "\n",
    "DIRECT = False\n",
    "if DIRECT:\n",
    "    CMDARGS = [\n",
    "        \"--model_dir=\" + MODEL_DIR,\n",
    "    ]\n",
    "else:\n",
    "    CMDARGS = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_custom_job:mbsdk"
   },
   "source": [
    "运行自定义训练作业\n",
    "\n",
    "接下来，您可以通过调用`run`方法来运行自定义作业，启动训练作业，具体参数如下：\n",
    "\n",
    "- `args`：要传递给训练脚本的命令行参数。\n",
    "- `replica_count`：用于训练的计算实例数量（replica_count = 1表示单节点训练）。\n",
    "- `machine_type`：计算实例的机器类型。\n",
    "- `accelerator_type`：硬件加速器类型。\n",
    "- `accelerator_count`：要附加到工作人员副本的加速器数量。\n",
    "- `base_output_dir`：用于写入模型工件的云存储位置。\n",
    "- `sync`：是否阻塞直到作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCruQq1aox9Y"
   },
   "outputs": [],
   "source": [
    "job.run(\n",
    "    args=CMDARGS,\n",
    "    replica_count=1,\n",
    "    machine_type=TRAIN_COMPUTE,\n",
    "    base_output_dir=MODEL_DIR,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "model_path_to_deploy = MODEL_DIR + \"/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "list_job"
   },
   "source": [
    "### 列出一个自定义培训工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBM_KLMSox9Y"
   },
   "outputs": [],
   "source": [
    "_job = job.list(filter=f\"display_name=iris_{TIMESTAMP}\")\n",
    "print(_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "custom_job_wait:mbsdk"
   },
   "source": [
    "### 等待自定义训练作业完成\n",
    "\n",
    "接下来，等待自定义训练作业完成。或者，可以在`run()`方法中将参数`sync`设置为`True`，以阻止直到自定义训练作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHPMHbSyox9Z"
   },
   "outputs": [],
   "source": [
    "job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "delete_job"
   },
   "source": [
    "### 删除自定义训练作业\n",
    "\n",
    "在训练作业完成之后，您可以使用 `delete()` 方法来删除训练作业。在完成之前，可以使用 `cancel()` 方法取消训练作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlYg7Sp-ox9Z"
   },
   "outputs": [],
   "source": [
    "job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2478e67d679f"
   },
   "source": [
    "### 验证模型工件\n",
    "\n",
    "接下来，验证训练脚本是否成功将训练好的模型保存到您的云存储位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c644f0d3a201"
   },
   "outputs": [],
   "source": [
    "print(f\"Model path with trained model artifacts {model_path_to_deploy}\")\n",
    "\n",
    "! gsutil ls $model_path_to_deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_model:migration,new"
   },
   "source": [
    "## 部署 LightGBM 模型到 Vertex AI 端点\n",
    "\n",
    "### 使用 FastAPI 构建 HTTP 服务器\n",
    "\n",
    "接下来，您可以使用 FastAPI 来实现一个 HTTP 服务器作为自定义部署容器。该容器必须监听并响应存活检查、健康检查和预测请求。HTTP 服务器必须在 0.0.0.0 上监听请求。\n",
    "\n",
    "了解更多关于[部署容器要求](https://cloud.google.com/ai-platform-unified/docs/predictions/custom-container-requirements#image)。\n",
    "\n",
    "了解更多关于[FastAPI](https://fastapi.tiangolo.com/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b28b53f8b3f4"
   },
   "outputs": [],
   "source": [
    "# Make folder for serving script\n",
    "! rm -rf serve\n",
    "! mkdir serve\n",
    "\n",
    "# Make the predictor subfolder\n",
    "! mkdir serve/app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8baa8361ecb4"
   },
   "source": [
    "为服务容器创建要求文件\n",
    "\n",
    "接下来，在服务器环境中创建`requirements.txt`文件，指定需要在服务容器上安装的Python包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2dd3e671130"
   },
   "outputs": [],
   "source": [
    "%%writefile serve/requirements.txt\n",
    "\n",
    "numpy\n",
    "scikit-learn>=0.24\n",
    "pandas==1.0.4\n",
    "lightgbm==3.2.1\n",
    "google-cloud-storage>=1.26.0,<2.0.0dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07c16e1003ef"
   },
   "source": [
    "### 写一个FastAPI的服务脚本\n",
    "\n",
    "接下来，您可以使用`FastAPI`编写HTTP服务器的服务脚本，如下所示：\n",
    "\n",
    "- `app`: 实例化一个`FastAPI`应用程序\n",
    "- `health()`: 定义对健康请求的响应。\n",
    "    - 返回状态码200\n",
    "- `predict()`: 定义对预测请求的响应。\n",
    "    - `body = await request.json()`: 异步等待HTTP请求。\n",
    "    - `instances = body[\"instances\"]`: 预测请求的内容。\n",
    "    - `inputs = np.asarray(instances)`: 重新格式化预测请求为一个numpy数组。\n",
    "    - `outputs = model.predict(inputs)`: 调用模型进行预测。\n",
    "    - `return {\"predictions\": ... }`: 在响应体中返回格式化后的预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97b0cd77339c"
   },
   "outputs": [],
   "source": [
    "%%writefile serve/app/main.py\n",
    "from fastapi.logger import logger\n",
    "from fastapi import FastAPI, Request\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import lightgbm as lgb\n",
    "\n",
    "import logging\n",
    "\n",
    "gunicorn_logger = logging.getLogger('gunicorn.error')\n",
    "logger.handlers = gunicorn_logger.handlers\n",
    "\n",
    "if __name__ != \"main\":\n",
    "    logger.setLevel(gunicorn_logger.level)\n",
    "else:\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "model_f = \"/model/model.txt\"\n",
    "\n",
    "logger.info(\"Loading model\")\n",
    "_model = lgb.Booster(model_file=model_f)\n",
    "logger.info(\"Loading target class labels\")\n",
    "_class_names = load_iris().target_names\n",
    "\n",
    "@app.get(os.environ['AIP_HEALTH_ROUTE'], status_code=200)\n",
    "def health():\n",
    "    \"\"\" health check to ensure HTTP server is ready to handle \n",
    "        prediction requests\n",
    "    \"\"\"\n",
    "    return {\"status\": \"healthy\"}\n",
    "\n",
    "\n",
    "@app.post(os.environ['AIP_PREDICT_ROUTE'])\n",
    "async def predict(request: Request):\n",
    "    body = await request.json()\n",
    "\n",
    "    instances = body[\"instances\"]\n",
    "    inputs = np.asarray(instances)\n",
    "    \n",
    "    outputs = _model.predict(inputs)\n",
    "\n",
    "    logger.info(f\"Outputs {outputs}\")\n",
    "    return {\"predictions\": [_class_names[class_num] for class_num in np.argmax(outputs, axis=1)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea37d0597e2b"
   },
   "source": [
    "### 添加预启动脚本\n",
    "FastAPI将在启动服务器之前执行此脚本。为了在与AI平台（Unified）所期望的端口上运行FastAPI，将`PORT`环境变量设置为等于`AIP_HTTP_PORT`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e029a2d85935"
   },
   "outputs": [],
   "source": [
    "%%writefile serve/app/prestart.sh\n",
    "\n",
    "#!/bin/bash\n",
    "export PORT=$AIP_HTTP_PORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a402c1f4bcc"
   },
   "source": [
    "### 存储测试实例\n",
    "\n",
    "接下来，您创建合成示例，以后可用于测试 FastAPI 服务器和训练好的 LightGBM 模型。\n",
    "\n",
    "了解有关[自定义模型预测请求的 JSON 格式化](https://cloud.google.com/ai-platform-unified/docs/predictions/online-predictions-custom-models#request-body-details)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d45c868ccaed"
   },
   "outputs": [],
   "source": [
    "%%writefile serve/instances.json\n",
    "{\n",
    "    \"instances\": [\n",
    "        [6.7, 3.1, 4.7, 1.5],\n",
    "        [4.6, 3.1, 1.5, 0.2]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ae1b8aead6c"
   },
   "source": [
    "构建并推送预测容器到Artifact Registry\n",
    "\n",
    "编写Dockerfile，使用`tiangolo/uvicorn-gunicorn-fastapi`作为基础镜像。这将自动运行FastAPI，使用Gunicorn和Uvicorn。\n",
    "\n",
    "了解更多关于[使用Docker部署FastAPI](https://fastapi.tiangolo.com/deployment/docker/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "289dcdf1c4f4"
   },
   "outputs": [],
   "source": [
    "%%bash -s $MODEL_DIR\n",
    "\n",
    "MODEL_DIR=$1\n",
    "\n",
    "mkdir -p ./serve/model/\n",
    "gsutil cp -r ${MODEL_DIR}/model/ ./serve/model/ \n",
    "\n",
    "cat > ./serve/Dockerfile <<EOF\n",
    "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
    "\n",
    "COPY ./app /app\n",
    "COPY ./model /\n",
    "COPY requirements.txt requirements.txt\n",
    "\n",
    "RUN pip3 install -r requirements.txt\n",
    "\n",
    "EXPOSE 7080\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"7080\"]\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f3bca44ead4"
   },
   "source": [
    "构建本地容器\n",
    "\n",
    "接下来，您可以构建并标记您的自定义部署容器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64261b86085e"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! docker build --tag={DEPLOY_IMAGE} ./serve\n",
    "else:\n",
    "    # install docker daemon\n",
    "    ! apt-get -qq install docker.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c746c507aba6"
   },
   "source": [
    "### 在本地运行和测试容器（可选）\n",
    "\n",
    "以分离模式在本地运行容器，并提供容器所需的环境变量。这些环境变量将在部署后由AI平台预测提供给容器。测试 `/health` 和 `/predict` 路由，然后停止运行中的映像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6534859e481b"
   },
   "source": [
    "在将容器映像推送到Artifact Registry以与Vertex Predictions一起使用之前，您可以在本地环境中将其作为容器运行，以验证服务器是否按预期工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3246b3a01d92"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! docker rm local-iris 2>/dev/null\n",
    "    ! docker run -t -d --rm -p 7080:7080 \\\n",
    "        --name=local-iris \\\n",
    "        -e AIP_HTTP_PORT=7080 \\\n",
    "        -e AIP_HEALTH_ROUTE=/health \\\n",
    "        -e AIP_PREDICT_ROUTE=/predict \\\n",
    "        -e AIP_STORAGE_URI={MODEL_DIR} \\\n",
    "        {DEPLOY_IMAGE}\n",
    "    ! docker container ls\n",
    "    ! sleep 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bdfb565a253"
   },
   "source": [
    "健康检查\n",
    "\n",
    "发送容器服务器健康检查。输出应为 {\"status\": \"healthy\"}。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdc1f41f8dcc"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! curl http://localhost:7080/health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c92e4992b2f4"
   },
   "source": [
    "如果成功，服务器将返回以下响应：\n",
    "\n",
    "```\n",
    "{\n",
    "   \"status\": \"healthy\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5433a0c62a99"
   },
   "source": [
    "预测检查\n",
    "\n",
    "向容器的服务器发送一个预测请求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "458de32ee979"
   },
   "outputs": [],
   "source": [
    "! curl -X POST \\\n",
    "  -d @serve/instances.json \\\n",
    "  -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "  http://localhost:7080/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "db78dc1f2313"
   },
   "source": [
    "这个请求使用一个测试句子。如果成功，服务器会以下列格式返回预测结果：\n",
    "\n",
    "```\n",
    "{\"predictions\":[\"versicolor\",\"setosa\"]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc16b5fa1b6d"
   },
   "source": [
    "停止本地容器\n",
    "\n",
    "最后，停止本地容器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8127f3e5b74"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! docker stop local-iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c57c65c5d25"
   },
   "source": [
    "将提供容器推送到Artifact Registry\n",
    "\n",
    "将带有推理代码和依赖项的容器镜像推送到Artifact Registry。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8f1fc336bf79"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! docker push $DEPLOY_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f50e9c553fb7"
   },
   "source": [
    "在Colab中执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7e8c98f1e56"
   },
   "outputs": [],
   "source": [
    "%%bash -s $IS_COLAB $DEPLOY_IMAGE\n",
    "if [ $1 == \"False\" ]; then\n",
    "  exit 0\n",
    "fi\n",
    "set -x\n",
    "dockerd -b none --iptables=0 -l warn &\n",
    "for i in $(seq 5); do [ ! -S \"/var/run/docker.sock\" ] && sleep 2 || break; done\n",
    "docker build --tag={DEPLOY_IMAGE} ./serve\n",
    "docker push $2\n",
    "kill $(jobs -p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ac8627fc8434"
   },
   "source": [
    "将服务容器部署到Vertex Predictions\n",
    "我们在Vertex 人工智能上创建一个模型资源，并将模型部署到一个Vertex 终端。在使用模型之前，您必须将模型部署到终端。部署的模型会运行自定义容器图像以提供预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_model:mbsdk"
   },
   "source": [
    "## 上传模型\n",
    "\n",
    "接下来，使用`Model.upload()`方法将您的模型上传到`Model`资源，使用以下参数：\n",
    "\n",
    "- `display_name`：`Model`资源的人类可读名称。\n",
    "- `artifact`：训练模型工件的云存储位置。\n",
    "- `serving_container_image_uri`：提供服务的容器镜像。\n",
    "- `serving_container_predict_route`：发送预测请求到容器的HTTP路径。\n",
    "- `serving_container_health_route`：发送健康检查请求到容器的HTTP路径。\n",
    "- `serving_container_ports`：容器暴露的端口，用于监听请求。\n",
    "- `sync`：是否以异步或同步方式进行上传。\n",
    "\n",
    "如果使用异步方式运行`upload()`方法，您随后可以使用`wait()`方法阻塞直到完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c34825f267d4"
   },
   "outputs": [],
   "source": [
    "APP_NAME = \"iris\"\n",
    "\n",
    "model_display_name = f\"{APP_NAME}-{TIMESTAMP}\"\n",
    "model_description = \"LightGBM based iris flower classifier with custom container\"\n",
    "\n",
    "MODEL_NAME = APP_NAME\n",
    "health_route = \"/ping\"\n",
    "predict_route = \"/predict\"\n",
    "serving_container_ports = [7080]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=model_display_name,\n",
    "    description=model_description,\n",
    "    serving_container_image_uri=DEPLOY_IMAGE,\n",
    "    serving_container_predict_route=predict_route,\n",
    "    serving_container_health_route=health_route,\n",
    "    serving_container_ports=serving_container_ports,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_batch_predictions:migration"
   },
   "source": [
    "进行批量预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batchpredictionjobs_create:migration,new,mbsdk"
   },
   "source": [
    "文档 - [批量预测请求 - Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_test_items:xgboost,tabular,iris"
   },
   "source": [
    "制作测试项目\n",
    "\n",
    "您将使用合成数据作为测试数据项。不必担心我们使用的是合成数据 -- 我们只是想要展示如何进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "make_test_items:xgboost,tabular,iris"
   },
   "outputs": [],
   "source": [
    "INSTANCES = [[6.7, 3.1, 4.7, 1.5], [4.6, 3.1, 1.5, 0.2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_batch_file:custom,tabular,list"
   },
   "source": [
    "### 制作批量输入文件\n",
    "\n",
    "现在制作一个批量输入文件，您将存储在本地的云存储桶中。预测请求中的每个实例都是以下形式的列表：\n",
    "\n",
    "                        [ [内容1], [内容2] ]\n",
    "\n",
    "- `内容`: 测试项的特征值作为列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae7342e19f2b"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "[json.dumps(record) for record in INSTANCES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "make_batch_file:custom,tabular,list"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gcs_input_uri = f\"{BUCKET_URI}/{APP_NAME}/test/batch_input/test.jsonl\"\n",
    "with tf.io.gfile.GFile(gcs_input_uri, \"w\") as f:\n",
    "    for i in INSTANCES:\n",
    "        f.write(str(i) + \"\\n\")\n",
    "\n",
    "! gsutil cat $gcs_input_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request:mbsdk,jsonl,custom,cpu"
   },
   "source": [
    "### 发起批量预测请求\n",
    "\n",
    "现在您的模型资源已经训练完成，您可以通过调用batch_predict()方法来发起批量预测，使用以下参数：\n",
    "\n",
    "- `job_display_name`: 批量预测作业的可读名称。\n",
    "- `gcs_source`: 一个或多个批量请求输入文件的列表。\n",
    "- `gcs_destination_prefix`: 用于存储批量预测结果的云存储位置。\n",
    "- `instances_format`: 输入实例的格式，可以是'csv'或'jsonl'。默认为'jsonl'。\n",
    "- `predictions_format`: 输出预测的格式，可以是'csv'或'jsonl'。默认为'jsonl'。\n",
    "- `machine_type`: 用于训练的机器类型。\n",
    "- `sync`: 如果设置为True，则在等待异步批量作业完成时，调用将会被阻塞。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request:mbsdk,jsonl,custom,cpu"
   },
   "outputs": [],
   "source": [
    "MIN_NODES = 1\n",
    "MAX_NODES = 1\n",
    "\n",
    "batch_predict_job = model.batch_predict(\n",
    "    job_display_name=f\"{APP_NAME}_TIMESTAMP\",\n",
    "    gcs_source=gcs_input_uri,\n",
    "    gcs_destination_prefix=f\"{BUCKET_URI}/{APP_NAME}/test/batch_output/\",\n",
    "    instances_format=\"jsonl\",\n",
    "    predictions_format=\"jsonl\",\n",
    "    model_parameters=None,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    starting_replica_count=MIN_NODES,\n",
    "    max_replica_count=MAX_NODES,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "print(batch_predict_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "source": [
    "等待批量预测作业完成\n",
    "\n",
    "接下来，等待批处理作业完成。或者，在`batch_predict()` 方法中将参数`sync`设置为`True`，以阻塞直到批量预测作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "outputs": [],
   "source": [
    "batch_predict_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_batch_prediction:mbsdk,custom,lcn"
   },
   "source": [
    "### 获取预测结果\n",
    "\n",
    "接下来，从已完成的批量预测任务中获取结果。\n",
    "\n",
    "结果将被写入您在批量预测请求中指定的 Cloud 存储输出桶中。您可以调用 iter_outputs() 方法获取生成的结果文件列表。每个文件以 JSON 格式包含一个或多个预测请求：\n",
    "\n",
    "- `instance`：预测请求。\n",
    "- `prediction`：预测响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_batch_prediction:mbsdk,custom,lcn"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "bp_iter_outputs = batch_predict_job.iter_outputs()\n",
    "\n",
    "prediction_results = list()\n",
    "for blob in bp_iter_outputs:\n",
    "    if blob.name.split(\"/\")[-1].startswith(\"prediction\"):\n",
    "        prediction_results.append(blob.name)\n",
    "\n",
    "tags = list()\n",
    "for prediction_result in prediction_results:\n",
    "    gfile_name = f\"gs://{bp_iter_outputs.bucket.name}/{prediction_result}\"\n",
    "    with tf.io.gfile.GFile(name=gfile_name, mode=\"r\") as gfile:\n",
    "        for line in gfile.readlines():\n",
    "            line = json.loads(line)\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_online_predictions:migration"
   },
   "source": [
    "做在线预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:migration,new,mbsdk"
   },
   "source": [
    "文档 - [在线预测请求](https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:mbsdk,cpu"
   },
   "source": [
    "## 部署模型\n",
    "\n",
    "接下来，部署您的模型进行在线预测。要部署模型，您需要调用`deploy`方法，并传入以下参数：\n",
    "\n",
    "- `deployed_model_display_name`：部署模型的可读名称。\n",
    "- `traffic_split`：传入一个包含一个或多个键值对的字典，表示流量分配给该模型的百分比。\n",
    "如果只有一个模型，可以指定为{ \"0\": 100 }，其中\"0\"表示已上传的模型，100表示100%的流量。\n",
    "如果端点上已经存在其他模型，需要将流量进行分流，则使用model_id来指定：{ \"0\": 百分比, model_id: 百分比, ... }，其中model_id是已部署到端点的模型的模型ID。百分比必须加起来等于100。\n",
    "- `machine_type`：用于训练的计算机类型。\n",
    "- `starting_replica_count`：最初配置的计算实例数。\n",
    "- `max_replica_count`：可扩展到的最大计算实例数。在本教程中，只配置了一个实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy_model:mbsdk,cpu"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_NAME = f\"{APP_NAME}-{TIMESTAMP}\"\n",
    "\n",
    "TRAFFIC_SPLIT = {\"0\": 100}\n",
    "\n",
    "MIN_NODES = 1\n",
    "MAX_NODES = 1\n",
    "\n",
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name=DEPLOYED_NAME,\n",
    "    traffic_split=TRAFFIC_SPLIT,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    min_replica_count=MIN_NODES,\n",
    "    max_replica_count=MAX_NODES,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "predict_request:mbsdk,custom,lcn"
   },
   "source": [
    "### 进行预测\n",
    "\n",
    "现在您的 `Model` 资源已部署到 `Endpoint` 资源上，您可以通过向 `Endpoint` 资源发送预测请求来进行在线预测。\n",
    "\n",
    "#### 请求\n",
    "\n",
    "每个实例的格式为：\n",
    "\n",
    "    [feature_list]\n",
    "\n",
    "由于 predict() 方法可以接受多个项目（实例），请将您的单个测试项目作为一个测试项目列表发送。\n",
    "\n",
    "#### 响应\n",
    "\n",
    "从 predict() 调用的响应是一个带有以下条目的Python字典：\n",
    "\n",
    "- `ids`: 每个预测请求的内部分配的唯一标识符。\n",
    "- `predictions`: 每个类别标签的预测置信度，介于 0 到 1 之间。\n",
    "- `deployed_model_id`: 执行预测的部署了 `Model` 资源的 Vertex AI 标识符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "predict_request:mbsdk,custom,lcn"
   },
   "outputs": [],
   "source": [
    "instances_list = INSTANCES\n",
    "\n",
    "prediction = endpoint.predict(instances_list)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "source": [
    "## 撤销模型\n",
    "\n",
    "当你完成了预测工作后，你可以从`Endpoint`资源中撤销模型。这将取消所有计算资源并终止已部署模型的计费。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gar_delete_repo"
   },
   "source": [
    "删除您的私人Docker仓库\n",
    "\n",
    "最后，当您的私人仓库变得过时时，请使用命令`gcloud artifacts repositories delete`在`Google Artifact Registry`中将其删除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gar_delete_repo"
   },
   "outputs": [],
   "source": [
    "! gcloud artifacts repositories delete {PRIVATE_REPO} --location={REGION} --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于此教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在此教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "outputs": [],
   "source": [
    "# Delete the model using the Vertex model object\n",
    "try:\n",
    "    model.delete()\n",
    "    endpoint.delete()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "delete_bucket = True\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_vertex_training_lightgbm.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
