{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "# GCP上的端到端ML：MLOps阶段2：实验：开始使用Vertex AI Training进行XGBoost\n",
    "\n",
    "<table align=\"left\">\n",
    "    <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training_xgboost.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "    \n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_training_xgboost.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage2/get_started_vertex_training_xgboost.ipynb\">\n",
    "    <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:mlops"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了在谷歌云上使用Vertex AI进行端到端MLOps生产过程。本教程涵盖了阶段2：实验：开始使用Vertex AI训练XGBoost模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:mlops,stage2,get_started_vertex_training_xgboost"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用 `Vertex AI Training` 来训练一个 XGBoost 自定义模型。\n",
    "\n",
    "本教程使用以下 Google Cloud ML 服务：\n",
    "\n",
    "- `Vertex AI Training`\n",
    "- `Vertex AI Model` 资源\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 使用 Python 软件包进行训练。\n",
    "- 在超参数调整时报告准确性。\n",
    "- 使用 GCSFuse 将模型工件保存到云存储中。\n",
    "- 创建一个 `Vertex AI Model` 资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:iris,lcn"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是来自[TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview)的[Iris数据集](https://www.tensorflow.org/datasets/catalog/iris)。这个数据集不需要任何特征工程。本教程中使用的数据集版本存储在一个公共的云存储桶中。训练好的模型可以预测三个种类中的一个：山鸢尾、维吉尼亚鸢尾或者变色鸢尾。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fc0ad661ebb"
   },
   "source": [
    "###成本\n",
    "\n",
    "本教程使用 Google Cloud 的计费组件:\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解有关 [Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing) 和[Cloud Storage 价格](https://cloud.google.com/storage/pricing) 的信息，并使用 [定价计算器](https://cloud.google.com/products/calculator/) 根据您预期的使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_mlops"
   },
   "source": [
    "安装以下软件包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncRJ_Dfdox9L"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "! pip3 install --upgrade google-cloud-aiplatform $USER_FLAG -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQhwq1iozAxh"
   },
   "source": [
    "### 重新启动内核\n",
    "\n",
    "在安装了额外的软件包之后，您需要重新启动笔记本内核，以便它能够找到这些软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zo3YFZXLzCRJ"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2721ef0202d9"
   },
   "source": [
    "## 在开始之前\n",
    "\n",
    "### 设置您的谷歌云项目\n",
    "\n",
    "**无论您使用的是什么笔记本环境都需要执行以下步骤。**\n",
    "\n",
    "1. [选择或创建一个谷歌云项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建帐户时，您将获得$300的免费信用用于计算/存储成本。\n",
    "\n",
    "2. [确保您的项目已启用计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "3. [启用 Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。\n",
    "\n",
    "4. 如果您在本地运行此笔记本，您需要安装[Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "5. 在下面的单元格中输入您的项目ID。然后运行该单元格，以确保Cloud SDK在本笔记本中的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter将以`!`为前缀的行作为shell命令运行，并将以`$`为前缀的Python变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id"
   },
   "source": [
    "设置您的项目 ID\n",
    "\n",
    "**如果您不知道您的项目 ID**，您可以使用 `gcloud` 获取您的项目 ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 区域\n",
    "\n",
    "您也可以更改“REGION”变量，该变量在笔记本的其余部分中使用。以下是Vertex AI支持的区域。我们建议您选择距离您最近的区域。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太地区：`asia-east1`\n",
    "\n",
    "您可能无法在Vertex AI中使用多区域存储桶进行训练。并非所有区域都支持所有Vertex AI服务。\n",
    "\n",
    "了解更多关于[Vertex AI区域](https://cloud.google.com/vertex-ai/docs/general/locations)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKBTnvJpox9P"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type:\"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06571eb4063b"
   },
   "source": [
    "UUID\n",
    "\n",
    "如果您正在进行实时教程会话，您可能正在使用共享的测试账户或项目。为了避免用户在创建的资源之间的名称冲突，您为每个实例会话创建一个uuid，并将其附加到您在本教程中创建的资源的名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e166d927e36"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77c385f0db59"
   },
   "source": [
    "### 验证您的Google Cloud账户\n",
    "\n",
    "**如果您正在使用Vertex AI Workbench笔记本**，则您的环境已经经过验证。请跳过此步骤。\n",
    "\n",
    "**如果您正在使用Colab**，运行下面的单元格，并按提示进行操作以通过oAuth验证您的账户。\n",
    "\n",
    "**否则**，请按照以下步骤操作：\n",
    "\n",
    "在Cloud控制台中，转到[创建服务帐号密钥](https://console.cloud.google.com/apis/credentials/serviceaccountkey)页面。\n",
    "\n",
    "1. **点击创建服务帐号**。\n",
    "\n",
    "2. 在**服务帐号名称**字段中输入一个名称，然后点击**创建**。\n",
    "\n",
    "3. 在**授予这个服务帐号对项目的访问权限**部分，点击角色下拉列表。在过滤框中输入\"Vertex AI\"，并选择**Vertex AI管理员**。在过滤框中输入\"存储对象管理员\"，并选择**存储对象管理员**。\n",
    "\n",
    "4. 点击创建。一个包含您密钥的JSON文件将下载到您的本地环境。\n",
    "\n",
    "5. 在下面的单元格中输入您的服务帐号密钥路径作为GOOGLE_APPLICATION_CREDENTIALS变量，然后运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNc5Bf_NpPTq"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "When you initialize the Vertex AI SDK for Python, you specify a Cloud Storage staging bucket. The staging bucket is where all the data associated with your dataset and model resources are retained across sessions.\n",
    "\n",
    "Set the name of your Cloud Storage bucket below. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"[your-bucket-name]\":\n",
    "    BUCKET_NAME = PROJECT_ID + \"aip-\" + UUID\n",
    "    BUCKET_URI = \"gs://\" + BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有当您的存储桶尚不存在时：运行以下单元格来创建您的云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aO4sKJfFox9R"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "最后，通过检查其内容来验证对您的云存储桶的访问权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWnghzKFox9S"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。\n",
    "导入库并定义常量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "### 初始化 Vertex AI Python SDK\n",
    "\n",
    "为您的项目和对应的存储桶初始化 Vertex AI Python SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZg2sszQox9T"
   },
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "source": [
    "设置硬件加速器\n",
    "\n",
    "您可以为训练和预测设置硬件加速器。\n",
    "\n",
    "将变量`TRAIN_GPU/TRAIN_NGPU`和`DEPLOY_GPU/DEPLOY_NGPU`设置为使用支持GPU的容器映像以及分配给虚拟机（VM）实例的GPU数量。例如，要使用一个带有4个 Nvidia Telsa K80 GPU 的容器映像分配给每个 VM，您可以指定：\n",
    "\n",
    "（aip.AcceleratorType.NVIDIA_TESLA_K80, 4）\n",
    "\n",
    "否则，指定`(None, None)`来使用一个用于在CPU上运行的容器映像。\n",
    "\n",
    "了解有关您所在地区的[硬件加速器支持](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)。\n",
    "\n",
    "*注意*：用于 GPU 支持的 TF 2.3 之前的版本将无法在本教程中加载自定义模型。这是一个已知问题，在 TF 2.3 中已修复。这是由于在服务功能中生成的静态图操作引起的。如果在您自己的自定义模型上遇到此问题，请使用具有 GPU 支持的 TF 2.3 容器映像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQUrG4Mbox9T"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"IS_TESTING_TRAIN_GPU\"):\n",
    "    TRAIN_GPU, TRAIN_NGPU = (\n",
    "        aip.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "        int(os.getenv(\"IS_TESTING_TRAIN_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    TRAIN_GPU, TRAIN_NGPU = (None, None)\n",
    "\n",
    "if os.getenv(\"IS_TESTING_DEPLOY_GPU\"):\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (\n",
    "        aip.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "        int(os.getenv(\"IS_TESTING_DEPLOY_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction,xgboost"
   },
   "source": [
    "将预先构建的Docker容器映像设置为用于训练和预测。\n",
    "\n",
    "有关最新列表，请参阅[用于训练的预构建容器](https://cloud.google.com/ai-platform-unified/docs/training/pre-built-containers)。\n",
    "\n",
    "有关最新列表，请参阅[用于预测的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XujRA5ueox9U"
   },
   "outputs": [],
   "source": [
    "TRAIN_VERSION = \"xgboost-cpu.1-1\"\n",
    "DEPLOY_VERSION = \"xgboost-cpu.1-1\"\n",
    "\n",
    "TRAIN_IMAGE = \"{}-docker.pkg.dev/vertex-ai/training/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], TRAIN_VERSION\n",
    ")\n",
    "DEPLOY_IMAGE = \"{}-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], DEPLOY_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于训练的机器类型。\n",
    "\n",
    "- 设置变量`TRAIN_COMPUTE`来配置用于训练的VM的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`：每个vCPU 3.75GB内存。\n",
    "     - `n1-highmem`：每个vCPU 6.5GB内存。\n",
    "     - `n1-highcpu`：每个vCPU 0.9GB内存。\n",
    " - `vCPUs`：数量为\\[2, 4, 8, 16, 32, 64, 96\\]\n",
    "\n",
    "*注意：以下不支持用于训练：*\n",
    "\n",
    " - `standard`：2个vCPUs\n",
    " - `highcpu`：2、4和8个vCPUs\n",
    "\n",
    "*注意：您也可以使用n2和e2机器类型进行训练和部署，但它们不支持GPU。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMPFgENkox9U"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TRAIN_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_TRAIN_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgboost_intro"
   },
   "source": [
    "## XGBoost训练简介\n",
    "\n",
    "一旦您训练了一个XGBoost模型，您会希望将其保存在云存储位置，以便随后上传到`Vertex AI Model`资源。 XGBoost软件包不支持将模型保存到云存储位置。相反，您将按照以下步骤保存到云存储位置。\n",
    "\n",
    "1. 将内存中的模型保存到本地文件系统（例如，model.bst）。\n",
    "2. 使用gsutil将本地副本复制到指定的云存储位置。\n",
    "\n",
    "*注意*：您可以对XGBoost模型进行超参数调整。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_training_package:xgboost"
   },
   "source": [
    "### 检查培训包\n",
    "\n",
    "#### 包布局\n",
    "\n",
    "在开始培训之前，您将查看Python包是如何为自定义培训任务组装的。当解压缩后，包含以下目录/文件布局的包。\n",
    "\n",
    "- PKG-INFO\n",
    "- README.md\n",
    "- setup.cfg\n",
    "- setup.py\n",
    "- trainer\n",
    "  - \\_\\_init\\_\\_.py\n",
    "  - task.py\n",
    "\n",
    "文件`setup.cfg`和`setup.py`是安装包到Docker镜像的操作环境的指令。\n",
    "\n",
    "文件`trainer/task.py`是执行自定义培训任务的Python脚本。*注意*，当我们在工作池规范中引用它时，我们会用点(`trainer.task`)替换目录斜杠，并且去掉文件后缀(`.py`)。\n",
    "\n",
    "#### 包装配\n",
    "\n",
    "在接下来的单元格中，您将组装培训包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4wS4eISox9V"
   },
   "outputs": [],
   "source": [
    "# Make folder for Python training script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\nsetuptools.setup(\\n\\n    install_requires=[\\n\\n        'cloudml-hypertune',\\n\\n    ],\\n\\n    packages=setuptools.find_packages())\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\nName: Iris tabular classification\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taskpy_contents:iris,xgboost"
   },
   "source": [
    "### 为Python训练包创建任务脚本\n",
    "\n",
    "接下来，您可以为驱动训练包创建`task.py`脚本。一些值得注意的步骤包括：\n",
    "\n",
    "- 命令行参数：\n",
    "    - `model-dir`：保存训练模型的位置。在使用Vertex AI自定义训练时，位置将在环境变量中指定为`AIP_MODEL_DIR`，\n",
    "    - `dataset_data_url`：要下载的训练数据的位置。\n",
    "    - `dataset_labels_url`：要下载的训练标签的位置。\n",
    "    - `boost-rounds`：可调参数\n",
    "- 数据预处理（`get_data()`）：\n",
    "    - 下载数据集并拆分为训练集和测试集。\n",
    "- 训练（`train_model()`）：\n",
    "    - 训练模型\n",
    "- 评估（`evaluate_model()`）：\n",
    "    - 评估模型。\n",
    "    - 如果进行超参数调优，报告准确率指标。\n",
    "- 模型工件保存\n",
    "    - 将模型工件和评估指标保存在由`model-dir`指定的云存储位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiSnFuDoox9W"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import hypertune\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model-dir', dest='model_dir',\n",
    "                    default=os.getenv('AIP_MODEL_DIR'), type=str, help='Model dir.')\n",
    "parser.add_argument(\"--dataset-data-url\", dest=\"dataset_data_url\",\n",
    "                    type=str, help=\"Download url for the training data.\")\n",
    "parser.add_argument(\"--dataset-labels-url\", dest=\"dataset_labels_url\",\n",
    "                    type=str, help=\"Download url for the training data labels.\")\n",
    "parser.add_argument(\"--boost-rounds\", dest=\"boost_rounds\",\n",
    "                    default=20, type=int, help=\"Number of boosted rounds\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "def get_data():\n",
    "    logging.info(\"Downloading training data and labelsfrom: {}, {}\".format(args.dataset_data_url, args.dataset_labels_url))\n",
    "    # gsutil outputs everything to stderr so we need to divert it to stdout.\n",
    "    subprocess.check_call(['gsutil', 'cp', args.dataset_data_url, 'data.csv'], stderr=sys.stdout)\n",
    "    # gsutil outputs everything to stderr so we need to divert it to stdout.\n",
    "    subprocess.check_call(['gsutil', 'cp', args.dataset_labels_url, 'labels.csv'], stderr=sys.stdout)\n",
    "\n",
    "\n",
    "    # Load data into pandas, then use `.values` to get NumPy arrays\n",
    "    data = pd.read_csv('data.csv').values\n",
    "    labels = pd.read_csv('labels.csv').values\n",
    "\n",
    "    # Convert one-column 2D array into 1D array for use with XGBoost\n",
    "    labels = labels.reshape((labels.size,))\n",
    "\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=7)\n",
    "\n",
    "    # Load data into DMatrix object\n",
    "    dtrain = xgb.DMatrix(train_data, label=train_labels)\n",
    "    return dtrain, test_data, test_labels\n",
    "\n",
    "def train_model(dtrain):\n",
    "    logging.info(\"Start training ...\")\n",
    "    # Train XGBoost model\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 3\n",
    "    }\n",
    "    model = xgb.train(params, dtrain, num_boost_round=args.boost_rounds)\n",
    "    logging.info(\"Training completed\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_data, test_labels):\n",
    "    dtest = xgb.DMatrix(test_data)\n",
    "    pred = model.predict(dtest)\n",
    "    predictions = [np.around(value) for value in pred]\n",
    "    # evaluate predictions\n",
    "    try:\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "    except:\n",
    "        accuracy = 0.0\n",
    "    logging.info(f\"Evaluation completed with model accuracy: {accuracy}\")\n",
    "\n",
    "    # report metric for hyperparameter tuning\n",
    "    hpt = hypertune.HyperTune()\n",
    "    hpt.report_hyperparameter_tuning_metric(\n",
    "        hyperparameter_metric_tag='accuracy',\n",
    "        metric_value=accuracy\n",
    "    )\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "dtrain, test_data, test_labels = get_data()\n",
    "model = train_model(dtrain)\n",
    "accuracy = evaluate_model(model, test_data, test_labels)\n",
    "\n",
    "# GCSFuse conversion\n",
    "gs_prefix = 'gs://'\n",
    "gcsfuse_prefix = '/gcs/'\n",
    "if args.model_dir.startswith(gs_prefix):\n",
    "    args.model_dir = args.model_dir.replace(gs_prefix, gcsfuse_prefix)\n",
    "    dirpath = os.path.split(args.model_dir)[0]\n",
    "    if not os.path.isdir(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "# Export the classifier to a file\n",
    "gcs_model_path = os.path.join(args.model_dir, 'model.bst')\n",
    "logging.info(\"Saving model artifacts to {}\". format(gcs_model_path))\n",
    "model.save_model(gcs_model_path)\n",
    "\n",
    "logging.info(\"Saving metrics to {}/metrics.json\". format(args.model_dir))\n",
    "gcs_metrics_path = os.path.join(args.model_dir, 'metrics.json')\n",
    "with open(gcs_metrics_path, \"w\") as f:\n",
    "    f.write(f\"{'accuracy: {accuracy}'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tarball_training_script"
   },
   "source": [
    "将培训脚本存储在您的云存储桶中\n",
    "\n",
    "接下来，您将培训文件夹打包成一个压缩的tar文件，并将其存储在您的云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnmdycf6ox9X"
   },
   "outputs": [],
   "source": [
    "! rm -f custom.tar custom.tar.gz\n",
    "! tar cvf custom.tar custom\n",
    "! gzip custom.tar\n",
    "! gsutil cp custom.tar.gz $BUCKET_URI/trainer_iris.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_pp_training_job:mbsdk"
   },
   "source": [
    "### 创建并运行自定义训练任务\n",
    "\n",
    "要训练一个自定义模型，您需要执行两个步骤：1) 创建一个自定义训练任务，2) 运行这个任务。\n",
    "\n",
    "#### 创建自定义训练任务\n",
    "\n",
    "使用 `CustomTrainingJob` 类创建一个自定义训练任务，需要以下参数：\n",
    "\n",
    "- `display_name`：自定义训练任务的可读名称。\n",
    "- `container_uri`：训练容器镜像。\n",
    "\n",
    "- `python_package_gcs_uri`：Python训练包的位置，以tarball形式。\n",
    "- `python_module_name`：Python包中训练脚本的相对路径。\n",
    "- `model_serving_container_uri`：用于部署模型的容器镜像。\n",
    "\n",
    "*注意：* 没有`requirements`参数。您可以在Python包的`setup.py`脚本中指定任何依赖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVEMz1xqox9X"
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"iris_\" + UUID\n",
    "\n",
    "job = aip.CustomPythonPackageTrainingJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    python_package_gcs_uri=f\"{BUCKET_URI}/trainer_iris.tar.gz\",\n",
    "    python_module_name=\"trainer.task\",\n",
    "    container_uri=TRAIN_IMAGE,\n",
    "    model_serving_container_image_uri=DEPLOY_IMAGE,\n",
    "    project=PROJECT_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prepare_custom_cmdargs:iris,xgboost"
   },
   "source": [
    "### 准备您的命令行参数\n",
    "\n",
    "现在为您自定义训练容器定义命令行参数：\n",
    "\n",
    "- `args`：传递给设置为容器入口点的可执行文件的命令行参数。\n",
    "  - `--model-dir`：对于我们的演示，我们使用这个命令行参数来指定存储模型工件的位置。\n",
    "      - 直接：您将云存储位置作为命令行参数传递给您的训练脚本（设置变量`DIRECT = True`），或者\n",
    "      - 间接：服务将云存储位置作为环境变量`AIP_MODEL_DIR`传递给您的训练脚本（设置变量`DIRECT = False`）。在这种情况下，您需要在作业规范中告诉服务模型工件的位置。\n",
    "  - `--dataset-data-url`：要下载的训练数据的位置。\n",
    "  - `--dataset-labels-url`：要下载的训练标签的位置。\n",
    "  - `--boost-rounds`：可调节的超参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AoUfpBqVox9Y"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = \"{}/{}\".format(BUCKET_URI, UUID)\n",
    "DATASET_DIR = \"gs://cloud-samples-data/ai-platform/iris\"\n",
    "\n",
    "ROUNDS = 20\n",
    "\n",
    "DIRECT = False\n",
    "if DIRECT:\n",
    "    CMDARGS = [\n",
    "        \"--dataset-data-url=\" + DATASET_DIR + \"/iris_data.csv\",\n",
    "        \"--dataset-labels-url=\" + DATASET_DIR + \"/iris_target.csv\",\n",
    "        \"--boost-rounds=\" + str(ROUNDS),\n",
    "        \"--model_dir=\" + MODEL_DIR,\n",
    "    ]\n",
    "else:\n",
    "    CMDARGS = [\n",
    "        \"--dataset-data-url=\" + DATASET_DIR + \"/iris_data.csv\",\n",
    "        \"--dataset-labels-url=\" + DATASET_DIR + \"/iris_target.csv\",\n",
    "        \"--boost-rounds=\" + str(ROUNDS),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_custom_job:mbsdk"
   },
   "source": [
    "#### 运行自定义训练作业\n",
    "\n",
    "接下来，您可以通过调用 `run` 方法来运行自定义作业，以启动训练作业，并使用以下参数：\n",
    "\n",
    "- `model_display_name`：`Model` 资源的可读名称。\n",
    "- `args`：传递到训练脚本的命令行参数。\n",
    "- `replica_count`：用于训练的计算实例数量（replica_count = 1 是单节点训练）。\n",
    "- `machine_type`：计算实例的机器类型。\n",
    "- `accelerator_type`：硬件加速器类型。\n",
    "- `accelerator_count`：要附加到工作器复制品的加速器数量。\n",
    "- `base_output_dir`：将模型工件写入的 Cloud Storage 位置。\n",
    "- `sync`：是否阻塞直到作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCruQq1aox9Y"
   },
   "outputs": [],
   "source": [
    "if TRAIN_GPU:\n",
    "    model = job.run(\n",
    "        model_display_name=\"iris_\" + UUID,\n",
    "        args=CMDARGS,\n",
    "        replica_count=1,\n",
    "        machine_type=TRAIN_COMPUTE,\n",
    "        accelerator_type=TRAIN_GPU.name,\n",
    "        accelerator_count=TRAIN_NGPU,\n",
    "        base_output_dir=MODEL_DIR,\n",
    "        sync=False,\n",
    "    )\n",
    "else:\n",
    "    model = job.run(\n",
    "        model_display_name=\"iris_\" + UUID,\n",
    "        args=CMDARGS,\n",
    "        replica_count=1,\n",
    "        machine_type=TRAIN_COMPUTE,\n",
    "        base_output_dir=MODEL_DIR,\n",
    "        sync=False,\n",
    "    )\n",
    "\n",
    "model_path_to_deploy = MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "list_job"
   },
   "source": [
    "### 列出一个自定义培训任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBM_KLMSox9Y"
   },
   "outputs": [],
   "source": [
    "_job = job.list(filter=f\"display_name={DISPLAY_NAME}\")\n",
    "print(_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "custom_job_wait:mbsdk"
   },
   "source": [
    "等待自定义训练作业完成\n",
    "\n",
    "接下来，等待自定义训练作业完成。或者，可以在`run()`方法中将参数`sync`设置为`True`，以阻塞直到自定义训练作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHPMHbSyox9Z"
   },
   "outputs": [],
   "source": [
    "model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "delete_job"
   },
   "source": [
    "删除自定义训练作业\n",
    "\n",
    "在训练作业完成后，您可以使用`delete()`方法删除训练作业。在完成之前，训练作业可以使用`cancel()`方法取消。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlYg7Sp-ox9Z"
   },
   "outputs": [],
   "source": [
    "job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "# 清理工作\n",
    "\n",
    "要清理此项目中使用的所有 Google Cloud 资源，您可以 [删除用于本教程的 Google Cloud 项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的单个资源：\n",
    "\n",
    "- 自定义作业（在上一步中删除了自定义训练作业）\n",
    "- 云存储桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyWy23gDox9a"
   },
   "outputs": [],
   "source": [
    "delete_bucket = True\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_vertex_training_xgboost.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
