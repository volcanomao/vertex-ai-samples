{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "在GCP上进行端到端机器学习：MLOps阶段2：实验：使用Vertex AI超参数调整开始使用XGBoost\n",
    "\n",
    "<table align=\"left\">\n",
    "    <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_hpt_xgboost.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "    \n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage2/get_started_vertex_hpt_xgboost.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage2/get_started_vertex_hpt_xgboost.ipynb\">\n",
    "    <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:mlops"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何在Google Cloud上使用Vertex AI进行端到端的MLOps生产操作。本教程涵盖了阶段2：实验：使用Vertex AI超参数调整来开始使用XGBoost。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:mlops,stage2,get_started_vertex_training_xgboost"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用 `Vertex AI 超参数调整` 来训练一个 XGBoost 自定义模型。\n",
    "\n",
    "本教程使用以下谷歌云机器学习服务：\n",
    "\n",
    "- `Vertex AI 训练`\n",
    "- `Vertex AI 超参数调整`\n",
    "- `Vertex AI Vizier`\n",
    "- `Vertex AI 模型` 资源\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 使用 Python 包进行训练。\n",
    "- 在超参数调整时报告准确性。\n",
    "- 使用 GCSFuse 将模型工件保存到云存储。\n",
    "- 创建一个 `Vertex AI 模型` 资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:iris,lcn"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "此教程使用的数据集是来自[TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview)的[Iris数据集](https://www.tensorflow.org/datasets/catalog/iris)。该数据集不需要任何特征工程。本教程中的数据集版本存储在一个公共云存储桶中。训练好的模型可以预测三种Iris花的类型：山鸢尾、杂色鸢尾或者维吉尼亚鸢尾。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fc0ad661ebb"
   },
   "source": [
    "### 成本\n",
    "\n",
    "本教程使用 Google Cloud 的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* 云存储\n",
    "\n",
    "了解 [Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing) 和 [云存储价格](https://cloud.google.com/storage/pricing)，并使用 [价格计算器](https://cloud.google.com/products/calculator/) 根据您预计的使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_mlops"
   },
   "source": [
    "安装以下软件包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncRJ_Dfdox9L"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "! pip3 install --upgrade google-cloud-aiplatform $USER_FLAG -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "重新启动内核\n",
    "\n",
    "一旦您安装了额外的软件包，您需要重新启动笔记本内核，这样它可以找到这些软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "restart"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2721ef0202d9"
   },
   "source": [
    "##开始之前\n",
    "\n",
    "###设置您的Google Cloud项目\n",
    "\n",
    "**以下步骤是必需的，无论您使用的笔记本环境是什么。**\n",
    "\n",
    "1. [选择或创建一个Google Cloud项目](https://console.cloud.google.com/cloud-resource-manager)。当您第一次创建帐户时，您将获得$300的免费信用额度，可用于计算/存储成本。\n",
    "\n",
    "1. [确保为您的项目启用了计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "1. [启用Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。\n",
    "\n",
    "1. 如果您是在本地运行此笔记本，您需要安装[Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "1. 在下面的单元格中输入您的项目ID。然后运行单元格，确保Cloud SDK在本笔记本中的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter将以`!`为前缀的行视为shell命令，并将以`$`为前缀的Python变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用`gcloud`来获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 地区\n",
    "\n",
    "您也可以更改`REGION`变量，该变量用于本笔记本其余部分的操作。以下是Vertex AI支持的地区。我们建议您选择离您最近的地区。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太地区：`asia-east1`\n",
    "\n",
    "不能使用多区域存储桶来训练Vertex AI。并非所有地区都支持所有Vertex AI服务。\n",
    "\n",
    "了解更多关于[Vertex AI地区](https://cloud.google.com/vertex-ai/docs/general/locations)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKBTnvJpox9P"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type:\"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "时间戳\n",
    "\n",
    "如果您正在进行实时教程会话，您可能正在使用共享测试帐户或项目。为了避免用户在创建的资源之间发生名称冲突，您需要为每个实例会话创建一个时间戳，并将时间戳附加到您在本教程中创建的资源名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYtXOocrox9Q"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77c385f0db59"
   },
   "source": [
    "### 认证您的 Google Cloud 账户\n",
    "\n",
    "**如果您正在使用 Vertex AI Workbench 笔记本**，您的环境已经经过身份验证。请跳过此步骤。\n",
    "\n",
    "**如果您正在使用 Colab**，运行下面的单元格，并按照提示进行身份验证。\n",
    "\n",
    "**否则**，请按照以下步骤操作：\n",
    "\n",
    "在 Cloud 控制台中，转到 [创建服务帐号密钥](https://console.cloud.google.com/apis/credentials/serviceaccountkey) 页面。\n",
    "\n",
    "1. **单击创建服务帐号**。\n",
    "\n",
    "2. 在 **服务帐号名称** 栏中输入一个名称，然后单击 **创建**。\n",
    "\n",
    "3. 在 **将此服务帐号授予项目访问权限** 部分，单击角色下拉列表。在筛选框中输入 \"Vertex AI\"，然后选择 **Vertex AI 管理员**。在筛选框中输入 \"Storage Object Admin\"，然后选择 **Storage Object Admin**。\n",
    "\n",
    "4. 单击创建。包含您的密钥的 JSON 文件将下载到您的本地环境中。\n",
    "\n",
    "5. 在下面的单元格中将您的服务帐号密钥路径输入为 GOOGLE_APPLICATION_CREDENTIALS 变量，并运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNc5Bf_NpPTq"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "**无论您使用的笔记本环境如何，以下步骤都是必需的。**\n",
    "\n",
    "当您为Python初始化Vertex AI SDK时，您需要指定一个云存储临时桶。临时桶是您的数据集和模型资源关联的所有数据在会话之间保留的地方。\n",
    "\n",
    "在下面设置您的云存储桶的名称。存储桶的名称必须在所有Google Cloud项目中是全局唯一的，包括您的组织之外的项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"[your-bucket-name]\":\n",
    "    BUCKET_NAME = PROJECT_ID + \"aip-\" + TIMESTAMP\n",
    "    BUCKET_URI = \"gs://\" + BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有你的存储桶不存在时：运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aO4sKJfFox9R"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "最后，通过检查云存储桶的内容来验证对其的访问权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWnghzKFox9S"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。\n",
    "### 导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "### 初始化 Python 的 Vertex AI SDK\n",
    "\n",
    "为您的项目和相应的存储桶初始化 Python 的 Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZg2sszQox9T"
   },
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "source": [
    "#### 设置硬件加速器\n",
    "\n",
    "您可以为训练和预测设置硬件加速器。\n",
    "\n",
    "将变量`TRAIN_GPU/TRAIN_NGPU`和`DEPLOY_GPU/DEPLOY_NGPU`设置为使用支持GPU的容器映像以及分配给虚拟机（VM）实例的GPU数量。例如，要使用一个带有4个Nvidia Telsa K80 GPU分配给每个VM的GPU容器映像，您可以指定：\n",
    "\n",
    "    （aip.AcceleratorType.NVIDIA_TESLA_K80, 4）\n",
    "\n",
    "否则，指定（None，None）以使用一个在CPU上运行的容器映像。\n",
    "\n",
    "了解有关您区域的[硬件加速器支持的更多信息](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)。\n",
    "\n",
    "*注意*：在2.3之前的TF版本中，GPU支持将无法在本教程中加载自定义模型。这是一个已知问题，在TF 2.3中已修复。这是由于在serving函数中生成的静态图操作而引起的。如果您在自己的自定义模型上遇到此问题，请使用带有GPU支持的TF 2.3的容器映像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQUrG4Mbox9T"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"IS_TESTING_TRAIN_GPU\"):\n",
    "    TRAIN_GPU, TRAIN_NGPU = (\n",
    "        aip.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "        int(os.getenv(\"IS_TESTING_TRAIN_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    TRAIN_GPU, TRAIN_NGPU = (None, None)\n",
    "\n",
    "if os.getenv(\"IS_TESTING_DEPLOY_GPU\"):\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (\n",
    "        aip.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "        int(os.getenv(\"IS_TESTING_DEPLOY_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction,xgboost"
   },
   "source": [
    "设置预构建的容器\n",
    "\n",
    "为训练和预测设置预构建的Docker容器镜像。\n",
    "\n",
    "有关最新列表，请参阅[用于训练的预构建容器](https://cloud.google.com/ai-platform-unified/docs/training/pre-built-containers)。\n",
    "\n",
    "有关最新列表，请参阅[用于预测的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XujRA5ueox9U"
   },
   "outputs": [],
   "source": [
    "TRAIN_VERSION = \"xgboost-cpu.1-1\"\n",
    "DEPLOY_VERSION = \"xgboost-cpu.1-1\"\n",
    "\n",
    "TRAIN_IMAGE = \"{}-docker.pkg.dev/vertex-ai/training/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], TRAIN_VERSION\n",
    ")\n",
    "DEPLOY_IMAGE = \"{}-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], DEPLOY_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于训练的机器类型。\n",
    "\n",
    "- 设置变量 `TRAIN_COMPUTE` 来配置您将用于训练的虚拟机的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`: 每个vCPU 3.75GB的内存。\n",
    "     - `n1-highmem`: 每个vCPU 6.5GB的内存\n",
    "     - `n1-highcpu`: 每个vCPU 0.9GB的内存\n",
    " - `vCPUs`: 数量为 \\[2, 4, 8, 16, 32, 64, 96 \\]\n",
    "\n",
    "*注意: 以下机器类型不支持用于训练:*\n",
    "\n",
    " - `standard`: 2个vCPUs\n",
    " - `highcpu`: 2, 4和8个vCPUs\n",
    "\n",
    "*注意: 您也可以使用n2和e2机器类型进行训练和部署，但它们不支持GPU。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMPFgENkox9U"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TRAIN_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_TRAIN_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgboost_intro"
   },
   "source": [
    "## XGBoost 训练简介\n",
    "\n",
    "一旦您训练了一个 XGBoost 模型，您会希望将其保存在云存储位置，以便随后可以上传到 `Vertex AI Model` 资源。\n",
    "XGBoost 包不支持将模型保存到云存储位置。相反，您将执行以下步骤将其保存到云存储位置。\n",
    "\n",
    "1. 将内存中的模型保存到本地文件系统（例如，model.bst）。\n",
    "2. 使用 gsutil 将本地副本复制到指定的云存储位置。\n",
    "\n",
    "## Vertex AI 超参数调优服务\n",
    "\n",
    "以下示例演示了如何使用 Vertex AI 超参数调优服务和 `Vizier` 搜索算法来设置、执行和评估试验。\n",
    "\n",
    "了解更多关于[超参数调优概述](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_training_package:xgboost"
   },
   "source": [
    "### 检查培训包\n",
    "\n",
    "#### 包布局\n",
    "\n",
    "在开始培训之前，您将查看如何为自定义培训任务组装 Python 包。解压缩后，包含以下目录/文件布局的包。\n",
    "\n",
    "- PKG-INFO\n",
    "- README.md\n",
    "- setup.cfg\n",
    "- setup.py\n",
    "- trainer\n",
    "  - \\_\\_init\\_\\_.py\n",
    "  - task.py\n",
    "\n",
    "文件 `setup.cfg` 和 `setup.py` 是将包安装到 Docker 镜像的操作环境中的指令。\n",
    "\n",
    "文件 `trainer/task.py` 是执行自定义培训任务的 Python 脚本。*请注意*，当我们在工作池规范中提到它时，我们将目录斜杠替换为点(`trainer.task`)，并且去掉文件后缀(`.py`)。\n",
    "\n",
    "#### 包装配\n",
    "\n",
    "在下面的单元格中，您将组装培训包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4wS4eISox9V"
   },
   "outputs": [],
   "source": [
    "# Make folder for Python training script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\nsetuptools.setup(\\n\\n    install_requires=[\\n\\n        'cloudml-hypertune',\\n\\n    ],\\n\\n    packages=setuptools.find_packages())\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\nName: Iris tabular classification\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taskpy_contents:iris,xgboost"
   },
   "source": [
    "### 为Python培训包创建任务脚本\n",
    "\n",
    "接下来，您将为驱动培训包的`task.py`脚本。一些值得注意的步骤包括：\n",
    "\n",
    "- 命令行参数：\n",
    "    - `model-dir`：保存训练模型的位置。在使用Vertex AI自定义训练时，位置将在环境变量`AIP_MODEL_DIR`中指定。\n",
    "    - `dataset_data_url`：要下载的训练数据的位置。\n",
    "    - `dataset_labels_url`：要下载的训练标签的位置。\n",
    "    - `boost-rounds`：可调参数。\n",
    "- 数据预处理（`get_data()`）：\n",
    "    - 下载数据集并拆分为训练集和测试集。\n",
    "- 训练（`train_model()`）：\n",
    "    - 训练模型。\n",
    "- 评估（`evaluate_model()`）：\n",
    "    - 评估模型。\n",
    "    - 如果进行超参数调整，则报告准确度指标。\n",
    "- 模型工件保存\n",
    "    - 将模型工件和评估指标保存在由`model-dir`指定的云存储位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiSnFuDoox9W"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import hypertune\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model-dir', dest='model_dir',\n",
    "                    default=os.getenv('AIP_MODEL_DIR'), type=str, help='Model dir.')\n",
    "parser.add_argument(\"--dataset-data-url\", dest=\"dataset_data_url\",\n",
    "                    type=str, help=\"Download url for the training data.\")\n",
    "parser.add_argument(\"--dataset-labels-url\", dest=\"dataset_labels_url\",\n",
    "                    type=str, help=\"Download url for the training data labels.\")\n",
    "parser.add_argument(\"--boost-rounds\", dest=\"boost_rounds\",\n",
    "                    default=20, type=int, help=\"Number of boosted rounds\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "def get_data():\n",
    "    logging.info(\"Downloading training data and labelsfrom: {}, {}\".format(args.dataset_data_url, args.dataset_labels_url))\n",
    "    # gsutil outputs everything to stderr so we need to divert it to stdout.\n",
    "    subprocess.check_call(['gsutil', 'cp', args.dataset_data_url, 'data.csv'], stderr=sys.stdout)\n",
    "    # gsutil outputs everything to stderr so we need to divert it to stdout.\n",
    "    subprocess.check_call(['gsutil', 'cp', args.dataset_labels_url, 'labels.csv'], stderr=sys.stdout)\n",
    "\n",
    "\n",
    "    # Load data into pandas, then use `.values` to get NumPy arrays\n",
    "    data = pd.read_csv('data.csv').values\n",
    "    labels = pd.read_csv('labels.csv').values\n",
    "\n",
    "    # Convert one-column 2D array into 1D array for use with XGBoost\n",
    "    labels = labels.reshape((labels.size,))\n",
    "\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=7)\n",
    "\n",
    "    # Load data into DMatrix object\n",
    "    dtrain = xgb.DMatrix(train_data, label=train_labels)\n",
    "    return dtrain, test_data, test_labels\n",
    "\n",
    "def train_model(dtrain):\n",
    "    logging.info(\"Start training ...\")\n",
    "    # Train XGBoost model\n",
    "    model = xgb.train({}, dtrain, num_boost_round=args.boost_rounds)\n",
    "    logging.info(\"Training completed\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_data, test_labels):\n",
    "    dtest = xgb.DMatrix(test_data)\n",
    "    pred = model.predict(dtest)\n",
    "    predictions = [round(value) for value in pred]\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    logging.info(f\"Evaluation completed with model accuracy: {accuracy}\")\n",
    "\n",
    "    # report metric for hyperparameter tuning\n",
    "    hpt = hypertune.HyperTune()\n",
    "    hpt.report_hyperparameter_tuning_metric(\n",
    "        hyperparameter_metric_tag='accuracy',\n",
    "        metric_value=accuracy\n",
    "    )\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "dtrain, test_data, test_labels = get_data()\n",
    "model = train_model(dtrain)\n",
    "accuracy = evaluate_model(model, test_data, test_labels)\n",
    "\n",
    "# GCSFuse conversion\n",
    "gs_prefix = 'gs://'\n",
    "gcsfuse_prefix = '/gcs/'\n",
    "if args.model_dir.startswith(gs_prefix):\n",
    "    args.model_dir = args.model_dir.replace(gs_prefix, gcsfuse_prefix)\n",
    "    dirpath = os.path.split(args.model_dir)[0]\n",
    "    if not os.path.isdir(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "# Export the classifier to a file\n",
    "gcs_model_path = os.path.join(args.model_dir, 'model.bst')\n",
    "logging.info(\"Saving model artifacts to {}\". format(gcs_model_path))\n",
    "model.save_model(gcs_model_path)\n",
    "\n",
    "logging.info(\"Saving metrics to {}/metrics.json\". format(args.model_dir))\n",
    "gcs_metrics_path = os.path.join(args.model_dir, 'metrics.json')\n",
    "with open(gcs_metrics_path, \"w\") as f:\n",
    "    f.write(f\"{'accuracy: {accuracy}'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tarball_training_script"
   },
   "source": [
    "将培训脚本存储在您的云存储桶中。\n",
    "\n",
    "接下来，您将训练文件夹打包成压缩 tar 包，然后将其存储在您的云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnmdycf6ox9X"
   },
   "outputs": [],
   "source": [
    "! rm -f custom.tar custom.tar.gz\n",
    "! tar cvf custom.tar custom\n",
    "! gzip custom.tar\n",
    "! gsutil cp custom.tar.gz $BUCKET_URI/trainer_iris.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_custom_job_machine_specification"
   },
   "source": [
    "### 准备您的机器规格\n",
    "\n",
    "现在为您的自定义超参数调整作业定义机器规格。这告诉 Vertex 需要为超参数调整提供什么类型的机器实例。\n",
    "  - `machine_type`: 要提供的 GCP 实例的类型 - 例如，n1-standard-8。\n",
    "  - `accelerator_type`: （如果有的话）硬件加速器的类型。在本教程中，如果您之前设置变量`TRAIN_GPU != None`，则使用GPU；否则将使用CPU。\n",
    "  - `accelerator_count`: 加速器的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_custom_job_machine_specification"
   },
   "outputs": [],
   "source": [
    "if TRAIN_GPU:\n",
    "    machine_spec = {\n",
    "        \"machine_type\": TRAIN_COMPUTE,\n",
    "        \"accelerator_type\": TRAIN_GPU,\n",
    "        \"accelerator_count\": TRAIN_NGPU,\n",
    "    }\n",
    "else:\n",
    "    machine_spec = {\"machine_type\": TRAIN_COMPUTE, \"accelerator_count\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_custom_job_disk_specification"
   },
   "source": [
    "### 准备您的磁盘规格\n",
    "\n",
    "（可选）现在定义您自定义超参数调整作业的磁盘规格。这将告诉Vertex每台机器实例在超参数调整中要提供的磁盘类型和大小。\n",
    "\n",
    "- `boot_disk_type`：SSD或Standard。SSD速度更快，Standard价格更便宜。默认为SSD。\n",
    "- `boot_disk_size_gb`：磁盘大小，以GB为单位。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_custom_job_disk_specification"
   },
   "outputs": [],
   "source": [
    "DISK_TYPE = \"pd-ssd\"  # [ pd-ssd, pd-standard]\n",
    "DISK_SIZE = 200  # GB\n",
    "\n",
    "disk_spec = {\"boot_disk_type\": DISK_TYPE, \"boot_disk_size_gb\": DISK_SIZE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prepare_custom_cmdargs:iris,xgboost"
   },
   "source": [
    "### 准备命令行参数\n",
    "\n",
    "现在定义自定义训练容器的命令行参数：\n",
    "\n",
    "- `args`：要传递给设置为容器入口点的可执行文件的命令行参数。\n",
    "  - `--model-dir`：对于我们的演示，我们使用此命令行参数来指定存储模型工件的位置。\n",
    "      - 直接：您将云存储位置作为命令行参数传递给训练脚本（设置变量`DIRECT = True`），或\n",
    "      - 间接：服务将云存储位置作为环境变量`AIP_MODEL_DIR`传递给您的训练脚本（设置变量`DIRECT = False`）。 在这种情况下，您需要在作业规范中告诉服务模型工件的位置。\n",
    "  - `--dataset-data-url`：要下载的训练数据的位置。\n",
    "  - `--dataset-labels-url`：要下载的训练标签的位置。\n",
    "  - `--boost-rounds`：可调参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AoUfpBqVox9Y"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = \"{}/aiplatform-custom-job-{}\".format(BUCKET_URI, TIMESTAMP)\n",
    "DATASET_DIR = \"gs://cloud-samples-data/ai-platform/iris\"\n",
    "\n",
    "\n",
    "CMDARGS = [\n",
    "    \"--dataset-data-url=\" + DATASET_DIR + \"/iris_data.csv\",\n",
    "    \"--dataset-labels-url=\" + DATASET_DIR + \"/iris_target.csv\",\n",
    "]\n",
    "\n",
    "worker_pool_spec = [\n",
    "    {\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": machine_spec,\n",
    "        \"disk_spec\": disk_spec,\n",
    "        \"python_package_spec\": {\n",
    "            \"executor_image_uri\": TRAIN_IMAGE,\n",
    "            \"package_uris\": [BUCKET_URI + \"/trainer_iris.tar.gz\"],\n",
    "            \"python_module\": \"trainer.task\",\n",
    "            \"args\": CMDARGS,\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_job:mbsdk"
   },
   "source": [
    "创建自定义作业\n",
    "\n",
    "使用`CustomJob`类创建自定义作业，例如用于超参数调整，具有以下参数：\n",
    "\n",
    "- `display_name`：自定义作业的人类可读的名称。\n",
    "- `worker_pool_specs`：相应虚拟机实例的规范。\n",
    "- `base_output_dir`：用于存储模型工件的Cloud Storage位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_custom_job:mbsdk"
   },
   "outputs": [],
   "source": [
    "job = aip.CustomJob(\n",
    "    display_name=\"iris_\" + TIMESTAMP,\n",
    "    worker_pool_specs=worker_pool_spec,\n",
    "    base_output_dir=MODEL_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_hpt_job:mbsdk"
   },
   "source": [
    "创建一个超参数调整作业\n",
    "\n",
    "使用类`HyperparameterTuningJob`来创建一个超参数调整作业，具有以下参数：\n",
    "\n",
    "- `display_name`：用于自定义作业的人类可读名称。\n",
    "- `custom_job`：此自定义作业中的工作人员池规范适用于所有试验中创建的CustomJobs。\n",
    "- `metrics_spec`：要优化的指标。字典键是指标id，由您的训练作业报告，字典值是该指标的优化目标（'minimize'或'maximize'）。\n",
    "- `parameter_spec`：要优化的参数。字典键是指标id，作为命令行关键字参数传递到您的训练作业中，字典值是指标的参数规范。\n",
    "- `search_algorithm`：要使用的搜索算法：`grid`，`random`和`None`。如果指定了`None`，则使用`Vizier`服务（贝叶斯）。\n",
    "- `max_trial_count`：要执行的最大试验次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_hpt_job:mbsdk"
   },
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "\n",
    "hpt_job = aip.HyperparameterTuningJob(\n",
    "    display_name=\"iris_\" + TIMESTAMP,\n",
    "    custom_job=job,\n",
    "    metric_spec={\n",
    "        \"accuracy\": \"maximize\",\n",
    "    },\n",
    "    parameter_spec={\n",
    "        \"boost-rounds\": hpt.IntegerParameterSpec(min=10, max=100, scale=\"linear\"),\n",
    "    },\n",
    "    search_algorithm=None,\n",
    "    max_trial_count=6,\n",
    "    parallel_trial_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_hpt_job:mbsdk"
   },
   "source": [
    "## Run the hyperparameter tuning job\n",
    "\n",
    "Use the `run()` method to execute the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_hpt_job:mbsdk"
   },
   "outputs": [],
   "source": [
    "hpt_job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpt_trial_results:mbsdk"
   },
   "source": [
    "### 显示超参数调整作业试验结果\n",
    "\n",
    "在超参数调整作业完成后，属性 `trials` 将返回每次试验的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpt_trial_results:mbsdk"
   },
   "outputs": [],
   "source": [
    "print(hpt_job.trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "best_trial:mbsdk"
   },
   "source": [
    "现在看看哪个试验是最好的:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "best_trial:mbsdk"
   },
   "outputs": [],
   "source": [
    "best = (None, None, None, 0.0)\n",
    "for trial in hpt_job.trials:\n",
    "    # Keep track of the best outcome\n",
    "    if float(trial.final_measurement.metrics[0].value) > best[3]:\n",
    "        try:\n",
    "            best = (\n",
    "                trial.id,\n",
    "                float(trial.parameters[0].value),\n",
    "                float(trial.parameters[1].value),\n",
    "                float(trial.final_measurement.metrics[0].value),\n",
    "            )\n",
    "        except:\n",
    "            best = (\n",
    "                trial.id,\n",
    "                float(trial.parameters[0].value),\n",
    "                None,\n",
    "                float(trial.final_measurement.metrics[0].value),\n",
    "            )\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_best_model"
   },
   "source": [
    "获取最佳模型\n",
    "\n",
    "如果使用了用于让服务告诉调整脚本在哪里保存模型工件的方法（`DIRECT = False`），那么最佳模型的模型工件将保存在：\n",
    "\n",
    "    MODEL_DIR/<best_trial_id>/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_best_model"
   },
   "outputs": [],
   "source": [
    "BEST_MODEL_DIR = MODEL_DIR + \"/\" + best[0] + \"/model\"\n",
    "\n",
    "! gsutil ls {BEST_MODEL_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "delete_hpt_job"
   },
   "source": [
    "删除超参数调整作业\n",
    "\n",
    "方法'delete()'将删除超参数调整作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "delete_hpt_job"
   },
   "outputs": [],
   "source": [
    "hpt_job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于教程的[Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的个别资源：\n",
    "\n",
    "- 自定义作业（在上一步中删除了自定义训练作业）\n",
    "- 云存储存储桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyWy23gDox9a"
   },
   "outputs": [],
   "source": [
    "delete_bucket = False\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_vertex_hpt_xgboost.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
