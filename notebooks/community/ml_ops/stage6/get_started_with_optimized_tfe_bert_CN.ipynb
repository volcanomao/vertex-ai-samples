{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "# GCP上的端到端机器学习：MLOps阶段6：使用优化的TensorFlow Enterprise容器与Vertex AI Prediction /文本模型开始\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_optimized_tfe_bert.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_optimized_tfe_bert.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage6/get_started_with_optimized_tfe_bert.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>       \n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何将 TensorFlow 文本模型上传并部署到带有 TensorFlow 企业（TFE）运行时优化容器的 `Vertex AI Endpoint`。\n",
    "\n",
    "虽然优化可以应用于任何 TensorFlow 模型，但优化对表格和文本模型类型效果最好。\n",
    "\n",
    "*注意:* 使用 T4 训练模型大约需要 15 分钟。如果在 CPU 上训练，需要几个小时。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9402cfbdc2d"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用`TensorFlow Enterprise Optimized`容器部署到`Vertex AI Endpoint`资源的TensorFlow模型。\n",
    "\n",
    "本教程使用以下Google Cloud ML服务和资源：\n",
    "\n",
    "- `Vertex AI Prediction`\n",
    "- `Vertex AI Models`\n",
    "- `Vertex AI Endpoints`\n",
    "- `TensorFlow Enterprise Optimized`容器\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 从TensorFlow Hub下载一个预训练的BERT模型。\n",
    "- 将BERT模型进行微调（迁移学习）作为二元分类器。\n",
    "- 将TensorFlow Hub模型上传为`Vertex AI Model`资源，使用标准的TensorFlow serving容器。\n",
    "- 将TensorFlow Hub模型上传为`Vertex AI Model`资源，使用TensorFlow Enterprise Optimized容器。\n",
    "- 创建两个`Endpoint`资源。\n",
    "- 将两个`Model`资源部署到单独的`Endpoint`资源中。\n",
    "- 对部署的两个`Model`资源进行相同的在线预测请求。\n",
    "- 比较两个部署的`Model`资源之间的预测准确性。\n",
    "- 配置容器设置以控制微调优化。\n",
    "- 创建一个`Private Endpoint`资源。\n",
    "- 将使用`TensorFlow Enterprise Optimized`的`Model`资源部署到`Private Endpoint`资源中。\n",
    "- 向`Private Endpoint`资源发出在线预测请求。 \n",
    "\n",
    "了解更多关于[TensorFlow Enterprise Optimized container](https://cloud.google.com/vertex-ai/docs/predictions/optimized-tensorflow-runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:iris,lcn"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用了来自TensorFlow Hub的一个预训练的BERT文本模型，然后在包含50,000部电影评论的[大型电影评论数据集](https://ai.stanford.edu/~amaas/data/sentiment/)（来自[互联网电影数据库](https://www.imdb.com/)）上进行微调（迁移学习）。训练好的模型可以预测一部电影评论是积极的还是消极的。\n",
    "\n",
    "了解更多关于[BERT预训练编码器模型](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "成本\n",
    "\n",
    "本教程使用Google Cloud的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI\n",
    "价格](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage\n",
    "价格](https://cloud.google.com/storage/pricing)，并使用[Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "根据您预期的使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装以下包以运行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "! pip3 install --upgrade google-cloud-aiplatform $USER_FLAG -q\n",
    "! pip3 install --upgrade google-cloud-pipeline-components $USER_FLAG -q\n",
    "! pip3 install tensorflow tensorflow-text $USER_FLAG -q\n",
    "! pip3 install tensorflow-hub $USER_FLAG -q\n",
    "! pip3 install tf-models-official $USER_FLAG -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhq5zEbGg0XX"
   },
   "source": [
    "### 重新启动内核\n",
    "\n",
    "安装额外的包后，您需要重新启动笔记本内核，以便它可以找到这些包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzrelQZ22IZj"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin"
   },
   "source": [
    "##在开始之前\n",
    "\n",
    "### GPU运行时\n",
    "\n",
    "*如果您有这个选项，请确保您在GPU运行时中运行此笔记本。在Colab中，选择* **运行时 > 更改运行时类型 > GPU**\n",
    "\n",
    "###设置您的Google Cloud项目\n",
    "\n",
    "**无论您的笔记本环境如何，以下步骤都是必需的。**\n",
    "\n",
    "1. [选择或创建一个Google Cloud项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建帐户时，您将获得$300的免费信用额，用于您的计算/存储成本。\n",
    "\n",
    "2. [确保您的项目已启用计费。](https://cloud.google.com/billing/docs/how-to/modify-project)\n",
    "\n",
    "3. [启用以下API：Vertex AI API、计算引擎API和云存储。](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component,storage-component.googleapis.com)\n",
    "\n",
    "4. 如果您在本地运行此笔记本，您需要安装[Cloud SDK]((https://cloud.google.com/sdk))。\n",
    "\n",
    "5. 在下面的单元格中输入您的项目ID。然后运行该单元格，以确保Cloud SDK对本笔记本中的所有命令使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter运行以`!`为前缀的行作为shell命令，并插入以`$`为前缀的Python变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用`gcloud`来获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 地区\n",
    "\n",
    "您还可以更改“REGION”变量，该变量用于整个笔记本的操作。以下是Vertex AI支持的地区。我们建议您选择距离您最近的地区。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太地区：`asia-east1`\n",
    "\n",
    "您可能无法使用多区域存储桶来训练 Vertex AI。并非所有地区都支持所有Vertex AI服务。\n",
    "\n",
    "了解更多有关[Vertex AI地区](https://cloud.google.com/vertex-ai/docs/general/locations)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "时间戳\n",
    "\n",
    "如果您在进行实时教程会话，可能会使用共享测试账户或项目。为了避免资源命名冲突，您可以为每个实例会话创建一个时间戳，然后将时间戳附加在您在本教程中创建的资源名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "timestamp"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 验证您的谷歌云帐户\n",
    "\n",
    "**如果您正在使用谷歌云笔记本**，您的环境已经通过验证。跳过这一步。\n",
    "\n",
    "**如果您正在使用Colab**，运行下面的单元格，并按提示进行身份验证来通过oAuth验证您的帐户。\n",
    "\n",
    "**否则**，请按照以下步骤操作：\n",
    "\n",
    "在 Cloud Console 中，转到 [创建服务帐户密钥](https://console.cloud.google.com/apis/credentials/serviceaccountkey) 页面。\n",
    "\n",
    "**点击创建服务帐户**。\n",
    "\n",
    "在**服务帐户名称**字段中输入名称，然后点击**创建**。\n",
    "\n",
    "在**授予该服务帐户对项目的访问权限**部分，点击角色下拉列表。在过滤框中输入“Vertex”，然后选择**Vertex管理员**。在过滤框中输入“存储对象管理员”，然后选择**存储对象管理员**。\n",
    "\n",
    "点击创建。包含您的密钥的 JSON 文件将下载到本地环境。\n",
    "\n",
    "在下面的单元格中，输入您服务帐户密钥的路径作为 GOOGLE_APPLICATION_CREDENTIALS 变量，并运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcp_authenticate"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = False\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        IS_COLAB = True\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "**无论您使用的是哪个笔记本环境，都需要执行以下步骤。**\n",
    "\n",
    "当您为 Python 初始化 Vertex AI SDK 时，您需要指定一个云存储暂存桶。这个暂存桶是您数据集和模型资源所关联的数据在会话间保留的地方。\n",
    "\n",
    "请在下方设置您的云存储桶的名称。存储桶的名称必须在所有 Google Cloud 项目中全局唯一，包括您组织之外的项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_URI == \"\" or BUCKET_URI is None or BUCKET_URI == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_URI = \"gs://\" + PROJECT_ID + \"aip-\" + TIMESTAMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有当您的存储桶尚不存在时才运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "最后，通过检查其内容来验证对云存储桶的访问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。 \n",
    "### 导入库和定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "from official.nlp import optimization  # to create AdamW optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "### 初始化用于Python的Vertex AI SDK\n",
    "\n",
    "为您的项目和相应的存储桶初始化Python的Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "source": [
    "#### 设置硬件加速器\n",
    "\n",
    "您可以为训练和预测设置硬件加速器。\n",
    "\n",
    "将变量 `DEPLOY_GPU/DEPLOY_NGPU` 设置为使用支持 GPU 的容器映像以及分配给虚拟机实例的 GPU 数量。例如，要使用一个具有 4 个 Nvidia Telsa K80 GPU 的容器映像分配给每个虚拟机实例，您可以指定：\n",
    "\n",
    "    (aip.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
    "\n",
    "\n",
    "否则，指定 `(None, None)` 以使用一个在 CPU 上运行的容器映像。\n",
    "\n",
    "了解有关您地区的[硬件加速器支持](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)。\n",
    "\n",
    "*注意*：TF 2.3 之前的 GPU 支持版本将无法在此教程中加载自定义模型。这是一个已知问题，在 TF 2.3 中已修复。这是由在服务函数中生成的静态图操作引起的。如果在您自己的自定义模型上遇到此问题，请使用在 TF 2.3 中带有 GPU 支持的容器映像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_DEPLOY_GPU\"):\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (\n",
    "        aip.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "        int(os.getenv(\"IS_TESTING_DEPLOY_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction"
   },
   "source": [
    "设置预先构建的容器\n",
    "\n",
    "为预测设置预先构建的Docker容器镜像。\n",
    "\n",
    "获取最新列表，请查看[用于预测的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:training,prediction"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TF\"):\n",
    "    TF = os.getenv(\"IS_TESTING_TF\")\n",
    "else:\n",
    "    TF = \"2.5\".replace(\".\", \"-\")\n",
    "\n",
    "if TF[0] == \"2\":\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf2-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf2-cpu.{}\".format(TF)\n",
    "else:\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "\n",
    "DEPLOY_IMAGE = \"{}-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], DEPLOY_VERSION\n",
    ")\n",
    "\n",
    "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU, DEPLOY_NGPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于预测的机器类型。\n",
    "\n",
    "- 将变量`DEPLOY_COMPUTE`设置为配置将用于预测的虚拟机的计算资源。\n",
    "- `机器类型`\n",
    "     - `n1-standard`：每个 vCPU 的内存为3.75GB。\n",
    "     - `n1-highmem`：每个 vCPU 的内存为6.5GB。\n",
    "     - `n1-highcpu`：每个 vCPU 的内存为0.9GB。\n",
    "- `vCPUs`：数值范围为\\[2, 4, 8, 16, 32, 64, 96\\]\n",
    "\n",
    "*注意：您也可以在训练和部署中使用 n2 和 e2 机器类型，但它们不支持GPU*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_DEPLOY_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_DEPLOY_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8128b8ff025"
   },
   "source": [
    "从TensorFlow Hub获取预训练的编码器嵌入模型\n",
    "\n",
    "为了演示目的，本教程使用了从TensorFlow Hub（TFHub）获取的预训练的BERT编码器模型，对模型进行微调作为二元分类器，然后将其上传到`Vertex AI Model`资源。一旦您拥有了`Vertex AI Model`资源，该模型可以部署到`Vertex AI Endpoint`资源上。\n",
    "\n",
    "### 下载预训练编码器模型\n",
    "\n",
    "首先，您需要从TensorFlow Hub下载预训练的BERT编码器模型和对应的BERT文本预处理器。编码器和文本预处理器将会以TF.Keras层的形式下载。在本例中，为了完成模型，您需要创建一个使用下载的TFHub编码器和预处理器的`Functional`模型，并添加一个分类器将模型完成为一个二元分类器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c55fa4c826f7"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "encoder = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\", trainable=True\n",
    ")\n",
    "classifier = tf.keras.layers.Dense(\n",
    "    1, activation=\"sigmoid\", kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
    ")\n",
    "\n",
    "x = preprocess(inputs)\n",
    "x = encoder(x)\n",
    "outputs = classifier(x[\"pooled_output\"])\n",
    "tfhub_model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "tfhub_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfd262d9b6e2"
   },
   "source": [
    "### 下载数据集\n",
    "\n",
    "从[互联网电影数据库](https://www.imdb.com/)下载[大型电影评论数据集](https://ai.stanford.edu/~amaas/data/sentiment/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "439777aad931"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\n",
    "    \"aclImdb_v1.tar.gz\", url, untar=True, cache_dir=\".\", cache_subdir=\"\"\n",
    ")\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
    "\n",
    "train_dir = os.path.join(dataset_dir, \"train\")\n",
    "\n",
    "# remove unused folders to make it easier to load the data\n",
    "remove_dir = os.path.join(train_dir, \"unsup\")\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "863d86fbff5b"
   },
   "source": [
    "### 数据预处理\n",
    "\n",
    "IMDB 数据集已经被划分为训练集和测试集，但缺乏验证集。为了创建一个验证集，您使用训练数据的80:20拆分，通过使用 validation_split 参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17e2c99751ea"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69c998c4da30"
   },
   "source": [
    "### 编译模型\n",
    "\n",
    "接下来，为后续的微调（迁移学习）进行编译。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c17ab236527b"
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1 * num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(\n",
    "    init_lr=init_lr,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    optimizer_type=\"adamw\",\n",
    ")\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "\n",
    "tfhub_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd37efbd63ab"
   },
   "source": [
    "训练模型\n",
    "\n",
    "接下来，您训练（微调）模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2033a6e050ed"
   },
   "outputs": [],
   "source": [
    "history = tfhub_model.fit(x=train_ds, validation_data=val_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b0608f70b57"
   },
   "source": [
    "时代1/3\n",
    "625/625 [==============================] - 5081秒 8秒/步 - 损失: 0.7344 - 二元准确率: 0.4785 - 验证损失: 0.7025 - 验证二元准确率: 0.4992\n",
    "时代2/3\n",
    "625/625 [==============================] - 5080秒 8秒/步 - 损失: 0.6966 - 二元准确率: 0.5167 - 验证损失: 0.6946 - 验证二元准确率: 0.5338\n",
    "时代3/3\n",
    "625/625 [==============================] - 预计时间: 0秒 - 损失: 0.6917 - 二元准确率: 0.5344"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1ae10e92f49"
   },
   "source": [
    "### 评估模型\n",
    "\n",
    "接下来，评估模型。预计验证损失约为0.43。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83dbf3edd0ce"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = tfhub_model.evaluate(test_ds)\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63de49055083"
   },
   "source": [
    "### 保存模型工件\n",
    "\n",
    "此时，模型已存储在内存中。接下来，您可以将模型工件保存到云存储位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64618c713db9"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = BUCKET_URI + \"/model\"\n",
    "tfhub_model.save(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8ce91147c93"
   },
   "source": [
    "### 将TensorFlow Hub模型上传至带有标准TensorFlow容器的“Vertex AI Model”资源\n",
    "\n",
    "接下来，您将从TFHub模型中上传模型构件至带有标准TensorFlow容器的“Vertex AI Model”资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad61e1429512"
   },
   "outputs": [],
   "source": [
    "DEPLOY_IMAGE = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest\"\n",
    "\n",
    "model_standard = aip.Model.upload(\n",
    "    display_name=\"standard_\" + TIMESTAMP,\n",
    "    artifact_uri=MODEL_DIR,\n",
    "    serving_container_image_uri=DEPLOY_IMAGE,\n",
    ")\n",
    "\n",
    "print(model_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "170aafc0ad24"
   },
   "source": [
    "### 将TensorFlow Hub模型上传到带有优化TensorFlow容器的“Vertex AI Model”资源\n",
    "\n",
    "接下来，您将模型工件从TFHub模型上传到第二个带有TensorFlow Enterprise优化容器的“Vertex AI Model”资源：`us-docker.pkg.dev/vertex-ai-restricted/prediction/tf_opt-gpu.nightly:latest`。\n",
    "\n",
    "模型应用了两种优化选项。\n",
    "\n",
    "- *allow_precompilation* - 打开模型预编译以实现更好的性能。请注意，当具有新批量大小的第一个请求到达时，模型预编译会发生，并且在预编译完成后发送该请求的响应。为了减轻这种情况，请指定一个热身文件（请参阅此colab中较早的部分）。模型预编译适用于不同类型的模型，在大多数情况下对性能有积极影响。然而，我们建议您在生产环境之前尝试使用它来适应您的模型。\n",
    "\n",
    "- *allow_precision_affecting_optimizations* - 启用影响精度的优化。在某些情况下，这会使模型运行速度显着提高，但会对模型预测能力造成非常小的损失。在使用此优化时，您应评估其对模型精度的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebfb338a0b05"
   },
   "outputs": [],
   "source": [
    "DEPLOY_IMAGE = \"us-docker.pkg.dev/vertex-ai-restricted/prediction/tensorflow-enterprise-inference-engine-alpha:latest\"\n",
    "model_tfe_opt = aip.Model.upload(\n",
    "    display_name=\"tfe_opt_\" + TIMESTAMP,\n",
    "    artifact_uri=MODEL_DIR,\n",
    "    serving_container_image_uri=DEPLOY_IMAGE,\n",
    "    serving_container_args=[\n",
    "        \"--allow_precompilation=true\",\n",
    "        \"--allow_precision_affecting_optimizations=true\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(model_tfe_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "628de0914ba1"
   },
   "source": [
    "创建两个公共 `Endpoint` 资源\n",
    "\n",
    "您可以使用 `Endpoint.create()` 方法创建两个公共 `Endpoint` 资源。至少，您需要指定端点的显示名称。可选地，您可以指定项目和位置（地区）；否则，设置将继承在初始化 Vertex AI SDK 时使用 `init()` 方法设置的值。\n",
    "\n",
    "在此示例中，指定了以下参数：\n",
    "\n",
    "- `display_name`：`Endpoint` 资源的人类可读名称。\n",
    "- `project`：您的项目 ID。\n",
    "- `location`：您的地区。\n",
    "- `labels`：（可选）`Endpoint` 的用户定义的元数据，以键/值对的形式。\n",
    "\n",
    "此方法返回一个 `Endpoint` 对象。\n",
    "\n",
    "了解有关 [Vertex AI Endpoints](https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api) 的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ea443f9593b"
   },
   "outputs": [],
   "source": [
    "endpoint_standard = aip.Endpoint.create(\n",
    "    display_name=\"standard_\" + TIMESTAMP,\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    labels={\"your_key\": \"your_value\"},\n",
    ")\n",
    "\n",
    "print(endpoint_standard)\n",
    "\n",
    "endpoint_tfe_opt = aip.Endpoint.create(\n",
    "    display_name=\"tfe_opt_\" + TIMESTAMP,\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    labels={\"your_key\": \"your_value\"},\n",
    ")\n",
    "\n",
    "print(endpoint_tfe_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ca3fa3f6a894"
   },
   "source": [
    "部署`Model`资源到`Endpoint`资源。\n",
    "\n",
    "接下来，您将标准和优化容器的两个实例部署到不同的公共`Vertex AI Endpoints`中。\n",
    "\n",
    "*注意:* 在这个示例中，您在上一步将TFHub模型的部署容器指定为上传模型工件到`Vertex AI Model`资源。\n",
    "\n",
    "在这个示例中，您将以最少数量的指定参数部署模型，具体如下：\n",
    "\n",
    "- `model`：`Model`资源。\n",
    "- `deployed_model_displayed_name`：部署模型实例的可读名称。\n",
    "- `machine_type`：每个虚拟机实例的机器类型。\n",
    "\n",
    "由于资源的需求，这可能需要几分钟的时间来完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e93b034a72f"
   },
   "outputs": [],
   "source": [
    "response = endpoint_standard.deploy(\n",
    "    model=model_standard,\n",
    "    deployed_model_display_name=\"standard_\" + TIMESTAMP,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    ")\n",
    "\n",
    "print(endpoint_standard)\n",
    "\n",
    "response = endpoint_tfe_opt.deploy(\n",
    "    model=model_tfe_opt,\n",
    "    deployed_model_display_name=\"tfe_opt_\" + TIMESTAMP,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    ")\n",
    "\n",
    "print(endpoint_tfe_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cad0a1fe622"
   },
   "source": [
    "### 为预测准备测试数据\n",
    "\n",
    "接下来，您要为预测准备测试数据。在这个例子中，您将使用合成数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ff52779cffd7"
   },
   "outputs": [],
   "source": [
    "INSTANCES = [\"This was the best movie ever\", \"Movie was boring\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "predict_request:mbsdk,custom,icn"
   },
   "source": [
    "### 进行预测\n",
    "\n",
    "现在您的`Model`资源已部署到`Endpoint`资源，您可以通过向Endpoint资源发送预测请求来进行在线预测。\n",
    "\n",
    "#### 请求\n",
    "\n",
    "预测请求中的每个实例都是以下形式的字典条目：\n",
    "\n",
    "                        {input_name: content}\n",
    "\n",
    "- `input_name`：底层模型的输入层的名称。\n",
    "- `content`：作为1D Python列表的数据项。\n",
    "\n",
    "由于`predict()`服务可以接受多个数据项（实例），您将将您的单个数据项发送为一个数据项的列表。最后一步是将实例列表打包成Google的protobuf格式 - 这是我们传递给`predict()`服务的内容。\n",
    "\n",
    "#### 响应\n",
    "\n",
    "从`predict()`调用的响应是一个Python字典，具有以下条目：\n",
    "\n",
    "- `ids`：每个预测请求的内部分配的唯一标识符。\n",
    "- `predictions`：每个类别标签的预测置信度，介于0和1之间。\n",
    "- `deployed_model_id`：执行预测的已部署`Model`资源的Vertex AI标识符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "predict_request:mbsdk,custom,icn"
   },
   "outputs": [],
   "source": [
    "serving_input = tfhub_model.input.name\n",
    "\n",
    "# The format of each instance should conform to the deployed model's prediction input schema.\n",
    "instances = [{serving_input: INSTANCES[0]}, {serving_input: INSTANCES[1]}]\n",
    "\n",
    "prediction_standard = endpoint_standard.predict(instances=instances)\n",
    "\n",
    "print(prediction_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ed2310874ca"
   },
   "outputs": [],
   "source": [
    "# The format of each instance should conform to the deployed model's prediction input schema.\n",
    "instances = [{serving_input: INSTANCES[0]}, {serving_input: INSTANCES[1]}]\n",
    "\n",
    "prediction_tfe_opt = endpoint_tfe_opt.predict(instances=instances)\n",
    "\n",
    "print(prediction_tfe_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adc156331e62"
   },
   "source": [
    "比较精度差异\n",
    "\n",
    "最后，比较优化部署模型和未优化部署模型之间的精度差异。这个差异看起来非常微小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6af9065a8ff"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "abs(\n",
    "    np.asarray(prediction_standard.predictions)\n",
    "    - np.asarray(prediction_tfe_opt.predictions)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## 清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于教程的[Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "delete_bucket = False\n",
    "delete_model = True\n",
    "delete_endpoint = True\n",
    "\n",
    "if delete_endpoint:\n",
    "    try:\n",
    "        endpoint_standard.undeploy_all()\n",
    "        endpoint_standard.delete()\n",
    "        endpoint_tfe_opt.undeploy_all()\n",
    "        endpoint_tfe_opt.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "if delete_model:\n",
    "    try:\n",
    "        tfhub_model.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -rf {BUCKET_URI}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "get_started_with_optimized_tfe_bert.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
