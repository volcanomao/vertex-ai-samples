{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "# GCP上的端到端ML：MLOps阶段6： 使用Vertex AI批处理预测开始定制文本模型\n",
    "\n",
    "<table align=left>\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_custom_text_model_batch.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_custom_text_model_batch.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage6/get_started_with_custom_text_model_batch.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>        \n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概览\n",
    "\n",
    "本教程演示了如何从自定义文本模型中进行批量预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9402cfbdc2d"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何在自定义文本模型中使用`Vertex AI Batch Prediction`。\n",
    "\n",
    "本教程使用以下谷歌云 ML 服务和资源：\n",
    "\n",
    "- `Vertex AI Batch Prediction`\n",
    "- `Vertex AI 模型`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 下载一个预训练的 TensorFlow RNN 模型。\n",
    "- 将预训练模型上传为`Vertex AI 模型`资源。\n",
    "- 对`模型`资源进行批量预测，以JSONL格式。\n",
    "\n",
    "在使用批量预测和在线预测之间有一个关键区别：\n",
    "\n",
    "* 预测服务：为整个实例集（即一个或多个数据项）进行即时预测，并实时返回结果。\n",
    "\n",
    "* 批处理预测服务：对整个实例集进行排队（批）预测，并在准备就绪时将结果存储在 Cloud Storage 存储桶中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:iris,lcn"
   },
   "source": [
    "### 模型\n",
    "\n",
    "本教程中使用的模型是来自 TensorFlow Hub 的预训练的[通用句子编码器](https://tfhub.dev/google/universal-sentence-encoder/4)。该模型接收一个文本句子，并输出一个长度为512的向量嵌入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "### 费用\n",
    "\n",
    "本教程使用Google Cloud的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI\n",
    "定价](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage\n",
    "定价](https://cloud.google.com/storage/pricing)，并使用[Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "根据您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装以下软件包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "! pip3 install --upgrade google-cloud-aiplatform $USER_FLAG -q\n",
    "! pip3 install --upgrade tensorflow $USER_FLAG -q\n",
    "! pip3 install --upgrade tensorflow-hub $USER_FLAG -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhq5zEbGg0XX"
   },
   "source": [
    "### 重新启动内核\n",
    "\n",
    "在安装额外的包之后，您需要重新启动笔记本内核，以便它可以找到这些包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzrelQZ22IZj"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### GPU 运行时\n",
    "\n",
    "*如果有选择的话，请确保在 GPU 运行时中运行本笔记本。在 Colab 中，选择* **Runtime > Change Runtime Type > GPU**\n",
    "\n",
    "### 设置您的 Google Cloud 项目\n",
    "\n",
    "**无论您的笔记本环境如何，以下步骤都是必需的。**\n",
    "\n",
    "1. [选择或创建一个 Google Cloud 项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建账户时，您将获得 $300 的免费信用额度，可用于计算/存储成本。\n",
    "\n",
    "2. [确保为您的项目启用了计费。](https://cloud.google.com/billing/docs/how-to/modify-project)\n",
    "\n",
    "3. [启用以下 API：Vertex AI API、Compute Engine API 和 Cloud Storage。](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component,storage-component.googleapis.com)\n",
    "\n",
    "4. 如果您是在本地运行此笔记本，您需要安装 [Cloud SDK]((https://cloud.google.com/sdk))。\n",
    "\n",
    "5. 在下面的单元格中输入您的项目 ID。然后运行该单元格，确保 Cloud SDK 在本笔记本中的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter 将以 `!` 为前缀的行作为 shell 命令运行，并会解析以 `$` 为前缀的 Python 变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用`gcloud`来获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "区域\n",
    "\n",
    "您还可以更改`REGION`变量，该变量用于本笔记本的其余操作。以下是Vertex AI支持的区域。我们建议您选择距离您最近的区域。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太地区：`asia-east1`\n",
    "\n",
    "您可能无法在Vertex AI中使用多区域存储桶进行训练。并非所有区域都支持所有Vertex AI服务。\n",
    "\n",
    "了解更多关于[Vertex AI区域](https://cloud.google.com/vertex-ai/docs/general/locations)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "UUID\n",
    "\n",
    "如果你正在进行现场教程，你可能正在使用一个共享的测试账号或项目。为了避免用户在创建资源时发生名称冲突，你可以为每个实例会话创建一个UUID，并将其附加到在本教程中创建的资源的名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "timestamp"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 验证您的Google Cloud帐户\n",
    "\n",
    "**如果您正在使用Vertex AI Workbench笔记本**，您的环境已经通过身份验证。\n",
    "\n",
    "**如果您正在使用Colab**，运行下面的单元格，并按照提示进行身份验证以通过oAuth进行帐户认证。\n",
    "\n",
    "**否则**，请按照以下步骤操作：\n",
    "\n",
    "在Cloud控制台中，转到[创建服务账号密钥](https://console.cloud.google.com/apis/credentials/serviceaccountkey)页面。\n",
    "\n",
    "**点击创建服务帐号**。\n",
    "\n",
    "在**服务帐号名称**字段中输入名称，然后点击**创建**。\n",
    "\n",
    "在**授予此服务帐号对项目的访问权限**部分，点击角色下拉列表。在筛选框中输入\"Vertex\"，选择**Vertex管理员**。在筛选框中输入\"Storage对象管理员\"，选择**Storage对象管理员**。\n",
    "\n",
    "点击创建。包含您密钥的JSON文件将下载到您的本地环境中。\n",
    "\n",
    "在下面的单元格中将您的服务帐号密钥路径输入为GOOGLE_APPLICATION_CREDENTIALS变量，并运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcp_authenticate"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "**无论您使用的是哪个笔记本环境，以下步骤都是必需的。**\n",
    "\n",
    "当您在 Python 中初始化 Vertex AI SDK 时，您需要指定一个云存储暂存桶。这个暂存桶是您的数据集和模型资源相关数据在会话之间保留的地方。\n",
    "\n",
    "在下面设置您的云存储桶的名称。存储桶的名称必须在所有谷歌云项目中全局唯一，包括组织之外的项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_URI == \"\" or BUCKET_URI is None or BUCKET_URI == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_NAME = PROJECT_ID + \"aip-\" + UUID\n",
    "    BUCKET_URI = \"gs://\" + BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有您的存储桶尚不存在：才运行以下单元格以创建您的云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "最终，通过检查您的云存储桶的内容来验证访问权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。\n",
    "### 导入库和定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "初始化Vertex AI SDK用于Python\n",
    "\n",
    "为您的项目和相应的存储桶初始化Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "source": [
    "#### 设置硬件加速器\n",
    "\n",
    "您可以为预测设置硬件加速器。\n",
    "\n",
    "将变量`DEPLOY_GPU/DEPLOY_NGPU`设置为使用支持 GPU 的容器映像以及分配给虚拟机实例 (VM) 的 GPU 数量。例如，要使用一个支持 GPU 的容器映像，每个 VM 分配 4 个 Nvidia Telsa K80 GPU，您可以指定：\n",
    "\n",
    "    (aip.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
    "\n",
    "\n",
    "否则，指定`(None, None)`以使用一个在 CPU 上运行的容器映像。\n",
    "\n",
    "了解更多关于[您所在地区的硬件加速器支持信息](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_DEPLOY_GPU\"):\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (\n",
    "        aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "        int(os.getenv(\"IS_TESTING_DEPLOY_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction"
   },
   "source": [
    "设置预构建的容器\n",
    "\n",
    "设置用于预测的预构建 Docker 容器镜像。\n",
    "\n",
    "有关最新列表，请参阅[用于预测的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:training,prediction"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TF\"):\n",
    "    TF = os.getenv(\"IS_TESTING_TF\")\n",
    "else:\n",
    "    TF = \"2.5\".replace(\".\", \"-\")\n",
    "\n",
    "if TF[0] == \"2\":\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf2-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf2-cpu.{}\".format(TF)\n",
    "else:\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "\n",
    "DEPLOY_IMAGE = \"{}-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], DEPLOY_VERSION\n",
    ")\n",
    "\n",
    "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU, DEPLOY_NGPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于预测的机器类型。\n",
    "\n",
    "- 将变量`DEPLOY_COMPUTE`设置为配置您将用于预测的VM的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`：每个虚拟CPU 3.75GB内存。\n",
    "     - `n1-highmem`：每个虚拟CPU 6.5GB内存\n",
    "     - `n1-highcpu`：每个虚拟CPU 0.9GB内存\n",
    " - `vCPUs`：\\ [2, 4, 8, 16, 32, 64, 96\\] 的数量\n",
    "\n",
    "*注意：您也可以使用n2和e2机器类型进行训练和部署，但它们不支持GPU*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_DEPLOY_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_DEPLOY_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8128b8ff025"
   },
   "source": [
    "从TensorFlow Hub获取预训练的编码器嵌入模型\n",
    "\n",
    "为了演示目的，本教程使用了从TensorFlow Hub（TFHub）获取的预训练的通用句子编码器（USE）编码器模型，然后将其上传到“Vertex AI Model”资源中。一旦您拥有了“Vertex AI Model”资源，该模型就可以部署到“Vertex AI Endpoint”资源中。\n",
    "\n",
    "### 下载预训练的编码器模型\n",
    "\n",
    "首先，您需要从TensorFlow Hub下载预训练的通用句子编码器模型。该编码器作为一个TF.Keras层。在本示例中，为了完成模型，您将使用下载的TFHub编码器创建一个“Sequential”模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f76c8e27240"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Sequential\n",
    "\n",
    "encoder = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "tfhub_model = Sequential([Input(shape=(), dtype=tf.string), encoder])\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "optimizer = tf.optimizers.Adam()\n",
    "\n",
    "tfhub_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "tfhub_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63de49055083"
   },
   "source": [
    "### 保存模型工件\n",
    "\n",
    "在这一点上，模型在内存中。接下来，您将模型工件保存到云存储位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64618c713db9"
   },
   "outputs": [],
   "source": [
    "! mkdir model\n",
    "MODEL_DIR = f\"{BUCKET_URI}\"\n",
    "tfhub_model.save(\"model\")\n",
    "\n",
    "! gsutil cp -r model {MODEL_DIR}\n",
    "! rm -rf model\n",
    "\n",
    "MODEL_DIR = MODEL_DIR + \"/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bf06cd476e9"
   },
   "source": [
    "### 将模型工件上传为`Vertex AI Model`资源\n",
    "\n",
    "首先，您可以使用`upload()`方法将预训练的自定义表格模型工件作为`Vertex AI Model`资源上传，使用以下参数：\n",
    "\n",
    "- `display_name`：`Model`资源的人类可读名称。\n",
    "- `artifact_uri`：模型工件的Cloud Storage位置。\n",
    "- `serving_container_image`：在将模型部署到`Vertex AI Endpoint`资源时要使用的服务容器映像。\n",
    "- `sync`：是否等待进程完成，还是立即返回（异步）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0193f247e216"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=\"use_\" + UUID,\n",
    "    artifact_uri=MODEL_DIR,\n",
    "    serving_container_image_uri=DEPLOY_IMAGE,\n",
    "    sync=True,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11e16f54bc90"
   },
   "source": [
    "## 批量预测简介\n",
    "\n",
    "批量预测提供了离线批处理大量预测请求的能力。资源仅在批处理过程中进行配置，然后在批处理请求完成时取消配置。结果存储在云存储中，与在线预测不同，后者将结果作为HTTP响应数据返回。\n",
    "\n",
    "批处理作业的输入格式取决于您的模型服务器支持的格式。首先，您的模型服务器中的Web服务器必须支持JSONL格式，Web服务器将其转换为模型输入接口或服务功能接口直接支持的格式。对于批量预测，该JSONL格式称为“pivot”格式。\n",
    "\n",
    "### 批量预测作业的输入格式\n",
    "\n",
    "批处理服务器接受以下自定义文本模型的输入格式：\n",
    "\n",
    "- JSONL\n",
    "- 文件列表\n",
    "\n",
    "批处理服务器接受以下自定义文本模型的输出格式：\n",
    "\n",
    "- JSONL\n",
    "\n",
    "### Pivot格式\n",
    "\n",
    "批处理服务器将输入格式转换为“pivot”（JSONL）格式如下：\n",
    "\n",
    "**JSONL**\n",
    "\n",
    "每个输入行（请求）应包含一个并且只有一个有效的json值。\n",
    "\n",
    "    {\"values\": [1, 2, 3, 4], \"key\": 1}\n",
    "    {\"values\": [5, 6, 7, 8], \"key\": 2}\n",
    "\n",
    "批处理服务器使用相同的格式生成pivot数据。生成的pivot数据然后被包装成一个负载请求：\n",
    "\n",
    "    {\"instances\": [\n",
    "      {\"values\": [1, 2, 3, 4], \"key\": 1},\n",
    "      {\"values\": [5, 6, 7, 8], \"key\": 2}\n",
    "    ]}\n",
    "\n",
    "**CSV**\n",
    "\n",
    "第一行中的csv标题将始终被忽略。字符串字段需要明确用双引号括起来，否则该行将被丢弃，解析错误消息将被输出到错误文件中。非引号值始终以浮点数进行传输。\n",
    "\n",
    "    col1,col2,col3\n",
    "    1,3,\"cat1\"\n",
    "    2,4,\"cat2\"\n",
    "\n",
    "批处理服务器将每个输入行（请求）转换为JSON数组。\n",
    "\n",
    "    {\"instances\": [\n",
    "     [1.0,3.0,\"cat1\"],\n",
    "     [2.0,4.0,\"cat2\"]\n",
    "    ]}\n",
    "    \n",
    "**BigQuery**\n",
    "\n",
    "每一行都被转换为一个JSON数组。例如：\n",
    "\n",
    "    [1.0,3.0,\"cat1\"]\n",
    "    [2.0,4.0,\"cat2\"]\n",
    "    \n",
    "批处理服务器使用相同的格式生成pivot数据。生成的pivot数据然后被包装成一个负载请求：\n",
    "\n",
    "    {\"instances\": [\n",
    "     [1.0,3.0,\"cat1\"],\n",
    "     [2.0,4.0,\"cat2\"]\n",
    "    ]}\n",
    "\n",
    "**TFRecords**\n",
    "\n",
    "TFRecord文件中的实例被apache_beam.io.tfrecordio模块读取为二进制。然后将二进制对象序列化为ASCII字符串。预测服务器负责知道解码器以恢复实例。\n",
    "\n",
    "    {\"instances\": [\n",
    "     {\"b64\",\"b64EncodedASCIIString\"},\n",
    "     {\"b64\",\"b64EncodedASCIIString\"}\n",
    "    ]}\n",
    "\n",
    "**文件列表**\n",
    "\n",
    "文件列表格式包含文件列表。在“FileList”文件中，每行指定一个文件路径，指定为云存储位置。\n",
    "\n",
    "    gs://my-bucket/file1.txt\n",
    "    gs://my-bucket/file2.txt\n",
    "\n",
    "批处理服务器将文件读取为二进制。二进制对象被序列化为ASCII字符串。\n",
    "\n",
    "    {\"instances\": [\n",
    "     {\"b64\",\"b64EncodedASCIIString\"},\n",
    "     {\"b64\",\"b64EncodedASCIIString\"}\n",
    "    ]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_batch_file:automl,tabular,alt"
   },
   "source": [
    "制作包含JSONL输入的批处理输入文件\n",
    "\n",
    "现在制作一个批处理输入文件，将其存储在本地云存储桶中。在这个例子中，您使用JSONL格式作为输入和输出。对于输入，JSONL文件的布局如下，每个句子单独占一行并用双引号括起来：\n",
    "\n",
    "\"text_string_1\"\n",
    "\"text_string_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "make_batch_file:custom,text"
   },
   "outputs": [],
   "source": [
    "gcs_input_uri = BUCKET_URI + \"/\" + \"test.jsonl\"\n",
    "with open(\"test.jsonl\", \"w\") as f:\n",
    "    data = \"the quick brown fox jumps over the lazy dog\"\n",
    "    f.write('\"' + data + '\"\\n')\n",
    "    data = \"one two\"\n",
    "    f.write('\"' + data + '\"\\n')\n",
    "\n",
    "! gsutil cp test.jsonl {gcs_input_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request:mbsdk"
   },
   "source": [
    "### 发送批量预测请求\n",
    "\n",
    "现在您的模型资源已经训练好，您可以通过调用batch_predict()方法进行批量预测，使用以下参数：\n",
    "\n",
    "- `job_display_name`：批量预测作业的人类可读名称。\n",
    "- `instances_format`：批量预测请求文件的格式：“jsonl”，“csv”，“bigquery”，“tf-record”，“tf-record-gzip”或“file-list”。\n",
    "- `prediction_format`：批量预测响应文件的格式：“jsonl”，“csv”，“bigquery”，“tf-record”，“tf-record-gzip”或“file-list”。\n",
    "- `gcs_source`：一个或多个批请求输入文件的列表。\n",
    "- `gcs_destination_prefix`：用于存储批量预测结果的云存储位置。\n",
    "- `sync`：如果设置为True，则调用将在等待异步批处理作业完成时阻塞。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request:mbsdk"
   },
   "outputs": [],
   "source": [
    "batch_predict_job = model.batch_predict(\n",
    "    job_display_name=\"use_\" + UUID,\n",
    "    instances_format=\"jsonl\",\n",
    "    predictions_format=\"jsonl\",\n",
    "    gcs_source=gcs_input_uri,\n",
    "    gcs_destination_prefix=BUCKET_URI,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "print(batch_predict_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "source": [
    "等待批量预测作业完成\n",
    "\n",
    "接下来，等待批量作业完成。或者，可以在`batch_predict()`方法中将参数`sync`设置为`True`，以阻止直到批量预测作业完成为止。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "outputs": [],
   "source": [
    "batch_predict_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_batch_prediction:mbsdk,tcn"
   },
   "source": [
    "### 获取预测结果\n",
    "\n",
    "接下来，从已完成的批量预测作业中获取结果。\n",
    "\n",
    "结果将被写入你在批量预测请求中指定的云存储输出桶中。你可以调用 iter_outputs() 方法来获取生成的带有结果的每个云存储文件的列表。每个文件都以 JSON 格式包含一个或多个预测请求：\n",
    "\n",
    "- `content`：预测请求。\n",
    "- `prediction`：预测响应。\n",
    " - `ids`：每个预测请求的内部分配的唯一标识符。\n",
    " - `displayNames`：每个类别标签的类名。\n",
    " - `confidences`：每个类别标签的预测置信度，介于 0 和 1 之间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_batch_prediction:mbsdk,tcn"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "bp_iter_outputs = batch_predict_job.iter_outputs()\n",
    "\n",
    "prediction_results = list()\n",
    "for blob in bp_iter_outputs:\n",
    "    if blob.name.split(\"/\")[-1].startswith(\"prediction\"):\n",
    "        prediction_results.append(blob.name)\n",
    "\n",
    "tags = list()\n",
    "for prediction_result in prediction_results:\n",
    "    gfile_name = f\"gs://{bp_iter_outputs.bucket.name}/{prediction_result}\"\n",
    "    with tf.io.gfile.GFile(name=gfile_name, mode=\"r\") as gfile:\n",
    "        for line in gfile.readlines():\n",
    "            line = json.loads(line)\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdd8ad4f66ae"
   },
   "source": [
    "您可以使用`delete()`方法删除批量预测作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "063c5b274845"
   },
   "outputs": [],
   "source": [
    "batch_predict_job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_batch_file:automl,tabular,alt"
   },
   "source": [
    "使用文件列表输入创建批处理输入文件\n",
    "\n",
    "现在创建一个批处理输入文件，将其存储在您的本地云存储桶中。在这个示例中，您将使用文件列表格式进行输入。在这种情况下，文件列表文件中的每一行都指向一个文本文件在云存储中的位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1e29665076f"
   },
   "source": [
    "准备数据以进行批量预测\n",
    "\n",
    "接下来，您将相同的批处理预测请求实例格式化为文件列表格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "df7eb4692bff"
   },
   "outputs": [],
   "source": [
    "with open(\"test1.txt\", \"w\") as f:\n",
    "    f.write('\"the quick brown fox jumps over the lazy dog\"\\n')\n",
    "with open(\"test2.txt\", \"w\") as f:\n",
    "    f.write('\"search Google or type an Url\"\\n')\n",
    "\n",
    "! gsutil cp test1.txt {BUCKET_URI}/test1.txt\n",
    "! gsutil cp test2.txt {BUCKET_URI}/test2.txt\n",
    "\n",
    "! rm test1.txt test2.txt\n",
    "\n",
    "with open(\"test.txt\", \"w\") as f:\n",
    "    f.write(f\"{BUCKET_URI}/test1.txt\\n\")\n",
    "    f.write(f\"{BUCKET_URI}/test2.txt\\n\")\n",
    "\n",
    "gcs_input_uri = f\"{BUCKET_URI}/test.txt\"\n",
    "\n",
    "! gsutil cp test.txt $gcs_input_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request:mbsdk"
   },
   "source": [
    "### 发送批量预测请求\n",
    "\n",
    "现在您的模型资源已经训练好了，您可以通过调用batch_predict() 方法来进行批量预测，需要指定以下参数：\n",
    "\n",
    "- `job_display_name`: 批量预测作业的可读名称。\n",
    "- `instances_format`: 批量预测请求文件的格式：\"jsonl\"、\"csv\"、\"bigquery\"、\"tf-record\"、\"tf-record-gzip\" 或 \"file-list\"。\n",
    "- `prediction_format`: 批量预测响应文件的格式：\"jsonl\"、\"csv\"、\"bigquery\"、\"tf-record\"、\"tf-record-gzip\" 或 \"file-list\"。\n",
    "- `gcs_source`: 包含一个或多个批量请求输入文件的列表。\n",
    "- `gcs_destination_prefix`: 用于存储批量预测结果的云存储位置。\n",
    "- `sync`: 如果设置为True，则调用将在等待异步批处理作业完成时阻塞。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request:mbsdk"
   },
   "outputs": [],
   "source": [
    "batch_predict_job = model.batch_predict(\n",
    "    job_display_name=\"use_\" + UUID,\n",
    "    instances_format=\"file-list\",\n",
    "    predictions_format=\"jsonl\",\n",
    "    gcs_source=gcs_input_uri,\n",
    "    gcs_destination_prefix=BUCKET_URI,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "print(batch_predict_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "source": [
    "### 等待批处理预测任务完成\n",
    "\n",
    "接下来，等待批处理任务完成。另外，可以在`batch_predict()`方法中将参数`sync`设置为`True`，以阻塞直到批处理预测任务完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "outputs": [],
   "source": [
    "batch_predict_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_batch_prediction:mbsdk,tcn"
   },
   "source": [
    "### 获取预测结果\n",
    "\n",
    "接下来，从完成的批量预测作业中获取结果。\n",
    "\n",
    "结果将写入您在批量预测请求中指定的云存储输出桶中。您可以调用 iter_outputs() 方法来获取包含结果的每个云存储文件的列表。每个文件都以 JSON 格式包含一个或多个预测请求：\n",
    "\n",
    "- `content`：预测请求。\n",
    "- `prediction`：预测响应。\n",
    " - `ids`：每个预测请求的内部分配的唯一标识符。\n",
    " - `displayNames`：每个类别标签的类名。\n",
    " - `confidences`：每个类别标签的预测置信度，介于 0 和 1 之间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_batch_prediction:mbsdk,tcn"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "bp_iter_outputs = batch_predict_job.iter_outputs()\n",
    "\n",
    "prediction_results = list()\n",
    "for blob in bp_iter_outputs:\n",
    "    if blob.name.split(\"/\")[-1].startswith(\"prediction\"):\n",
    "        prediction_results.append(blob.name)\n",
    "\n",
    "tags = list()\n",
    "for prediction_result in prediction_results:\n",
    "    gfile_name = f\"gs://{bp_iter_outputs.bucket.name}/{prediction_result}\"\n",
    "    with tf.io.gfile.GFile(name=gfile_name, mode=\"r\") as gfile:\n",
    "        for line in gfile.readlines():\n",
    "            line = json.loads(line)\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除您用于教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除您在此教程中创建的各个资源："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "delete_bucket = True\n",
    "delete_model = True\n",
    "delete_batch_job = True\n",
    "\n",
    "if delete_model:\n",
    "    try:\n",
    "        model.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "if delete_batch_job:\n",
    "    batch_prediction_job.delete()\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -rf {BUCKET_URI}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "get_started_with_custom_text_model_batch.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
