{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "在GCP上的E2E ML：MLOps阶段6：serving：使用Vertex AI Online Prediction为AutoML表格模型入门\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_automl_tabular_model_online.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_automl_tabular_model_online.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage6/get_started_with_automl_tabular_model_online.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:automl"
   },
   "source": [
    "概述\n",
    "\n",
    "本教程演示如何使用Vertex AI SDK创建表格二元分类模型，并使用AutoML模型进行在线预测和解释。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:automl,training,batch_prediction"
   },
   "source": [
    "目标\n",
    "\n",
    "在本教程中，您将从Python脚本中创建一个AutoML表格二元分类模型，然后使用Vertex AI SDK进行在线预测。您还可以选择使用`gcloud`命令行工具或通过Cloud Console在线创建和部署模型。\n",
    "\n",
    "本教程使用以下谷歌云ML服务和资源：\n",
    "\n",
    "- `Vertex AutoML`\n",
    "- `Vertex AI Online Prediction`\n",
    "- `Vertex Explainable AI`\n",
    "- `Vertex AI Datasets`\n",
    "- `Vertex AI Models`\n",
    "- `Vertex AI Endpoints`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 创建一个Vertex `Dataset`资源。\n",
    "- 训练一个`AutoML`表格模型。\n",
    "- 将模型部署到一个`Endpoint`资源。\n",
    "- 进行在线预测。\n",
    "- 使用解释进行在线预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:bank,lbn"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是[银行营销](https://pantheon.corp.google.com/storage/browser/_details/cloud-ml-tables-data/bank-marketing.csv)。这个数据集不需要任何特征工程。您在本教程中使用的数据集版本存储在公共云存储桶中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "### 费用\n",
    "\n",
    "本教程使用 Google Cloud 的收费组件：\n",
    "\n",
    "- Vertex AI\n",
    "- 云存储\n",
    "\n",
    "了解关于[Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing)，[云存储价格](https://cloud.google.com/storage/pricing)，并使用[定价计算器](https://cloud.google.com/products/calculator/)根据您的预期使用量生成费用估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_local"
   },
   "source": [
    "### 设置本地开发环境\n",
    "\n",
    "如果您正在使用Colab或Vertex AI Workbench笔记本，您的环境已经满足运行本笔记本的所有要求。您可以跳过这一步。\n",
    "\n",
    "否则，请确保您的环境满足本笔记本的要求。您需要以下内容：\n",
    "\n",
    "- 云存储SDK\n",
    "- Git\n",
    "- Python 3\n",
    "- virtualenv\n",
    "- 在使用Python 3的虚拟环境中运行的Jupyter笔记本\n",
    "\n",
    "云存储指南[设置Python开发环境](https://cloud.google.com/python/setup)和[Jupyter安装指南](https://jupyter.org/install)提供了满足这些要求的详细说明。以下步骤提供了一套简洁的说明：\n",
    "\n",
    "1. [安装和初始化SDK](https://cloud.google.com/sdk/docs/)。\n",
    "\n",
    "2. [安装Python 3](https://cloud.google.com/python/setup#installing_python)。\n",
    "\n",
    "3. [安装virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv)并创建一个使用Python 3的虚拟环境。激活虚拟环境。\n",
    "\n",
    "4. 要安装Jupyter，在终端shell中运行`pip3 install jupyter`。\n",
    "\n",
    "5. 要启动Jupyter，在终端shell中运行`jupyter notebook`。\n",
    "\n",
    "6. 在Jupyter笔记本仪表板中打开此笔记本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装以下包以执行这个笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "! pip3 install --upgrade {USER_FLAG} -q google-cloud-aiplatform \\\n",
    "                                        tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### 重新启动内核\n",
    "\n",
    "安装了额外的包之后，您需要重新启动笔记本内核，以便它可以找到这些包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "restart"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "##开始之前\n",
    "\n",
    "###GPU运行时\n",
    "\n",
    "此教程不需要GPU运行时。\n",
    "\n",
    "###设置您的Google Cloud项目\n",
    "\n",
    "**无论您使用什么笔记本环境，下面的步骤都是必需的。**\n",
    "\n",
    "1. [选择或创建一个Google Cloud项目](https://console.cloud.google.com/cloud-resource-manager)。您第一次创建帐户时，您会获得$300的免费信用额度，可用于计算/存储成本。\n",
    "\n",
    "2. [确保为您的项目启用了计费。](https://cloud.google.com/billing/docs/how-to/modify-project)\n",
    "\n",
    "3. [启用以下API：Vertex AI API、Compute Engine API和Cloud Storage。](https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,compute_component,storage-component.googleapis.com)\n",
    "\n",
    "4. 如果您在本地运行此笔记本，您需要安装[Cloud SDK]((https://cloud.google.com/sdk))。\n",
    "\n",
    "5. 在下面的单元格中输入您的项目ID。然后运行该单元格，以确保Cloud SDK在此笔记本中的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter会将以`!`为前缀的行作为shell命令运行，并会替换以`$`为前缀的Python变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用`gcloud`来获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 区域\n",
    "\n",
    "您还可以更改“REGION”变量，该变量用于本笔记本的其余部分操作。以下是Vertex AI支持的区域。我们建议您选择距离您最近的区域。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太地区：`asia-east1`\n",
    "\n",
    "您可能无法使用多区域存储桶来进行Vertex AI的训练。并非所有区域都支持所有Vertex AI服务。\n",
    "\n",
    "了解更多关于[Vertex AI区域](https://cloud.google.com/vertex-ai/docs/general/locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "UUID\n",
    "\n",
    "如果您正在进行实时教程会话，您可能正在使用共享的测试帐户或项目。为了避免用户在创建的资源之间发生名称冲突，您为每个实例会话创建一个uuid，并将其附加到您在本教程中创建的资源的名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "timestamp"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 认证您的Google Cloud帐户\n",
    "\n",
    "**如果您正在使用Vertex AI Workbench笔记本**，您的环境已经经过身份验证。\n",
    "\n",
    "**如果您正在使用Colab**，请运行下面的单元格，并按照提示进行身份验证，通过OAuth。\n",
    "\n",
    "**否则**，请按照以下步骤操作：\n",
    "\n",
    "在Cloud Console中，转到[创建服务帐户密钥](https://console.cloud.google.com/apis/credentials/serviceaccountkey)页面。\n",
    "\n",
    "**点击创建服务帐户**。\n",
    "\n",
    "在**服务帐户名称**字段中输入名称，然后点击**创建**。\n",
    "\n",
    "在**授予此服务帐户访问项目权限**部分，点击角色下拉列表。在过滤框中输入\"Vertex\"，然后选择**Vertex管理员**。在过滤框中输入\"Storage Object Admin\"，然后选择**存储对象管理员**。\n",
    "\n",
    "点击创建。包含您的密钥的JSON文件将下载到您的本地环境。\n",
    "\n",
    "在下面的单元格中将您的服务帐户密钥的路径输入为GOOGLE_APPLICATION_CREDENTIALS变量，然后运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcp_authenticate"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "**无论您使用的是哪种笔记本环境，都需要执行以下步骤。**\n",
    "\n",
    "当您初始化用于 Python 的 Vertex AI SDK 时，需要指定一个云存储暂存桶。这个暂存桶是您的数据集和模型资源在会话之间保留的地方。\n",
    "\n",
    "请在下方设置您的云存储桶的名称。存储桶的名称必须在所有谷歌云项目中全局唯一，包括您组织之外的项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_URI == \"\" or BUCKET_URI is None or BUCKET_URI == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_NAME = PROJECT_ID + \"aip-\" + UUID\n",
    "    BUCKET_URI = \"gs://\" + BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有在您的储存桶不存在时才能执行以下单元格以创建您的云存储储存桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "最后，通过检查云存储桶的内容来验证访问权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "###设定变量\n",
    "\n",
    "接下来，设定一些在本教程中使用的变量。\n",
    "###导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "初始化Vertex AI SDK适用于Python\n",
    "\n",
    "为您的项目和相应的存储桶初始化Vertex AI SDK适用于Python。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "source": [
    "#### 设置硬件加速器\n",
    "\n",
    "您可以为训练和预测设置硬件加速器。\n",
    "\n",
    "将变量 `DEPLOY_GPU/DEPLOY_NGPU` 设置为使用支持 GPU 的容器镜像，以及分配给虚拟机实例（VM）的 GPU 数量。例如，要使用一个带有 4 个 Nvidia Telsa K80 GPU 的容器镜像分配到每个 VM，您可以指定：\n",
    "\n",
    "(aip.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
    "\n",
    "否则，指定`(None, None)`来使用一个在 CPU 上运行的容器镜像。\n",
    "\n",
    "了解有关[您所在区域的硬件加速器支持](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)。\n",
    "\n",
    "了解更多关于[机器类型的 GPU 兼容性](https://cloud.google.com/vertex-ai/docs/training/configure-compute#gpu-compatibility-table)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_DEPLOY_GPU\"):\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (\n",
    "        aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "        int(os.getenv(\"IS_TESTING_DEPLOY_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于预测的机器类型。\n",
    "\n",
    "- 将变量 `DEPLOY_COMPUTE` 设置为配置用于预测的VM所需的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`: 每个vCPU有3.75GB内存。\n",
    "     - `n1-highmem`: 每个vCPU有6.5GB内存。\n",
    "     - `n1-highcpu`: 每个vCPU有0.9GB内存。\n",
    " - `vCPUs`: \\[2, 4, 8, 16, 32, 64, 96\\]中的数量\n",
    "\n",
    "*注意：您也可以在训练和部署时使用n2和e2机器类型，但它们不支持GPU*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_DEPLOY_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_DEPLOY_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tutorial_start:automl"
   },
   "source": [
    "现在您可以开始创建自己的AutoML表格二分类模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_file:u_dataset,csv"
   },
   "source": [
    "云存储训练数据的位置。\n",
    "\n",
    "现在将变量 `IMPORT_FILE` 设置为云存储中 CSV 索引文件的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:bank,csv,lbn"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = \"gs://cloud-ml-tables-data/bank-marketing.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick_peek:tabular"
   },
   "source": [
    "#### 快速查看您的数据\n",
    "\n",
    "本教程使用存储在公共云存储桶中的一个版本的银行营销数据集，使用CSV索引文件。\n",
    "\n",
    "首先快速查看数据。通过计算CSV索引文件中的行数（`wc -l`）来计算示例数，然后查看前几行。\n",
    "\n",
    "您还需要知道训练时标签列的标题名称，这个名称保存为`label_column`。对于这个数据集，它是CSV文件中的最后一列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quick_peek:tabular"
   },
   "outputs": [],
   "source": [
    "count = ! gsutil cat $IMPORT_FILE | wc -l\n",
    "print(\"Number of Examples\", int(count[0]))\n",
    "\n",
    "print(\"First 10 rows\")\n",
    "! gsutil cat $IMPORT_FILE | head\n",
    "\n",
    "heading = ! gsutil cat $IMPORT_FILE | head -n1\n",
    "label_column = str(heading).split(\",\")[-1].split(\"'\")[0]\n",
    "print(\"Label Column Name\", label_column)\n",
    "if label_column is None:\n",
    "    raise Exception(\"label column missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_dataset:tabular,lbn"
   },
   "source": [
    "### 创建数据集\n",
    "\n",
    "接下来，使用`TabularDataset`类的`create`方法创建`Dataset`资源，需要以下参数：\n",
    "\n",
    "- `display_name`：`Dataset`资源的可读名称。\n",
    "- `gcs_source`：一个或多个数据集索引文件的列表，用于将数据项导入`Dataset`资源中。\n",
    "- `bq_source`：或者，从BigQuery表中导入数据项到`Dataset`资源中。\n",
    "\n",
    "此操作可能需要几分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataset:tabular,lbn"
   },
   "outputs": [],
   "source": [
    "dataset = aiplatform.TabularDataset.create(\n",
    "    display_name=\"Bank Marketing_\" + UUID, gcs_source=[IMPORT_FILE]\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_automl_pipeline:tabular,lbn"
   },
   "source": [
    "### 创建并运行训练流水线\n",
    "\n",
    "为了训练一个AutoML模型，您需要执行两个步骤：1）创建一个训练流水线，2）运行流水线。\n",
    "\n",
    "#### 创建训练流水线\n",
    "\n",
    "使用`AutoMLTabularTrainingJob`类创建一个AutoML训练流水线，指定以下参数：\n",
    "\n",
    "- `display_name`：用于`TrainingJob`资源的可读名称。\n",
    "- `optimization_prediction_type`：要为模型训练的任务类型。\n",
    "  - `classification`：一个表格分类模型。\n",
    "  - `regression`：一个表格回归模型。\n",
    "- `column_transformations`：（可选）要应用于输入列的变换。\n",
    "- `optimization_objective`：要最小化或最大化的优化目标。\n",
    "  - 二元分类：\n",
    "    - `minimize-log-loss`\n",
    "    - `maximize-au-roc`\n",
    "    - `maximize-au-prc`\n",
    "    - `maximize-precision-at-recall`\n",
    "    - `maximize-recall-at-precision`\n",
    "  - 多类别分类：\n",
    "    - `minimize-log-loss`\n",
    "  - 回归：\n",
    "    - `minimize-rmse`\n",
    "    - `minimize-mae`\n",
    "    - `minimize-rmsle`\n",
    "\n",
    "实例化的对象是训练流水线的DAG（有向无环图）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_automl_pipeline:tabular,lbn"
   },
   "outputs": [],
   "source": [
    "dag = aiplatform.AutoMLTabularTrainingJob(\n",
    "    display_name=\"bank_\" + UUID,\n",
    "    optimization_prediction_type=\"classification\",\n",
    "    optimization_objective=\"minimize-log-loss\",\n",
    ")\n",
    "\n",
    "print(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_automl_pipeline:tabular"
   },
   "source": [
    "#### 运行训练管道\n",
    "\n",
    "接下来，您可以运行DAG来启动训练作业，通过调用`run`方法，并传入以下参数：\n",
    "\n",
    "- `dataset`：要训练模型的`Dataset`资源。\n",
    "- `model_display_name`：训练模型的可读名称。\n",
    "- `training_fraction_split`：用于训练的数据集百分比。\n",
    "- `test_fraction_split`：用于测试（留出数据）的数据集百分比。\n",
    "- `validation_fraction_split`：用于验证的数据集百分比。\n",
    "- `target_column`：作为标签进行训练的列名。\n",
    "- `budget_milli_node_hours`：（可选）以毫小时为单位指定的最大训练时间（1000 = 小时）。\n",
    "- `disable_early_stopping`：如果设置为`True`，则在服务认为无法进一步改善模型目标测量时，训练可能会提前完成预算使用。\n",
    "\n",
    "完成`run`方法后将返回`Model`资源。\n",
    "\n",
    "执行训练管道可能需要高达8小时。\n",
    "\n",
    "*注意：*与训练定制模型不同，经过训练的AutoML模型的相应服务二进制文件是预定义的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_automl_pipeline:tabular"
   },
   "outputs": [],
   "source": [
    "model = dag.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"bank_\" + UUID,\n",
    "    training_fraction_split=0.6,\n",
    "    validation_fraction_split=0.2,\n",
    "    test_fraction_split=0.2,\n",
    "    budget_milli_node_hours=8000,\n",
    "    disable_early_stopping=False,\n",
    "    target_column=label_column,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "628de0914ba1"
   },
   "source": [
    "创建 `Endpoint` 资源\n",
    "\n",
    "您可以使用 `Endpoint.create()` 方法创建 `Endpoint` 资源。至少，您需要指定端点的显示名称。可选地，您可以指定项目和位置（区域）；否则，设置会继承您使用 `init()` 方法初始化 Vertex AI SDK 时设置的值。\n",
    "\n",
    "在此示例中，指定了以下参数：\n",
    "\n",
    "- `display_name`：`Endpoint` 资源的可读名称。\n",
    "- `project`：您的项目 ID。\n",
    "- `location`：您的区域。\n",
    "- `labels`：（可选）`Endpoint` 的用户定义元数据，以键/值对的形式。\n",
    "\n",
    "此方法返回一个 `Endpoint` 对象。\n",
    "\n",
    "了解更多关于 [Vertex AI Endpoints](https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ea443f9593b"
   },
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint.create(\n",
    "    display_name=\"bank_\" + UUID,\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    labels={\"your_key\": \"your_value\"},\n",
    ")\n",
    "\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ca3fa3f6a894"
   },
   "source": [
    "将`Model`资源部署到`Endpoint`资源。\n",
    "\n",
    "您可以将一个或多个`Vertex AI Model`资源实例部署到同一个端点。每个部署的`Vertex AI Model`资源将拥有自己的用于服务二进制模型的部署容器。\n",
    "\n",
    "*注意：* 对于本示例，您的`AutoML`模型的部署容器是预定义的。\n",
    "\n",
    "### 扩展\n",
    "\n",
    "`Vertex AI Endpoint`资源支持三种类型的扩展：\n",
    "\n",
    "- 无扩展：服务二进制部署到单个VM实例。\n",
    "- 手动扩展：服务二进制部署到固定数量的多个VM实例。\n",
    "- 自动扩展：根据负载的不同，服务二进制被部署到的VM实例数量会有所变化。\n",
    "\n",
    "对于AutoML模型，只支持无扩展和手动扩展。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ae12f1afe50"
   },
   "source": [
    "### 手动扩展\n",
    "\n",
    "在下一个例子中，您会将`Vertex AI Model`资源部署到一个`Vertex AI Endpoint`资源中进行手动扩展——固定数量（大于1）的虚拟机实例。换句话说，当模型部署时，固定数量的虚拟机实例被预配并保持预配直到模型被取消部署。\n",
    "\n",
    "在这个例子中，您将使用最少数量的指定参数部署模型，如下所示：\n",
    "\n",
    "- `model`：要部署的`Model`资源。\n",
    "- `machine_type`：每个虚拟机实例的机器类型。\n",
    "- `deployed_model_displayed_name`：部署模型实例的可读名称。\n",
    "- `min_replica_count`：要预配的最小虚拟机实例（节点）数量。\n",
    "- `max_replica_count`：要预配的最大虚拟机实例（节点）数量。\n",
    "- `accelerator_type`：每个虚拟机实例的硬件加速器类型，如果有的话。\n",
    "- `accelerator_count`：每个虚拟机实例的硬件加速器数量，如果有的话。\n",
    "\n",
    "对于手动扩展，固定数量的虚拟机实例在模型部署期间被预配。\n",
    "\n",
    "*注意：* 对于手动扩展，节点的最小数和最大数设置为相同值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "277de42a6475"
   },
   "outputs": [],
   "source": [
    "MIN_NODES = 2\n",
    "MAX_NODES = 2\n",
    "\n",
    "if DEPLOY_NGPU:\n",
    "    response = endpoint.deploy(\n",
    "        model=model,\n",
    "        deployed_model_display_name=\"bank_\" + UUID,\n",
    "        machine_type=DEPLOY_COMPUTE,\n",
    "        min_replica_count=MIN_NODES,\n",
    "        max_replica_count=MAX_NODES,\n",
    "        accelerator_type=DEPLOY_GPU.name,\n",
    "        accelerator_count=DEPLOY_NGPU,\n",
    "    )\n",
    "else:\n",
    "    response = endpoint.deploy(\n",
    "        model=model,\n",
    "        deployed_model_display_name=\"bank_\" + UUID,\n",
    "        machine_type=DEPLOY_COMPUTE,\n",
    "        min_replica_count=MIN_NODES,\n",
    "        max_replica_count=MAX_NODES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_prediction"
   },
   "source": [
    "发送一个在线预测请求\n",
    "\n",
    "向您部署的模型发送一个在线预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_test_item:automl,online_prediction"
   },
   "source": [
    "制作测试项目\n",
    "\n",
    "您将使用合成数据作为测试数据项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "make_test_item:automl,tabular,bank"
   },
   "outputs": [],
   "source": [
    "INSTANCE = {\n",
    "    \"Age\": \"58\",\n",
    "    \"Job\": \"managment\",\n",
    "    \"MaritalStatus\": \"married\",\n",
    "    \"Education\": \"teritary\",\n",
    "    \"Default\": \"no\",\n",
    "    \"Balance\": \"2143\",\n",
    "    \"Housing\": \"yes\",\n",
    "    \"Loan\": \"no\",\n",
    "    \"Contact\": \"unknown\",\n",
    "    \"Day\": \"5\",\n",
    "    \"Month\": \"may\",\n",
    "    \"Duration\": \"261\",\n",
    "    \"Campaign\": \"1\",\n",
    "    \"PDays\": \"-1\",\n",
    "    \"Previous\": \"0\",\n",
    "    \"POutcome\": \"unknown\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "predict_request:mbsdk,lbn"
   },
   "source": [
    "### 进行预测\n",
    "\n",
    "现在您的`Model`资源已部署到一个`Endpoint`资源上，您可以通过向`Endpoint`资源发送预测请求来进行在线预测。\n",
    "\n",
    "#### 请求\n",
    "\n",
    "每个实例的格式为：\n",
    "\n",
    "    [feature_list]\n",
    "\n",
    "由于`predict()`方法可以接受多个项目（实例），请将您的单个测试项作为一个测试项列表发送。\n",
    "\n",
    "#### 响应\n",
    "\n",
    "从`predict()`调用的响应是一个Python字典，包含以下条目：\n",
    "\n",
    "- `ids`：每个预测请求的内部分配的唯一标识符。\n",
    "- `displayNames`：每个类标签的类名。\n",
    "- `confidences`：每个类标签的预测置信度，介于0和1之间。\n",
    "- `deployed_model_id`：执行预测的已部署`Model`资源的Vertex AI标识符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "predict_request:mbsdk,lbn"
   },
   "outputs": [],
   "source": [
    "instances_list = [INSTANCE]\n",
    "\n",
    "prediction = endpoint.predict(instances_list)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_prediction:xai"
   },
   "source": [
    "发送一个带有可解释性的在线预测请求\n",
    "\n",
    "向部署的模型发送一个带有可解释性的在线预测请求。在这种方法中，预测的响应将包括一个关于特征如何 contributed to the explanation的解释。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "explain_request:mbsdk,lcn"
   },
   "source": [
    "现在，您的“模型”资源已部署到“端点”资源，可以通过向“端点”资源发送预测请求来进行在线解释。\n",
    "\n",
    "#### 请求\n",
    "\n",
    "每个实例的格式为：\n",
    "\n",
    "    [feature_list]\n",
    "\n",
    "由于explain()方法可以接受多个项目（实例），请将您的单个测试项目作为一个测试项目列表发送。\n",
    "\n",
    "#### 响应\n",
    "\n",
    "从explain()调用中得到的响应是一个包含以下条目的Python字典：\n",
    "\n",
    "- `ids`：每个预测请求的内部分配的唯一标识符。\n",
    "- `displayNames`：每个类别标签的类别名称。\n",
    "- `confidences`：对于分类任务，每个类别标签的预测置信度，介于0和1之间。\n",
    "- `values`：对于回归任务，预测的值。\n",
    "- `deployed_model_id`：执行预测的部署的“模型”资源的Vertex AI标识符。\n",
    "- `explanations`：特征归因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "explain_request:mbsdk,lcn"
   },
   "outputs": [],
   "source": [
    "instances_list = [INSTANCE]\n",
    "\n",
    "prediction = endpoint.explain(instances_list)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "understand_explanations"
   },
   "source": [
    "### 理解解释的回应\n",
    "\n",
    "首先，您需要查看您的模型预测结果并将其与实际值进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "understand_explanations:mbsdk,lcn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    label = np.argmax(prediction[0][0][\"scores\"])\n",
    "    cls = prediction[0][0][\"classes\"][label]\n",
    "    print(\"Predicted Value:\", cls, prediction[0][0][\"scores\"][label])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_feature_attributions"
   },
   "source": [
    "### 检查特征归因\n",
    "\n",
    "接下来，您将查看此特定示例的特征归因。积极的归因值意味着特定特征将您的模型预测值上升了该量，反之负值意味着特征将您的模型预测值下降了该量。\n",
    "\n",
    "归因值的总和等于基准平均值和预测值之间的差值，例如，`baseline_average_value - predicted_value)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "examine_feature_attributions:mbsdk,iris"
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    \"Age\",\n",
    "    \"Job\",\n",
    "    \"MaritalStatus\",\n",
    "    \"Education\",\n",
    "    \"Default\",\n",
    "    \"Balance\",\n",
    "    \"Housing\",\n",
    "    \"Loan\",\n",
    "    \"Contact\",\n",
    "    \"Day\",\n",
    "    \"Month\",\n",
    "    \"Duration\",\n",
    "    \"Campaign\",\n",
    "    \"PDays\",\n",
    "    \"Previous\",\n",
    "    \"POutcome\",\n",
    "]\n",
    "attributions = prediction.explanations[0].attributions[0].feature_attributions\n",
    "\n",
    "rows = []\n",
    "for i, val in enumerate(feature_names):\n",
    "    rows.append([val, INSTANCE[val], attributions[val]])\n",
    "print(tabulate(rows, headers=[\"Feature name\", \"Feature value\", \"Attribution value\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check_explanations_baselines"
   },
   "source": [
    "### 检查您的解释和基线\n",
    "\n",
    "为了更好地理解您获得的特征归因，您应该将它们与您模型的基线进行比较。在大多数情况下，您的归因值之和加上基线应该非常接近每个输入的模型预测值。另外，请注意，对于回归模型，从 AI 解释返回的`baseline_score`将对发送到您的模型的每个示例都是相同的。对于分类模型，每个类别将有自己的基线。\n",
    "\n",
    "在本节中，您将向您的模型发送 10 个测试示例进行预测，以便将特征归因与基线进行比较。然后，您将通过`sanity_check_explanations`方法对每个测试示例的归因进行一次逻辑检查。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_explanations_baselines:mbsdk,iris"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Prepare 10 test examples to your model for prediction using a random distribution to generate\n",
    "# test instances\n",
    "instances = []\n",
    "for i in range(10):\n",
    "    age = str(random.randint(25, 65))\n",
    "    job = [\"management\", \"technican\", \"unknown\"][random.randint(0, 2)]\n",
    "    status = [\"single\", \"married\", \"divorced\"][random.randint(0, 2)]\n",
    "    ed = [\"primary\", \"secondary\", \"tertiary\"][random.randint(0, 2)]\n",
    "    df = [\"yes\", \"no\"][random.randint(0, 1)]\n",
    "    bal = str(random.randint(0, 4000))\n",
    "    housing = [\"yes\", \"no\"][random.randint(0, 1)]\n",
    "    loan = [\"yes\", \"no\"][random.randint(0, 1)]\n",
    "    contact = \"unknown\"\n",
    "    day = str(random.randint(1, 28))\n",
    "    month = \"may\"\n",
    "    dur = str(random.randint(1, 360))\n",
    "    camp = str(random.randint(0, 1))\n",
    "    pdays = \"-1\"\n",
    "    previous = \"0\"\n",
    "    poutcome = \"unknown\"\n",
    "    instances.append(\n",
    "        {\n",
    "            \"Age\": age,\n",
    "            \"Job\": job,\n",
    "            \"MaritalStatus\": status,\n",
    "            \"Education\": ed,\n",
    "            \"Default\": df,\n",
    "            \"Balance\": bal,\n",
    "            \"Housing\": housing,\n",
    "            \"Loan\": loan,\n",
    "            \"Contact\": contact,\n",
    "            \"Day\": day,\n",
    "            \"Month\": month,\n",
    "            \"Duration\": dur,\n",
    "            \"Campaign\": camp,\n",
    "            \"PDays\": pdays,\n",
    "            \"Previous\": previous,\n",
    "            \"POutcome\": poutcome,\n",
    "        }\n",
    "    )\n",
    "\n",
    "response = endpoint.explain(instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sanity_check_explanations"
   },
   "source": [
    "#### 健康检查\n",
    "\n",
    "在下面的功能中，您对解释进行了健康检查。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sanity_check_explanations"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sanity_check_explanations(\n",
    "    explanation, prediction, mean_tgt_value=None, variance_tgt_value=None\n",
    "):\n",
    "    passed_test = 0\n",
    "    total_test = 1\n",
    "    # `attributions` is a dict where keys are the feature names\n",
    "    # and values are the feature attributions for each feature\n",
    "    baseline_score = explanation.attributions[0].baseline_output_value\n",
    "    print(\"baseline:\", baseline_score)\n",
    "\n",
    "    # Sanity check 1\n",
    "    # The prediction at the input is equal to that at the baseline.\n",
    "    #  Please use a different baseline. Some suggestions are: random input, training\n",
    "    #  set mean.\n",
    "    if abs(prediction - baseline_score) <= 0.05:\n",
    "        print(\"Warning: example score and baseline score are too close.\")\n",
    "        print(\"You might not get attributions.\")\n",
    "    else:\n",
    "        passed_test += 1\n",
    "        print(\"Sanity Check 1: Passed\")\n",
    "\n",
    "    print(passed_test, \" out of \", total_test, \" sanity checks passed.\")\n",
    "\n",
    "\n",
    "i = 0\n",
    "for explanation in response.explanations:\n",
    "    try:\n",
    "        prediction = np.max(response.predictions[i][\"scores\"])\n",
    "    except TypeError:\n",
    "        prediction = np.max(response.predictions[i])\n",
    "    sanity_check_explanations(explanation, prediction)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "source": [
    "取消部署模型\n",
    "\n",
    "当完成预测后，您可以从`Vertex AI Endpoint`资源中取消部署模型。这将清除所有计算资源并停止已部署模型的计费。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d43f29ad633"
   },
   "source": [
    "删除模型\n",
    "\n",
    "接下来，您可以使用`delete()`方法删除`Vertex AI Model`资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0feab0a0b5d7"
   },
   "outputs": [],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42edc3105657"
   },
   "source": [
    "删除数据集\n",
    "\n",
    "接下来，您可以使用 `delete()` 方法删除 `Vertex AI Dataset` 资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5f999471744"
   },
   "outputs": [],
   "source": [
    "dataset.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于本教程的[Google Cloud 项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "outputs": [],
   "source": [
    "delete_bucket = False\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -rf {BUCKET_URI}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_with_automl_tabular_model_online.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
