{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dd626314fed"
   },
   "source": [
    "# GCP 上的 E2E 机器学习：MLOps 阶段 6：serving：使用定制部署容器快速开始使用 Vertex Explainable AI\n",
    "\n",
    "这是由 [Brian Kang 和 Siping Hu](https://colab.corp.google.com/drive/1aYERnouogPXqlCHlfDRCff04BMV1JpyE?resourcekey=0-BrkuuARc--pA7CvD5LS-oQ#scrollTo=cuKvd9SrmIQw) 贡献的 Colab 笔记本的更新版本。\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_xai_and_custom_server.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_xai_and_custom_server.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage6/get_started_with_xai_and_custom_server.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在 Vertex AI Workbench 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "424e4efb7a8d"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何在Google Cloud上使用Vertex AI进行端到端MLOps生产。本教程涵盖了第6阶段：serving: 使用可解释的AI开始进行自定义部署容器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何构建一个自定义容器来为`Vertex AI Endpoint`上的PyTorch模型提供服务。您将使用FastAPI Python web服务器框架来创建用于服务二进制文件的HTTP服务器。然后，您将将该容器推送到`Artifact Registry`，部署模型，并进行预测和解释请求。\n",
    "\n",
    "本教程使用以下Google Cloud ML服务:\n",
    "\n",
    "- `Vertex AI Prediction`\n",
    "- `Vertex Explainable AI`\n",
    "- `Google Artifact Registry`\n",
    "\n",
    "执行的步骤包括:\n",
    "\n",
    "- 在本地训练PyTorch表格分类器。\n",
    "- 在本地测试训练模型。\n",
    "- 使用FastAPI构建HTTP服务器。\n",
    "- 创建一个包含训练模型和FastAPI服务器的自定义服务容器。\n",
    "- 在本地测试自定义服务容器。\n",
    "- 将自定义服务容器推送到Artifact Registry。\n",
    "- 将自定义服务容器上传为`Model`资源。\n",
    "- 部署`Model`资源到`Endpoint`资源。\n",
    "- 向部署的自定义服务容器发送预测请求。\n",
    "- 向部署的自定义服务容器发出解释请求。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c2f46b60759"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是来自[Scikit-Learn Datasets](https://scikit-learn.org/stable/datasets/)的[Iris数据集](https://scikit-learn.org/stable/datasets/index.html#iris-dataset)。该数据集不需要任何特征工程。训练好的模型可以预测三种不同种类的鸢尾花品种：山鸢尾（setosa）、维吉尼亚鸢尾（virginica）或者变色鸢尾（versicolor）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a61ca6d7eb5c"
   },
   "source": [
    "### 费用\n",
    "\n",
    "本教程使用 Google Cloud 中可计费的组件：\n",
    "\n",
    "* Vertex AI\n",
    "\n",
    "了解 [Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing)，并使用 [定价计算器](https://cloud.google.com/products/calculator/) 根据您的预期使用量生成费用估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ze4-nDLfK4pw"
   },
   "source": [
    "搭建本地开发环境\n",
    "\n",
    "**如果您正在使用Colab或Vertex AI Workbench笔记本**，您的环境已满足运行这个笔记本的所有要求。您可以跳过这一步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCuSR8GkAgzl"
   },
   "source": [
    "否则，请确保您的环境符合此笔记本的要求。\n",
    "您需要以下内容：\n",
    "\n",
    "* Docker\n",
    "* Git\n",
    "* Google Cloud SDK（gcloud）\n",
    "* Python 3\n",
    "* virtualenv\n",
    "* 在使用Python 3的虚拟环境中运行的Jupyter笔记本\n",
    "\n",
    "Google Cloud的Python开发环境设置指南和Jupyter安装指南提供了满足这些要求的详细说明。以下步骤提供了简明的说明：\n",
    "\n",
    "1. [安装和初始化Cloud SDK。](https://cloud.google.com/sdk/docs/)\n",
    "\n",
    "2. [安装Python 3。](https://cloud.google.com/python/setup#installing_python)\n",
    "\n",
    "3. [安装virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv)并创建一个使用Python 3的虚拟环境。激活虚拟环境。\n",
    "\n",
    "4. 要安装Jupyter，在终端窗口的命令行中运行 `pip install jupyter`。\n",
    "\n",
    "5. 要启动Jupyter，在终端窗口的命令行中运行 `jupyter notebook`。\n",
    "\n",
    "6. 在Jupyter Notebook仪表板中打开此笔记本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_mlops"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装执行此笔记本所需的包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fd7b50e225c3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "! pip3 install joblib {USER_FLAG} -q\n",
    "! pip3 install numpy {USER_FLAG} -q\n",
    "! pip3 install scikit-learn {USER_FLAG} -q\n",
    "! pip3 install torch {USER_FLAG} -q\n",
    "! pip3 install \"uvicorn[standard]>=0.12.0,<0.14.0\" fastapi~=0.63 {USER_FLAG} -q\n",
    "! pip3 install --upgrade google-cloud-aiplatform {USER_FLAG} -q\n",
    "! pip3 install --upgrade google-cloud-storage {USER_FLAG} -q\n",
    "! pip3 install --upgrade python-tabulate $USER_FLAG -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhq5zEbGg0XX"
   },
   "source": [
    "### 重新启动内核\n",
    "\n",
    "在安装额外的包之后，您需要重新启动笔记本内核，这样它才能找到这些包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzrelQZ22IZj"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWEdiXsJg0XY"
   },
   "source": [
    "在你开始之前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "### 设置您的Google Cloud项目\n",
    "\n",
    "**无论您的笔记本环境如何，都需要执行以下步骤。**\n",
    "\n",
    "1. [选择或创建一个Google Cloud项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建帐户时，您将获得$300的免费信用额度，可用于计算/存储成本。\n",
    "\n",
    "1. [确保您的项目已启用计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "1. [启用Vertex AI API和Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component)。\n",
    "\n",
    "1. 如果您在本地运行此笔记本，您需要安装[Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "1. 在下面的单元格中输入您的项目ID。然后运行该单元格，以确保Cloud SDK对本笔记本中的所有命令使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter在带有`!`或`%`前缀的行上运行，它会将Python变量插入到这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "#### 设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用`gcloud`来获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "区域\n",
    "\n",
    "您也可以更改`REGION`变量，该变量用于本笔记本的其余操作。以下是 Vertex AI 支持的区域。我们建议您选择距离您最近的区域。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太：`asia-east1`\n",
    "\n",
    "您不能在 Vertex AI 上使用多区域存储桶进行训练。并非所有区域都支持所有 Vertex AI 服务。\n",
    "\n",
    "了解更多关于[Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "时间戳\n",
    "\n",
    "如果您在进行直播教程会话，您可能会使用共享的测试帐户或项目。为避免用户在创建的资源之间发生名称冲突，您需要为每个实例会话创建一个时间戳，并将时间戳附加到您在本教程中创建的资源的名称中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "timestamp"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ffa6b6c7cdb"
   },
   "source": [
    "### 验证您的谷歌云账户\n",
    "\n",
    "**如果您正在使用Vertex AI Workbench Notebooks**，您的环境已经通过身份验证。\n",
    "\n",
    "**如果您正在使用Colab**，运行下面的单元格，并在提示时按照说明进行oAuth身份验证。\n",
    "\n",
    "**否则**，请按照以下步骤操作：\n",
    "\n",
    "在Cloud Console中，转到[创建服务账户密钥](https://console.cloud.google.com/apis/credentials/serviceaccountkey)页面。\n",
    "\n",
    "1. **点击创建服务账户**。\n",
    "\n",
    "2. 在**服务账户名称**字段中输入一个名称，然后点击**创建**。\n",
    "\n",
    "3. 在**授予该服务账户项目访问权限**部分，点击角色下拉列表。在过滤框中输入“Vertex AI”，并选中**Vertex AI管理员**。在过滤框中输入“存储对象管理员”，并选中**存储对象管理员**。\n",
    "\n",
    "4. 点击创建。一个包含您密钥的JSON文件将下载到本地环境。\n",
    "\n",
    "5. 在下面的单元格中将您的服务账户密钥路径作为GOOGLE_APPLICATION_CREDENTIALS变量输入，并运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b72272258fc"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "**无论您的笔记本环境如何，都需要执行以下步骤。**\n",
    "\n",
    "在初始化用于Python的Vertex SDK时，您需要指定一个云存储分期桶。分期桶是您的数据集和模型资源在会话之间保留的地方。\n",
    "\n",
    "请在下面设置您的云存储桶的名称。桶的名称必须在所有Google Cloud项目中全局唯一，包括您组织之外的项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_URI == \"\" or BUCKET_URI is None or BUCKET_URI == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_NAME = PROJECT_ID + \"aip-\" + TIMESTAMP\n",
    "    BUCKET_URI = \"gs://\" + BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有当您的存储桶不存在时：运行以下单元格以创建您的云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "最后，通过检查Cloud Storage桶的内容来验证对其的访问权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。\n",
    "\n",
    "### 导入库并定义常数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "### 初始化 Vertex AI SDK for Python\n",
    "\n",
    "为您的项目和相应的存储桶初始化 Vertex AI SDK for Python。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf"
   },
   "source": [
    "### 配置项目和资源名称\n",
    "\n",
    "`IMAGE` - 将要推送的容器图像的名称。\n",
    "\n",
    "`MODEL_DISPLAY_NAME` - Vertex AI 模型资源的显示名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "IMAGE = \"xai-fastapi-server\"  # @param {type:\"string\"}\n",
    "MODEL_DISPLAY_NAME = \"xai-fastapi-custom-container\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gar_enable_api"
   },
   "source": [
    "### 启用制品注册表 API\n",
    "\n",
    "首先，您必须为您的项目启用制品注册表 API 服务。\n",
    "\n",
    "了解更多关于 [启用服务](https://cloud.google.com/artifact-registry/docs/enable-service)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gar_enable_api"
   },
   "outputs": [],
   "source": [
    "! gcloud services enable artifactregistry.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gar_create_repo"
   },
   "source": [
    "### 创建一个私有的 Docker 仓库\n",
    "\n",
    "您的第一步是在 Google Artifact Registry 中创建您自己的 Docker 仓库。\n",
    "\n",
    "1. 运行 `gcloud artifacts repositories create` 命令，使用您的地区和描述“docker 仓库”来创建一个新的 Docker 仓库。\n",
    "\n",
    "2. 运行 `gcloud artifacts repositories list` 命令来验证您的仓库是否已创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gar_create_repo"
   },
   "outputs": [],
   "source": [
    "PRIVATE_REPO = \"my-docker-repo\"\n",
    "\n",
    "! gcloud artifacts repositories create {PRIVATE_REPO} --repository-format=docker --location={REGION} --description=\"Docker repository\"\n",
    "\n",
    "! gcloud artifacts repositories list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gar_auth"
   },
   "source": [
    "### 配置对您的私有存储库的身份验证\n",
    "\n",
    "在推送或拉取容器镜像之前，配置Docker使用`gcloud`命令行工具来对您所在地区的`Artifact Registry`进行身份验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gar_auth"
   },
   "outputs": [],
   "source": [
    "! gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4b816cd52f4b"
   },
   "source": [
    "## 训练模型\n",
    "\n",
    "接下来，您将为模型创建训练脚本，然后在本地训练模型。\n",
    "\n",
    "### 脚本\n",
    "\n",
    "您将创建以下脚本：\n",
    "\n",
    "- `data.py`：返回经过预处理的训练数据。\n",
    "- `model.py`：返回用于训练的模型架构。\n",
    "- `train.py`：返回训练好的模型。\n",
    "- `server.py`：创建模型服务器。\n",
    "- `main.py`：创建HTTP服务器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6e74556ea0b4"
   },
   "outputs": [],
   "source": [
    "%mkdir app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "269be534fab2"
   },
   "source": [
    "### 创建数据预处理脚本\n",
    "\n",
    "接下来，您创建脚本`data.py`来获取数据集并预处理训练数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MySs9l18mIQn"
   },
   "outputs": [],
   "source": [
    "%%writefile app/data.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def get_data():\n",
    "    # Dataset\n",
    "    iris = load_iris()\n",
    "    X = iris['data']\n",
    "    y = iris['target']\n",
    "    names = iris['target_names']\n",
    "    feature_names = iris['feature_names']\n",
    "\n",
    "    # Scale data to have mean 0 and variance 1 \n",
    "    # which is importance for convergence of the neural network\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split the data set into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=2)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fca78723a98"
   },
   "source": [
    "在本地测试脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74d91f8a330b"
   },
   "outputs": [],
   "source": [
    "! python3 app/data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15f228bf14e7"
   },
   "source": [
    "### 创建获取模型架构的脚本\n",
    "\n",
    "接下来，您创建返回用于训练的模型架构的脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jb8K8TI8mIQn"
   },
   "outputs": [],
   "source": [
    "%%writefile app/model.py\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "# Build model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 50)\n",
    "        self.layer2 = nn.Linear(50, 50)\n",
    "        self.layer3 = nn.Linear(50, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.softmax(self.layer3(x), dim=1)\n",
    "        return x  \n",
    "    \n",
    "def get_model(X_train):\n",
    "    model = Model(X_train.shape[1])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn   = nn.CrossEntropyLoss()\n",
    "    print(model)\n",
    "    return model, optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "584620fa3554"
   },
   "source": [
    "在本地测试脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1311d9e7b9d3"
   },
   "outputs": [],
   "source": [
    "! python3 app/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9db8bddfa2f0"
   },
   "source": [
    "### 训练模型\n",
    "\n",
    "接下来，您要创建用于训练模型的脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jCpXDQ6mIQo"
   },
   "outputs": [],
   "source": [
    "%%writefile app/train.py\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from data import get_data\n",
    "from model import get_model\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_data()\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Train and save the model\n",
    "EPOCHS  = 100\n",
    "X_train = Variable(torch.from_numpy(X_train)).float()\n",
    "y_train = Variable(torch.from_numpy(y_train)).long()\n",
    "X_test  = Variable(torch.from_numpy(X_test)).float()\n",
    "y_test  = Variable(torch.from_numpy(y_test)).long()\n",
    "\n",
    "model, optimizer, loss_fn = get_model(X_train)\n",
    "\n",
    "loss_list = np.zeros((EPOCHS,))\n",
    "accuracy_list = np.zeros((EPOCHS,))\n",
    "\n",
    "for epoch in tqdm.trange(EPOCHS):\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss_list[epoch] = loss.item()\n",
    "    \n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "        correct = (torch.argmax(y_pred, dim=1) == y_test).type(torch.FloatTensor)\n",
    "        accuracy_list[epoch] = correct.mean()\n",
    "\n",
    "# Save the model to a checkpoint\n",
    "print('Saving..')\n",
    "state = {\n",
    "    'net': model.state_dict(),\n",
    "}\n",
    "if not os.path.isdir('app'):\n",
    "    os.mkdir('app')\n",
    "torch.save(state, './app/model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d00985dcb64c"
   },
   "source": [
    "测试本地脚本。这将训练模型并将模型工件存储在`app/model.pth`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "008d9fd058c8"
   },
   "outputs": [],
   "source": [
    "! python3 app/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d79932fd90be"
   },
   "source": [
    "### 创建模型服务器\n",
    "\n",
    "接下来，创建用于提供模型的脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zTr509nmIQo"
   },
   "outputs": [],
   "source": [
    "%%writefile app/server.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import os\n",
    "\n",
    "from model import Model\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "class IrisClassifier:\n",
    "    def __init__(self, model_artifact):\n",
    "        self.net = Model(4)\n",
    "        self.checkpoint = torch.load(model_artifact)\n",
    "        self.net.load_state_dict(self.checkpoint['net'])\n",
    "        self.net.eval()\n",
    "        self.iris_type = {\n",
    "            0: 'setosa',\n",
    "            1: 'versicolor',\n",
    "            2: 'virginica'\n",
    "        }\n",
    "        \n",
    "    def predict(self, features:dict):\n",
    "        X = [features['sepal_length'], features['sepal_width'], features['petal_length'], features['petal_width']]\n",
    "        X = torch.tensor(X)\n",
    "        X  = torch.unsqueeze(X, 0)\n",
    "        with torch.no_grad():\n",
    "            output = self.net(X)\n",
    "            prob, clas =  output.max(1)\n",
    "\n",
    "        return {'class': self.iris_type[int(clas.cpu().detach().numpy()[0])],\n",
    "                'probability': float(prob.cpu().detach().numpy()[0])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8e1d823cec63"
   },
   "source": [
    "在本地测试脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5f037ed613e3"
   },
   "outputs": [],
   "source": [
    "! python3 app/server.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "465f90d67387"
   },
   "source": [
    "### 在本地执行模型服务器测试\n",
    "\n",
    "接下来，通过实例化模型服务器并进行本地预测请求来测试模型服务器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYuRVgB5mIQp"
   },
   "outputs": [],
   "source": [
    "%%writefile app/test.py\n",
    "import torch\n",
    "from server import IrisClassifier\n",
    "model = IrisClassifier('./app/model.pth')\n",
    "\n",
    "# The features are scaled\n",
    "pred1 = model.predict(features={\"sepal_length\": -1.38535265, \"sepal_width\": 0.32841405,\n",
    "                                \"petal_length\": -1.39706395, \"petal_width\": 1.3154443})\n",
    "pred2  = model.predict(features={\"sepal_length\": -1.02184904, \"sepal_width\": -2.43394714,\n",
    "                                 \"petal_length\": -0.14664056, \"petal_width\": -0.26238682})\n",
    "print(pred1)\n",
    "print(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1e8ad052ce0"
   },
   "outputs": [],
   "source": [
    "! python3 app/test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "480a1d88ecdb"
   },
   "source": [
    "### 构建一个FastAPI HTTP服务器\n",
    "\n",
    "最后，在部署容器中，您将需要一个HTTP服务器来处理 `predict` 和 `health` 请求。您可以使用FastAPI来构建HTTP服务器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94af0ba5eadd"
   },
   "outputs": [],
   "source": [
    "%%writefile app/main.py\n",
    "from fastapi import FastAPI, Request\n",
    "from starlette.responses import JSONResponse\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from google.cloud import storage\n",
    "from server import *\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "'''\n",
    "gcs_client = storage.Client()\n",
    "\n",
    "with open(\"model.joblib\", 'wb') as model_f:\n",
    "    gcs_client.download_blob_to_file(\n",
    "        f\"{os.environ['AIP_STORAGE_URI']}/model.joblib\", model_f\n",
    "    )\n",
    "\n",
    "#_model = joblib.load(\"model.joblib\")\n",
    "'''\n",
    "\n",
    "@app.get(os.environ['AIP_HEALTH_ROUTE'], status_code=200)\n",
    "def health():\n",
    "    return {\"status\": \"healthy\"}\n",
    "\n",
    "\n",
    "@app.post(os.environ['AIP_PREDICT_ROUTE'])\n",
    "async def predict(request: Request):\n",
    "    body = await request.json()\n",
    "    print (body)\n",
    "    \n",
    "    import os\n",
    "    print(os.listdir())\n",
    "\n",
    "    model = IrisClassifier('./model.pth')\n",
    "    \n",
    "    instances = body[\"instances\"]\n",
    "    output = []\n",
    "    for i in instances:\n",
    "        output.append(model.predict(i))\n",
    "        print(model.predict(i))\n",
    "    #return 'class' and 'probability'\n",
    "    return JSONResponse({\"predictions\": output})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "469f55daf250"
   },
   "source": [
    "### 添加预启动脚本\n",
    "\n",
    "FastAPI将在启动服务器之前执行此脚本。`PORT`环境变量设置为等于`AIP_HTTP_PORT`，以便在与Vertex AI期望的端口相同的端口上运行FastAPI。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69f438aca35b"
   },
   "outputs": [],
   "source": [
    "%%writefile app/prestart.sh\n",
    "#!/bin/bash\n",
    "export PORT=$AIP_HTTP_PORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b62ddf1def3"
   },
   "source": [
    "将测试示例存储以备后用\n",
    "\n",
    "接下来，您需要创建一个 JSON 文件，用于向模型服务器发送测试预测请求。\n",
    "\n",
    "了解更多关于[在线预测请求格式的信息](https://cloud.google.com/vertex-ai/docs/predictions/online-predictions-custom-models#request-body-details)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6605e9e6186"
   },
   "outputs": [],
   "source": [
    "%%writefile instances.json\n",
    "{\n",
    "    \"instances\": [{\n",
    "        \"sepal_length\": -1.38535265,\n",
    "        \"sepal_width\": 0.32841405,\n",
    "        \"petal_length\": -1.39706395,\n",
    "        \"petal_width\": 1.3154443\n",
    "    },{\n",
    "        \"sepal_length\": -1.02184904,\n",
    "        \"sepal_width\": -2.43394714,\n",
    "        \"petal_length\": -0.14664056,\n",
    "        \"petal_width\": -0.26238682\n",
    "    }]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51e149fdec1b"
   },
   "source": [
    "## 构建并推送容器到工件注册表\n",
    "\n",
    "接下来，您将构建自定义部署容器。\n",
    "\n",
    "### 创建要求文件\n",
    "\n",
    "首先，创建用于所需安装软件包的requirements.txt文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c52b830d5a92"
   },
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "joblib~=1.0\n",
    "numpy~=1.20\n",
    "scikit-learn~=0.24\n",
    "google-cloud-storage>=1.26.0,<2.0.0dev\n",
    "torch~=1.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "240578ec9efe"
   },
   "source": [
    "构建自己的容器\n",
    "\n",
    "编写 Dockerfile，以 `tiangolo/uvicorn-gunicorn-fastapi` 作为基础镜像。这将自动使用 Gunicorn 和 Uvicorn 为您运行 FastAPI。访问[FastAPI文档了解更多关于如何使用Docker部署FastAPI](https://fastapi.tiangolo.com/deployment/docker/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3d3a6b9ed22b"
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
    "\n",
    "COPY ./app /app\n",
    "COPY requirements.txt requirements.txt\n",
    "\n",
    "RUN pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04c988201499"
   },
   "source": [
    "构建并标记部署镜像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1e7d639b9cc"
   },
   "outputs": [],
   "source": [
    "DEPLOY_IMAGE = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{PRIVATE_REPO}/{IMAGE}\"\n",
    "\n",
    "if not IS_COLAB:\n",
    "    ! docker build -t $DEPLOY_IMAGE .\n",
    "else:\n",
    "    # install docker daemon\n",
    "    ! apt-get -qq install docker.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "147a555f6c93"
   },
   "source": [
    "### 在本地运行和测试容器（可选）\n",
    "\n",
    "以分离模式在本地运行容器，并提供容器所需的环境变量。这些环境变量将在部署后由 Vertex Prediction 提供给容器。测试 `/health` 和 `/predict` 路由，然后停止运行的镜像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62ed2d334d0f"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "\n",
    "    ! docker stop local-iris 2>/dev/null\n",
    "    ! docker rm local-iris 2>/dev/null\n",
    "    container_id = ! docker run -d -p 80:8080 \\\n",
    "        --name=local-iris \\\n",
    "        -e AIP_HTTP_PORT=8080 \\\n",
    "        -e AIP_HEALTH_ROUTE=/health \\\n",
    "        -e AIP_PREDICT_ROUTE=/predict \\\n",
    "        -e AIP_STORAGE_URI={BUCKET_URI}/{MODEL_ARTIFACT_DIR} \\\n",
    "        -e GOOGLE_APPLICATION_CREDENTIALS=credentials.json \\\n",
    "        {DEPLOY_IMAGE}\n",
    "\n",
    "    ! sleep 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b2efa66d50c"
   },
   "source": [
    "测试健康路由\n",
    "\n",
    "接下来，测试部署容器的健康路由。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce629eea32fd"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! curl localhost/health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "687aa32007c5"
   },
   "source": [
    "显示相应的日志条目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "do4r-MI-5Vug"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! docker logs {container_id[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e9458d82ea8"
   },
   "source": [
    "测试预测路线\n",
    "\n",
    "接下来，测试部署容器的预测路线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BeFu0W_GmIQt"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! curl -X POST \\\n",
    "      -d @instances.json \\\n",
    "      -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "      localhost/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6e1ed9fa1d14"
   },
   "source": [
    "显示相应的日志条目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3f666f0e020c"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! docker logs {container_id[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eeed192b3ca"
   },
   "source": [
    "停止Docker镜像\n",
    "\n",
    "现在您已经在本地测试了Docker镜像，您可以停止Docker镜像的执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlpGgblsmIQt"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! docker stop local-iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "name_container:training"
   },
   "source": [
    "将容器推送到Artifact Registry\n",
    "\n",
    "接下来，您将为您的客户容器提供一个名称，以便在提交到Google Artifact Registry时使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dd7448f4703"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! docker push {REGION}-docker.pkg.dev/{PROJECT_ID}/{PRIVATE_REPO}/{IMAGE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f50e9c553fb7"
   },
   "source": [
    "在 Colab 中执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7e8c98f1e56"
   },
   "outputs": [],
   "source": [
    "%%bash -s $IS_COLAB $DEPLOY_IMAGE\n",
    "if [ $1 == \"False\" ]; then\n",
    "  exit 0\n",
    "fi\n",
    "set -x\n",
    "dockerd -b none --iptables=0 -l warn &\n",
    "for i in $(seq 5); do [ ! -S \"/var/run/docker.sock\" ] && sleep 2 || break; done\n",
    "docker build . -t $2\n",
    "docker push $2\n",
    "kill $(jobs -p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b438bfa2129f"
   },
   "source": [
    "## 上传自定义服务容器作为Vertex AI `Model` 资源。\n",
    "\n",
    "接下来，您将上传您的自定义服务容器作为 `Model` 资源。\n",
    "\n",
    "### 设置说明配置\n",
    "\n",
    "首先，您需要指定解释设置，这些设置将作为参数传递给上传自定义服务容器时。\n",
    "\n",
    "**注意**：在选择要用于特征归因的方法时，请确保该方法与您的模型兼容。 继承梯度和XRAI 仅与 TensorFlow 模型和AutoML 图像模型兼容。 Sampled Shapley 适用于表格模型，但无法在图像模型上工作。\n",
    "\n",
    "了解更多关于[比较解释方法](https://cloud.google.com/vertex-ai/docs/explainable-ai/overview#compare-methods)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "explanation_parameters:mbsdk"
   },
   "outputs": [],
   "source": [
    "XAI = \"shapley\"  # [ shapley, ig, xrai ]\n",
    "\n",
    "if XAI == \"shapley\":\n",
    "    PARAMETERS = {\"sampled_shapley_attribution\": {\"path_count\": 10}}\n",
    "elif XAI == \"ig\":\n",
    "    PARAMETERS = {\"integrated_gradients_attribution\": {\"step_count\": 50}}\n",
    "elif XAI == \"xrai\":\n",
    "    PARAMETERS = {\"xrai_attribution\": {\"step_count\": 50}}\n",
    "\n",
    "parameters = aiplatform.explain.ExplanationParameters(PARAMETERS)\n",
    "print(parameters)\n",
    "\n",
    "EXPLANATION_METADATA = aiplatform.explain.ExplanationMetadata(\n",
    "    inputs={\n",
    "        \"sepal_length\": {},\n",
    "        \"sepal_width\": {},\n",
    "        \"petal_length\": {},\n",
    "        \"petal_width\": {},\n",
    "    },\n",
    "    outputs={\"probability\": {}},\n",
    ")\n",
    "print(EXPLANATION_METADATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ae19df6a33e"
   },
   "source": [
    "### 上传自定义服务容器\n",
    "\n",
    "接下来，您将使用`upload()`方法将自定义的服务容器上传为`Model`资源，参数如下：\n",
    "\n",
    "- `display_name`：`Model`资源的人类可读名称。\n",
    "- `serving_container_image_name`：您的自定义服务容器。\n",
    "- `explanation_parameters`：用于配置模型预测解释的参数。\n",
    "- `explanation_metadata`：描述模型输入和输出以供解释的元数据。\n",
    "\n",
    "*注意：*由于模型嵌入在服务容器中，因此无需指定`artifacts_uri`参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2738154345d5"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    serving_container_image_uri=f\"{DEPLOY_IMAGE}\",\n",
    "    explanation_parameters=parameters,\n",
    "    explanation_metadata=EXPLANATION_METADATA,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd1b85afc7df"
   },
   "source": [
    "部署自定义服务容器到`Endpoint`资源\n",
    "\n",
    "接下来，使用`deploy()`方法将您的`Model`资源，用于自定义服务容器，部署到一个`Endpoint`资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62cf66498a28"
   },
   "outputs": [],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6883e7b07143"
   },
   "source": [
    "发送一个预测请求\n",
    "\n",
    "接下来，您可以使用`predict()`方法向部署的自定义服务容器发送一个在线预测请求。\n",
    "\n",
    "*注意:* 这些示例已经进行过预缩放。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8hj0lfGn5Vuo"
   },
   "outputs": [],
   "source": [
    "endpoint.predict(\n",
    "    instances=[\n",
    "        {\n",
    "            \"sepal_length\": -1.38535265,\n",
    "            \"sepal_width\": 0.32841405,\n",
    "            \"petal_length\": -1.39706395,\n",
    "            \"petal_width\": 1.3154443,\n",
    "        },\n",
    "        {\n",
    "            \"sepal_length\": -1.02184904,\n",
    "            \"sepal_width\": -2.43394714,\n",
    "            \"petal_length\": -0.14664056,\n",
    "            \"petal_width\": -0.26238682,\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91a7f0cb3f26"
   },
   "source": [
    "发送解释请求\n",
    "\n",
    "接下来，您可以通过`explain()`方法向部署的定制服务容器发送在线解释请求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cuKvd9SrmIQw"
   },
   "outputs": [],
   "source": [
    "prediction = endpoint.explain(\n",
    "    instances=[\n",
    "        {\n",
    "            \"sepal_length\": -1.38535265,\n",
    "            \"sepal_width\": 0.32841405,\n",
    "            \"petal_length\": -1.39706395,\n",
    "            \"petal_width\": 1.3154443,\n",
    "        },\n",
    "        {\n",
    "            \"sepal_length\": -1.02184904,\n",
    "            \"sepal_width\": -2.43394714,\n",
    "            \"petal_length\": -0.14664056,\n",
    "            \"petal_width\": -0.26238682,\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_feature_attributions"
   },
   "source": [
    "检查特征归因\n",
    "\n",
    "接下来，您将查看此特定示例的特征归因。正面归因值意味着特定特征将您的模型预测上升了那么多，负面归因值则相反。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "examine_feature_attributions:mbsdk,xgboost,iris"
   },
   "outputs": [],
   "source": [
    "INSTANCE = {\n",
    "    \"sepal_length\": -1.38535265,\n",
    "    \"sepal_width\": 0.32841405,\n",
    "    \"petal_length\": -1.39706395,\n",
    "    \"petal_width\": 1.3154443,\n",
    "}\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "feature_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "attributions = prediction.explanations[0].attributions[0].feature_attributions\n",
    "\n",
    "rows = []\n",
    "for i, val in enumerate(feature_names):\n",
    "    rows.append([val, INSTANCE[val], attributions[val]])\n",
    "print(tabulate(rows, headers=[\"Feature name\", \"Feature value\", \"Attribution value\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "清理工作\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于本教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "delete_bucket = True\n",
    "\n",
    "# Undeploy model and delete endpoint\n",
    "try:\n",
    "    endpoint.delete(force=True)\n",
    "\n",
    "    # Delete the model resource\n",
    "    model.delete()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Delete the container image from Artifact Registry\n",
    "!gcloud artifacts docker images delete \\\n",
    "    --quiet \\\n",
    "    --delete-tags \\\n",
    "    {DEPLOY_IMAGE}\n",
    "\n",
    "! rm -rf app\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -rf {BUCKET_URI}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "get_started_with_xai_and_custom_server.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
