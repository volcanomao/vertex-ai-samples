{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "# 在GCP上进行的端到端机器学习：MLOps阶段4：评估：开始使用Vertex AI模型评估\n",
    "\n",
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage4/get_started_with_model_evaluation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage4/get_started_with_model_evaluation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage4/get_started_with_model_evaluation.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI工作台中打开\n",
    "    </a>\n",
    "  </td>                                                                                               \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:mlops"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何在谷歌云上使用Vertex AI进行端到端MLOps生产过程。此教程涵盖了第4阶段：评估：开始使用Vertex AI模型评估。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:mlops,stage4,get_started_vertex_model_evaluation"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用 `Vertex AI Model Evaluation`。\n",
    "\n",
    "本教程使用以下谷歌云机器学习服务：\n",
    "\n",
    "- `Vertex AI AutoML`\n",
    "- `BigQuery ML`\n",
    "- `Vertex AI Training`\n",
    "- `Vertex AI Batch Prediction`\n",
    "- `Vertex AI Model Evaluation`\n",
    "- `Google Cloud Pipeline Components`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "**SDK**\n",
    "\n",
    "- 评估一个 `AutoML` 模型。\n",
    "    - 训练一个 `AutoML` 图像分类模型。\n",
    "    - 获取来自训练的默认评估指标。\n",
    "    - 为自定义的评估切片执行批量评估。\n",
    "- 评估一个 BigQuery ML 模型。\n",
    "    - 训练一个 `BigQuery ML` 表格分类模型。\n",
    "    - 获取来自训练的默认评估指标。\n",
    "    - 为自定义的评估切片执行批量评估。\n",
    "- 评估一个自定义模型。\n",
    "    - 为自定义的评估切片执行批量评估。\n",
    "    - 将一个评估添加到 `Model Registry` 中的 `Model` 资源。\n",
    "\n",
    "**管道组件**\n",
    "\n",
    "- 评估一个 `AutoML` 模型。\n",
    "    - 训练一个 `AutoML` 图像分类模型。\n",
    "    - 获取来自训练的默认评估指标。\n",
    "    - 为自定义的评估切片执行批量评估。\n",
    "- 评估一个 BigQuery ML 模型。\n",
    "    - 训练一个 `BigQuery ML` 表格分类模型。\n",
    "    - 获取来自训练的默认评估指标。\n",
    "    - 为自定义的评估切片执行批量评估。\n",
    "- 评估一个自定义模型。\n",
    "    - 为自定义的评估切片执行批量评估。\n",
    "    - 为 `Model` 资源的 `Model Registry` 添加一个评估。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:bank,lbn"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "**AutoML 图像模型**\n",
    "\n",
    "本教程使用的数据集是来自[TensorFlow数据集](https://www.tensorflow.org/datasets/catalog/overview)中的[Flowers数据集](https://www.tensorflow.org/datasets/catalog/tf_flowers)。本教程中的数据集版本存储在一个公共Cloud Storage存储桶中。训练好的模型可以预测图像属于五种不同花卉中的哪一种：雏菊、蒲公英、玫瑰、向日葵或郁金香。\n",
    "\n",
    "**BigQuery ML 表格模型**\n",
    "\n",
    "本教程中使用的数据集是来自[BigQuery公共数据集](https://cloud.google.com/bigquery/public-data)中的企鹅数据集。该数据集版本用于根据可用特征如喙长、鳍深度等预测企鹅的物种。\n",
    "\n",
    "**自定义模型**\n",
    "\n",
    "本教程使用了一个在ImageNet数据集上训练的来自TensorFlow Hub的预训练图像分类模型。\n",
    "\n",
    "了解有关[ResNet V2预训练模型](https://tfhub.dev/google/imagenet/resnet_v2_101/classification/5)的更多信息。\n",
    "\n",
    "**流水线**\n",
    "\n",
    "本教程使用的数据集是[银行营销](https://pantheon.corp.google.com/storage/browser/_details/cloud-ml-tables-data/bank-marketing.csv)。这个数据集不需要任何特征工程处理。本教程中的数据集版本存储在一个公共Cloud Storage存储桶中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c997d8d92ce"
   },
   "source": [
    "费用\n",
    "此教程使用Google Cloud的计费组件：\n",
    "\n",
    "- Vertex AI\n",
    "- 云存储\n",
    "- BigQuery\n",
    "\n",
    "了解有关[Vertex AI定价](https://cloud.google.com/vertex-ai/pricing)，[云存储定价](https://cloud.google.com/storage/pricing)和[BigQuery定价](https://cloud.google.com/bigquery/pricing)的信息，并使用[Pricing Calculator](https://cloud.google.com/products/calculator/)根据您的预期使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_mlops"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装本笔记本执行所需的软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_mlops"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "# Install the packages\n",
    "! pip3 install --upgrade google-cloud-aiplatform $USER_FLAG -q\n",
    "! pip3 install --upgrade google-cloud-pipeline-components $USER_FLAG -q\n",
    "! pip3 install --upgrade google-cloud-bigquery $USER_FLAG -q\n",
    "! pip3 install --upgrade tensorflow $USER_FLAG -q\n",
    "! pip3 install --upgrade tensorflow-hub $USER_FLAG -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### 重新启动内核\n",
    "\n",
    "一旦你安装了额外的包，你需要重新启动笔记本内核，这样它就能找到这些包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "restart"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### GPU运行时\n",
    "\n",
    "*如果您有这个选项，请确保在GPU运行时中运行此笔记本。在Colab中，选择* **运行时 > 更改运行时类型 > GPU**\n",
    "\n",
    "### 设置您的Google Cloud项目\n",
    "\n",
    "**无论您使用的是哪种笔记本环境，下面的步骤都是必需的。**\n",
    "\n",
    "1. [选择或创建一个Google Cloud项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建帐户时，您将获得$300的免费信用额度用于计算/存储成本。\n",
    "\n",
    "2. [确保您的项目已启用结算。](https://cloud.google.com/billing/docs/how-to/modify-project)\n",
    "\n",
    "3. [启用以下API：Vertex AI API、Compute Engine API和Cloud Storage。](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component,storage-component.googleapis.com)\n",
    "\n",
    "4. 如果您是在本地运行此笔记本，您需要安装[Cloud SDK]((https://cloud.google.com/sdk))。\n",
    "\n",
    "5. 在下面的单元格中输入您的项目ID。然后运行该单元格，确保Cloud SDK为本笔记本中的所有命令使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter在以`!`为前缀的行上运行作为shell命令，并会解析以`$`为前缀的Python变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用`gcloud`来获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 地区\n",
    "\n",
    "您还可以更改 `REGION` 变量，此变量用于本笔记本的其余操作。以下是 Vertex AI 支持的地区。我们建议您选择离您最近的地区。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太地区：`asia-east1`\n",
    "\n",
    "您不能使用多区域存储桶进行 Vertex AI 训练。并非所有地区都支持所有 Vertex AI 服务。\n",
    "\n",
    "了解有关[Vertex AI 地区](https://cloud.google.com/vertex-ai/docs/general/locations)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "时间戳\n",
    "\n",
    "如果您正在参加直播教程会议，您可能会使用共享测试账户或项目。为了避免用户在创建的资源之间发生名称碰撞，您可以为每个实例会话创建一个时间戳，并将时间戳附加到您在本教程中创建的资源的名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "timestamp"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 验证您的谷歌云账户\n",
    "\n",
    "**如果您正在使用Vertex AI工作台笔记本**，您的环境已经通过身份验证。跳过此步骤。\n",
    "\n",
    "**如果您正在使用Colab**，运行下面的单元格，并按照提示进行身份验证。\n",
    "\n",
    "**否则**，按照以下步骤操作：\n",
    "\n",
    "在云控制台中，转到[创建服务账户密钥](https://console.cloud.google.com/apis/credentials/serviceaccountkey)页面。\n",
    "\n",
    "**点击创建服务账户**。\n",
    "\n",
    "在**服务账户名称**字段中输入一个名称，然后点击**创建**。\n",
    "\n",
    "在**授予此服务账户对项目的访问权限**部分，点击角色下拉列表。在过滤框中输入\"Vertex\"，然后选择**Vertex管理员**。在过滤框中输入\"存储对象管理员\"，然后选择**存储对象管理员**。\n",
    "\n",
    "点击创建。包含您密钥的JSON文件会下载到您的本地环境。\n",
    "\n",
    "在下面的单元格中输入您的服务账户密钥的路径作为GOOGLE_APPLICATION_CREDENTIALS变量，并运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcp_authenticate"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = False\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        IS_COLAB = True\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### 创建一个云存储存储桶\n",
    "\n",
    "**无论您使用的是什么笔记本环境，下面的步骤都是必要的。**\n",
    "\n",
    "当您初始化 Python 的 Vertex SDK 时，您需要指定一个云存储暂存桶。这个暂存桶是所有与您的数据集和模型资源相关的数据在会话之间保留的地方。\n",
    "\n",
    "在下面设置您的云存储存储桶的名称。存储桶的名称必须在所有谷歌云项目中全局唯一，包括您的组织外的项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"[your-bucket-name]\":\n",
    "    BUCKET_NAME = PROJECT_ID + \"aip-\" + TIMESTAMP\n",
    "    BUCKET_URI = \"gs://\" + BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有当您的存储桶不存在时：运行以下代码以创建您的云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "最后，通过检查其内容验证您的云存储桶的访问权限："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "set_service_account"
   },
   "source": [
    "#### 服务账户\n",
    "\n",
    "**如果您不知道您的服务账户**，请尝试使用`gcloud`命令在下面执行第二个单元格以获取您的服务账户。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_service_account"
   },
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = \"[your-service-account]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_service_account"
   },
   "outputs": [],
   "source": [
    "if (\n",
    "    SERVICE_ACCOUNT == \"\"\n",
    "    or SERVICE_ACCOUNT is None\n",
    "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
    "):\n",
    "    # Get your service account from gcloud\n",
    "    if not IS_COLAB:\n",
    "        shell_output = !gcloud auth list 2>/dev/null\n",
    "        SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\n",
    "\n",
    "    if IS_COLAB:\n",
    "        shell_output = ! gcloud projects describe  $PROJECT_ID\n",
    "        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
    "        SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
    "\n",
    "    print(\"Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "set_service_account:pipelines"
   },
   "source": [
    "设置 Vertex AI Pipelines 的服务账号访问权限\n",
    "\n",
    "运行以下命令，为您的服务账号授予读取和写入流水线文件的权限，该文件位于您在上一步创建的存储桶中--您只需要为每个服务账号运行一次这些命令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_service_account:pipelines"
   },
   "outputs": [],
   "source": [
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n",
    "\n",
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在整个教程中使用的变量。\n",
    "### 导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_kfp"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import google.cloud.aiplatform as aiplatform\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_bq"
   },
   "source": [
    "#### 导入BigQuery\n",
    "\n",
    "在您的Python环境中导入BigQuery包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_bq"
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk,all"
   },
   "source": [
    "### 初始化用于 Python 的 Vertex AI SDK\n",
    "\n",
    "为您的项目和相应的存储桶初始化用于 Python 的 Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk,all"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_bq"
   },
   "source": [
    "创建BigQuery客户端。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_bq"
   },
   "outputs": [],
   "source": [
    "bqclient = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:prediction,mbsdk"
   },
   "source": [
    "#### 设置硬件加速器\n",
    "\n",
    "您可以为预测设置硬件加速器。\n",
    "\n",
    "将变量`DEPLOY_GPU/DEPLOY_NGPU`设置为使用支持GPU的容器映像以及分配给虚拟机（VM）实例的GPU数量。例如，要使用一个GPU容器映像，并为每个VM分配4个Nvidia Telsa K80 GPU，则应指定：\n",
    "\n",
    "    (aip.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
    "\n",
    "否则，指定`(None, None)`来使用一个在CPU上运行的容器映像。\n",
    "\n",
    "在[这里](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)了解更多关于您地区的硬件加速器支持。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accelerators:prediction,mbsdk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"IS_TESTING_DEPLOY_GPU\"):\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (\n",
    "        aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "        int(os.getenv(\"IS_TESTING_DEPLOY_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:prediction"
   },
   "source": [
    "设置预构建的容器\n",
    "\n",
    "为预测设置预构建的Docker容器镜像。\n",
    "\n",
    "- 将变量`TF`设置为容器镜像的TensorFlow版本。例如，`2-1`表示版本2.1，`1-15`表示版本1.15。以下列表显示一些可用的预构建镜像：\n",
    "\n",
    "有关最新列表，请参见[用于预测的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:prediction"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TF\"):\n",
    "    TF = os.getenv(\"IS_TESTING_TF\")\n",
    "else:\n",
    "    TF = \"2-5\".replace(\".\", \"-\")\n",
    "\n",
    "if TF[0] == \"2\":\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf2-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf2-cpu.{}\".format(TF)\n",
    "else:\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "\n",
    "DEPLOY_IMAGE = \"{}-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], DEPLOY_VERSION\n",
    ")\n",
    "\n",
    "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:prediction"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于预测的机器类型。\n",
    "\n",
    "- 将变量`DEPLOY_COMPUTE`设置为配置用于预测的虚拟机的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`：每个vCPU 3.75GB内存。\n",
    "     - `n1-highmem`：每个vCPU 6.5GB内存\n",
    "     - `n1-highcpu`：每个vCPU 0.9GB内存\n",
    " - `vCPU`：\\[2, 4, 8, 16, 32, 64, 96 \\]中的数字\n",
    "\n",
    "*注意：您也可以使用n2和e2机器类型进行训练和部署，但它们不支持GPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:prediction"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_DEPLOY_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_DEPLOY_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro:model_eval,automl"
   },
   "source": [
    "## Vertex AI模型评估介绍，适用于AutoML模型。\n",
    "\n",
    "对于AutoML模型，您可以使用`Vertex AI模型评估`服务从划分为训练集和测试集的数据集中检索在训练过程中获得的模型评估指标。此外，您还可以使用自定义评估切片进一步评估模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_file:u_dataset,csv"
   },
   "source": [
    "云存储培训数据的位置。\n",
    "\n",
    "现在将变量“IMPORT_FILE”设置为云存储中CSV索引文件的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:flowers,csv,icn"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = (\n",
    "    \"gs://cloud-samples-data/vision/automl_classification/flowers/all_data_v2.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_dataset:image,icn"
   },
   "source": [
    "### 创建数据集\n",
    "\n",
    "接下来，使用`ImageDataset`类的`create`方法为`Dataset`资源创建数据集，需要传入以下参数：\n",
    "\n",
    "- `display_name`：`Dataset`资源的人类可读名称。\n",
    "- `gcs_source`：一个或多个数据集索引文件的列表，用于将数据项导入`Dataset`资源。\n",
    "- `import_schema_uri`：数据项的数据标记模式。\n",
    "\n",
    "此操作可能需要几分钟时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataset:image,icn"
   },
   "outputs": [],
   "source": [
    "dataset = aiplatform.ImageDataset.create(\n",
    "    display_name=\"Flowers\" + \"_\" + TIMESTAMP,\n",
    "    gcs_source=[IMPORT_FILE],\n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.image.single_label_classification,\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_automl_pipeline:image,icn"
   },
   "source": [
    "### 创建和运行训练管道\n",
    "\n",
    "要训练AutoML模型，您需要执行两个步骤：1）创建训练管道，2）运行管道。\n",
    "\n",
    "#### 创建训练管道\n",
    "\n",
    "使用`AutoMLImageTrainingJob`类创建AutoML训练管道，参数如下：\n",
    "\n",
    "- `display_name`：`TrainingJob`资源的可读名称。\n",
    "- `prediction_type`：要为其训练模型的任务类型。\n",
    "  - `classification`：图像分类模型。\n",
    "  - `object_detection`：图像目标检测模型。\n",
    "- `multi_label`：如果是分类任务，则是单标签(`False`)还是多标签(`True`)。\n",
    "- `model_type`：部署模型的类型。\n",
    "  - `CLOUD`：在Google Cloud上部署。\n",
    "  - `CLOUD_HIGH_ACCURACY_1`：针对部署在Google Cloud上的准确性优化。\n",
    "  - `CLOUD_LOW_LATENCY`：针对部署在Google Cloud上的延迟优化。\n",
    "  - `MOBILE_TF_VERSATILE_1`：部署在边缘设备上。\n",
    "  - `MOBILE_TF_HIGH_ACCURACY_1`：针对部署在边缘设备上的准确性优化。\n",
    "  - `MOBILE_TF_LOW_LATENCY_1`：针对部署在边缘设备上的延迟优化。\n",
    "- `base_model`：（可选）从现有的`Model`资源进行迁移学习 -- 仅支持图像分类。\n",
    "\n",
    "实例化的对象是训练作业的DAG（有向无环图）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_automl_pipeline:image,icn"
   },
   "outputs": [],
   "source": [
    "dag = aiplatform.AutoMLImageTrainingJob(\n",
    "    display_name=\"flowers_\" + TIMESTAMP,\n",
    "    prediction_type=\"classification\",\n",
    "    multi_label=False,\n",
    "    model_type=\"CLOUD\",\n",
    "    base_model=None,\n",
    ")\n",
    "\n",
    "print(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_automl_pipeline:image"
   },
   "source": [
    "#### 运行训练管道\n",
    "\n",
    "接下来，您可以运行DAG以通过调用`run`方法来启动训练作业，参数如下：\n",
    "\n",
    "- `dataset`: 用于训练模型的`Dataset`资源。\n",
    "- `model_display_name`: 训练模型的可读名称。\n",
    "- `training_fraction_split`: 用于训练的数据集百分比。\n",
    "- `test_fraction_split`: 用于测试（留存数据）的数据集百分比。\n",
    "- `validation_fraction_split`: 用于验证的数据集百分比。\n",
    "- `budget_milli_node_hours`: （可选）以毫小时为单位指定的最大训练时间（1000 = 小时）。\n",
    "- `disable_early_stopping`: 如果为`True`，则训练可能在服务认为无法进一步提高模型客观度量之前完成。\n",
    "\n",
    "当`run`方法完成时，会返回`Model`资源。\n",
    "\n",
    "执行训练管道将需要最多20分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_automl_pipeline:image"
   },
   "outputs": [],
   "source": [
    "model = dag.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"flowers_\" + TIMESTAMP,\n",
    "    training_fraction_split=0.8,\n",
    "    validation_fraction_split=0.1,\n",
    "    test_fraction_split=0.1,\n",
    "    budget_milli_node_hours=8000,\n",
    "    disable_early_stopping=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c1cb501c4ad"
   },
   "source": [
    "### 获取`AutoML Model`资源的默认评估\n",
    "\n",
    "BLAH GAPIC 占位符\n",
    "在您的模型训练完成后，您可以查看其评估分数。\n",
    "\n",
    "首先，您需要获取对新模型的引用。与数据集一样，您可以使用部署模型时创建的模型变量引用，或者列出项目中的所有模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bfc39c62ff5"
   },
   "outputs": [],
   "source": [
    "model_evaluations = model.list_model_evaluations()\n",
    "\n",
    "for model_evaluation in model_evaluations:\n",
    "    print(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d448681f2724"
   },
   "source": [
    "### 在自定义评估切片上评估\n",
    "\n",
    "占位符 - 废话"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c89cd59d390f"
   },
   "source": [
    "### 创建批量输入文件\n",
    "\n",
    "现在创建一个批量输入文件，将其存储在您的本地云存储存储桶中。批量输入文件必须采用JSONL格式。对于JSONL文件，您需要为每个数据项（实例）的每一行创建一个字典条目。该字典包含键/值对：\n",
    "\n",
    "- `content`：图像的云存储路径。\n",
    "- `mime_type`：内容类型。在我们的示例中，它是一个`jpeg`文件。\n",
    "\n",
    "例如：\n",
    "\n",
    "                        {'content': '[your-bucket]/file1.jpg', 'mime_type': 'jpeg'}\n",
    "    \n",
    "为了演示目的，创建一个评估切片，您可以使用部分训练数据 -- 就好像它是单独的（非训练）数据，例如在生产环境中看到的实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3661bc67e841"
   },
   "outputs": [],
   "source": [
    "EVAL_SLICE = BUCKET_URI + \"/flowers_eval.jsonl\"\n",
    "\n",
    "! gsutil cat {IMPORT_FILE} | head -n 200 >tmp.csv\n",
    "\n",
    "import csv\n",
    "\n",
    "entries = []\n",
    "with open(\"tmp.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        path = row[0]\n",
    "        label = row[1]\n",
    "\n",
    "        file = path.split(\"/\")[-1]\n",
    "\n",
    "        new_path = BUCKET_URI + \"/flowers/\" + file\n",
    "\n",
    "        ! gsutil cp {path} {new_path} >/dev/null\n",
    "        entries.append({\"content\": new_path, \"mime_type\": \"jpeg\"})\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"tmp.jsonl\", \"w\") as f:\n",
    "    for entry in entries:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "! gsutil cp tmp.jsonl {EVAL_SLICE}\n",
    "#! rm tmp.csv tmp.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request:mbsdk"
   },
   "source": [
    "### 发起批量预测请求\n",
    "\n",
    "现在您的模型资源已经训练好了，您可以通过调用batch_predict()方法进行批量预测，使用以下参数：\n",
    "\n",
    "- `job_display_name`：批量预测工作的可读名称。\n",
    "- `instances_format`：预测请求的格式；只能是JSONL（默认）。\n",
    "- `gcs_source`：一个或多个批量请求输入文件的列表。\n",
    "- `gcs_destination_prefix`：用于存储批量预测结果的Cloud Storage位置。\n",
    "- `sync`：如果设置为True，则调用将在等待异步批量作业完成时阻塞。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request:mbsdk"
   },
   "outputs": [],
   "source": [
    "batch_predict_job = model.batch_predict(\n",
    "    job_display_name=\"flowers_\" + TIMESTAMP,\n",
    "    instances_format=\"jsonl\",\n",
    "    gcs_source=EVAL_SLICE,\n",
    "    gcs_destination_prefix=BUCKET_URI,\n",
    "    sync=True,\n",
    ")\n",
    "\n",
    "print(batch_predict_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6c400027f1b4"
   },
   "source": [
    "### TODO: 获取批量结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_batch_prediction:mbsdk,icn"
   },
   "source": [
    "获得预测\n",
    "\n",
    "接下来，从已完成的批量预测作业中获取结果。\n",
    "\n",
    "结果将写入您在批量预测请求中指定的云存储输出桶中。您可以调用iter_outputs()方法来获取生成结果的每个云存储文件的列表。每个文件以JSON格式包含一个或多个预测请求：\n",
    "\n",
    "- `content`：预测请求。\n",
    "- `prediction`：预测响应。\n",
    " - `ids`：每个预测请求的内部分配的唯一标识符。\n",
    " - `displayNames`：每个类别标签的类名。\n",
    " - `confidences`：每个类别标签的预测置信度，介于0和1之间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_batch_prediction:mbsdk,icn"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "bp_iter_outputs = batch_predict_job.iter_outputs()\n",
    "\n",
    "prediction_results = list()\n",
    "for blob in bp_iter_outputs:\n",
    "    if blob.name.split(\"/\")[-1].startswith(\"prediction\"):\n",
    "        prediction_results.append(blob.name)\n",
    "\n",
    "tags = list()\n",
    "for prediction_result in prediction_results:\n",
    "    gfile_name = f\"gs://{bp_iter_outputs.bucket.name}/{prediction_result}\"\n",
    "    with tf.io.gfile.GFile(name=gfile_name, mode=\"r\") as gfile:\n",
    "        for line in gfile.readlines():\n",
    "            line = json.loads(line)\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e6dc2a7bb53"
   },
   "source": [
    "#### 删除临时资源\n",
    "\n",
    "接下来，您删除此示例创建的所有临时资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5181cf916f12"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    dag.delete()\n",
    "    model.delete()\n",
    "    batch_predict_job.delete()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro:model_eval,automl"
   },
   "source": [
    "## 介绍如何使用 Vertex AI 模型评估来评估 BigQuery ML 模型。\n",
    "\n",
    "对于 BigQuery ML 模型，您可以使用 `Vertex AI 模型评估` 服务从在训练期间获取的数据集分割为训练和测试的模型评估指标。此外，您还可以使用自定义评估分片进一步评估模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "807327fe3ec8"
   },
   "source": [
    "### BigQuery培训数据的位置\n",
    "\n",
    "现在将变量`IMPORT_FILE`和`BQ_TABLE`设置为`BigQuery`中培训数据的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:penguins,bq,lcn"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = \"bq://bigquery-public-data.ml_datasets.penguins\"\n",
    "BQ_TABLE = \"bigquery-public-data.ml_datasets.penguins\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqml_create_dataset"
   },
   "source": [
    "### 创建BQ数据集资源\n",
    "\n",
    "首先，在您的项目中创建一个空的数据集资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqml_create_dataset"
   },
   "outputs": [],
   "source": [
    "BQ_DATASET_NAME = \"penguins\"\n",
    "DATASET_QUERY = f\"\"\"CREATE SCHEMA {BQ_DATASET_NAME}\n",
    "\"\"\"\n",
    "\n",
    "job = bqclient.query(DATASET_QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b4498ca6fea"
   },
   "source": [
    "### 设置权限以自动注册模型\n",
    "\n",
    "在训练后自动上传和注册模型之前，您需要为BigQuery ML设置一些额外的IAM权限。根据您的服务帐号，设置下面的权限可能会失败。在这种情况下，我们建议在Cloud Shell中执行权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0472e888105e"
   },
   "outputs": [],
   "source": [
    "! gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "      --member='serviceAccount:cloud-dataengine@system.gserviceaccount.com' \\\n",
    "      --role='roles/aiplatform.admin'\n",
    "\n",
    "! gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "      --member='user:cloud-dataengine@prod.google.com' \\\n",
    "      --role='roles/aiplatform.admin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqml_create_model"
   },
   "source": [
    "### 训练和注册BigQuery ML模型\n",
    "\n",
    "接下来，您将从公共数据集企鹅中创建并训练一个BigQuery ML表格分类模型，并使用`CREATE MODEL`语句将模型存储在您的项目中。模型配置在`OPTIONS`语句中指定如下：\n",
    "\n",
    "- `model_type`：要训练的表格模型的类型和架构，例如DNN分类。\n",
    "- `labels`：标签所在的列。\n",
    "- `model_registry`：设置为\"vertex_ai\"，表示自动注册到`Vertex AI Model Registry`。\n",
    "- `vertex_ai_model_id`：已注册模型的人类可读的显示名称。\n",
    "- `vertex_ai_model_version_aliases`：模型的备用名称。\n",
    "\n",
    "了解更多关于[CREATE MODEL语句](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqml_create_model"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"penguins\"\n",
    "MODEL_QUERY = f\"\"\"\n",
    "CREATE OR REPLACE MODEL `{BQ_DATASET_NAME}.{MODEL_NAME}`\n",
    "OPTIONS(\n",
    "    model_type='DNN_CLASSIFIER',\n",
    "    labels = ['species'],\n",
    "    model_registry=\"vertex_ai\",\n",
    "    vertex_ai_model_id=\"bqml_model_{TIMESTAMP}\", \n",
    "    vertex_ai_model_version_aliases=[\"1\"]\n",
    "    )\n",
    "AS\n",
    "SELECT *\n",
    "FROM `{BQ_TABLE}`\n",
    "\"\"\"\n",
    "\n",
    "job = bqclient.query(MODEL_QUERY)\n",
    "print(job.errors, job.state)\n",
    "\n",
    "while job.running():\n",
    "    from time import sleep\n",
    "\n",
    "    sleep(30)\n",
    "    print(\"Running ...\")\n",
    "print(job.errors, job.state)\n",
    "\n",
    "tblname = job.ddl_target_table\n",
    "tblname = \"{}.{}\".format(tblname.dataset_id, tblname.table_id)\n",
    "print(\"{} created in {}\".format(tblname, job.ended - job.started))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqml_eval_model"
   },
   "source": [
    "### 使用BigQuery评估已训练的BigQuery模型\n",
    "\n",
    "接下来，在BigQuery中检索已训练的BigQuery ML模型的模型评估。\n",
    "\n",
    "了解更多关于[ML.EVALUATE函数](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqml_eval_model"
   },
   "outputs": [],
   "source": [
    "EVAL_QUERY = f\"\"\"\n",
    "SELECT *\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL {BQ_DATASET_NAME}.{MODEL_NAME})\n",
    "ORDER BY  roc_auc desc\n",
    "LIMIT 1\"\"\"\n",
    "\n",
    "job = bqclient.query(EVAL_QUERY)\n",
    "results = job.result().to_dataframe()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5b4970272040"
   },
   "source": [
    "### 在`Vertex AI模型注册表`中找到模型\n",
    "\n",
    "最后，您可以使用`Vertex AI模型`的list()方法并带有过滤查询来找到自动注册的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76c22674ba99"
   },
   "outputs": [],
   "source": [
    "models = aiplatform.Model.list(filter=\"display_name=bqml_model_\" + TIMESTAMP)\n",
    "model = models[0]\n",
    "\n",
    "print(model.gca_resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41aecf259370"
   },
   "source": [
    "### 从 `Vertex AI Model Registry` 中检索`BigQuery ML Model`资源的默认评估\n",
    "\n",
    "BLAH GAPIC 占位符\n",
    "在模型训练完成后，您可以查看其评估分数。\n",
    "\n",
    "首先，您需要获取对新模型的引用。与数据集一样，您可以使用部署模型时创建的模型变量的引用，或者列出项目中的所有模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ab9abfb7184e"
   },
   "outputs": [],
   "source": [
    "# Get a reference to the Model Service client\n",
    "client_options = {\"api_endpoint\": f\"{REGION}-aiplatform.googleapis.com\"}\n",
    "model_service_client = aiplatform.gapic.ModelServiceClient(\n",
    "    client_options=client_options\n",
    ")\n",
    "\n",
    "model_evaluations = model_service_client.list_model_evaluations(\n",
    "    parent=model.resource_name\n",
    ")\n",
    "model_evaluation = list(model_evaluations)[0]\n",
    "print(model_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ae5b591a2105"
   },
   "source": [
    "### 在自定义评估片段上进行评估\n",
    "\n",
    "占位符 - 垃圾\n",
    "\n",
    "垃圾 - 批处理文件格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04c37f78af15"
   },
   "source": [
    "#### 删除临时资源\n",
    "\n",
    "接下来，删除该示例创建的所有临时资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4418968b5dd"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model.delete()\n",
    "    batch_predict_job.delete()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    # Delete the created BigQuery dataset\n",
    "    ! bq rm -r -f $PROJECT_ID:$BQ_DATASET_NAME\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "MODEL_QUERY = f\"\"\"\n",
    "DROP MODEL `{BQ_DATASET_NAME}.{MODEL_NAME}`\n",
    "\"\"\"\n",
    "\n",
    "job = bqclient.query(MODEL_QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro:model_eval,automl"
   },
   "source": [
    "## 介绍自定义模型的Vertex AI模型评估。\n",
    "\n",
    "对于自定义模型，您可以使用`Vertex AI模型评估`服务从训练集中提取在训练期间获取的模型评估指标。此外，您还可以使用自定义评估切片进一步评估模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8128b8ff025"
   },
   "source": [
    "## 从TensorFlow Hub获取预训练模型\n",
    "\n",
    "出于演示目的，本教程使用了从TensorFlow Hub（TFHub）获取的预训练模型，然后将其上传到`Vertex AI Model`资源。一旦您拥有了`Vertex AI Model`资源，该模型就可以部署到`Vertex AI Endpoint`资源中。\n",
    "\n",
    "### 下载预训练模型\n",
    "\n",
    "首先，您需要从TensorFlow Hub下载预训练模型。该模型将作为TF.Keras层进行下载。在本示例中，为了完成模型，您将创建一个包含下载的TFHub模型作为层的`Sequential()`模型，并指定模型的输入形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c55fa4c826f7"
   },
   "outputs": [],
   "source": [
    "tfhub_model = tf.keras.Sequential(\n",
    "    [hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_101/classification/5\")]\n",
    ")\n",
    "\n",
    "tfhub_model.build([None, 224, 224, 3])\n",
    "\n",
    "tfhub_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63de49055083"
   },
   "source": [
    "### 保存模型工件\n",
    "\n",
    "此时，模型位于内存中。接下来，您需要将模型工件保存到一个云存储位置。\n",
    "\n",
    "*注意:* 对于 TF Serving，MODEL_DIR 必须以一个数字结尾的子文件夹，例如，1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64618c713db9"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = BUCKET_URI + \"/model/1\"\n",
    "tfhub_model.save(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "how_serving_function_works"
   },
   "source": [
    "上传用于提供服务的模型\n",
    "\n",
    "接下来，您将从自定义作业中将您的TF.Keras模型上传到Vertex `Model`服务，该服务将为您的自定义模型创建一个Vertex `Model`资源。在上传过程中，您需要定义一个用于将数据转换为您的模型期望格式的服务函数。如果您将编码数据发送到Vertex AI，您的服务函数将确保在将数据作为输入传递到您的模型之前，在模型服务器上对数据进行解码。\n",
    "\n",
    "### 服务函数如何工作\n",
    "\n",
    "当您向在线预测服务器发送请求时，请求将由HTTP服务器接收。HTTP服务器从HTTP请求内容主体中提取预测请求。提取的预测请求将转发到服务函数。对于Google预构建的预测容器，请求内容将以`tf.string`的形式传递给服务函数。\n",
    "\n",
    "服务函数由两部分组成：\n",
    "\n",
    "- `预处理函数`：\n",
    "  - 将输入(`tf.string`)转换为基础模型（动态图）期望的输入形状和数据类型。\n",
    "  - 执行与培训基础模型期间相同的数据预处理操作--例如，归一化，缩放等。\n",
    "- `后处理函数`：\n",
    "  - 将模型输出转换为接收应用程序期望的格式--例如，压缩输出。\n",
    "  - 封装输出以供接收应用程序使用--例如，添加标题，创建JSON对象等。\n",
    "\n",
    "预处理和后处理函数都转换为与模型融合的静态图。基础模型的输出传递给后处理函数。后处理函数将转换/封装的输出传递回HTTP服务器。HTTP服务器将输出作为HTTP响应内容返回。\n",
    "\n",
    "在为TF.Keras模型构建服务函数时需要考虑的一点是，它们作为静态图运行。这意味着，您不能使用需要动态图的TF图操作。如果这样做，您将在服务函数的编译期间收到错误，指出您正在使用不受支持的EagerTensor。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "serving_function_image:post"
   },
   "source": [
    "###图像数据的提供功能\n",
    "\n",
    "####预处理\n",
    "\n",
    "要将图像传递给预测服务，您需要将压缩的（例如JPEG）图像字节编码为base 64——这样可以使内容在通过网络传输二进制数据时免受修改。由于部署的模型期望输入数据为原始（未压缩）字节，因此您需要确保base 64编码的数据被转换回原始字节，然后经过预处理以符合模型输入要求，然后再将其作为输入传递到部署的模型。\n",
    "\n",
    "要解决这个问题，您可以定义一个提供功能（`serving_fn`）并将其附加到模型作为预处理步骤。添加`@tf.function`装饰器，以便将提供功能合并到底层模型中（而不是在CPU上游）。\n",
    "\n",
    "当您发送预测或解释请求时，请求的内容被解码成一个Tensorflow字符串（`tf.string`），然后传递给提供功能（`serving_fn`）。提供功能将`tf.string`预处理为原始（未压缩）的numpy字节（`preprocess_fn`），以匹配模型的输入要求：\n",
    "\n",
    "- `io.decode_jpeg`- 解压缩返回为带有三个通道（RGB）的Tensorflow张量的JPG图像。\n",
    "- `image.convert_image_dtype`- 将整数像素值更改为浮点32，并在0和1之间重新调整像素数据。\n",
    "- `image.resize`- 将图像调整大小以匹配模型的输入形状。\n",
    "\n",
    "在这一点上，数据可以通过具体函数传递给模型（`m_call`）。提供功能是一个静态图，而模型是一个动态图。具体函数执行将输入数据从提供功能传递到模型的任务，并将来自模型的预测结果从模型重新传递到提供功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "serving_function_image"
   },
   "outputs": [],
   "source": [
    "CONCRETE_INPUT = \"numpy_inputs\"\n",
    "\n",
    "\n",
    "def _preprocess(bytes_input):\n",
    "    decoded = tf.io.decode_jpeg(bytes_input, channels=3)\n",
    "    decoded = tf.image.convert_image_dtype(decoded, tf.float32)\n",
    "    resized = tf.image.resize(decoded, size=(224, 224))\n",
    "    return resized\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "def preprocess_fn(bytes_inputs):\n",
    "    decoded_images = tf.map_fn(\n",
    "        _preprocess, bytes_inputs, dtype=tf.float32, back_prop=False\n",
    "    )\n",
    "    return {\n",
    "        CONCRETE_INPUT: decoded_images\n",
    "    }  # User needs to make sure the key matches model's input\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "def serving_fn(bytes_inputs):\n",
    "    images = preprocess_fn(bytes_inputs)\n",
    "    prob = m_call(**images)\n",
    "    return prob\n",
    "\n",
    "\n",
    "m_call = tf.function(tfhub_model.call).get_concrete_function(\n",
    "    [tf.TensorSpec(shape=[None, 224, 224, 3], dtype=tf.float32, name=CONCRETE_INPUT)]\n",
    ")\n",
    "\n",
    "tf.saved_model.save(tfhub_model, MODEL_DIR, signatures={\"serving_default\": serving_fn})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "serving_function_signature:image"
   },
   "source": [
    "获取服务函数签名\n",
    "\n",
    "您可以通过重新加载模型到内存中，并查询每个层对应的签名来获取模型的输入和输出层的签名。\n",
    "\n",
    "对于您的目的，您需要服务函数的签名。为什么？当我们将数据作为HTTP请求包发送进行预测时，图像数据是base64编码的，而我们的TF.Keras模型需要numpy输入。您的服务函数将从base64转换为numpy数组。\n",
    "\n",
    "在发起预测请求时，您需要将请求路由到服务函数而不是模型，因此您需要知道服务函数的输入层名称 - 这将在您发起预测请求时使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "serving_function_signature:image"
   },
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(MODEL_DIR)\n",
    "\n",
    "serving_input = list(\n",
    "    loaded.signatures[\"serving_default\"].structured_input_signature[1].keys()\n",
    ")[0]\n",
    "print(\"Serving function input:\", serving_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8ce91147c93"
   },
   "source": [
    "将TensorFlow Hub模型上传到“Vertex AI Model”资源中。\n",
    "\n",
    "最后，您将TFHub模型中的模型工件上传到“Vertex AI Model”资源中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad61e1429512"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=\"example_\" + TIMESTAMP,\n",
    "    artifact_uri=MODEL_DIR,\n",
    "    serving_container_image_uri=DEPLOY_IMAGE,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "222ef231f3d7"
   },
   "source": [
    "### 翻译: 在自定义模型上进行批量预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d21a9f6a7798"
   },
   "source": [
    "### BLAH 注册自定义评估指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aeb23e71108"
   },
   "source": [
    "使用`Vertex AI Pipeline`组件进行模型评估\n",
    "\n",
    "在这一部分中，您可以使用`Vertex AI Pipeline`组件对`AutoML`、`BigQuery ML`和自定义模型进行模型评估。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "572dd365e30b"
   },
   "source": [
    "### AutoML模型评估管道组件\n",
    "\n",
    "BLAH\n",
    "\n",
    "另外，您可以使用BatchPredictionOp和ModelEvaluationOp组件组合来使用自定义评估切片评估AutoML模型，步骤如下：\n",
    "\n",
    "- 自定义评估切片数据包含标签值（真实值）。\n",
    "- 对自定义评估切片进行批量预测。\n",
    "- 使用批量预测结果和标签值进行模型评估。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_file:u_dataset,csv"
   },
   "source": [
    "#### 云存储培训数据的位置。\n",
    "\n",
    "现在将变量 `IMPORT_FILE` 设置为云存储中CSV索引文件的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:bank,lbn,split"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = \"gs://cloud-ml-tables-data/bank-marketing.csv\"\n",
    "! gsutil cat {IMPORT_FILE} | head -n 40000 > train.csv\n",
    "! gsutil cat {IMPORT_FILE} | head -n 1 >eval.csv\n",
    "! gsutil cat {IMPORT_FILE} | tail -n 5200 >> eval.csv\n",
    "\n",
    "IMPORT_TRAIN = BUCKET_NAME + \"/train.csv\"\n",
    "IMPORT_EVAL = BUCKET_NAME + \"/eval.csv\"\n",
    "\n",
    "! gsutil cp train.csv {IMPORT_TRAIN}\n",
    "! gsutil cp eval.csv {IMPORT_EVAL}\n",
    "\n",
    "! rm -f train.csv eval.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_automl_eval_component"
   },
   "source": [
    "### 创建AutoML模型评估组件\n",
    "\n",
    "Vertex AI预构建的管道组件目前没有用于检索AutoML模型评估的组件。因此，您将首先按照以下步骤编写自己的组件：\n",
    "\n",
    "- 以AutoML训练组件返回的区域和模型工件作为输入。\n",
    "- 创建一个客户端接口到Vertex AI模型服务（`metadata[\"resource_name\"]）。\n",
    "- 从模型工件参数构建模型的资源ID。\n",
    "- 检索模型评估。\n",
    "- 将模型评估作为字符串返回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_automl_eval_component"
   },
   "outputs": [],
   "source": [
    "from kfp.v2.dsl import Artifact, Input, Model\n",
    "\n",
    "\n",
    "@component(packages_to_install=[\"google-cloud-aiplatform\"])\n",
    "def evaluateAutoMLModelOp(model: Input[Artifact], region: str) -> str:\n",
    "    import logging\n",
    "\n",
    "    import google.cloud.aiplatform.gapic as gapic\n",
    "\n",
    "    # Get a reference to the Model Service client\n",
    "    client_options = {\"api_endpoint\": f\"{region}-aiplatform.googleapis.com\"}\n",
    "    model_service_client = gapic.ModelServiceClient(client_options=client_options)\n",
    "\n",
    "    model_id = model.metadata[\"resourceName\"]\n",
    "\n",
    "    model_evaluations = model_service_client.list_model_evaluations(parent=model_id)\n",
    "    model_evaluation = list(model_evaluations)[0]\n",
    "    logging.info(model_evaluation)\n",
    "    return str(model_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_automl_pipeline:lbn,eval"
   },
   "source": [
    "### 构建AutoML训练的流水线，并进行批量模型评估\n",
    "\n",
    "接下来，使用以下任务构建流水线:\n",
    "\n",
    "- 创建一个Vertex AI数据集资源。\n",
    "- 训练一个AutoML表格分类模型。\n",
    "- 检索AutoML评估统计数据。\n",
    "- 使用在训练过程中未使用的评估切片，对AutoML模型进行批量预测。\n",
    "- 使用批量预测的结果对AutoML模型进行评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_automl_pipeline:lbn,eval"
   },
   "outputs": [],
   "source": [
    "PIPELINE_ROOT = \"{}/pipeline_root/automl_lbn_training\".format(BUCKET_NAME)\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"automl-lbn-training\", description=\"AutoML tabular classification training\"\n",
    ")\n",
    "def pipeline(\n",
    "    import_file: str,\n",
    "    batch_files: list,\n",
    "    display_name: str,\n",
    "    bucket: str = PIPELINE_ROOT,\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION,\n",
    "):\n",
    "    from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "    from google_cloud_pipeline_components.experimental.evaluation import \\\n",
    "        ModelEvaluationOp\n",
    "    from google_cloud_pipeline_components.v1.batch_predict_job import \\\n",
    "        ModelBatchPredictOp\n",
    "\n",
    "    dataset_op = gcc_aip.TabularDatasetCreateOp(\n",
    "        project=project, display_name=display_name, gcs_source=import_file\n",
    "    )\n",
    "\n",
    "    training_op = gcc_aip.AutoMLTabularTrainingJobRunOp(\n",
    "        project=project,\n",
    "        display_name=display_name,\n",
    "        optimization_prediction_type=\"classification\",\n",
    "        dataset=dataset_op.outputs[\"dataset\"],\n",
    "        model_display_name=display_name,\n",
    "        training_fraction_split=0.8,\n",
    "        validation_fraction_split=0.1,\n",
    "        test_fraction_split=0.1,\n",
    "        budget_milli_node_hours=8000,\n",
    "        optimization_objective=\"minimize-log-loss\",\n",
    "        target_column=\"Deposit\",\n",
    "    )\n",
    "\n",
    "    eval_op = evaluateAutoMLModelOp(model=training_op.outputs[\"model\"], region=region)\n",
    "\n",
    "    batch_op = ModelBatchPredictOp(\n",
    "        project=project,\n",
    "        job_display_name=\"batch_predict_job\",\n",
    "        model=training_op.outputs[\"model\"],\n",
    "        gcs_source_uris=batch_files,\n",
    "        gcs_destination_output_uri_prefix=bucket,\n",
    "        instances_format=\"csv\",\n",
    "        predictions_format=\"jsonl\",\n",
    "        model_parameters={},\n",
    "        machine_type=DEPLOY_COMPUTE,\n",
    "        starting_replica_count=1,\n",
    "        max_replica_count=1,\n",
    "    ).after(eval_op)\n",
    "\n",
    "    batch_eval_op = ModelEvaluationOp(\n",
    "        project=project,\n",
    "        root_dir=bucket,\n",
    "        problem_type=\"classification\",\n",
    "        classification_type=\"multiclass\",\n",
    "        ground_truth_column=\"Deposit\",\n",
    "        class_names=[\"0\", \"1\"],\n",
    "        predictions_format=\"jsonl\",\n",
    "        batch_prediction_job=batch_op.outputs[\"batchpredictionjob\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_automl_pipeline:lbn,eval"
   },
   "source": [
    "### 编译并执行AutoML训练和批量模型评估管道\n",
    "\n",
    "接下来，您编译管道，然后执行它。管道接受以下参数，这些参数作为字典`parameter_values`传递：\n",
    "\n",
    "- `import_file`：训练数据的Cloud Storage位置。\n",
    "- `batch_files`：一个或多个评估数据的Cloud Storage位置列表。\n",
    "- `display_name`：Vertex AI模型和端点资源的显示名称。\n",
    "- `project`：项目ID。\n",
    "- `region`：地区。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_automl_pipeline:lbn,eval"
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"automl_lbn_training.json\"\n",
    ")\n",
    "\n",
    "pipeline = aip.PipelineJob(\n",
    "    display_name=\"automl_lbn_training\",\n",
    "    template_path=\"automl_lbn_training.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\n",
    "        \"import_file\": IMPORT_TRAIN,\n",
    "        \"batch_files\": [IMPORT_EVAL],\n",
    "        \"display_name\": \"bank\" + TIMESTAMP,\n",
    "        \"project\": PROJECT_ID,\n",
    "        \"region\": REGION,\n",
    "    },\n",
    ")\n",
    "\n",
    "pipeline.run()\n",
    "\n",
    "! rm -f automl_lbn_training.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view_pipeline_results:automl,eval,lbn"
   },
   "source": [
    "查看AutoML训练和批量评估管道的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "view_pipeline_results:automl,eval,lbn"
   },
   "outputs": [],
   "source": [
    "PROJECT_NUMBER = pipeline.gca_resource.name.split(\"/\")[1]\n",
    "print(PROJECT_NUMBER)\n",
    "\n",
    "\n",
    "def print_pipeline_output(job, output_task_name):\n",
    "    JOB_ID = job.name\n",
    "    print(JOB_ID)\n",
    "    for _ in range(len(job.gca_resource.job_detail.task_details)):\n",
    "        TASK_ID = job.gca_resource.job_detail.task_details[_].task_id\n",
    "        EXECUTE_OUTPUT = (\n",
    "            PIPELINE_ROOT\n",
    "            + \"/\"\n",
    "            + PROJECT_NUMBER\n",
    "            + \"/\"\n",
    "            + JOB_ID\n",
    "            + \"/\"\n",
    "            + output_task_name\n",
    "            + \"_\"\n",
    "            + str(TASK_ID)\n",
    "            + \"/executor_output.json\"\n",
    "        )\n",
    "        GCP_RESOURCES = (\n",
    "            PIPELINE_ROOT\n",
    "            + \"/\"\n",
    "            + PROJECT_NUMBER\n",
    "            + \"/\"\n",
    "            + JOB_ID\n",
    "            + \"/\"\n",
    "            + output_task_name\n",
    "            + \"_\"\n",
    "            + str(TASK_ID)\n",
    "            + \"/gcp_resources\"\n",
    "        )\n",
    "        if tf.io.gfile.exists(EXECUTE_OUTPUT):\n",
    "            ! gsutil cat $EXECUTE_OUTPUT\n",
    "            break\n",
    "        elif tf.io.gfile.exists(GCP_RESOURCES):\n",
    "            ! gsutil cat $GCP_RESOURCES\n",
    "            break\n",
    "\n",
    "    return EXECUTE_OUTPUT\n",
    "\n",
    "\n",
    "print(\"tabular-dataset-create\")\n",
    "artifacts = print_pipeline_output(pipeline, \"tabular-dataset-create\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"automl-tabular-training-job\")\n",
    "artifacts = print_pipeline_output(pipeline, \"automl-tabular-training-job\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"evaluateautomlmodelop\")\n",
    "artifacts = print_pipeline_output(pipeline, \"evaluateautomlmodelop\")\n",
    "output = !gsutil cat $artifacts\n",
    "output = json.loads(output[0])\n",
    "metrics = output[\"parameters\"][\"Output\"][\"stringValue\"]\n",
    "print(\"\\n\")\n",
    "print(metrics)\n",
    "print(\"\\n\\n\")\n",
    "print(\"model-batch-predict\")\n",
    "artifacts = print_pipeline_output(pipeline, \"model-batch-predict\")\n",
    "output = !gsutil cat $artifacts\n",
    "output = json.loads(output[0])\n",
    "print(\"\\n\\n\")\n",
    "print(\n",
    "    output[\"artifacts\"][\"batchpredictionjob\"][\"artifacts\"][0][\"metadata\"][\n",
    "        \"gcsOutputDirectory\"\n",
    "    ]\n",
    ")\n",
    "print(\"model-evaluation\")\n",
    "artifacts = print_pipeline_output(pipeline, \"model-evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "delete_pipeline"
   },
   "source": [
    "删除管道作业\n",
    "\n",
    "在管道作业完成之后，您可以使用`delete()`方法来删除管道作业。在完成之前，管道作业可以使用`cancel()`方法来取消。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "delete_pipeline"
   },
   "outputs": [],
   "source": [
    "pipeline.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro:model_eval,bqml"
   },
   "source": [
    "## 为BigQuery ML模型介绍顶点AI模型评估。\n",
    "\n",
    "对于BigQuery ML模型，您可以使用`BigQuery ML`服务从拆分为训练集和测试集的数据集中检索在训练期间获得的模型评估指标。\n",
    "\n",
    "此外，您可以使用`BatchPredictionOp`和`ModelEvaluationOp`组件的组合来使用自定义评估切片评估BigQuery ML模型，如下所示：\n",
    "\n",
    "- 自定义评估切片数据包含标签值（地面真相）。\n",
    "- 在自定义评估切片上执行批量预测。\n",
    "- 使用批量预测结果和标签值执行模型评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:penguins,bq,lcn"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = \"bq://bigquery-public-data.ml_datasets.penguins\"\n",
    "BQ_TABLE = \"bigquery-public-data.ml_datasets.penguins\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49d953424b88"
   },
   "outputs": [],
   "source": [
    "BQ_TABLE = \"bigquery-public-data.ml_datasets.penguins\"\n",
    "BQ_DATASET = BQ_TABLE.split(\".\")[1]\n",
    "\n",
    "\n",
    "def get_data(slice_name, limit):\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{slice_name}`\n",
    "    AS (\n",
    "        WITH\n",
    "          penguins AS (\n",
    "          SELECT\n",
    "            island,\n",
    "            sex,\n",
    "            culmen_length_mm,\n",
    "            culmen_depth_mm,\n",
    "            flipper_length_mm,\n",
    "            body_mass_g,\n",
    "            species\n",
    "          FROM\n",
    "            `{BQ_TABLE}`\n",
    "        )\n",
    "\n",
    "        SELECT\n",
    "          island,\n",
    "          sex,\n",
    "          culmen_length_mm,\n",
    "          culmen_depth_mm,\n",
    "          flipper_length_mm,\n",
    "          body_mass_g,\n",
    "          species\n",
    "        FROM\n",
    "          penguins\n",
    "        LIMIT {limit}\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    response = bqclient.query(query)\n",
    "    _ = response.result()\n",
    "\n",
    "\n",
    "BQ_TABLE_EVAL = f\"{PROJECT_ID}.{BQ_DATASET}.penguins_eval\"\n",
    "IMPORT_EVAL = f\"bq://{BQ_TABLE_EVAL}\"\n",
    "LIMIT = 44\n",
    "get_data(BQ_TABLE_EVAL, LIMIT)\n",
    "\n",
    "BQ_TABLE_TRAIN = f\"{PROJECT_ID}.{BQ_DATASET}.penguins_train\"\n",
    "IMPORT_TRAIN = f\"bq://{BQ_TABLE_TRAIN}\"\n",
    "LIMIT = \"300 OFFSET 44\"\n",
    "get_data(BQ_TABLE_TRAIN, LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bqml_pipeline:lcn,eval"
   },
   "source": [
    "### 构建用于 BigQuery ML 训练和批处理模型评估的流水线\n",
    "\n",
    "接下来，构建以下任务的流水线：\n",
    "\n",
    "- 创建一个 BigQuery ML 数据集资源。\n",
    "- 训练一个 BigQuery ML 表格分类模型。\n",
    "- 检索 BigQuery ML 评估统计数据。\n",
    "- 使用在训练过程中未使用的评估切片，对 BigQuery ML 模型进行批量预测。\n",
    "- 使用批量预测结果评估 BigQuery ML 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bqml_pipeline:lcn,eval"
   },
   "outputs": [],
   "source": [
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/bq_query\"\n",
    "\n",
    "\n",
    "@dsl.pipeline(name=\"bq-hello-world\", pipeline_root=PIPELINE_ROOT)\n",
    "def pipeline(\n",
    "    bq_train_table: str,\n",
    "    bq_eval_table: str,\n",
    "    label: str,\n",
    "    class_names: list,\n",
    "    dataset: str,\n",
    "    model: str,\n",
    "    artifact_uri: str,\n",
    "    # num_trials: int,\n",
    "    deploy_image: str,\n",
    "    machine_type: str,\n",
    "    min_replica_count: int,\n",
    "    max_replica_count: int,\n",
    "    display_name: str,\n",
    "    bucket: str,\n",
    "    accelerator_type: str = \"\",\n",
    "    accelerator_count: int = 0,\n",
    "    project: str = PROJECT_ID,\n",
    "    location: str = \"US\",\n",
    "    region: str = \"us-central1\",\n",
    "):\n",
    "    from google_cloud_pipeline_components.experimental.evaluation import \\\n",
    "        ModelEvaluationOp\n",
    "    from google_cloud_pipeline_components.v1.batch_predict_job import \\\n",
    "        ModelBatchPredictOp\n",
    "    from google_cloud_pipeline_components.v1.bigquery import (\n",
    "        BigqueryCreateModelJobOp, BigqueryEvaluateModelJobOp,\n",
    "        BigqueryExportModelJobOp, BigqueryQueryJobOp)\n",
    "    from google_cloud_pipeline_components.v1.model import ModelUploadOp\n",
    "\n",
    "    bq_dataset = BigqueryQueryJobOp(\n",
    "        project=project, location=\"US\", query=f\"CREATE SCHEMA {dataset}\"\n",
    "    )\n",
    "\n",
    "    bq_model = BigqueryCreateModelJobOp(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        query=f\"CREATE OR REPLACE MODEL {dataset}.{model} OPTIONS (model_type='dnn_classifier', labels=['{label}']) AS SELECT * FROM `{bq_train_table}` WHERE body_mass_g IS NOT NULL AND sex IS NOT NULL\",\n",
    "    ).after(bq_dataset)\n",
    "\n",
    "    bq_eval = BigqueryEvaluateModelJobOp(\n",
    "        project=PROJECT_ID, location=\"US\", model=bq_model.outputs[\"model\"]\n",
    "    ).after(bq_model)\n",
    "\n",
    "    bq_export = BigqueryExportModelJobOp(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        model=bq_model.outputs[\"model\"],\n",
    "        model_destination_path=artifact_uri,\n",
    "    ).after(bq_model)\n",
    "\n",
    "    model_upload = ModelUploadOp(\n",
    "        display_name=display_name,\n",
    "        artifact_uri=artifact_uri,\n",
    "        serving_container_image_uri=deploy_image,\n",
    "        project=project,\n",
    "        location=region,\n",
    "    ).after(bq_export)\n",
    "\n",
    "    batch_predict = ModelBatchPredictOp(\n",
    "        project=project,\n",
    "        job_display_name=\"batch_predict_job\",\n",
    "        model=model_upload.outputs[\"model\"],\n",
    "        bigquery_source_input_uri=bq_eval_table,\n",
    "        bigquery_destination_output_uri=f\"bq://{project}\",\n",
    "        instances_format=\"bigquery\",\n",
    "        predictions_format=\"bigquery\",\n",
    "        model_parameters={},\n",
    "        machine_type=DEPLOY_COMPUTE,\n",
    "        starting_replica_count=min_replica_count,\n",
    "        max_replica_count=max_replica_count,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=accelerator_count,\n",
    "    ).after(model_upload)\n",
    "\n",
    "    batch_eval = ModelEvaluationOp(\n",
    "        project=project,\n",
    "        root_dir=bucket,\n",
    "        problem_type=\"classification\",\n",
    "        classification_type=\"multiclass\",\n",
    "        ground_truth_column=label,\n",
    "        class_names=class_names,\n",
    "        predictions_format=\"jsonl\",\n",
    "        batch_prediction_job=batch_predict.outputs[\"batchpredictionjob\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_pipeline:bqml,eval"
   },
   "source": [
    "### 编译和执行 BigQuery ML 训练和批量模型评估管道\n",
    "\n",
    "接下来，您编译管道然后执行它。管道接受以下参数，这些参数作为字典 `parameter_values` 传递：\n",
    "\n",
    "- `bq_train_table`: 包含训练数据的 BigQuery 表。\n",
    "- `bq_eval_table`: 包含评估数据的 BigQuery 表。\n",
    "- `label`: BigQuery 数据集的对应标签。\n",
    "- `dataset`: BigQuery 数据集组件名称。\n",
    "- `model`: BigQuery 模型组件名称。\n",
    "- `artifact_uri`: 导出 BigQuery 模型工件的 Cloud Storage 位置。\n",
    "- `num_trials`: 如果大于一，则使用 Vertex AI Vizier 服务执行指定数量的试验进行超参数调整。\n",
    "- `deploy_image`: 用于提供预测服务的容器映像。\n",
    "- `machine_type`: 提供预测服务的虚拟机。\n",
    "- `min_replica_count`/`max_replica_count`: 用于自动扩展预测的虚拟机数量。\n",
    "- `display_name`: Vertex AI Model 资源的显示名称。\n",
    "- `project`: 项目 ID。\n",
    "- `region`: 区域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_pipeline:bqml,eval"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = BUCKET_NAME + \"/bqmodel\"\n",
    "\n",
    "compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"bqml.json\")\n",
    "\n",
    "pipeline = aip.PipelineJob(\n",
    "    display_name=\"bqml\",\n",
    "    template_path=\"bqml.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\n",
    "        \"bq_train_table\": BQ_TABLE_TRAIN,\n",
    "        \"bq_eval_table\": IMPORT_EVAL,\n",
    "        \"label\": \"species\",\n",
    "        \"class_names\": [\n",
    "            \"Adelie Penguin (Pygoscelis adeliae)\",\n",
    "            \"Chinstrap penguin (Pygoscelis antarctica)\",\n",
    "            \"Gentoo penguin (Pygoscelis papua)\",\n",
    "        ],\n",
    "        \"dataset\": \"bqml_tutorial\",\n",
    "        \"model\": \"penguins_model\",\n",
    "        \"artifact_uri\": MODEL_DIR,\n",
    "        #'num_trials': 1,\n",
    "        \"deploy_image\": DEPLOY_IMAGE,\n",
    "        \"display_name\": \"penguins\",\n",
    "        \"machine_type\": DEPLOY_COMPUTE,\n",
    "        \"min_replica_count\": 1,\n",
    "        \"max_replica_count\": 1,\n",
    "        \"accelerator_type\": DEPLOY_GPU.name,\n",
    "        \"accelerator_count\": 1,\n",
    "        \"bucket\": BUCKET_NAME,\n",
    "        \"project\": PROJECT_ID,\n",
    "        \"location\": \"US\",\n",
    "    },\n",
    "    # enable_caching=False\n",
    ")\n",
    "\n",
    "pipeline.run()\n",
    "\n",
    "! rm -rf bqml.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view_pipeline_results:bqml,eval,lcn"
   },
   "source": [
    "查看BigQuery ML的训练和批量评估管道结果###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "view_pipeline_results:bqml,eval,lcn"
   },
   "outputs": [],
   "source": [
    "PROJECT_NUMBER = pipeline.gca_resource.name.split(\"/\")[1]\n",
    "print(PROJECT_NUMBER)\n",
    "\n",
    "\n",
    "def print_pipeline_output(job, output_task_name):\n",
    "    JOB_ID = job.name\n",
    "    print(JOB_ID)\n",
    "    for _ in range(len(job.gca_resource.job_detail.task_details)):\n",
    "        TASK_ID = job.gca_resource.job_detail.task_details[_].task_id\n",
    "        EXECUTE_OUTPUT = (\n",
    "            PIPELINE_ROOT\n",
    "            + \"/\"\n",
    "            + PROJECT_NUMBER\n",
    "            + \"/\"\n",
    "            + JOB_ID\n",
    "            + \"/\"\n",
    "            + output_task_name\n",
    "            + \"_\"\n",
    "            + str(TASK_ID)\n",
    "            + \"/executor_output.json\"\n",
    "        )\n",
    "        GCP_RESOURCES = (\n",
    "            PIPELINE_ROOT\n",
    "            + \"/\"\n",
    "            + PROJECT_NUMBER\n",
    "            + \"/\"\n",
    "            + JOB_ID\n",
    "            + \"/\"\n",
    "            + output_task_name\n",
    "            + \"_\"\n",
    "            + str(TASK_ID)\n",
    "            + \"/gcp_resources\"\n",
    "        )\n",
    "        if tf.io.gfile.exists(EXECUTE_OUTPUT):\n",
    "            ! gsutil cat $EXECUTE_OUTPUT\n",
    "            break\n",
    "        elif tf.io.gfile.exists(GCP_RESOURCES):\n",
    "            ! gsutil cat $GCP_RESOURCES\n",
    "            break\n",
    "\n",
    "    return EXECUTE_OUTPUT\n",
    "\n",
    "\n",
    "print(\"bigquery-query-job\")\n",
    "artifacts = print_pipeline_output(pipeline, \"bigquery-query-job\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"bigquery-create-model-job\")\n",
    "artifacts = print_pipeline_output(pipeline, \"bigquery-create-model-job\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"bigquery-evaluate-model-job\")\n",
    "artifacts = print_pipeline_output(pipeline, \"bigquery-evaluate-model-job\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"bigquery-export-model-job\")\n",
    "artifacts = print_pipeline_output(pipeline, \"bigquery-export-model-job\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"model-upload\")\n",
    "artifacts = print_pipeline_output(pipeline, \"model-upload\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"model-batch-predict\")\n",
    "artifacts = print_pipeline_output(pipeline, \"model-batch-predict\")\n",
    "output = !gsutil cat $artifacts\n",
    "output = json.loads(output[0])\n",
    "print(\"\\n\\n\")\n",
    "print(\n",
    "    output[\"artifacts\"][\"batchpredictionjob\"][\"artifacts\"][0][\"metadata\"][\n",
    "        \"gcsOutputDirectory\"\n",
    "    ]\n",
    ")\n",
    "print(\"model-evaluation\")\n",
    "artifacts = print_pipeline_output(pipeline, \"model-evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "delete_pipeline"
   },
   "source": [
    "### 删除管道作业\n",
    "\n",
    "在管道作业完成后，您可以使用`delete()`方法删除管道作业。在完成之前，可以使用`cancel()`方法取消管道作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "delete_pipeline"
   },
   "outputs": [],
   "source": [
    "pipeline.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "delete:bqml,penguins"
   },
   "source": [
    "删除BigQuery模型和数据集\n",
    "\n",
    "接下来，删除BigQuery模型和数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "delete:bqml,penguins"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    job = bqclient.delete_model(\"bqml_tutorial.penguins_model\")\n",
    "except:\n",
    "    pass\n",
    "job = bqclient.delete_dataset(\"bqml_tutorial\", delete_contents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理本项目中使用的所有谷歌云资源，您可以删除用于本教程的[谷歌云项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源。\n",
    "\n",
    "- 数据集\n",
    "- 流水线\n",
    "- 模型\n",
    "- 端点\n",
    "- AutoML 训练作业\n",
    "- 批处理作业\n",
    "- 自定义作业\n",
    "- 超参数调整作业\n",
    "- 云存储存储桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "outputs": [],
   "source": [
    "delete_all = True\n",
    "\n",
    "if delete_all:\n",
    "    # Delete the dataset using the Vertex dataset object\n",
    "    try:\n",
    "        if \"dataset\" in globals():\n",
    "            dataset.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Delete the model using the Vertex model object\n",
    "    try:\n",
    "        if \"model\" in globals():\n",
    "            model.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Delete the endpoint using the Vertex endpoint object\n",
    "    try:\n",
    "        if \"endpoint\" in globals():\n",
    "            endpoint.undeploy_all()\n",
    "            endpoint.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Delete the AutoML or Pipeline training job\n",
    "    try:\n",
    "        if \"dag\" in globals():\n",
    "            dag.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Delete the custom training job\n",
    "    try:\n",
    "        if \"job\" in globals():\n",
    "            job.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Delete the batch prediction job using the Vertex batch prediction object\n",
    "    try:\n",
    "        if \"batch_predict_job\" in globals():\n",
    "            batch_predict_job.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Delete the hyperparameter tuning job using the Vertex hyperparameter tuning object\n",
    "    try:\n",
    "        if \"hpt_job\" in globals():\n",
    "            hpt_job.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    if \"BUCKET_NAME\" in globals():\n",
    "        ! gsutil rm -r $BUCKET_NAME"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_with_model_evaluation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
