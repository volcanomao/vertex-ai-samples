{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "# GCP上的端到端机器学习：MLOps阶段1：形式化：使用Vertex AI数据标注开始\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage1/get_started_with_data_labeling.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage1/get_started_with_data_labeling.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/ml_ops/stage1/get_started_with_data_labeling.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:mlops"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何在Google Cloud上使用Vertex AI进行端到端MLOps生产。本教程涵盖了第1阶段：数据管理：开始使用Vertex AI数据标记服务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:mlops,stage3,get_started_automl_pipeline_components"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用`Vertex AI数据标记`服务。\n",
    "\n",
    "本教程使用以下Google Cloud ML服务：\n",
    "\n",
    "- `Vertex AI数据标记`\n",
    "- `Vertex AI数据集`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 为数据标记者创建专家池。\n",
    "- 创建数据标记工作。\n",
    "- 提交数据标记工作。\n",
    "- 列出数据标记工作。\n",
    "- 取消数据标记工作。\n",
    "\n",
    "了解更多关于[请求Vertex AI数据标记工作](https://cloud.google.com/vertex-ai/docs/datasets/data-labeling-job)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:flowers,icn"
   },
   "source": [
    "数据集\n",
    "\n",
    "本教程使用的数据集是来自TensorFlow数据集的[花卉数据集](https://www.tensorflow.org/datasets/catalog/tf_flowers)。在本教程中使用的数据集版本存储在公共云存储桶中。训练模型可以预测一幅图像属于五种花朵中的哪一种：雏菊、蒲公英、玫瑰、向日葵或郁金香。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c997d8d92ce"
   },
   "source": [
    "费用\n",
    "\n",
    "本教程使用Google Cloud的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage 价格](https://cloud.google.com/storage/pricing)，并使用[Pricing 计算器](https://cloud.google.com/products/calculator/)根据您预计的使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装以下包以执行这个笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_mlops"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "# Install the packages\n",
    "! pip3 install --upgrade google-cloud-aiplatform $USER_FLAG -q\n",
    "! pip3 install --upgrade google-cloud-storage $USER_FLAG -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### 重新启动内核\n",
    "\n",
    "一旦您安装了Vertex AI SDK和Google *cloud-storage*，您需要重新启动笔记本内核，以便它可以找到这些软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GIwKc4pk_i_t"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### GPU 运行时\n",
    "\n",
    "*如果您有此选项，请确保在 GPU 运行时中运行此笔记本。在 Colab 中，选择* **运行时 > 更改运行时类型 > GPU**\n",
    "\n",
    "### 设置您的 GCP 项目\n",
    "\n",
    "**以下步骤是必需的，无论您的笔记本环境如何。**\n",
    "\n",
    "1. [选择或创建一个 GCP 项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建账户时，您将获得 $300 的免费信用以支付计算/存储成本。\n",
    "\n",
    "2. [确保为您的项目启用了计费。](https://cloud.google.com/billing/docs/how-to/modify-project)\n",
    "\n",
    "3. [启用 Vertex AI APIs 和 Compute Engine APIs。](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component)\n",
    "\n",
    "4. [Google Cloud SDK](https://cloud.google.com/sdk) 已经安装在 Vertex AI Workbench Notebooks 中。\n",
    "\n",
    "5. 在下面的单元格中输入您的项目 ID。然后运行该单元格，以确保 Cloud SDK 在本笔记本中的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**: Jupyter 会将以 `!` 为前缀的行视为 shell 命令，并将以 `$` 为前缀的 Python 变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "### 设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用 `gcloud` 命令获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "区域\n",
    "\n",
    "您还可以更改`REGION`变量，该变量用于整个笔记本的操作。以下是Vertex AI支持的区域。我们建议您选择离您最近的区域。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太：`asia-east1`\n",
    "\n",
    "您可能无法使用多区域存储桶进行Vertex AI的训练。并非所有区域都支持所有Vertex AI服务。 \n",
    "\n",
    "了解更多关于[Vertex AI区域](https://cloud.google.com/vertex-ai/docs/general/locations)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Xtp5tvK_i_y"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "时间戳\n",
    "\n",
    "如果您正在参加直播教程会议，您可能正在使用共享测试帐户或项目。为了避免用户在创建的资源上发生名称冲突，您可以为每个实例会话创建一个时间戳，并附加到在本教程中将要创建的资源的名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d70An-Mg_i_2"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d29f41c6619e"
   },
   "source": [
    "邮箱\n",
    "\n",
    "您需要一个邮箱地址来发送标注任务请求。这个邮箱地址将是数据标注专家池的管理员。\n",
    "\n",
    "在本教程中，如果您没有指定一个邮箱地址，将使用与您的项目ID关联的邮箱地址。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e443c02540c"
   },
   "outputs": [],
   "source": [
    "EMAIL = \"[your-email-address]\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ca885f17d6ac"
   },
   "outputs": [],
   "source": [
    "if EMAIL == \"[your-email-address]\":\n",
    "    shell_output = ! gcloud auth list 2>/dev/null\n",
    "    EMAIL = shell_output[2].replace(\"*\", \"\").strip()\n",
    "\n",
    "print(EMAIL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 认证您的 Google Cloud 账户\n",
    "\n",
    "**如果您正在使用 Vertex AI 工作台笔记本**，您的环境已经得到了认证。\n",
    "\n",
    "**如果您正在使用 Colab**，运行下面的单元格，并按照提示进行身份验证以通过 oAuth 认证您的账户。\n",
    "\n",
    "**否则**，请按照以下步骤操作：\n",
    "\n",
    "1. 在 Cloud 控制台中，转到 [**创建服务帐户密钥** 页面](https://console.cloud.google.com/apis/credentials/serviceaccountkey)。\n",
    "\n",
    "2. 点击 **创建服务帐户**。\n",
    "\n",
    "3. 在 **服务帐户名称** 字段中输入一个名称，并\n",
    "   点击 **创建**。\n",
    "\n",
    "4. 在 **授予此服务帐户对项目的访问权限** 部分，点击 **角色** 下拉列表。在筛选框中输入 \"Vertex AI\"，\n",
    "   选择 **Vertex AI 管理员**。在筛选框中输入 \"Storage Object Admin\"，选择 **Storage Object Admin**。\n",
    "\n",
    "5. 点击 *创建*。一个包含您密钥的 JSON 文件将下载到您的本地环境。\n",
    "\n",
    "6. 在下面的单元格中将您的服务帐户密钥路径输入为\n",
    "   `GOOGLE_APPLICATION_CREDENTIALS` 变量，并运行此单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chybg3Ap_i_2"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = False\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        IS_COLAB = True\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:batch_prediction"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "**无论您使用什么笔记本环境，都需要执行以下步骤。**\n",
    "\n",
    "本教程旨在使用公共云存储桶中的训练数据，并为批量预测使用本地云存储桶。您也可以使用存储在本地云存储桶中的自己的训练数据。\n",
    "\n",
    "在下面设置您的云存储桶的名称。它必须在所有云存储桶中是唯一的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_URI == \"\" or BUCKET_URI is None or BUCKET_URI == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_NAME = PROJECT_ID + \"aip-\" + TIMESTAMP\n",
    "    BUCKET_URI = \"gs://\" + BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有当您的存储桶不存在时：运行以下单元格以创建您的Cloud Storage存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPPrwWpO_i_6"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "最后，通过检查云存储桶中的内容来确认对其的访问权限："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fn744B7x_i_7"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。\n",
    "### 导入库并定义常量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_aip"
   },
   "source": [
    "#### 导入 Vertex AI SDK\n",
    "\n",
    "将Vertex AI SDK导入到我们的Python环境中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97-XQPkv_i_7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import google.cloud.aiplatform as aip\n",
    "from google.cloud import storage\n",
    "from google.cloud.aiplatform import gapic\n",
    "from google.protobuf.json_format import ParseDict\n",
    "from google.protobuf.struct_pb2 import Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "750d53e37094"
   },
   "source": [
    "### 初始化使用Python的Vertex AI SDK\n",
    "\n",
    "为您的项目和对应的存储桶初始化使用Python的Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adcc964aaaa1"
   },
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aip_constants"
   },
   "source": [
    "#### Vertex AI常量\n",
    "\n",
    "为Vertex AI设置以下常量：\n",
    "\n",
    "- `API_ENDPOINT`：用于数据集、模型、作业、管道和端点服务的Vertex AI API服务端点。\n",
    "- `PARENT`：用于数据集、模型和端点资源的Vertex AI位置根路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBBYqHEd_i_8"
   },
   "outputs": [],
   "source": [
    "# API Endpoint\n",
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "\n",
    "# Vertex AI location root path for your dataset, model and endpoint resources\n",
    "PARENT = \"projects/\" + PROJECT_ID + \"/locations/\" + REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "automl_constants:automl"
   },
   "source": [
    "常量架构\n",
    "\n",
    "接下来，为与图像分类数据集相关的架构设置常量：\n",
    "\n",
    "- 数据标签（注释）架构：告诉托管的数据集服务数据是如何标记（注释）的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "automl_constants:automl,icn"
   },
   "outputs": [],
   "source": [
    "# Image labeling task\n",
    "LABELING_SCHEMA_IMAGE = \"gs://google-cloud-aiplatform/schema/datalabelingjob/inputs/image_classification_1.0.0.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clients"
   },
   "source": [
    "## 创建客户端\n",
    "\n",
    "Vertex AI SDK采用客户端/服务器模型。在您的端上（Python脚本），您创建一个客户端，该客户端向服务器（Vertex AI）发送请求并接收响应。\n",
    "\n",
    "在本教程中，您将使用多个客户端，请提前设置它们。\n",
    "\n",
    "- 专业池服务用于专业池\n",
    "- 作业服务用于数据标记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2p2VYUz_i_-"
   },
   "outputs": [],
   "source": [
    "# client options same for all services\n",
    "client_options = {\"api_endpoint\": API_ENDPOINT}\n",
    "\n",
    "clients = {}\n",
    "clients[\"job\"] = gapic.JobServiceClient(client_options=client_options)\n",
    "\n",
    "# add client for specialist pool\n",
    "clients[\"specialist_pool\"] = gapic.SpecialistPoolServiceClient(\n",
    "    client_options=client_options\n",
    ")\n",
    "\n",
    "for client in clients.items():\n",
    "    print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d4b33eb3c71"
   },
   "source": [
    "创建一个用于示例标记的CSV文件\n",
    "\n",
    "接下来，您将为您要求标记的示例创建一个CSV文件。\n",
    "\n",
    "在本示例中，要标记的示例是图片。在CSV文件的每一行中，您都要指定要标记的图片在云存储中的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:flowers,csv,icn"
   },
   "outputs": [],
   "source": [
    "test_filename = \"labeling.csv\"\n",
    "LABELING_FILES = [\n",
    "    \"gs://cloud-samples-data/vision/automl_classification/flowers/daisy/100080576_f52e8ee070_n.jpg\",\n",
    "    \"gs://cloud-samples-data/vision/automl_classification/flowers/daisy/102841525_bd6628ae3c.jpg\",\n",
    "]\n",
    "\n",
    "IMPORT_FILE = BUCKET_URI + \"/labeling.csv\"\n",
    "\n",
    "bucket = storage.Client(project=PROJECT_ID).bucket(BUCKET_URI.replace(\"gs://\", \"\"))\n",
    "\n",
    "# creating a blob\n",
    "blob = bucket.blob(blob_name=test_filename)\n",
    "\n",
    "# creating data variable\n",
    "data = LABELING_FILES[0] + \"\\n\" + LABELING_FILES[1] + \"\\n\"\n",
    "\n",
    "# uploading data variable content to bucket\n",
    "blob.upload_from_string(data, content_type=\"text/csv\")\n",
    "\n",
    "# printing path of uploaded file\n",
    "print(IMPORT_FILE)\n",
    "\n",
    "# printing content of uploaded file\n",
    "! gsutil cat $IMPORT_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_a_dataset:migration"
   },
   "source": [
    "创建一个未标记的数据集\n",
    "\n",
    "接下来，您需要创建一个数据集来标记数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9af8aed4e3ab"
   },
   "outputs": [],
   "source": [
    "dataset = aip.ImageDataset.create(\"labeling_\" + TIMESTAMP)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92909927fe7e"
   },
   "source": [
    "## 导入未标记的数据\n",
    "\n",
    "现在，将未标记的数据导入数据集，即要标记的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c137a55b822e"
   },
   "outputs": [],
   "source": [
    "dataset.import_data(\n",
    "    gcs_source=[IMPORT_FILE],\n",
    "    import_schema_uri=aip.schema.dataset.ioformat.image.single_label_classification,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trainingpipelines_create:migration,new"
   },
   "source": [
    "## 创建一个新的数据专家池\n",
    "\n",
    "您的数据标注工作将会发送到一个数据专家池中。您可以拥有一个或多个专家池。\n",
    "\n",
    "在下一步中，您可以通过方法 `create_specialist_pool()` 来创建一个新的专家池。请求应该包括以下参数：\n",
    "\n",
    "- `name`：专家池的资源名称。\n",
    "- `display_name`：专家池的可读名称。\n",
    "- `specialist_manager_emails`：专家池经理（们）的电子邮件地址列表。\n",
    "\n",
    "*注意：* 如果已经存在一个专家池，您可以使用现有的专家池。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsXOMVOMq3jO"
   },
   "outputs": [],
   "source": [
    "specialist_pool = {\n",
    "    \"name\": \"labeling_\" + TIMESTAMP,\n",
    "    \"display_name\": \"labeling_\" + TIMESTAMP,\n",
    "    \"specialist_manager_emails\": [EMAIL],\n",
    "}\n",
    "\n",
    "request = clients[\"specialist_pool\"].create_specialist_pool(\n",
    "    parent=PARENT, specialist_pool=specialist_pool\n",
    ")\n",
    "\n",
    "result = request.result()\n",
    "print(result)\n",
    "\n",
    "specialist_name = result.name\n",
    "\n",
    "specialist_id = specialist_name.split(\"/\")[-1]\n",
    "\n",
    "print(specialist_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_a_model:migration"
   },
   "source": [
    "## 创建数据标注任务\n",
    "\n",
    "现在您已经有了专家池，您可以使用`create_data_labeling_job()`方法发送数据标注请求。\n",
    "\n",
    "您的请求将包括以下内容：\n",
    "\n",
    "- 包含未标记数据的Vertex AI数据集。\n",
    "- 标注指令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AY3SJjQq3jQ"
   },
   "outputs": [],
   "source": [
    "# create placeholder file for instructions for data labeling\n",
    "! echo \"this is instruction\" >> instruction.txt | gsutil cp instruction.txt $BUCKET_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trainingpipelines_create:migration,new,request,icn"
   },
   "outputs": [],
   "source": [
    "LABLEING_SCHEMA = LABELING_SCHEMA_IMAGE\n",
    "INSTRUCTION_FILE = BUCKET_URI + \"/instruction.txt\"\n",
    "\n",
    "inputs = ParseDict({\"annotation_specs\": [\"rose\"]}, Value())\n",
    "\n",
    "data_labeling_job = {\n",
    "    \"display_name\": \"labeling_\" + TIMESTAMP,\n",
    "    \"datasets\": [dataset.resource_name],\n",
    "    \"labeler_count\": 1,\n",
    "    \"instruction_uri\": INSTRUCTION_FILE,\n",
    "    \"inputs_schema_uri\": LABLEING_SCHEMA,\n",
    "    \"inputs\": inputs,\n",
    "    \"annotation_labels\": {\n",
    "        \"aiplatform.googleapis.com/annotation_set_name\": \"data_labeling_job_specialist_pool\"\n",
    "    },\n",
    "    \"specialist_pools\": [specialist_name],\n",
    "}\n",
    "\n",
    "print(data_labeling_job)\n",
    "\n",
    "request = clients[\"job\"].create_data_labeling_job(\n",
    "    parent=PARENT, data_labeling_job=data_labeling_job\n",
    ")\n",
    "\n",
    "print(request)\n",
    "\n",
    "labeling_task_name = request.name\n",
    "\n",
    "print(labeling_task_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3jRv70o_jAN"
   },
   "source": [
    "### 获得数据标注工作\n",
    "\n",
    "您可以使用`get_data_labeling_job()`方法获取有关您的数据标注工作的信息，以下是相应的参数：\n",
    "\n",
    "- `name`： 标注任务的名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPnMOftyq3jS"
   },
   "outputs": [],
   "source": [
    "request = clients[\"job\"].get_data_labeling_job(name=labeling_task_name)\n",
    "print(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQ0TVlokq3jS"
   },
   "source": [
    "取消数据标注任务\n",
    "\n",
    "您可以使用`cancel_data_labeling_job()`方法取消数据标注请求，参数如下:\n",
    "\n",
    "- `name`: 标注任务的名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZ3dlKJjq3jT"
   },
   "outputs": [],
   "source": [
    "request = clients[\"job\"].cancel_data_labeling_job(name=labeling_task_name)\n",
    "print(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d37f8ede2327"
   },
   "source": [
    "### 等待标记工作被取消\n",
    "\n",
    "取消请求是异步的。下面的代码会循环检查标记工作的状态，直到状态变为已取消。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trainingpipelines_get:migration,new,wait"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    response = clients[\"job\"].get_data_labeling_job(name=labeling_task_name)\n",
    "    if response.state == gapic.JobState.JOB_STATE_CANCELLED:\n",
    "        print(\"Labeling job CANCELED\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Canceling labeling job:\", response.state)\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:migration,new"
   },
   "source": [
    "清理工作\n",
    "\n",
    "要清理此项目中使用的所有GCP资源，您可以删除用于本教程的[GCP项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aoJ18d8Y_jAy"
   },
   "outputs": [],
   "source": [
    "# Set this to true only if you'd like to delete your bucket\n",
    "delete_bucket = False\n",
    "\n",
    "# Delete the dataset using the Vertex AI fully qualified identifier for the dataset\n",
    "dataset.delete()\n",
    "\n",
    "# Delete the labeling job using the Vertex AI fully qualified identifier for the dataset\n",
    "request = clients[\"job\"].delete_data_labeling_job(name=labeling_task_name)\n",
    "\n",
    "# Delete the specialist pool using the Vertex AI fully qualified identifier for the dataset\n",
    "clients[\"specialist_pool\"].delete_specialist_pool(name=specialist_name)\n",
    "\n",
    "# Delete the bucket created\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "timestamp",
    "gcp_authenticate",
    "bucket:batch_prediction",
    "setup_vars",
    "import_aip",
    "aip_constants",
    "automl_constants:automl",
    "datasets_create:migration,new",
    "request:migration",
    "call:migration",
    "response:migration",
    "datasets_import:migration,new",
    "oJtL08_Q_jAF",
    "rnhDF5vW_jAG",
    "zQoFJ2K0_jAH",
    "trainingpipelines_create:migration,new",
    "m5igPySU_jAJ",
    "xhuR86RL_jAK",
    "S8zP7wju_jAL",
    "trainingpipelines_get:migration,new",
    "A3jRv70o_jAN",
    "XC5I2xxt_jAN",
    "models_evaluations_list:migration,new",
    "Ngn6qqVy_jAQ",
    "F0ryqI3F_jAQ",
    "models_evaluations_get:migration,new",
    "_NXujm2U_jAR",
    "0RLTdCfj_jAS",
    "make_batch_prediction_file:migration,new",
    "make_batch_file:automl,image",
    "batchpredictionjobs_create:migration,new",
    "htIpycBi_jAX",
    "8QO3y-36_jAY",
    "DmClxRYK_jAY",
    "batchpredictionjobs_get:migration,new",
    "aSE_wqES_jAa",
    "LUy0NIF__jAa",
    "endpoints_create:migration,new",
    "Ph5S0j4v_jAc",
    "yjsSo1cM_jAd",
    "ijvF_HGd_jAe",
    "endpoints_deploymodel:migration,new",
    "NFIRI0XT_jAf",
    "c3_4BVyW_jAh",
    "7NmySa8R_jAh",
    "endpoints_predict:migration,new",
    "6fb84nKh_jAk",
    "h6IskqWe_jAo",
    "KHf2BSMR_jAo",
    "endpoints_undeploymodel:migration,new",
    "KrVZz6Uw_jAp",
    "wvFK-kir_jAq",
    "5bwEQMKT_jAr",
    "LOsxiKj4_jAs",
    "PWMEUCbF_jAt",
    "OalQ6m9P_jAu",
    "models_export:migration,new",
    "lqJoqYMI_jAv",
    "v6isqzPQ_jAw",
    "ZCyd1qAb_jAx"
   ],
   "name": "get_started_with_data_labeling.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
