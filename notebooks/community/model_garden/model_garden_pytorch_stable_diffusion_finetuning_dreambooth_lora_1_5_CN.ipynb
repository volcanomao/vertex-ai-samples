{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7d9bbf86da5e"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99c1c3fc2ca5"
   },
   "source": [
    "# Vertex AI模型园 - 稳定扩散V1.5（Dreambooth+LoRA微调）\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_stable_diffusion_finetuning_dreambooth_lora.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_stable_diffusion_finetuning_dreambooth_lora.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_pytorch_stable_diffusion_finetuning_dreambooth_lora.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "在Vertex AI工作台中打开\n",
    "    </a>\n",
    "    (推荐使用Python-3 CPU笔记本)\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3de7470326a2"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本笔记本演示如何在[Colab](https://colab.research.google.com)或[Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)上使用[Dreambooth和LoRA](https://huggingface.co/docs/diffusers/training/dreambooth#finetuning-with-lora)对[runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)模型进行微调，并在Vertex AI上部署以进行在线预测。\n",
    "\n",
    "\n",
    "### 目标\n",
    "\n",
    "- 使用[Dreambooth + LoRA](https://huggingface.co/docs/diffusers/training/dreambooth#finetuning-with-lora)对stable-diffusion-v1.5模型进行微调。\n",
    "- 将微调后的模型上传到[Vertex AI Model Registry](https://cloud.google.com/vertex-ai/docs/model-registry/introduction)。\n",
    "- 将微调后的模型部署到[Vertex AI Endpoint资源](https://cloud.google.com/vertex-ai/docs/predictions/using-private-endpoints)。\n",
    "- 为文本到图像的在线预测运行。\n",
    "\n",
    "### 费用\n",
    "\n",
    "本教程使用Google Cloud的可计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* 云存储\n",
    "\n",
    "了解[Vertex AI价格](https://cloud.google.com/vertex-ai/pricing)和[云存储价格](https://cloud.google.com/storage/pricing)，并使用[定价计算器](https://cloud.google.com/products/calculator/)根据您的预期使用情况生成费用估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "264c07757582"
   },
   "source": [
    "## 在开始之前\n",
    "\n",
    "**注意**：Jupyter会将以`!`为前缀的行作为shell命令运行，并将以`$`为前缀的Python变量插入到这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioensNKM8ned"
   },
   "source": [
    "设置笔记本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d73ffa0c0b83"
   },
   "source": [
    "只在Colab上运行以下命令。如果您正在使用Workbench，请跳过此部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2707b02ef5df"
   },
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    ! pip3 install --upgrade google-cloud-aiplatform\n",
    "    from google.colab import auth as google_auth\n",
    "\n",
    "    google_auth.authenticate_user()\n",
    "    # Install gdown for downloading example training images.\n",
    "    ! pip3 install gdown\n",
    "    # Remove wrong cublas version.\n",
    "    ! pip3 uninstall nvidia_cublas_cu11 --yes\n",
    "\n",
    "    # Restart the notebook kernel after installs.\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb671e75ca7b"
   },
   "source": [
    "仅工作台\n",
    "1. 点击[此链接](https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_pytorch_stable_diffusion_deployment_1_5.ipynb)将笔记本部署到Vertex AI工作台实例。\n",
    "2. 选择“创建新笔记本”。\n",
    "3. 点击“高级选项”。\n",
    "4. 在“环境”选项卡中，选择“Debian 10”作为“操作系统”，并选择“自定义容器”作为“环境”。\n",
    "5. 将“Docker容器镜像”设置为“us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/transformers-notebook”。\n",
    "6. 在“机器配置”下，选择1个“T4” GPU，并选择“自动为我安装NVIDIA GPU驱动程序”。\n",
    "7. 点击“创建”以创建Vertex AI工作台实例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb7adab99e41"
   },
   "source": [
    "### 设置Google Cloud项目\n",
    "\n",
    "1. [选择或创建一个Google Cloud项目](https://console.cloud.google.com/cloud-resource-manager)。在您第一次创建帐户时，您将获得300美元的免费信用额用于计算/存储成本。\n",
    "\n",
    "2. [确保您的项目已启用计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "3. [启用Vertex AI API和Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component)。\n",
    "\n",
    "4. [创建一个云存储存储桶](https://cloud.google.com/storage/docs/creating-buckets) 用于存储实验输出。\n",
    "\n",
    "5. [创建一个服务帐号](https://cloud.google.com/iam/docs/service-accounts-create#iam-service-accounts-create-console) 并为其分配 `Vertex AI用户` 和 `存储对象管理员` 角色，以将优化后的模型部署到Vertex AI端点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6c460088b873"
   },
   "source": [
    "为实验环境填写以下变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "855d6b96f291"
   },
   "outputs": [],
   "source": [
    "# Cloud project id.\n",
    "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# The region you want to launch jobs in.\n",
    "REGION = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# The Cloud Storage bucket for storing experiments output. Fill it without the 'gs://' prefix.\n",
    "GCS_BUCKET = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# The service account for deploying fine tuned model.\n",
    "SERVICE_ACCOUNT = \"\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e828eb320337"
   },
   "source": [
    "初始化Vertex-AI API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "12cd25839741"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cc825514deb"
   },
   "source": [
    "### 定义常数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "b42bd4fa2b2d"
   },
   "outputs": [],
   "source": [
    "# The pre-built training docker images. They contain training scripts and models.\n",
    "TRAIN_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-peft-train:20240202_1425_RC00\"\n",
    "\n",
    "# The pre-built serving docker images. They contains serving scripts and models.\n",
    "SERVE_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-diffusers-serve-opt:20240605_1400_RC00\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c250872074f"
   },
   "source": [
    "### 定义常见的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "354da31189dc"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "from google.cloud import aiplatform, storage\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def create_job_name(prefix):\n",
    "    user = os.environ.get(\"USER\")\n",
    "    now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    job_name = f\"{prefix}-{user}-{now}\"\n",
    "    return job_name\n",
    "\n",
    "\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    return Image.open(BytesIO(response.content))\n",
    "\n",
    "\n",
    "def image_to_base64(image, format=\"JPEG\"):\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=format)\n",
    "    image_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    return image_str\n",
    "\n",
    "\n",
    "def base64_to_image(image_str):\n",
    "    image = Image.open(BytesIO(base64.b64decode(image_str)))\n",
    "    return image\n",
    "\n",
    "\n",
    "def image_grid(imgs, rows=2, cols=2):\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "\n",
    "def deploy_model(\n",
    "    model_name,\n",
    "    base_model_id,\n",
    "    lora_id,\n",
    "    task,\n",
    "    machine_type=\"g2-standard-8\",\n",
    "    accelerator_type=\"NVIDIA_L4\",\n",
    "):\n",
    "    \"\"\"Deploys trained models into Vertex AI.\"\"\"\n",
    "    endpoint = aiplatform.Endpoint.create(display_name=f\"{model_name}-endpoint\")\n",
    "    serving_env = {\n",
    "        \"MODEL_ID\": base_model_id,\n",
    "        \"TASK\": task,\n",
    "        \"DEPLOY_SOURCE\": \"notebook\",\n",
    "    }\n",
    "    if lora_id:\n",
    "        serving_env[\"LORA_ID\"] = lora_id\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=model_name,\n",
    "        serving_container_image_uri=SERVE_DOCKER_URI,\n",
    "        serving_container_ports=[7080],\n",
    "        serving_container_predict_route=\"/predictions/diffusers_serving\",\n",
    "        serving_container_health_route=\"/ping\",\n",
    "        serving_container_environment_variables=serving_env,\n",
    "    )\n",
    "    model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        machine_type=machine_type,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=1,\n",
    "        deploy_request_timeout=1800,\n",
    "        service_account=SERVICE_ACCOUNT,\n",
    "    )\n",
    "    return model, endpoint\n",
    "\n",
    "\n",
    "def get_bucket_and_blob_name(filepath):\n",
    "    # The gcs path is of the form gs://<bucket-name>/<blob-name>\n",
    "    gs_suffix = filepath.split(\"gs://\", 1)[1]\n",
    "    return tuple(gs_suffix.split(\"/\", 1))\n",
    "\n",
    "\n",
    "def upload_local_dir_to_gcs(local_dir_path, gcs_dir_path):\n",
    "    \"\"\"Uploads files in a local directory to a GCS directory.\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket_name = gcs_dir_path.split(\"/\")[2]\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    for local_file in glob.glob(local_dir_path + \"/**\"):\n",
    "        if not os.path.isfile(local_file):\n",
    "            continue\n",
    "        filename = local_file[1 + len(local_dir_path) :]\n",
    "        gcs_file_path = os.path.join(gcs_dir_path, filename)\n",
    "        _, blob_name = get_bucket_and_blob_name(gcs_file_path)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        blob.upload_from_filename(local_file)\n",
    "        print(\"Copied {} to {}.\".format(local_file, gcs_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jTetcepAZeO"
   },
   "source": [
    "用Dreambooth和LoRA进行微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gQFXhVuAcc-"
   },
   "source": [
    "### 微调\n",
    "\n",
    "本节使用[dreambooth](https://dreambooth.github.io/)和[LoRA](https://arxiv.org/abs/2106.09685)来微调[stable-diffusion-v1.5](https://huggingface.co/runwayml/stable-diffusion-v1-5)模型，使用[5张狗的图片](https://drive.google.com/drive/folders/1BO_dyz-p65qhBRRMRA4TbZ8qW4rB99JZ)来个性化文本生成图像的模型。\n",
    "\n",
    "在微调作业完成后，完整的模型将被保存，可以通过[StableDiffusionPipeline](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img)加载以进行推理。\n",
    "\n",
    "注：在使用LoRA时，可以使用比普通dreambooth更高的学习率。这里我们使用`1e-4`，而不是通常的`2e-6`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dh1JNKYDUuwZ"
   },
   "outputs": [],
   "source": [
    "# Download example training images.\n",
    "!gdown --folder https://drive.google.com/drive/folders/1BO_dyz-p65qhBRRMRA4TbZ8qW4rB99JZ\n",
    "\n",
    "# Upload data to Cloud Storage bucket.\n",
    "upload_local_dir_to_gcs(\"dog\", f\"gs://{GCS_BUCKET}/dreambooth-lora/dog\")\n",
    "upload_local_dir_to_gcs(\"dog\", f\"gs://{GCS_BUCKET}/dreambooth-lora/dog_class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22zEZjQKU4R-"
   },
   "source": [
    "注意：如果由于权限不足导致上传步骤失败，您需要为笔记本的云账户[授予存储对象管理员角色](https://cloud.google.com/storage/docs/access-control/using-iam-permissions)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKUXH9b9Bvta"
   },
   "outputs": [],
   "source": [
    "# The pre-trained model to be loaded.\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "# Input and output path.\n",
    "instance_dir = f\"/gcs/{GCS_BUCKET}/dreambooth-lora/dog\"\n",
    "output_dir_dreambooth_lora = f\"/gcs/{GCS_BUCKET}/dreambooth-lora/output\"\n",
    "gs_output_dir_dreambooth_lora = f\"gs://{GCS_BUCKET}/dreambooth-lora/output\"\n",
    "\n",
    "\n",
    "# Worker pool spec.\n",
    "machine_type = \"n1-highmem-8\"\n",
    "num_nodes = 1\n",
    "gpu_type = \"NVIDIA_TESLA_V100\"\n",
    "num_gpus = 1\n",
    "\n",
    "# Setup training job.\n",
    "job_name = create_job_name(\"dreambooth-lora-stable-diffusion\")\n",
    "job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=job_name,\n",
    "    container_uri=TRAIN_DOCKER_URI,\n",
    ")\n",
    "\n",
    "# Set task to \"text-to-image-dreambooth-lora\" to finetune using Dreambooth and\n",
    "# LoRA.\n",
    "# Pass training arguments and launch job.\n",
    "# See https://github.com/huggingface/diffusers/blob/87ae330056f6942817656c8f7146283e90cf986b/examples/dreambooth/train_dreambooth_lora.py#L142\n",
    "# for a full list of training arguments.\n",
    "model = job.run(\n",
    "    args=[\n",
    "        \"--task=text-to-image-dreambooth-lora\",\n",
    "        f\"--pretrained_model_name_or_path={model_id}\",\n",
    "        f\"--instance_data_dir={instance_dir}\",\n",
    "        f\"--output_dir={output_dir_dreambooth_lora}\",\n",
    "        \"--instance_prompt='a photo of sks dog'\",\n",
    "        \"--resolution=512\",\n",
    "        \"--train_batch_size=1\",\n",
    "        \"--gradient_accumulation_steps=1\",\n",
    "        \"--checkpointing_steps=100\",\n",
    "        \"--learning_rate=1e-2\",\n",
    "        \"--lr_scheduler=constant\",\n",
    "        \"--lr_warmup_steps=0\",\n",
    "        \"--max_train_steps=50\",\n",
    "        \"--validation_prompt='A photo of sks dog in a bucket'\",\n",
    "        \"--validation_epochs=10\",\n",
    "        \"--seed=0\",\n",
    "    ],\n",
    "    replica_count=num_nodes,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_type=gpu_type,\n",
    "    accelerator_count=num_gpus,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqrVgsVODmZb"
   },
   "source": [
    "### 部署\n",
    "\n",
    "为文本到图像任务部署稳定的扩散模型。\n",
    "\n",
    "部署完成后，您可以将一批文本提示发送到端点以生成图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ye3_N5bxDmZc"
   },
   "outputs": [],
   "source": [
    "model, endpoint = deploy_model(\n",
    "    model_name=create_job_name(prefix=\"lora-stable-diffusion\"),\n",
    "    model_id=model_id,\n",
    "    lora_id=gs_output_dir_dreambooth_lora,\n",
    "    task=\"text-to-image\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xT1Bh_XDmZc"
   },
   "source": [
    "请注意：在部署成功后，将下载模型权重。\n",
    "\n",
    "---\n",
    "\n",
    "因此，在上述模型部署步骤成功后，需要额外等待5分钟，然后再运行下面的下一步。否则，当您向端点发送请求时，可能会出现“ServiceUnavailable: 503 502:Bad Gateway”错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gH23yBtYDmZd"
   },
   "outputs": [],
   "source": [
    "instances = [\n",
    "    {\"prompt\": \"A picture of a sks dog in a house\"},\n",
    "    {\"prompt\": \"A picture of a sks dog catching a frisbee\"},\n",
    "    {\"prompt\": \"A picture of a sks dog in front of a computer\"},\n",
    "    {\"prompt\": \"A picture of a sks dog in a bucket\"},\n",
    "]\n",
    "response = endpoint.predict(instances=instances)\n",
    "images = [base64_to_image(image) for image in response.predictions]\n",
    "image_grid(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed3795d474b9"
   },
   "source": [
    "清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b53b883257b4"
   },
   "outputs": [],
   "source": [
    "# Undeploy model and delete endpoints.\n",
    "endpoint.delete(force=True)\n",
    "\n",
    "# Delete models.\n",
    "model.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "model_garden_pytorch_stable_diffusion_finetuning_dreambooth_lora_1_5.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
