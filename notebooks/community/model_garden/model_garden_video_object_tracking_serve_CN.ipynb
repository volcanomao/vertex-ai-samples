{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ad30fe2-1fc1-47e3-8a9f-624170b5aae6"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "411c319c-49c9-412b-aff1-ce7832412bd7"
   },
   "source": [
    "# Vertex AI模型花园：使用Bytetrack进行视频目标跟踪\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_video_object_tracking_serve.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_video_object_tracking_serve.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_video_object_tracking_serve.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "    (建议使用Python-3 CPU笔记本)\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "962e636b5cee"
   },
   "source": [
    "注意：此笔记本已在以下环境中进行测试：\n",
    "\n",
    "Python版本= 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05131ed9-08a2-4825-b35c-46986f14789b"
   },
   "source": [
    "## 概述\n",
    "\n",
    "该 Jupyter 笔记本提供了部署视频目标跟踪模型到 Vertex AI Endpoint 资源的逐步操作指南，使用开源的 [ByteTrack](https://github.com/ifzhang/ByteTrack) 目标跟踪算法。\n",
    "\n",
    "### 目标\n",
    "* 设置 Vertex AI Endpoint 资源，并选择以下其中一个子选项：\n",
    "    * TensorFlow Vision [笔记本](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_object_detection.ipynb) 或\n",
    "    * Google 专有 [笔记本](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_object_detection.ipynb)\n",
    "<br></br>\n",
    "* 测试集成跟踪模型\n",
    "    * 上传模型到模型注册表\n",
    "    * 部署已上传的模型\n",
    "    * 运行批量预测\n",
    "    * 验证和可视化跟踪结果\n",
    "<br></br>\n",
    "* 清理资源\n",
    "\n",
    "### 成本\n",
    "\n",
    "本教程使用 Google Cloud 中的可计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解有关 [Vertex AI 定价](https://cloud.google.com/vertex-ai/pricing) 和 [Cloud Storage 定价](https://cloud.google.com/storage/pricing) 的信息，并使用 [定价计算器](https://cloud.google.com/products/calculator/) 根据您的预期使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUgTNX8aOLDx"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装以下所需的软件包以执行这个笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDPiiagrONAe"
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade pip\n",
    "! pip install fastapi==0.96.0\n",
    "! pip install google-cloud-aiplatform==1.25.0\n",
    "! pip install google-cloud-storage==2.9.0\n",
    "! pip install tensorflow==2.11.0\n",
    "! pip install uvicorn==0.22.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea399cf543a4"
   },
   "source": [
    "仅限Colab\n",
    "如果您正在使用Workbench，请运行以下命令并跳过本部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72f4e86b394c"
   },
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    ! pip install --upgrade google-cloud-aiplatform\n",
    "\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "\n",
    "    from google.colab import auth as google_auth\n",
    "\n",
    "    google_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fc1fc14-2d77-4bf7-8f6d-c1afc10c848a"
   },
   "source": [
    "如果您在本地运行此笔记本，您将需要安装[Cloud SDK](https://cloud.google.com/sdk)和[gsutil](https://cloud.google.com/storage/docs/gsutil_install)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6c1bc20-3495-448a-b242-01930ba8153c"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### 设置您的Google Cloud项目\n",
    "\n",
    "1. [选择或创建一个Google Cloud项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建一个帐户时，您将获得$300的免费信用，可用于您的计算/存储成本。\n",
    "\n",
    "2. [确保为您的项目启用了计费](https://cloud.google.com/billing/docs/how-to/modify-project)。了解[Vertex AI定价](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage定价](https://cloud.google.com/storage/pricing)，并使用[Pricing Calculator](https://cloud.google.com/products/calculator/)根据您的预计使用量生成费用估算。\n",
    "\n",
    "3. [启用Artifact Registry](https://cloud.google.com/artifact-registry/docs/enable-service)并[创建存储Docker镜像的仓库](https://cloud.google.com/artifact-registry/docs/repositories/create-repos)。\n",
    "\n",
    "4. [创建一个GCS存储桶](https://cloud.google.com/storage/docs/creating-buckets)用于存储实验输出。\n",
    "\n",
    "5. [启用Vertex AI API和Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component)。\n",
    "\n",
    "6. [创建一个服务账号](https://cloud.google.com/iam/docs/service-accounts-create?&_ga=2.233472348.-356102079.1688744268#iam-service-accounts-create-console)，为其分配Vertex AI User和Storage Object Admin角色，用于部署微调模型到Vertex AI终端。[查看如何向您的服务账号授予Cloud Storage权限](https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc52f3503d91"
   },
   "source": [
    "### 设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下操作：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3ce64be5527"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ff96cc60ab6"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "**无论您的笔记本环境如何，都需要执行以下步骤。**\n",
    "\n",
    "要更新您的模型工件而无需重新构建容器，您必须将模型工件和任何自定义代码上传到云存储中。\n",
    "\n",
    "请在下面设置您的云存储桶的名称。它必须在所有云存储桶中保持唯一。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34fad6505e5c"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7c755f51afe"
   },
   "source": [
    "只有在您的存储桶尚不存在时才能运行以下单元格来创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80497c1171f7"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e02b9811-b730-4573-83fa-9d47f2ce0436"
   },
   "source": [
    "设置剩余的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7c2ce2fa-5a9b-40f6-b99d-6c1325775b36"
   },
   "outputs": [],
   "source": [
    "# Cloud project setup.\n",
    "\n",
    "# The folder in the GCS bucket with input videos.\n",
    "# Fill it without the 'gs://' prefix.\n",
    "INPUT_GCS_FOLDER = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# The video filename for the videos to be process.\n",
    "# Fill it without the 'gs://' prefix.\n",
    "VIDEO_FILE_NAME = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# The video filename extension like .mp4. Please include period.\n",
    "# Fill it without the 'gs://' prefix.\n",
    "VIDEO_FILE_EXTENSION = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# The folder in the GCS bucket where to store output videos and text\n",
    "# annotations. Fill it without the 'gs://' prefix.\n",
    "OUTPUT_GCS_FOLDER = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# The Vertex IOD endpoint for object detection.\n",
    "# It is like projects/<project_number>/locations/<location>/endpoints/<endpoint_id>\"\n",
    "DETECTION_ENDPOINT = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# The label map for the Vertex IOD endpoint.\n",
    "# It is the path to a .yaml in GCS.\n",
    "# It is like gs://{BUCKET_NAME}/{FOLDER_NAME}/label_map.yaml\n",
    "ENDPOINT_LABEL_MAP = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# You can choose a region from https://cloud.google.com/about/locations.\n",
    "# Only regions prefixed by \"us\", \"asia\", or \"europe\" are supported.\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "REGION_PREFIX = REGION.split(\"-\")[0]\n",
    "assert REGION_PREFIX in (\n",
    "    \"us\",\n",
    "    \"europe\",\n",
    "    \"asia\",\n",
    "), f'{REGION} is not supported. It must be prefixed by \"us\", \"asia\", or \"europe\".'\n",
    "\n",
    "# The pre-built docker images\n",
    "SERVE_DOCKER_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/vot-serve:latest\"\n",
    ")\n",
    "\n",
    "# Prediction constants\n",
    "PREDICTION_ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
    "PREDICTION_MACHINE_TYPE = \"n1-standard-4\"\n",
    "\n",
    "# The serving port.\n",
    "SERVE_PORT = 7080\n",
    "\n",
    "# The serving route.\n",
    "SERVE_ROUTE = \"/predictions/vot_serving\"\n",
    "\n",
    "# The service account you created in step-6 above.\n",
    "# It is like \"<account_name>@<project>.iam.gserviceaccount.com\"\n",
    "SERVICE_ACCOUNT = \"\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82058975-23b5-4b97-9e14-dd9a29c578ed"
   },
   "source": [
    "### 初始化Vertex AI SDK\n",
    "\n",
    "为您的项目初始化Python的Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0eb6283926b"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "# Init common setup.\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b2fa2cff870"
   },
   "source": [
    "### 定义效用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a78f988d-e5e2-4a57-ba0f-569e970514c0"
   },
   "outputs": [],
   "source": [
    "def get_job_name_with_datetime(prefix: str):\n",
    "    \"\"\"\n",
    "    Generate a job name string with the current date and time appended.\n",
    "\n",
    "    Args:\n",
    "        prefix: The prefix string to use for the job name.\n",
    "\n",
    "    Returns:\n",
    "        str: The job name string in the format \"{prefix}_{YYYYMMDD_HHMMSS}\".\n",
    "    \"\"\"\n",
    "    return prefix + datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "def deploy_model(\n",
    "    project_id=None,\n",
    "    detection_endpoint=None,\n",
    "    label_map=None,\n",
    "    output_bucket=None,\n",
    "    model_type=\"CUSTOM\",\n",
    "    save_video_results=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Deploy a model to a real-time prediction endpoint.\n",
    "\n",
    "    Args:\n",
    "        detection_endpoint: The endpoint URL for object detection.\n",
    "        label_map: Mapping of class IDs to class names.\n",
    "        output_bucket: GCS bucket to save results.\n",
    "        save_video_results: Whether to save video results.\n",
    "\n",
    "    Returns:\n",
    "        The created endpoint and deployed model objects.\n",
    "    \"\"\"\n",
    "    task = \"tracking\"\n",
    "    endpoint = aiplatform.Endpoint.create(display_name=f\"{task}-endpoint\")\n",
    "    serving_env = {\n",
    "        \"MODEL_ID\": \"Bytetrack-Multi-Object-Tracking\",\n",
    "        \"MODEL_TYPE\": model_type,\n",
    "        \"PROJECT_ID\": project_id,\n",
    "        \"DETECTION_ENDPOINT\": detection_endpoint,\n",
    "        \"LABEL_MAP\": label_map,\n",
    "        \"OUTPUT_BUCKET\": output_bucket,\n",
    "        \"SAVE_VIDEO_RESULTS\": save_video_results,\n",
    "        \"DEPLOY_SOURCE\": \"notebook\",\n",
    "    }\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=task,\n",
    "        serving_container_image_uri=SERVE_DOCKER_URI,\n",
    "        serving_container_ports=[SERVE_PORT],\n",
    "        serving_container_predict_route=SERVE_ROUTE,\n",
    "        serving_container_health_route=\"/ping\",\n",
    "        serving_container_environment_variables=serving_env,\n",
    "    )\n",
    "    model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        machine_type=PREDICTION_MACHINE_TYPE,\n",
    "        accelerator_type=PREDICTION_ACCELERATOR_TYPE,\n",
    "        accelerator_count=1,\n",
    "        service_account=SERVICE_ACCOUNT,\n",
    "    )\n",
    "    return endpoint, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "242fc8cf-5a0e-483b-8c9d-77a474cedc4b"
   },
   "source": [
    "视频对象跟踪与本地端点\n",
    "\n",
    "本节展示如何部署具有本地跟踪功能的链式IOD Vertex AI端点，并获取保存在文本文件中的预测结果。用户还可以选择将带注释的视频保存到他们的GCS存储桶中。\n",
    "\n",
    "* 如果您尚未这样做，请使用以下方法设置一个Vertex AI端点资源：\n",
    "    * TensorFlow Vision [笔记本](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_object_detection.ipynb) or\n",
    "    * Google 专有 [笔记本](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_object_detection.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyW_3gDz7Rk4"
   },
   "outputs": [],
   "source": [
    "# The Vertex IOD endpoint for object detection.\n",
    "# It is like projects/<project_number>/locations/<location>/endpoints/<endpoint_id>\"\n",
    "DETECTION_ENDPOINT = \"\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPlXzhjx4fkj"
   },
   "source": [
    "这是用于向在本地主机上运行的跟踪模型服务容器发出请求的本地URL。它指向SERVE_PORT端口上的/predictions路由，该路由将处理模型推断请求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_dp2-wY4guH"
   },
   "outputs": [],
   "source": [
    "LOCAL_SERVE_URL = f\"http://localhost:{SERVE_PORT}/{SERVE_ROUTE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CO0EaLXrmyiR"
   },
   "source": [
    "使用自定义模型IOD端点运行容器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seiABeZU5s-S"
   },
   "source": [
    "在单独的 shell 中运行服务容器。以下环境变量是必需的：\n",
    "\n",
    "* `DETECTION_ENDPOINT`：Vertex AI IOD 检测端点地址。\n",
    "* `LABEL_MAP`：用于训练 IOD 的标签映射 yaml 文件的 GCS URI。\n",
    "* `OUTPUT_BUCKET`：用于存储实验输出的 GCS 路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "No5ALIXA5tVl"
   },
   "outputs": [],
   "source": [
    "!nvidia-docker run -t --rm \\\n",
    "-p {SERVE_PORT}:{SERVE_PORT} \\\n",
    "-e DETECTION_ENDPOINT=f\"{DETECTION_ENDPOINT}\" \\\n",
    "-e LABEL_MAP=f\"{ENDPOINT_LABEL_MAP}\" \\\n",
    "-e OUTPUT_BUCKET=f\"gs://{GCS_BUCKET}/{OUTPUT_GCS_FOLDER}\" \\\n",
    "-e SAVE_VIDEO_RESULTS=1 \\\n",
    "-e CUDA_VISIBLE_DEVICES=0 \\\n",
    "{SERVE_DOCKER_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIJa8jxXmyiR"
   },
   "source": [
    "### 使用AutoML训练的模型IOD端点来运行容器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9boRetYmyiR"
   },
   "source": [
    "在单独的 shell 中运行提供容器。需要以下环境变量：\n",
    "\n",
    "* `PROJECT_ID`: Google Cloud 项目 ID。\n",
    "* `MODEL_TYPE`: CUSTOM 或 AUTOML。\n",
    "* `DETECTION_ENDPOINT`: 来自 AUTOML 训练的 IOD 模型的 Vertex AI IOD 检测终端点地址。\n",
    "* `OUTPUT_BUCKET`: 用于存储实验输出的 GCS 路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLGgAl2WmyiR"
   },
   "outputs": [],
   "source": [
    "!nvidia-docker run -t --rm \\\n",
    "-p {SERVE_PORT}:{SERVE_PORT} \\\n",
    "-e PROJECT_ID={PROJECT_ID} \\\n",
    "-e MODEL_TYPE={MODEL_TYPE}  \\\n",
    "-e DETECTION_ENDPOINT=f\"{DETECTION_ENDPOINT}\" \\\n",
    "-e OUTPUT_BUCKET=f\"gs://{GCS_BUCKET}/{OUTPUT_GCS_FOLDER}\" \\\n",
    "-e SAVE_VIDEO_RESULTS=1 \\\n",
    "-e CUDA_VISIBLE_DEVICES=0 \\\n",
    "{SERVE_DOCKER_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8a53d74-aa76-4429-adbe-0460ea29bae2"
   },
   "source": [
    "### 本地测试端点并进行在线预测\n",
    "本节展示如何向端点发出预测请求，以获取保存到文本文件和/或注释视频输出的检测和跟踪对象的轨迹ID和边界框坐标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6e51c57-b5e2-4ae7-888a-5391cceee5fb"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "payload = json.dumps(\n",
    "    {\n",
    "        \"instances\": [\n",
    "            {\n",
    "                \"video_uri\": f\"gs://{GCS_BUCKET}/{INPUT_GCS_FOLDER}/{VIDEO_FILE_NAME}1{VIDEO_FILE_EXTENSION}\"\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "r = requests.post(\n",
    "    LOCAL_SERVE_URL,\n",
    "    data=payload,\n",
    "    headers={\"content-type\": \"application/json\", \"Accept-Charset\": \"UTF-8\"},\n",
    ")\n",
    "preds = r.json()\n",
    "\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPfDH4JimyiR"
   },
   "source": [
    "部署Vertex AI端点和自定义IOD模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9j0rRXsmyiR"
   },
   "outputs": [],
   "source": [
    "endpoint, model = deploy_model(\n",
    "    detection_endpoint=\"\",  # @param {type:\"string\"}\n",
    "    label_map=\"\",  # @param {type:\"string\"}\n",
    "    output_bucket=\"\",  # @param {type:\"string\"}\n",
    "    model_type=\"CUSTOM\",  # @param {type:\"string\"}\n",
    "    save_video_results=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTbEywwGmyiR"
   },
   "source": [
    "### 部署 Vertex AI 端点和经 AutoML 训练的 IOD 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCybQp18myiR"
   },
   "outputs": [],
   "source": [
    "endpoint, model = deploy_model(\n",
    "    project_id=\"\",  # @param {type:\"string\"}\n",
    "    detection_endpoint=\"\",  # @param {type:\"string\"}\n",
    "    model_type=\"AUTOML\",  # @param {type:\"string\"}\n",
    "    output_bucket=\"\",  # @param {type:\"string\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SiGJXp5myiR"
   },
   "source": [
    "### 使用远程端点进行在线预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NJa752sJmyiV"
   },
   "outputs": [],
   "source": [
    "instances = [\n",
    "    {\n",
    "        \"data\": {\n",
    "            \"video_uri\": f\"gs://{GCS_BUCKET}/{INPUT_GCS_FOLDER}/{VIDEO_FILE_NAME}1{VIDEO_FILE_EXTENSION}\"\n",
    "        }\n",
    "    },\n",
    "]\n",
    "preds = endpoint.predict(instances=instances).predictions\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec86394f174d"
   },
   "source": [
    "## 批量预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4ce0a1f-96dc-4371-8dc6-803143a98e17"
   },
   "source": [
    "### 设置批量预测的输入文件并上传到gs桶\n",
    "提供jsonl格式的批量预测输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d79c03b3-7bce-4ddd-b362-f6663c026e9a"
   },
   "outputs": [],
   "source": [
    "INPUT_FILE = \"instances.jsonl\"\n",
    "VIDEO_PATH_1 = (\n",
    "    f\"gs://{GCS_BUCKET}/{INPUT_GCS_FOLDER}/{VIDEO_FILE_NAME}1{VIDEO_FILE_EXTENSION}\"\n",
    ")\n",
    "VIDEO_PATH_2 = (\n",
    "    f\"gs://{GCS_BUCKET}/{INPUT_GCS_FOLDER}/{VIDEO_FILE_NAME}2{VIDEO_FILE_EXTENSION}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bc92efe1-e178-402e-a7dc-0397ee7ae402"
   },
   "outputs": [],
   "source": [
    "%%writefile $INPUT_FILE\n",
    "{\"data\": { \"video_uri\": VIDEO_PATH_1}}\n",
    "{\"data\": { \"video_uri\": VIDEO_PATH_2}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8473cca5-6442-41d6-ac5e-881b155bdb56"
   },
   "outputs": [],
   "source": [
    "!gsutil cp \"instances.jsonl\" f\"gs://{GCS_BUCKET}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5749b8eb-76c7-4a83-8755-0ce2c759b684"
   },
   "outputs": [],
   "source": [
    "gcs_input_uri = f\"gs://{GCS_BUCKET}/instances.jsonl\"\n",
    "dest_uri = f\"gs://{GCS_BUCKET}/{OUTPUT_GCS_FOLDER}\"\n",
    "print(gcs_input_uri)\n",
    "! gsutil cat $gcs_input_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e3064a7-ff6d-463d-9688-129c5c6cf4d0"
   },
   "source": [
    "### 创建批量预测作业ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02609f01-5b61-42d7-a6e9-00ef6e3993f4"
   },
   "outputs": [],
   "source": [
    "JOB_PREFIX = \"<job name prefix>\"  # @param {type:\"string\"}\n",
    "job_name = get_job_name_with_datetime(JOB_PREFIX)\n",
    "print(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "948d95fc-16af-4921-8aaa-1c46cfd30eba"
   },
   "source": [
    "### 进行批量预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0c63153c-22a8-42b9-b251-1d9fb4611001"
   },
   "outputs": [],
   "source": [
    "batch_predict_job = model.batch_predict(\n",
    "    job_display_name=job_name,\n",
    "    gcs_source=gcs_input_uri,\n",
    "    gcs_destination_prefix=dest_uri,\n",
    "    sync=False,\n",
    "    machine_type=PREDICTION_MACHINE_TYPE,\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    ")\n",
    "\n",
    "print(batch_predict_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ca21ed1-b4c0-4a89-a04a-798f11bc85c3"
   },
   "outputs": [],
   "source": [
    "batch_predict_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b148a5e-cf83-4c05-9e86-3ba5cf4b224a"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于本教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在此教程中创建的各个资源："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ec87451-3f4b-46f5-9352-c903a90df852"
   },
   "outputs": [],
   "source": [
    "# Undeploy model and delete endpoint\n",
    "endpoint.delete(force=True)\n",
    "\n",
    "# Delete the model resource\n",
    "model.delete()\n",
    "\n",
    "delete_bucket = False\n",
    "\n",
    "if delete_bucket:\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "model_garden_video_object_tracking_serve.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
