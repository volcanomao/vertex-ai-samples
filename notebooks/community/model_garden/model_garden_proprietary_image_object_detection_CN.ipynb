{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TirJ-SGQseby"
   },
   "source": [
    "# Vertex AI模型花园：Google专有模型图像物体检测\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_object_detection.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_proprietary_image_object_detection.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_proprietary_image_object_detection.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwGLvtIeECLK"
   },
   "source": [
    "注意：此笔记本已在以下环境中进行了测试：\n",
    "\n",
    "* Python 版本 = 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本笔记本演示如何在[Vertex AI Model Garden](https://cloud.google.com/model-garden) 中使用Google专有的图像对象检测模型进行训练/部署。\n",
    "\n",
    "### 目标\n",
    "\n",
    "* 使用Vertex SDK训练新模型\n",
    "\n",
    "* 测试训练好的模型\n",
    "  * 在[Vertex AI模型注册表](https://cloud.google.com/vertex-ai/docs/model-registry/introduction)中查看训练好的模型\n",
    "  * 部署上传的模型\n",
    "  * 运行预测\n",
    "\n",
    "* 清理资源\n",
    "\n",
    "### 成本\n",
    "\n",
    "此教程使用Google Cloud的可计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI定价](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage定价](https://cloud.google.com/storage/pricing)，并使用[Pricing计算器](https://cloud.google.com/products/calculator/) 根据您的预计使用情况生成成本估算。\n",
    "\n",
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是来自[TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview) 的 [OpenImages dataset](https://www.tensorflow.org/datasets/catalog/open_images_v4) 中的 Salads 类别。这个数据集不需要任何特征工程。您在本教程中将使用的数据集版本存储在一个公共Cloud Storage存储桶中。训练好的模型能够预测图像中五种物品类别中沙拉、海鲜、番茄、烘焙食品或奶酪的边界框位置和相应类型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEukV6uRk_S3"
   },
   "source": [
    "在开始之前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jvqs-ehKlaYh"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade google-cloud-aiplatform\n",
    "\n",
    "# Automatically restart kernel after installs\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    from google.colab import auth as google_auth\n",
    "\n",
    "    google_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "### 设置您的Google Cloud项目\n",
    "\n",
    "**以下步骤是必需的，无论您使用什么笔记本环境。**\n",
    "\n",
    "1. [选择或创建一个Google Cloud项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建账户时，您将获得$300的免费信用用于计算/存储成本。\n",
    "\n",
    "2. [确保您的项目已启用计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "3. [启用Vertex AI API和Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component)。\n",
    "\n",
    "4. 如果您在本地运行此笔记本，则需要安装[Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "5. 在下面的单元格中输入您的项目ID。然后运行该单元格，以确保Cloud SDK在本笔记本中的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**: Jupyter运行以`!`为前缀的行作为shell命令，并且将以`$`为前缀的Python变量插入这些命令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wExiMUxFk91"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# The project and bucket are for experiments below.\n",
    "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# You can choose a region from https://cloud.google.com/about/locations.\n",
    "# Only regions prefixed by \"us\", \"europe\", or \"asia\" are supported.\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "REGION_PREFIX = REGION.split(\"-\")[0]\n",
    "assert REGION_PREFIX in (\n",
    "    \"us\",\n",
    "    \"europe\",\n",
    "    \"asia\",\n",
    "), f'{REGION} is not supported. It must be prefixed by \"us\", \"europe\", or \"asia\".'\n",
    "\n",
    "! gcloud config set project $PROJECT_ID\n",
    "\n",
    "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temporal\")\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6IFz75WGCam"
   },
   "source": [
    "### 定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riG_qUokg0XZ"
   },
   "outputs": [],
   "source": [
    "OBJECTIVE = \"iod\"\n",
    "\n",
    "# Dataset constants.\n",
    "DATASET_PREFIX = \"dataset-iod\"\n",
    "\n",
    "# Training constants.\n",
    "TRAINING_JOB_PREFIX = \"train\"\n",
    "# The image object detection salad dataset used to train the model\n",
    "DATASET_FILE = \"gs://cloud-samples-data/vision/salads.csv\"\n",
    "\n",
    "# Evaluation constants.\n",
    "EVALUATION_METRIC = \"AP50\"\n",
    "\n",
    "DEPLOY_JOB_PREFIX = \"deploy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZFPe_GezXg8"
   },
   "source": [
    "定义常见的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcYUGwr-AJGY"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from google.cloud import aiplatform\n",
    "from PIL import Image, ImageColor, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "def get_job_name_with_datetime(prefix: str):\n",
    "    return prefix + datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "def load_img(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return Image.fromarray(np.uint8(img)).convert(\"RGB\")\n",
    "\n",
    "\n",
    "def display_image(image):\n",
    "    _ = plt.figure(figsize=(20, 15))\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image)\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image(\n",
    "    image, ymin, xmin, ymax, xmax, color, font, thickness=4, display_str_list=()\n",
    "):\n",
    "    \"\"\"Adds a bounding box to an image.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    im_width, im_height = image.size\n",
    "    (left, right, top, bottom) = (\n",
    "        xmin * im_width,\n",
    "        xmax * im_width,\n",
    "        ymin * im_height,\n",
    "        ymax * im_height,\n",
    "    )\n",
    "    draw.line(\n",
    "        [(left, top), (left, bottom), (right, bottom), (right, top), (left, top)],\n",
    "        width=thickness,\n",
    "        fill=color,\n",
    "    )\n",
    "\n",
    "    # If the total height of the display strings added to the top of the bounding\n",
    "    # box exceeds the top of the image, stack the strings below the bounding box\n",
    "    # instead of above.\n",
    "    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "    # Each display_str has a top and bottom margin of 0.05x.\n",
    "    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "    if top > total_display_str_height:\n",
    "        text_bottom = top\n",
    "    else:\n",
    "        text_bottom = top + total_display_str_height\n",
    "    # Reverse list and print from bottom to top.\n",
    "    for display_str in display_str_list[::-1]:\n",
    "        text_width, text_height = font.getsize(display_str)\n",
    "        margin = np.ceil(0.05 * text_height)\n",
    "        draw.rectangle(\n",
    "            [\n",
    "                (left, text_bottom - text_height - 2 * margin),\n",
    "                (left + text_width, text_bottom),\n",
    "            ],\n",
    "            fill=color,\n",
    "        )\n",
    "        draw.text(\n",
    "            (left + margin, text_bottom - text_height - margin),\n",
    "            display_str,\n",
    "            fill=\"black\",\n",
    "            font=font,\n",
    "        )\n",
    "        text_bottom -= text_height - 2 * margin\n",
    "\n",
    "\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=40, min_score=0.05):\n",
    "    \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
    "    colors = list(ImageColor.colormap.values())\n",
    "    try:\n",
    "        font = ImageFont.truetype(\n",
    "            \"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\", 25\n",
    "        )\n",
    "    except OSError:\n",
    "        print(\"Font not found, using default font.\")\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for i in range(min(len(boxes), max_boxes)):\n",
    "        if scores[i] >= min_score:\n",
    "            ymin, xmin, ymax, xmax = boxes[i]\n",
    "            display_str = \"{}: {}%\".format(class_names[i], int(100 * scores[i]))\n",
    "            color = colors[hash(class_names[i]) % len(colors)]\n",
    "            draw_bounding_box_on_image(\n",
    "                image,\n",
    "                ymin,\n",
    "                xmin,\n",
    "                ymax,\n",
    "                xmax,\n",
    "                color,\n",
    "                font,\n",
    "                display_str_list=[display_str],\n",
    "            )\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZLVI9TtUuif"
   },
   "source": [
    "创建数据集\n",
    "\n",
    "本教程使用存储在公共云存储桶中的沙拉数据集的版本，使用CSV索引文件。\n",
    "\n",
    "首先快速查看数据。通过计算CSV索引文件中的行数（`wc -l`）来计算示例的数量，然后查看前几行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pr60Y1fpUuO9"
   },
   "outputs": [],
   "source": [
    "count = ! gsutil cat $DATASET_FILE | wc -l\n",
    "print(\"Number of Examples\", int(count[0]))\n",
    "\n",
    "print(\"First 10 rows\")\n",
    "! gsutil cat $DATASET_FILE | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZEdBfNZUxQn"
   },
   "source": [
    "接下来，使用 `create` 方法为 `ImageDataset` 类创建 `Dataset` 资源，该方法接受以下参数：\n",
    "\n",
    "- `display_name`：`Dataset` 资源的可读名称。\n",
    "- `gcs_source`：一个或多个数据集索引文件列表，用于将数据项导入到 `Dataset` 资源。\n",
    "- `import_schema_uri`：数据项的数据标记模式。\n",
    "\n",
    "此操作可能需要几分钟时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FlDqM5APU0As"
   },
   "outputs": [],
   "source": [
    "dataset = aiplatform.ImageDataset.create(\n",
    "    display_name=DATASET_PREFIX + \"_salads\",\n",
    "    gcs_source=[DATASET_FILE],\n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.image.bounding_box,\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RB_xY9ipr7ZU"
   },
   "source": [
    "## 训练新模型\n",
    "\n",
    "### 创建和运行训练流程\n",
    "\n",
    "要训练一个AutoML模型，您需要执行两个步骤：\n",
    "1. 创建一个训练流程。\n",
    "2. 运行这个流程。\n",
    "\n",
    "#### 创建训练流程\n",
    "\n",
    "通过`AutoMLImageTrainingJob`类创建一个AutoML训练流程，具有以下参数：\n",
    "\n",
    "- `display_name`：`TrainingJob`资源的可读性名称。\n",
    "- `prediction_type`：要为其训练模型的任务类型。\n",
    "  - `classification`：图像分类模型。\n",
    "  - `object_detection`：图像目标检测模型。\n",
    "- `model_type`：部署模型的类型。对于图像目标检测，我们目前支持以下类型：\n",
    "  - `SPINENET`：一个模型，可在 Vertex 模型库中进行图像目标检测训练，并具有可定制的超参数。最适合在 Google Cloud 内部使用，不能外部导出。\n",
    "  - `YOLO`：一个模型，可以在 Vertex 模型库中进行图像目标检测训练，并具有可定制的超参数。最适合在 Google Cloud 内部使用，不能外部导出。\n",
    "- `checkpoint_name`：可选。该字段针对模型库模型训练保留，基于提供的预训练模型检查点。\n",
    "- `trainer_config`：可选。通常与模型库模型训练一同使用，用于传递训练器的定制配置。`anchor_size` 不能与 `YOLO` 一起使用。\n",
    "\n",
    "  包含所有支持参数的示例：\n",
    "```\n",
    "  trainer_config = {\n",
    "    'global_batch_size': '8',\n",
    "    'learning_rate': '0.001',\n",
    "    'optimizer_type': 'sgd',\n",
    "    'optimizer_momentum': '0.9',\n",
    "    'train_steps': '10000',\n",
    "    'accelerator_count': '2',\n",
    "    'anchor_size': '8',\n",
    "  }\n",
    "```\n",
    "  global_batch_size 应该能够被 accelerator_count 整除。\n",
    "  optimizer_type 支持的值有 'sgd', 'adam', 'adamw', 'lamb', 'rmsprop', 'lars', 'adagrad' 和 'slide'。\n",
    "  accelerator_count 支持的值有 '2', '4' 和 '8'。\n",
    "- `metric_spec`：代表优化指标的字典。字典键是指标 ID，该 ID 由您的训练作业报告，可能的值为 ('loss', 'AP50')，字典值是指标的优化目标('minimize' 或 'maximize')。\n",
    "例如：`metric_spec = {'loss': 'minimize', 'AP50': 'maximize'}`\n",
    "- `parameter_spec`：代表要优化的参数的字典。字典键是 `metric_id`，作为命令行关键字参数传递给您的训练作业，字典值是指标的参数规范。支持的参数规范可以在 aiplatform.hyperparameter_tuning 中找到。\n",
    "```\n",
    "  from google.cloud.aiplatform.aiplatform import hpt as hpt\n",
    "\n",
    "  parameter_spec = {\n",
    "    'learning_rate': hpt.DoubleParameterSpec(min=1e-7, max=1, scale='linear'), \\\n",
    "  }\n",
    "```\n",
    "- `search_algorithm`：为研究指定的搜索算法。接受以下之一：\n",
    "  - `None`：如果不指定算法，您的作业将使用默认的 Vertex AI 算法。默认算法应用贝叶斯优化以在参数空间上进行更有效的搜索以达到最佳解决方案。\n",
    "  - `grid`：在可能空间内进行简单的网格搜索。如果要指定的试验数量大于可能空间中的点数，这个选项特别有用。在这种情况下，如果不指定网格搜索，Vertex AI 默认算法可能会生成重复的建议。要使用网格搜索，所有参数规格必须是 `IntegerParameterSpec`、`CategoricalParameterSpec` 或 `DiscreteParameterSpec` 类型。\n",
    "  - `random`：在可能空间内进行简单的随机搜索。\n",
    "- `measurement_selection`：如果服务自动从先前报告的中间测量中选择最终测量，则指示要使用哪个测量。\n",
    "  接受：`best`、`last` 根据两个考虑选择此选项：\n",
    "    - A)：您是否期望您的测量值单调提高？如果是这样，选择 `last`。另一方面，如果您的系统可能会**过度训练**，您期望性能一直提高一段时间，然后开始下降，选择 `best`。\n",
    "    - B)：您的测量值是否明显的嘈杂和/或不可重现的？如果是这样，`best` 会倾向于过于乐观，选择 `last` 可能更好。如果 (A) 和 (B) 中的任何一个或两者都不适用，则选择哪种选择类型都无关紧要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "um_XKbmpTaHx"
   },
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "\n",
    "TRAINER_CONFIG = {\n",
    "    \"global_batch_size\": \"8\",\n",
    "    \"learning_rate\": \"0.001\",\n",
    "    \"train_steps\": \"10000\",\n",
    "    \"accelerator_count\": \"2\",\n",
    "}\n",
    "METRIC_SPEC_KEY = \"AP50\"\n",
    "METRIC_SPEC_VALUE = \"maximize\"\n",
    "SEARCH_ALGORITHM = \"random\"\n",
    "MEASUREMENT_SELECTION = \"best\"\n",
    "MODEL_TYPE = \"SPINENET\"  # @param {type:\"string\"} one of the values [\"SPINENET\", \"YOLO\"]\n",
    "\n",
    "PARAMETER_SPEC = {}\n",
    "if MODEL_TYPE == \"YOLO\":\n",
    "    PARAMETER_SPEC = {\n",
    "        \"learning_rate\": hpt.DiscreteParameterSpec(\n",
    "            values=[0.001, 0.1],\n",
    "            scale=\"linear\",\n",
    "        ),\n",
    "        \"weight_decay\": hpt.DiscreteParameterSpec(\n",
    "            values=[0.0001, 0.001],\n",
    "            scale=\"linear\",\n",
    "        ),\n",
    "    }\n",
    "else:\n",
    "    PARAMETER_SPEC = {\n",
    "        \"learning_rate\": hpt.DiscreteParameterSpec(\n",
    "            values=[0.001, 0.01], scale=\"linear\"\n",
    "        ),\n",
    "        \"anchor_size\": hpt.DiscreteParameterSpec(values=[2, 4], scale=\"reverse_log\"),\n",
    "    }\n",
    "\n",
    "job = aiplatform.AutoMLImageTrainingJob(\n",
    "    display_name=get_job_name_with_datetime(TRAINING_JOB_PREFIX),\n",
    "    prediction_type=\"object_detection\",\n",
    "    model_type=MODEL_TYPE,\n",
    "    base_model=None,\n",
    "    trainer_config=TRAINER_CONFIG,\n",
    "    metric_spec={METRIC_SPEC_KEY: METRIC_SPEC_VALUE},\n",
    "    parameter_spec=PARAMETER_SPEC,\n",
    "    search_algorithm=SEARCH_ALGORITHM,\n",
    "    measurement_selection=MEASUREMENT_SELECTION,\n",
    ")\n",
    "\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwcCjwlBTQIz"
   },
   "source": [
    "#### 运行训练管道\n",
    "\n",
    "接下来，通过调用方法 `run`，使用以下参数来运行DAG以启动训练作业：\n",
    "\n",
    "- `dataset`: 要训练模型的 `Dataset` 资源。\n",
    "- `model_display_name`: 训练模型的人可读名称。\n",
    "- `training_fraction_split`: 用于训练的数据集百分比。\n",
    "- `test_fraction_split`: 用于测试（保留数据）的数据集百分比。\n",
    "- `validation_fraction_split`: 用于验证的数据集百分比。\n",
    "- `budget_milli_node_hours`: (可选) 最大培训时间，以毫小时为单位指定（1000 = 小时）。\n",
    "- `disable_early_stopping`: 如果为 `True`，训练可能会在服务认为无法进一步改善模型目标测量之前完成使用整个预算。\n",
    "\n",
    "当完成 `run` 方法时，将返回 `Model` 资源。\n",
    "\n",
    "训练管道的执行将需要最多60分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aec22792ee84"
   },
   "outputs": [],
   "source": [
    "model = job.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=get_job_name_with_datetime(\"salads\"),\n",
    "    training_fraction_split=0.8,\n",
    "    validation_fraction_split=0.1,\n",
    "    test_fraction_split=0.1,\n",
    "    budget_milli_node_hours=20000,\n",
    "    disable_early_stopping=False,\n",
    ")\n",
    "\n",
    "print(\"Model is: \", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0BGaofgsMsy"
   },
   "source": [
    "## 测试训练好的模型\n",
    "这一部分展示了如何测试训练好的模型。\n",
    "1. 从模型注册表部署模型\n",
    "2. 运行在线预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mj723H4NXu4v"
   },
   "outputs": [],
   "source": [
    "# @title Deploy model from Model Registry\n",
    "# Model does not support dedicated deployment resources.\n",
    "# An n1-standard-4 machine with 1 P100 GPU will be used.\n",
    "\n",
    "deploy_model_name = get_job_name_with_datetime(DEPLOY_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
    "print(\"The deployed job name is: \", deploy_model_name)\n",
    "\n",
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name=deploy_model_name,\n",
    "    traffic_split={\"0\": 100},\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=1,\n",
    ")\n",
    "\n",
    "endpoint_id = endpoint.name\n",
    "print(\"endpoint id is: \", endpoint_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTYvgFv6XyEe"
   },
   "outputs": [],
   "source": [
    "# @title Run online predictions\n",
    "\n",
    "# test image file path from a Cloud Storage bucket\n",
    "test_filepath = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "with tf.io.gfile.GFile(test_filepath, \"rb\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# The format of each instance should conform to the deployed model's prediction input schema.\n",
    "instances = [{\"content\": base64.b64encode(content).decode(\"utf-8\")}]\n",
    "\n",
    "prediction = endpoint.predict(instances=instances)\n",
    "\n",
    "img = load_img(test_filepath)\n",
    "display_image(img)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNPNJyUnrKY3"
   },
   "source": [
    "# 运行批量预测\n",
    "现在您的模型资源已经训练完成，您可以通过调用`batch_predict（）`方法来进行批量预测，需要设置以下参数：\n",
    "\n",
    "* `job_display_name`：批量预测作业的人类可读名称。\n",
    "* `gcs_source`：来自Cloud Storage桶的jsonl文件路径，包含一个或多个图像的列表。\n",
    "* `gcs_destination_prefix`：用于存储批量预测结果的Cloud Storage位置。\n",
    "* `sync`：如果设置为True，则调用将阻塞，等待异步批处理作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-MnutG5rNKR"
   },
   "outputs": [],
   "source": [
    "# A jsonl file path from a Cloud Storage bucket, with all the to-be-predicted images.\n",
    "gcs_source = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "batch_predict_job = model.batch_predict(\n",
    "    job_display_name=get_job_name_with_datetime(\"flowers_bp\"),\n",
    "    gcs_source=gcs_source,\n",
    "    gcs_destination_prefix=f\"gs://{BUCKET_URI}\",\n",
    "    sync=False,\n",
    ")\n",
    "print(batch_predict_job)\n",
    "\n",
    "# Wait for the batch prediction job to finish\n",
    "batch_predict_job.wait()\n",
    "\n",
    "\n",
    "# Get the batch prediction results\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "bp_iter_outputs = batch_predict_job.iter_outputs()\n",
    "\n",
    "prediction_results = list()\n",
    "for blob in bp_iter_outputs:\n",
    "    if blob.name.split(\"/\")[-1].startswith(\"prediction\"):\n",
    "        prediction_results.append(blob.name)\n",
    "\n",
    "tags = list()\n",
    "for prediction_result in prediction_results:\n",
    "    gfile_name = f\"gs://{bp_iter_outputs.bucket.name}/{prediction_result}\"\n",
    "    with tf.io.gfile.GFile(name=gfile_name, mode=\"r\") as gfile:\n",
    "        for line in gfile.readlines():\n",
    "            line = json.loads(line)\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frcGP5HFX1XN"
   },
   "source": [
    "清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2m8-u0IX4dX"
   },
   "outputs": [],
   "source": [
    "# Delete the dataset.\n",
    "if \"dataset\" in globals():\n",
    "    dataset.delete()\n",
    "\n",
    "# Undeploy model and delete endpoint.\n",
    "if \"endpoint\" in globals():\n",
    "    endpoint.undeploy_all()\n",
    "    endpoint.delete(force=True)\n",
    "\n",
    "# Delete models.\n",
    "if \"model\" in globals():\n",
    "    model.delete()\n",
    "\n",
    "# Delete the batch predictio job.\n",
    "if \"batch_prediction_job\" in globals():\n",
    "    batch_predict_job.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "model_garden_proprietary_image_object_detection.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
