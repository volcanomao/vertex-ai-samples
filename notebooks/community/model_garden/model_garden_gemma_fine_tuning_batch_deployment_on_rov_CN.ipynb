{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# 在 Vertex AI 上开始使用 Gemma\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma_fine_tuning_batch_deployment_on_rov.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> 在 Colab 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fcommunity%2Fmodel_garden%2Fmodel_garden_gemma_fine_tuning_batch_deployment_on_rov.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> 在 Colab Enterprise 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma_fine_tuning_batch_deployment_on_rov.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> 在 Vertex AI Workbench 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma_fine_tuning_batch_deployment_on_rov.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> 在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何在Vertex AI上使用Ray对Gemma进行微调和提供服务。\n",
    "\n",
    "了解更多关于[Ray on Vertex AI](https://cloud.google.com/vertex-ai/docs/open-source/ray-on-vertex-ai/overview)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何在Vertex AI上使用Ray来分发Gemma的监督调整。此外，您还将学习如何使用Ray Data在Vertex AI上的Ray上无缝部署经过训练的模型以进行离线预测。\n",
    "\n",
    "本教程使用以下Google Cloud ML服务和资源：\n",
    "\n",
    "- Vertex AI上的Ray\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 在Vertex AI上创建一个Ray集群\n",
    "- 使用Ray Train在Vertex AI上调整Gemma\n",
    "- 使用Ray Data为离线预测提供服务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08d289fa873f"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "[极端摘要（XSum）数据集](https://huggingface.co/datasets/EdinburghNLP/xsum) 是关于抽象单文档摘要系统的数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aed92deeb4a0"
   },
   "source": [
    "### 费用\n",
    "\n",
    "本教程使用 Google Cloud 的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解 [Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing)，\n",
    "和 [Cloud Storage 价格](https://cloud.google.com/storage/pricing)，\n",
    "并使用 [定价计算器](https://cloud.google.com/products/calculator/)\n",
    "根据您的预期使用量生成费用估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUKGInbrh0Cw"
   },
   "source": [
    "<b>注意</b>：本教程使用Ray Jobs API通过公共Ray仪表板。 Ray仪表板地址可以在VPC之外，包括公共互联网上访问。要了解更多关于私有与公共连接性的信息，请参阅[私有和公共连接性](https://cloud.google.com/vertex-ai/docs/open-source/ray-on-vertex-ai/create-cluster#private_and_public_connectivity) 章节中的 [在Vertex AI上创建Ray集群](https://cloud.google.com/vertex-ai/docs/open-source/ray-on-vertex-ai/create-cluster) 文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "## 在您开始之前\n",
    "\n",
    "### 设置您的 Google Cloud 项目\n",
    "\n",
    "**无论您使用的是哪种笔记本环境，下面的步骤都是必须的。**\n",
    "\n",
    "1. [选择或创建一个 Google Cloud 项目](https://console.cloud.google.com/cloud-resource-manager)。\n",
    "\n",
    "2. [确保为您的项目启用了计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "3. [启用API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,artifactregistry.googleapis.com,cloudbuild.googleapis.com)。\n",
    "\n",
    "4. 如果您是在本地运行此笔记本，请确保安装了[Cloud SDK](https://cloud.google.com/sdk)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### 安装\n",
    "\n",
    "安装以下所需的软件包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b4ef9b72d43"
   },
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    USER = \"--user\"\n",
    "else:\n",
    "    USER = \"\"\n",
    "\n",
    "! pip3 install {USER} google-cloud-aiplatform[ray]==1.48.0 -q --no-warn-conflicts\n",
    "! pip3 install {USER} google-cloud-aiplatform[tensorboard]==1.48.0 -q --no-warn-conflicts\n",
    "! pip3 install {USER} torch==2.2.1 datasets==2.17.0 transformers==4.38.1 evaluate==0.4.1 rouge-score==0.1.2 nltk==3.8.1 bitsandbytes==0.42.0 peft==0.8.2 accelerate==0.27.1 -q --no-warn-conflicts\n",
    "! pip3 install {USER} tensorflow==2.15.0 -q --no-warn-conflicts\n",
    "! pip3 install {USER} etils==1.5.0 fsspec==2023.10.0 gcsfs==2023.10.0 -q --no-warn-conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "重新启动运行时（仅适用于Colab）\n",
    "\n",
    "为了使用新安装的软件包，您必须重新启动Google Colab上的运行时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRvKdaPDTznN"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️内核将重新启动。在继续下一步之前，请等待它完成。⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### 在Colab上对您的笔记本环境进行身份验证\n",
    "\n",
    "在Google Colab上对您的环境进行身份验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyKGtVQjgx13"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CylYbUxrx3W-"
   },
   "source": [
    "设置谷歌云项目信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "#### 项目编号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 区域\n",
    "\n",
    "您还可以更改 Vertex AI 使用的 `REGION` 变量。了解有关 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations) 的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPrDj6HE9_EU"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "时间戳\n",
    "\n",
    "您创建时间戳以使您在本教程中创建的资源变得独一无二。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6Le1schAziq"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "#### 云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产物，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = f\"your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}\n",
    "\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "set_service_account"
   },
   "source": [
    "#### 服务账号\n",
    "\n",
    "设置服务账号并授予该服务账号访问 Vertex AI TensorBoard 的权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_C_BMVpzhug"
   },
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = \"[your-service-account]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lR2GDIkzp4af"
   },
   "outputs": [],
   "source": [
    "! gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
    "   --member=serviceAccount:{SERVICE_ACCOUNT} \\\n",
    "   --role=\"roles/storage.admin\"\n",
    "\n",
    "! gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
    "   --member=serviceAccount:{SERVICE_ACCOUNT} \\\n",
    "   --role=\"roles/aiplatform.user\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ek1-iTbPjzdJ"
   },
   "source": [
    "### 设置教程文件夹\n",
    "\n",
    "在本教程中设置要使用的文件夹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbfKRabXj3la"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path as path\n",
    "\n",
    "root_path = path.cwd()\n",
    "tutorial_path = root_path / \"tutorial\"\n",
    "data_path = tutorial_path / \"data\"\n",
    "src_path = tutorial_path / \"src\"\n",
    "experiments_path = tutorial_path / \"experiments\"\n",
    "models_path = tutorial_path / \"models\"\n",
    "build_path = tutorial_path / \"build\"\n",
    "tests_path = tutorial_path / \"tests\"\n",
    "\n",
    "data_path.mkdir(parents=True, exist_ok=True)\n",
    "src_path.mkdir(parents=True, exist_ok=True)\n",
    "experiments_path.mkdir(parents=True, exist_ok=True)\n",
    "models_path.mkdir(parents=True, exist_ok=True)\n",
    "build_path.mkdir(parents=True, exist_ok=True)\n",
    "tests_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9ryiScCEapt"
   },
   "source": [
    "在Vertex AI上设置一个Ray集群之前，请确保[设置](https://cloud.google.com/vertex-ai/docs/open-source/ray-on-vertex-ai/set-up)了Ray on Vertex AI。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mlq_1NLEonF"
   },
   "outputs": [],
   "source": [
    "import vertex_ray\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from vertex_ray import NodeImages, Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dorIZFvjnGKL"
   },
   "source": [
    "#### 为Python初始化Vertex AI SDK\n",
    "\n",
    "为您的项目初始化Vertex AI SDK的Python版本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOOgvRJoQ6Xj"
   },
   "outputs": [],
   "source": [
    "vertex_ai.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15PYjIyOcx1d"
   },
   "source": [
    "建立定制的集群镜像\n",
    "\n",
    "由于需要特定的依赖项，因此有必要利用Ray的定制集群镜像支持。\n",
    "\n",
    "要使用定制集群镜像，第一步是构建镜像。以下是要涉及的步骤：\n",
    "\n",
    "* 准备需求文件\n",
    "* 为定制镜像创建Dockerfile\n",
    "* 创建Docker镜像存储库\n",
    "* 构建Ray集群定制镜像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5vW6XpnkFeR"
   },
   "source": [
    "准备需求文件\n",
    "\n",
    "准备一个包含您的Ray应用程序运行所需依赖项的`requirements`文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83KUQQylbrJR"
   },
   "outputs": [],
   "source": [
    "requirements = \"\"\"\n",
    "ipython==8.22.2\n",
    "torch==2.2.1\n",
    "ray==2.10.0\n",
    "ray[data]==2.10.0\n",
    "ray[train]==2.10.0\n",
    "ray[tune]==2.10.0\n",
    "datasets==2.17.0\n",
    "transformers==4.38.1\n",
    "evaluate==0.4.1\n",
    "rouge-score==0.1.2\n",
    "nltk==3.8.1\n",
    "accelerate==0.27.1\n",
    "bitsandbytes==0.42.0\n",
    "peft==0.8.2\n",
    "trl==0.7.10\n",
    "# flash-attn==2.5.5\n",
    "pyarrow==15.0.2\n",
    "fsspec==2023.10.0\n",
    "gcsfs==2023.10.0\n",
    "etils==1.7.0\n",
    "importlib-resources==6.1.2\n",
    "\"\"\"\n",
    "\n",
    "with open(build_path / \"requirements.txt\", \"w\") as rfile:\n",
    "    rfile.write(requirements)\n",
    "rfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VHxHjCyKCyi"
   },
   "source": [
    "创建 Dockerfile\n",
    "\n",
    "通过利用预建的 Ray on Vertex AI 基础镜像之一，为自定义镜像创建 Dockerfile。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iu7bgcdeXZIS"
   },
   "outputs": [],
   "source": [
    "CUSTOM_BASE_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/ray-gpu.2-9.py310:latest\"  # @param [\"us-docker.pkg.dev/vertex-ai/training/ray-cpu.2-4.py310:latest\", \"us-docker.pkg.dev/vertex-ai/training/ray-cpu.2-9.py310:latest\", \"us-docker.pkg.dev/vertex-ai/training/ray-gpu.2-4.py310:latest\", \"us-docker.pkg.dev/vertex-ai/training/ray-gpu.2-9.py310:latest\", \"europe-docker.pkg.dev/vertex-ai/training/ray-cpu.2-4.py310:latest\", \"europe-docker.pkg.dev/vertex-ai/training/ray-cpu.2-9.py310:latest\", \"europe-docker.pkg.dev/vertex-ai/training/ray-gpu.2-4.py310:latest\", \"europe-docker.pkg.dev/vertex-ai/training/ray-gpu.2-9.py310:latest\", \"asia-docker.pkg.dev/vertex-ai/training/ray-cpu.2-4.py310:latest\", \"asia-docker.pkg.dev/vertex-ai/training/ray-cpu.2-9.py310:latest\", \"asia-docker.pkg.dev/vertex-ai/training/ray-gpu.2-4.py310:latest\", \"asia-docker.pkg.dev/vertex-ai/training/ray-gpu.2-9.py310:latest\"] {allow-input: true}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRSzXRpxKB_Q"
   },
   "outputs": [],
   "source": [
    "dockerfile = f\"\"\"\n",
    "FROM {CUSTOM_BASE_IMAGE}\n",
    "\n",
    "# Install training libraries.\n",
    "ENV PIP_ROOT_USER_ACTION=ignore\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "\"\"\"\n",
    "\n",
    "with open(build_path / \"Dockerfile\", \"w\") as image_file:\n",
    "    image_file.write(dockerfile)\n",
    "image_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTU6Ai5_RT1f"
   },
   "source": [
    "创建Docker镜像库\n",
    "\n",
    "为了存储自定义集群镜像，在Artifact Registry中创建一个Docker镜像库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUoNxKGIRiGb"
   },
   "outputs": [],
   "source": [
    "REPO_NAME = f\"your-repo-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zh0iT2qVKBDi"
   },
   "outputs": [],
   "source": [
    "! gcloud artifacts repositories create {REPO_NAME} --repository-format=docker \\\n",
    "    --location={REGION} --description=\"Tutorial repository\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9lYOI15SFgh"
   },
   "source": [
    "最后，使用Cloud Build构建Ray集群的自定义镜像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FR6BP7cgRLuD"
   },
   "outputs": [],
   "source": [
    "NODE_TRAIN_IMAGE = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPO_NAME}/train\"\n",
    "BUILD_MACHINE_TYPE = \"E2_HIGHCPU_32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VQKg4rMTLTa"
   },
   "outputs": [],
   "source": [
    "! gcloud builds submit --region={REGION} --tag={NODE_TRAIN_IMAGE} \\\n",
    "    --machine-type={BUILD_MACHINE_TYPE} --timeout=3600 {build_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_O1xUMt7Z6r0"
   },
   "source": [
    "#### 创建 Ray 集群\n",
    "\n",
    "使用自定义镜像，通过在 Vertex AI SDK for Python 上使用 Ray 创建 Ray 集群。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZkHOH3v2i1p"
   },
   "outputs": [],
   "source": [
    "CLUSTER_NAME = f\"your-cluster-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd2TmEdyVLo1"
   },
   "source": [
    "设置Ray集群配置\n",
    "\n",
    "在Vertex AI上使用Vertex AI Python SDK为Ray设置集群配置。\n",
    "\n",
    "要了解更多关于集群配置的信息，请参阅[文档](https://cloud.google.com/vertex-ai/docs/open-source/ray-on-vertex-ai/create-cluster#ray-on-vertex-ai-sdk)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0BBynZrFn7z"
   },
   "outputs": [],
   "source": [
    "HEAD_NODE_MACHINE_TYPE = \"n1-standard-16\"  # @param {type:\"string\"}\n",
    "HEAD_NODE_COUNT = 1  # @param {type:\"integer\"}\n",
    "\n",
    "WORKER_NODE_MACHINE_TYPE = \"a2-highgpu-1g\"  # @param {type:\"string\"}\n",
    "WORKER_NODE_COUNT = 1  # @param {type:\"integer\"}\n",
    "WORKER_ACCELERATION_TYPE = \"NVIDIA_TESLA_A100\"  # @param {type:\"string\"}\n",
    "WORKER_ACCELERATION_COUNT = 1  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppNbbhgm3_GE"
   },
   "outputs": [],
   "source": [
    "HEAD_NODE_TYPE = Resources(\n",
    "    machine_type=HEAD_NODE_MACHINE_TYPE,\n",
    "    node_count=HEAD_NODE_COUNT,\n",
    ")\n",
    "\n",
    "WORKER_NODE_TYPES = [\n",
    "    Resources(\n",
    "        machine_type=WORKER_NODE_MACHINE_TYPE,\n",
    "        node_count=WORKER_NODE_COUNT,\n",
    "        accelerator_type=WORKER_ACCELERATION_TYPE,\n",
    "        accelerator_count=WORKER_ACCELERATION_COUNT,\n",
    "    )\n",
    "]\n",
    "\n",
    "CUSTOM_IMAGES = NodeImages(\n",
    "    head=NODE_TRAIN_IMAGE,\n",
    "    worker=NODE_TRAIN_IMAGE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfkpGqRjksaW"
   },
   "source": [
    "创建 Ray 集群\n",
    "\n",
    "使用预定义的自定义配置创建 Ray 集群。根据配置不同，创建集群可能需要几分钟时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-g6kLwqUj5n"
   },
   "outputs": [],
   "source": [
    "ray_cluster_name = vertex_ray.create_ray_cluster(\n",
    "    head_node_type=HEAD_NODE_TYPE,\n",
    "    worker_node_types=WORKER_NODE_TYPES,\n",
    "    custom_images=CUSTOM_IMAGES,\n",
    "    cluster_name=CLUSTER_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmBlsbHAc2uO"
   },
   "source": [
    "获取Ray集群\n",
    "\n",
    "使用Python的Vertex AI SDK上的Ray来获取Ray集群。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UzG2WyXbZJi"
   },
   "outputs": [],
   "source": [
    "ray_clusters = vertex_ray.list_ray_clusters()\n",
    "ray_cluster_resource_name = ray_clusters[-1].cluster_resource_name\n",
    "ray_cluster = vertex_ray.get_ray_cluster(ray_cluster_resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7ZKdv5-GCWr"
   },
   "outputs": [],
   "source": [
    "print(\"Ray cluster on Vertex AI:\", ray_cluster_resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### 导入库\n",
    "\n",
    "导入所需的库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "# General\n",
    "import io\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import string\n",
    "import time\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "# Ray - Training\n",
    "import ray\n",
    "import torch\n",
    "import transformers\n",
    "from etils import epath\n",
    "from google.cloud import storage\n",
    "from huggingface_hub import login\n",
    "from peft import PeftModel\n",
    "from ray.job_submission import JobStatus, JobSubmissionClient\n",
    "# Ray - Batch Serving\n",
    "from ray.tune import ExperimentAnalysis\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9_UttTcNGYN"
   },
   "outputs": [],
   "source": [
    "print(\"Ray version: \", ray.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFgb-sZbBi8i"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "初始化一些教程变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zykxFjqUB9jt"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "HF_TOKEN = \"[your-hugging-face-token]\"  # @param {type:\"string\"}\n",
    "EXPERIMENTS_FOLDER_URI = epath.Path(BUCKET_URI) / \"experiments\"\n",
    "TENSORBOARD_NAME = f\"rov-xsum-gemma-tb-{TIMESTAMP}\"\n",
    "\n",
    "# Serving\n",
    "MODELS_PATH = epath.Path(BUCKET_URI) / \"models\"\n",
    "PREDICTIONS_FOLDER_URI = epath.Path(BUCKET_URI) / \"predictions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYQNboaOBk6B"
   },
   "source": [
    "### 定义辅助函数\n",
    "\n",
    "在您的笔记本中定义一个辅助函数，使用Ray Dashboard API 监控Ray作业的状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrvG6VDIm9hG"
   },
   "outputs": [],
   "source": [
    "def monitor_job(client, job_id):\n",
    "    \"\"\"Monitors the status of Ray job using Ray Dashboard API\"\"\"\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=f\"%(asctime)s.%(msecs)03d %(levelname)s {job_id} -- %(message)s\",\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "        force=True,\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        job_status = client.get_job_status(job_id)\n",
    "\n",
    "        if job_status == JobStatus.SUCCEEDED:\n",
    "            logging.info(\"Job succeeded!\")\n",
    "            break\n",
    "\n",
    "        elif job_status == JobStatus.FAILED:\n",
    "            logging.info(\"Job failed!\")\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            logging.info(\"Job is running...\")\n",
    "            time.sleep(60)\n",
    "\n",
    "    return job_status\n",
    "\n",
    "\n",
    "def read_json_files(bucket_name, prefix=None):\n",
    "    \"\"\"Reads JSON files from a cloud storage bucket and returns a Pandas DataFrame\"\"\"\n",
    "\n",
    "    # Set up storage client\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith(\".json\"):\n",
    "            file_bytes = blob.download_as_bytes()\n",
    "            file_string = file_bytes.decode(\"utf-8\")\n",
    "            with io.StringIO(file_string) as json_file:\n",
    "                df = pd.read_json(json_file, lines=True)\n",
    "            dfs.append(df)\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkAwZBj71ipc"
   },
   "source": [
    "图书馆设置\n",
    "\n",
    "启动一些图书馆设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3hT5TUM1lGc"
   },
   "outputs": [],
   "source": [
    "login(token=HF_TOKEN)\n",
    "datasets.disable_progress_bar()\n",
    "transformers.set_seed(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "assh71yp4G_O"
   },
   "source": [
    "### 创建一个 Vertex AI TensorBoard 实例\n",
    "\n",
    "创建一个 Vertex AI TensorBoard 实例来跟踪和监控您的调整作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKyJ1vREZRIY"
   },
   "outputs": [],
   "source": [
    "tensorboard = vertex_ai.Tensorboard.create(\n",
    "    display_name=TENSORBOARD_NAME, project=PROJECT_ID, location=REGION\n",
    ")\n",
    "\n",
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    staging_bucket=BUCKET_URI,\n",
    "    experiment_tensorboard=tensorboard,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BH0TlP3PtTB"
   },
   "source": [
    "## 使用 Ray Train 对 Gemma 进行微调\n",
    "\n",
    "在本教程中，您将使用 HuggingFace Transformer 和 Ray 在 Vertex AI 上对 Gemma 2B (`gemma-2b-it`) 进行微调，用于总结报纸文章。为了使这个笔记本易于复制，您编写了一个简单的 Python `trainer.py` 脚本，并通过公共 Ray 仪表板使用 Ray Jobs API 将其提交到 Vertex AI 上的 Ray 集群。\n",
    "\n",
    "正如在开头提到的那样，**请仅将此选项用于实验目的**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Du1IAdWos0AF"
   },
   "source": [
    "### 初始化Ray包\n",
    "\n",
    "创建一个`__init__.py`文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWrX2WLUs4um"
   },
   "outputs": [],
   "source": [
    "with open(src_path / \"__init__.py\", \"a\") as init_file:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVL71KFDstVR"
   },
   "source": [
    "### 准备训练脚本\n",
    "\n",
    "创建`src/train.py`文件，这是用于使用HuggingFace TRL库初始化Gemma微调的Python脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNQXWOHwtIDi"
   },
   "outputs": [],
   "source": [
    "train_script = '''\n",
    "# training libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "import datasets\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, Seq2SeqTrainingArguments\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "import evaluate\n",
    "import ray\n",
    "import ray.train.huggingface.transformers\n",
    "\n",
    "def train_func(config):\n",
    "    # Helpers\n",
    "    def formatting_func(example):\n",
    "        \"\"\"Helper function for formatting data for instruction tuning according to Gemma documentation.\"\"\"\n",
    "        output_texts = []\n",
    "        for i in range(len(example)):\n",
    "          messages = [\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": f\"Summarize the following ARTICLE in one sentence.\\\\n###ARTICLE: {example['document'][i]}\"},\n",
    "            {\"role\": \"assistant\",\n",
    "             \"content\": f\"{example['summary'][i]}<eos>\"} # Make minor gemma fixes #2029\n",
    "             ]\n",
    "          output_texts.append(tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False))\n",
    "        return output_texts\n",
    "\n",
    "    def compute_metrics(eval_preds):\n",
    "        \"\"\"Helper function for computing metrics\"\"\"\n",
    "        preds, labels = eval_preds\n",
    "        preds = preds[0]\n",
    "\n",
    "        preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        metrics = rouge.compute(predictions=decoded_preds,\n",
    "                                references=decoded_labels,\n",
    "                                rouge_types=['rouge1', 'rouge2', 'rougeL', 'rougeLsum'],\n",
    "                                use_aggregator=True, use_stemmer=True)\n",
    "        metrics = {k: round(v * 100, 4) for k, v in metrics.items()}\n",
    "        return metrics\n",
    "\n",
    "    def preprocess_logits_for_metrics(logits, labels):\n",
    "        \"\"\"Helper function for logits preprocessing for metrics\"\"\"\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        return preds, labels\n",
    "\n",
    "    # Setting training\n",
    "    login(token=os.environ['HF_TOKEN'], add_to_git_credential=True)\n",
    "    transformers.set_seed(8)\n",
    "\n",
    "    # Load dataset\n",
    "    dataset_id = \"xsum\"\n",
    "    dataset = datasets.load_dataset(dataset_id, trust_remote_code=True)\n",
    "    train_dataset = dataset[\"train\"]\n",
    "    eval_dataset = dataset[\"test\"]\n",
    "\n",
    "    # Preprocess dataset\n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    tokenizer.padding_side = 'right'\n",
    "\n",
    "    # Prepare model\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                                 quantization_config=bnb_config,\n",
    "                                                 device_map={'': torch.cuda.current_device()},\n",
    "                                                 torch_dtype=torch.bfloat16,\n",
    "                                                 # attn_implementation=\"flash_attention_2\"\n",
    "                                                 )\n",
    "    lora_config = LoraConfig(\n",
    "        r=32,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        target_modules=\"all-linear\",\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\"\n",
    "    )\n",
    "\n",
    "    # model.gradient_checkpointing_enable()\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=\"checkpoints\",\n",
    "        per_device_train_batch_size=config.get(\"per_device_train_batch_size\"),\n",
    "        per_device_eval_batch_size=config.get(\"per_device_eval_batch_size\"),\n",
    "        gradient_accumulation_steps=config.get(\"gradient_accumulation_steps\"),\n",
    "        logging_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        max_steps=config.get(\"max_steps\"),\n",
    "        save_steps=config.get(\"save_steps\"),\n",
    "        logging_steps=config.get(\"logging_steps\"),\n",
    "        learning_rate=config.get(\"learning_rate\"),\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        bf16=False,\n",
    "        fp16=True,\n",
    "        report_to=\"none\",\n",
    "        predict_with_generate=True,\n",
    "        ddp_find_unused_parameters=False,\n",
    "        gradient_checkpointing=True,\n",
    "        push_to_hub=False,\n",
    "        disable_tqdm=False,\n",
    "        load_best_model_at_end=False\n",
    "    )\n",
    "\n",
    "    max_seq_length = 512\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        max_seq_length=max_seq_length,\n",
    "        compute_metrics=compute_metrics,\n",
    "        preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "        peft_config=lora_config,\n",
    "        formatting_func=formatting_func\n",
    "    )\n",
    "    # model.config.use_cache = False\n",
    "\n",
    "    callback = ray.train.huggingface.transformers.RayTrainReportCallback()\n",
    "    trainer.add_callback(callback)\n",
    "    trainer = ray.train.huggingface.transformers.prepare_trainer(trainer)\n",
    "    trainer.train()\n",
    "'''\n",
    "\n",
    "with open(src_path / \"train.py\", \"w\") as f:\n",
    "    f.write(train_script)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pznqJKCpEcL3"
   },
   "source": [
    "准备分布式训练脚本\n",
    "\n",
    "创建`src/trainer.py`文件，这是用于执行Ray分布式训练任务的Python脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCFfhM7RP4RI"
   },
   "outputs": [],
   "source": [
    "trainer_script = \"\"\"\n",
    "# libraries\n",
    "import argparse\n",
    "\n",
    "# training libraries\n",
    "from train import train_func\n",
    "\n",
    "# ray libraries\n",
    "import ray\n",
    "import ray.train.huggingface.transformers\n",
    "from ray.train import ScalingConfig, RunConfig, CheckpointConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "\n",
    "\n",
    "# helpers\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Supervised tuning Gemma on Ray on Vertex AI')\n",
    "\n",
    "    # some gemma parameters\n",
    "    parser.add_argument(\"--train_batch_size\", type=int, default=1, help=\"train batch size\")\n",
    "    parser.add_argument(\"--eval_batch_size\", type=int, default=1, help=\"eval batch size\")\n",
    "    parser.add_argument(\"--gradient_accumulation_steps\", type=int, default=4, help=\"gradient accumulation steps\")\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=2e-4, help=\"learning rate\")\n",
    "    parser.add_argument(\"--max_steps\", type=int, default=100, help=\"max steps\")\n",
    "    parser.add_argument(\"--save_steps\", type=int, default=10, help=\"save steps\")\n",
    "    parser.add_argument(\"--logging_steps\", type=int, default=10, help=\"logging steps\")\n",
    "\n",
    "    # ray parameters\n",
    "    parser.add_argument('--num-workers', dest='num_workers', type=int, default=1, help='Number of workers')\n",
    "    parser.add_argument('--use-gpu', dest='use_gpu', action='store_true', default=False, help='Use GPU')\n",
    "    parser.add_argument('--experiment-name', dest='experiment_name', type=str, default='gemma-on-rov', help='Experiment name')\n",
    "    parser.add_argument('--logging-dir', dest='logging_dir', type=str, help='Logging directory')\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    args = get_args()\n",
    "    config = vars(args)\n",
    "\n",
    "    # initialize ray session\n",
    "    ray.shutdown()\n",
    "    ray.init()\n",
    "\n",
    "    # training config\n",
    "    train_loop_config = {\n",
    "        \"per_device_train_batch_size\": config['train_batch_size'],\n",
    "        \"per_device_eval_batch_size\": config['eval_batch_size'],\n",
    "        \"gradient_accumulation_steps\": config['gradient_accumulation_steps'],\n",
    "        \"learning_rate\": config['learning_rate'],\n",
    "        \"max_steps\": config['max_steps'],\n",
    "        \"save_steps\": config['save_steps'],\n",
    "        \"logging_steps\": config['logging_steps'],\n",
    "    }\n",
    "    scaling_config = ScalingConfig(num_workers=config['num_workers'], use_gpu=config['use_gpu'])\n",
    "    run_config = RunConfig(checkpoint_config=CheckpointConfig(num_to_keep=5,\n",
    "                          checkpoint_score_attribute=\"loss\",\n",
    "                          checkpoint_score_order=\"min\"),\n",
    "                           storage_path=config['logging_dir'],\n",
    "                           name=config['experiment_name'])\n",
    "    trainer = TorchTrainer(\n",
    "        train_loop_per_worker=train_func,\n",
    "        train_loop_config=train_loop_config,\n",
    "        run_config=run_config,\n",
    "        scaling_config=scaling_config\n",
    "    )\n",
    "    # train\n",
    "    result = trainer.fit()\n",
    "\n",
    "    ray.shutdown()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "with open(src_path / \"trainer.py\", \"w\") as f:\n",
    "    f.write(trainer_script)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYcmfEvZ3C1i"
   },
   "source": [
    "使用Ray Jobs API提交一个Ray作业\n",
    "\n",
    "使用Ray Jobs API将脚本提交到在Vertex AI上的Ray集群，在公共Ray仪表板地址。\n",
    "\n",
    "初始化客户端以提交作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FljDHRQ63EP4"
   },
   "outputs": [],
   "source": [
    "client = JobSubmissionClient(\n",
    "    address=\"vertex_ray://{}\".format(ray_cluster.dashboard_address)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDHIlGlQJ2oi"
   },
   "source": [
    "设置一些作业配置，包括实验名称、作业编号、训练入口等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxkqJ9vntz7C"
   },
   "outputs": [],
   "source": [
    "train_id = \"\".join(random.choices(string.ascii_lowercase + string.digits, k=3))\n",
    "train_experiment_name = f\"rov-dialog-gemma-tune-{train_id}\"\n",
    "train_submission_id = f\"ray-job-{train_id}\"\n",
    "train_entrypoint = f\"python3 trainer.py --experiment-name={train_experiment_name} --logging-dir={EXPERIMENTS_FOLDER_URI} --num-workers={WORKER_NODE_COUNT} --use-gpu\"\n",
    "train_experiment_uri = EXPERIMENTS_FOLDER_URI / train_experiment_name\n",
    "train_runtime_env = {\n",
    "    \"working_dir\": str(src_path),\n",
    "    \"env_vars\": {\"HF_TOKEN\": HF_TOKEN, \"TORCH_NCCL_ASYNC_ERROR_HANDLING\": \"3\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhwkH-NzgEHS"
   },
   "source": [
    "提交工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUPB6YKpur4f"
   },
   "outputs": [],
   "source": [
    "train_job_id = client.submit_job(\n",
    "    submission_id=train_submission_id,\n",
    "    entrypoint=train_entrypoint,\n",
    "    runtime_env=train_runtime_env,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8T0MaYZegF_1"
   },
   "source": [
    "使用`monitor_job`函数在任务运行时检查任务的状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uCeasefuso8"
   },
   "outputs": [],
   "source": [
    "train_job_status = monitor_job(client, train_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67FI31SqKFdF"
   },
   "source": [
    "### 检查训练工件\n",
    "\n",
    "Ray 训练作业完成后，在云存储位置查看模型工件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_JOYhXQKK8U"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -l {train_experiment_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAOAsmGYZ2l9"
   },
   "source": [
    "使用Vertex AI TensorBoard来记录产生的指标，验证您的训练工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSMCKEp9Z8jx"
   },
   "outputs": [],
   "source": [
    "vertex_ai.upload_tb_log(\n",
    "    tensorboard_id=tensorboard.name,\n",
    "    tensorboard_experiment_name=train_experiment_name,\n",
    "    logdir=str(train_experiment_uri),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2RfyLpW0XO7"
   },
   "source": [
    "使用Ray在Vertex AI上为离线预测提供调整后的Gemma模型\n",
    "\n",
    "在Vertex AI上使用Ray开发AI/ML应用程序具有各种好处。在这种情况下，您可以使用云存储方便地存储模型检查点、指标等。这使您能够快速地为AI/ML下游任务消耗模型，包括使用Ray Data生成批处理预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "700NkAsLQHJI"
   },
   "source": [
    "生成预测（本地）\n",
    "\n",
    "生成本地预测以验证调整后的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fN5YQ60PXbYq"
   },
   "source": [
    "#### 下载Ray培训检查点\n",
    "\n",
    "从Ray作业中下载所有生成的检查点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBf0_agLhrLV"
   },
   "outputs": [],
   "source": [
    "! gsutil -q cp -r {train_experiment_uri}/* {experiments_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VavpxaY1hlSN"
   },
   "source": [
    "获取最佳检查点\n",
    "\n",
    "使用“ExperimentAnalysis”方法根据相关指标和模式检索最佳检查点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUBEKpK1gVx9"
   },
   "outputs": [],
   "source": [
    "experiment_analysis = ExperimentAnalysis(experiments_path)\n",
    "log_path = experiment_analysis.get_best_trial(metric=\"eval_rougeLsum\", mode=\"max\")\n",
    "best_checkpoint = experiment_analysis.get_best_checkpoint(\n",
    "    log_path, metric=\"eval_rougeLsum\", mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icFuBCwJXSub"
   },
   "source": [
    "训练完成后加载模型\n",
    "\n",
    "训练模型后，根据Hugging Face文档中的描述加载模型。\n",
    "\n",
    "设置模型和适配器路径。还要设置存储结果调整模型的路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "370W-GHE7vM2"
   },
   "outputs": [],
   "source": [
    "base_model_path = \"google/gemma-2b-it\"\n",
    "peft_model_path = epath.Path(best_checkpoint.path) / \"checkpoint\"\n",
    "tuned_model_path = models_path / \"xsum-tuned-gemma-it\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UCc4hvGjES8"
   },
   "source": [
    "启动关联的Gemma标记器和基础模型。同时启动生成的适配器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbctXuXQAhLP"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path, device_map=\"auto\", torch_dtype=torch.float16\n",
    ")\n",
    "peft_model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    peft_model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    is_trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Jytit8inMGy"
   },
   "source": [
    "将基础模型和适配器合并，以保存调整后的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRGvb7hRnK-a"
   },
   "outputs": [],
   "source": [
    "tuned_model = peft_model.merge_and_unload()\n",
    "tuned_model.save_pretrained(tuned_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4WRLix49saQ"
   },
   "source": [
    "#### 生成摘要\n",
    "\n",
    "使用调整过的模型生成摘要。加载教程数据集的验证集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PrsR5HjNunzW"
   },
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\n",
    "    \"xsum\", split=\"validation\", cache_dir=data_path, trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dm5eFJNxoAHk"
   },
   "source": [
    "Sample一篇文章进行总结。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZjT8zAOPivt"
   },
   "outputs": [],
   "source": [
    "sample = dataset.select([random.randint(0, len(dataset) - 1)])\n",
    "document = sample[\"document\"][0]\n",
    "reference_summary = sample[\"summary\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16GiJy_EoEgi"
   },
   "source": [
    "根据[Gemma文档](https://ai.google.dev/gemma/docs/formatting)准备相关的提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFhA8R3wXPKj"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Summarize the following ARTICLE in one sentence.\\\\n###ARTICLE: {document}\",\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7Lvss80objd"
   },
   "source": [
    "启动文本生成管道以生成摘要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wq6m6G-b_w7b"
   },
   "outputs": [],
   "source": [
    "tuned_gemma_pipeline = pipeline(\n",
    "    \"text-generation\", model=tuned_model, tokenizer=tokenizer, max_new_tokens=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb5GNgv1ovpc"
   },
   "source": [
    "生成相关摘要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuF2CMGx6AGi"
   },
   "outputs": [],
   "source": [
    "generated_tuned_gemma_summary = tuned_gemma_pipeline(\n",
    "    prompt, do_sample=True, temperature=0.1, add_special_tokens=True\n",
    ")[0][\"generated_text\"][len(prompt) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKjU_Mhgo8yO"
   },
   "source": [
    "打印生成的摘要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq6HLy4Pu8oC"
   },
   "outputs": [],
   "source": [
    "print(f\"Reference summary: {reference_summary}\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"Tuned generated summary: {generated_tuned_gemma_summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdhPQC5aKmyP"
   },
   "source": [
    "评估模型\n",
    "\n",
    "作为一个额外的步骤，您可以评估调整过的模型。要评估模型，您需要在定性和定量上比较模型。\n",
    "\n",
    "在一个案例中，您会比较基础Gemma模型生成的响应和调整过的Gemma模型生成的响应。在另一个案例中，您会计算ROUGE指标及其改进，这会让您了解调整过的模型相对于基础模型正确地复现参考摘要的能力。\n",
    "\n",
    "通过比较生成的摘要来评估模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmbCCJpWora7"
   },
   "outputs": [],
   "source": [
    "gemma_pipeline = pipeline(\n",
    "    \"text-generation\", model=base_model, tokenizer=tokenizer, max_new_tokens=50\n",
    ")\n",
    "\n",
    "generated_gemma_summary = gemma_pipeline(\n",
    "    prompt, do_sample=True, temperature=0.1, add_special_tokens=True\n",
    ")[0][\"generated_text\"][len(prompt) :]\n",
    "\n",
    "print(f\"Reference summary: {reference_summary}\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"Base generated summary: {generated_gemma_summary}\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"Tuned generated summary: {generated_tuned_gemma_summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLt-3ovZq7y1"
   },
   "source": [
    "通过计算ROUGE指标及其改进来评估模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FRSPxJVpfJ3E"
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iEO5qqtsMC75"
   },
   "outputs": [],
   "source": [
    "gemma_results = rouge.compute(\n",
    "    predictions=[generated_gemma_summary],\n",
    "    references=[reference_summary],\n",
    "    rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYC5t4I594pn"
   },
   "outputs": [],
   "source": [
    "tuned_gemma_results = rouge.compute(\n",
    "    predictions=[generated_tuned_gemma_summary],\n",
    "    references=[reference_summary],\n",
    "    rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QnWVuRe394gh"
   },
   "outputs": [],
   "source": [
    "improvements = {}\n",
    "for rouge_metric, gemma_rouge in gemma_results.items():\n",
    "    tuned_gemma_rouge = tuned_gemma_results[rouge_metric]\n",
    "    if gemma_rouge != 0:\n",
    "        improvement = ((tuned_gemma_rouge - gemma_rouge) / gemma_rouge) * 100\n",
    "    else:\n",
    "        improvement = None\n",
    "    improvements[rouge_metric] = improvement\n",
    "\n",
    "print(\"Base Gemma vs Tuned Gemma - ROUGE improvements\")\n",
    "for rouge_metric, improvement in improvements.items():\n",
    "    print(f\"{rouge_metric}: {improvement:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G51Xhb4H0fa1"
   },
   "source": [
    "使用Ray Data进行批量预测\n",
    "\n",
    "要使用Ray Data在Vertex AI上生成经过调整的模型的批量预测，您需要一个数据集来生成预测以及存储在云存储桶中的经过调整的模型。\n",
    "\n",
    "接下来，您可以利用Ray Data，它提供了一个便于使用的API来进行离线批量推断。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjV1oHCTCe1r"
   },
   "source": [
    "上传调整后的模型\n",
    "\n",
    "上传调整后的模型至云存储。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFwD2p8jCjgH"
   },
   "outputs": [],
   "source": [
    "! gsutil -q cp -r {models_path} {MODELS_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eIwOKSnrpxkW"
   },
   "source": [
    "准备批量预测训练脚本\n",
    "\n",
    "准备`src/batch_predict.py`文件，这是执行Ray批量预测作业的Python脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekL5tV31pxkX"
   },
   "outputs": [],
   "source": [
    "batch_predictor_script = \"\"\"\n",
    "# General\n",
    "import argparse\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Serving\n",
    "import datasets\n",
    "import transformers\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.pipelines import pipeline\n",
    "\n",
    "# Ray\n",
    "import ray\n",
    "\n",
    "# Settings\n",
    "datasets.disable_progress_bar()\n",
    "\n",
    "# Variables\n",
    "base_model_path = \"google/gemma-2b-it\"\n",
    "\n",
    "\n",
    "# helpers\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Batch prediction with Gemma on Ray on Vertex AI')\n",
    "    parser.add_argument('--tuned_model_path', type=str, help='path of adapter model')\n",
    "    parser.add_argument('--num_gpus', type=int, default=1, help='number of gpus')\n",
    "    parser.add_argument('--batch_size', type=int, default=8, help='batch size')\n",
    "    parser.add_argument('--sample_size', type=int, default=20, help='number of articles to summarize')\n",
    "    parser.add_argument('--temperature', type=float, default=0.1, help='temperature for generating summaries')\n",
    "    parser.add_argument('--max_new_tokens', type=int, default=50, help='max new token for generating summaries')\n",
    "    parser.add_argument('--output_dir', type=str, help='output directory for predictions')\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Set configuration\n",
    "    args = get_args()\n",
    "    config = vars(args)\n",
    "\n",
    "    # Setting training\n",
    "    login(token=os.environ['HF_TOKEN'], add_to_git_credential=True)\n",
    "    transformers.set_seed(8)\n",
    "\n",
    "    # Load dataset\n",
    "    dataset_id = \"xsum\"\n",
    "    sample_size = config[\"sample_size\"]\n",
    "    input_data = datasets.load_dataset(dataset_id, split=\"validation\", trust_remote_code=True)\n",
    "    input_data = input_data.select(range(sample_size))\n",
    "    ray_input_data = ray.data.from_huggingface(input_data)\n",
    "\n",
    "    # Generate predictions\n",
    "\n",
    "    class Summarizer:\n",
    "\n",
    "      def __init__(self):\n",
    "          self.tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "          self.tokenizer.padding_side = \"right\"\n",
    "\n",
    "          self.tuned_model = AutoModelForCausalLM.from_pretrained(config[\"tuned_model_path\"],\n",
    "                                                                  device_map='auto',\n",
    "                                                                  torch_dtype=torch.float16)\n",
    "\n",
    "          self.pipeline = pipeline(\"text-generation\",\n",
    "                                    model=self.tuned_model,\n",
    "                                    tokenizer=self.tokenizer,\n",
    "                                    max_new_tokens=config[\"max_new_tokens\"])\n",
    "\n",
    "      def __call__(self, batch: np.ndarray):\n",
    "\n",
    "          # prepare dataset\n",
    "          messages = [{\"role\": \"user\",\n",
    "                      \"content\": f\"Summarize the following ARTICLE in one sentence.\\\\n###ARTICLE: {document}\"}\n",
    "                      for document in batch[\"document\"]]\n",
    "\n",
    "          batch['prompt'] = [self.tokenizer.apply_chat_template([message], tokenize=False, add_generation_prompt=True)\n",
    "                             for message in messages]\n",
    "\n",
    "          # generate\n",
    "          batch['generated_summary'] = [self.pipeline(prompt,\n",
    "                                                    do_sample=True,\n",
    "                                                    temperature=config[\"temperature\"],\n",
    "                                                    add_special_tokens=True)[0][\"generated_text\"][len(prompt):]\n",
    "                                                    for prompt in batch['prompt']]\n",
    "\n",
    "          return batch\n",
    "\n",
    "\n",
    "    predictions_data = ray_input_data.map_batches(\n",
    "        Summarizer,\n",
    "        concurrency=config[\"num_gpus\"],\n",
    "        num_gpus=1,\n",
    "        batch_size=config['batch_size'])\n",
    "\n",
    "    # Store resulting predictions\n",
    "    predictions_data.write_json(config[\"output_dir\"], try_create_dir=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "with open(src_path / \"batch_predictor.py\", \"w\") as f:\n",
    "    f.write(batch_predictor_script)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xynt8impxkX"
   },
   "source": [
    "使用Ray Jobs API提交一个Ray作业\n",
    "\n",
    "通过公共Ray仪表板地址，使用Ray Jobs API将脚本提交到Vertex AI集群上的Ray。\n",
    "\n",
    "初始化客户端以提交作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hY96qSQFpxkX"
   },
   "outputs": [],
   "source": [
    "client = JobSubmissionClient(\n",
    "    address=\"vertex_ray://{}\".format(ray_cluster.dashboard_address)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQ6EqvIF5q9F"
   },
   "source": [
    "设置一些作业配置，包括模型路径、作业ID、预测入口等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDycAWy45siE"
   },
   "outputs": [],
   "source": [
    "batch_predict_id = \"\".join(random.choices(string.ascii_lowercase + string.digits, k=4))\n",
    "batch_predict_submission_id = f\"ray-job-{batch_predict_id}\"\n",
    "tuned_model_uri_path = str(MODELS_PATH / \"xsum-tuned-gemma-it\").replace(\n",
    "    \"gs://\", \"/gcs/\"\n",
    ")\n",
    "batch_predict_entrypoint = f\"python3 batch_predictor.py --tuned_model_path={tuned_model_uri_path} --num_gpus=2 --output_dir={PREDICTIONS_FOLDER_URI}\"\n",
    "batch_predict_runtime_env = {\n",
    "    \"working_dir\": str(src_path),\n",
    "    \"env_vars\": {\"HF_TOKEN\": HF_TOKEN},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcaMEKz6pxkX"
   },
   "source": [
    "提交工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qADWE5LOpxkX"
   },
   "outputs": [],
   "source": [
    "batch_predict_job_id = client.submit_job(\n",
    "    submission_id=batch_predict_submission_id,\n",
    "    entrypoint=batch_predict_entrypoint,\n",
    "    runtime_env=batch_predict_runtime_env,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxrOwuVf6f3R"
   },
   "source": [
    "使用`monitor_job`辅助函数检查工作的状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXTF8pp9KJS8"
   },
   "outputs": [],
   "source": [
    "batch_predict_job_status = monitor_job(client, batch_predict_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2Iafitj7wtH"
   },
   "source": [
    "获取生成的摘要\n",
    "\n",
    "使用Pandas DataFrame 快速查看生成的摘要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "em4WQokY7050"
   },
   "outputs": [],
   "source": [
    "predictions_df = read_json_files(prefix=\"predictions/\", bucket_name=BUCKET_NAME)\n",
    "predictions_df = predictions_df[\n",
    "    [\"id\", \"document\", \"prompt\", \"summary\", \"generated_summary\"]\n",
    "]\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理本项目中使用的所有谷歌云资源，您可以删除用于教程的[谷歌云项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "delete_tensorboards = False\n",
    "delete_experiments = False\n",
    "delete_ray_clusters = False\n",
    "delete_image_repo = False\n",
    "delete_bucket = False\n",
    "delete_tutorial = False\n",
    "\n",
    "# Delete tensorboard\n",
    "if delete_tensorboards:\n",
    "    tensorboard_list = vertex_ai.Tensorboard.list()\n",
    "    for tensorboard in tensorboard_list:\n",
    "        tensorboard.delete()\n",
    "\n",
    "# Delete experiments\n",
    "if delete_experiments:\n",
    "    experiment_list = vertex_ai.Experiment.list()\n",
    "    for experiment in experiment_list:\n",
    "        experiment.delete()\n",
    "\n",
    "# Delete ray on vertex cluster\n",
    "if delete_ray_clusters:\n",
    "    ray_cluster_list = vertex_ray.list_ray_clusters()\n",
    "    for ray_cluster in ray_cluster_list:\n",
    "        vertex_ray.delete_ray_cluster(ray_cluster.cluster_resource_name)\n",
    "\n",
    "if delete_image_repo:\n",
    "    ! gcloud artifacts repositories delete {REPO_NAME}\n",
    "\n",
    "# Delete Cloud Storage objects that were created\n",
    "if delete_bucket:\n",
    "    ! gsutil -q -m rm -r {BUCKET_URI}\n",
    "\n",
    "# Delete tutorial folder\n",
    "if delete_tutorial:\n",
    "    shutil.rmtree(tutorial_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "model_garden_gemma_fine_tuning_batch_deployment_on_rov.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
