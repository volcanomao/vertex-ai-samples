{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TirJ-SGQseby"
   },
   "source": [
    "# Vertex AI 模型花园 MediaPipe 文本分类\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_mediapipe_text_classification.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "    </a>\n",
    "  </td>\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_mediapipe_text_classification.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_mediapipe_image_classification.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "在 Vertex AI 工作台中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwGLvtIeECLK"
   },
   "source": [
    "注意：这个笔记本已在以下环境中进行测试：\n",
    "\n",
    "* Python版本= 3.9\n",
    "\n",
    "注意：在Colab中链接的检查点和数据集不是由谷歌拥有或分发的，而是由第三方提供。在使用检查点和数据之前，请先查看第三方提供的条款和条件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本笔记本演示了如何使用[MediaPipe Model Maker](https://developers.google.com/mediapipe/solutions/model_maker)在Vertex AI Model Garden中训练一个设备上的文本分类模型。\n",
    "\n",
    "### 目标\n",
    "\n",
    "* 训练新模型\n",
    "  * 将输入数据转换为训练格式\n",
    "  * 创建[自定义作业](https://cloud.google.com/vertex-ai/docs/training/create-custom-job)来训练新模型\n",
    "  * 导出模型\n",
    "\n",
    "* 清理资源\n",
    "\n",
    "### 成本\n",
    "\n",
    "本教程使用 Google Cloud 的按量计费组件:\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage 价格](https://cloud.google.com/storage/pricing)，并使用[Pricing 计算器](https://cloud.google.com/products/calculator/)根据您的预期用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEukV6uRk_S3"
   },
   "source": [
    "在开始之前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z__i0w0lCAsW"
   },
   "source": [
    "### 仅限在Colab上运行\n",
    "运行以下命令来安装依赖库，并在Colab上认证Google Cloud。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jvqs-ehKlaYh"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade pip\n",
    "\n",
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    ! pip3 install --upgrade google-cloud-aiplatform\n",
    "\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "\n",
    "    from google.colab import auth as google_auth\n",
    "\n",
    "    google_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "设置项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 区域\n",
    "\n",
    "您还可以更改 Vertex AI 使用的 `REGION` 变量。了解有关[Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTy1gX11kCJY"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
    "REGION_PREFIX = REGION.split(\"-\")[0]\n",
    "assert REGION_PREFIX in (\n",
    "    \"us\",\n",
    "    \"europe\",\n",
    "    \"asia\",\n",
    "), f'{REGION} is not supported. It must be prefixed by \"us\", \"asia\", or \"europe\".'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶，用于存储中间产物，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "只有在您的存储桶不存在时: 运行以下单元格来创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "###导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk,all"
   },
   "source": [
    "### 初始化Python的Vertex AI SDK\n",
    "\n",
    "为您的项目初始化Python的Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wExiMUxFk91"
   },
   "outputs": [],
   "source": [
    "now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temp/%s\" % now)\n",
    "\n",
    "EVALUATION_RESULT_OUTPUT_DIRECTORY = os.path.join(STAGING_BUCKET, \"evaluation\")\n",
    "EVALUATION_RESULT_OUTPUT_FILE = os.path.join(\n",
    "    EVALUATION_RESULT_OUTPUT_DIRECTORY, \"evaluation.json\"\n",
    ")\n",
    "\n",
    "EXPORTED_MODEL_OUTPUT_DIRECTORY = os.path.join(STAGING_BUCKET, \"model\")\n",
    "EXPORTED_MODEL_OUTPUT_FILE = os.path.join(\n",
    "    EXPORTED_MODEL_OUTPUT_DIRECTORY, \"model.tflite\"\n",
    ")\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6IFz75WGCam"
   },
   "source": [
    "定义培训机规格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riG_qUokg0XZ"
   },
   "outputs": [],
   "source": [
    "TRAINING_JOB_DISPLAY_NAME = \"mediapipe_text_classifier_%s\" % now\n",
    "TRAINING_CONTAINER = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/mediapipe-train\"\n",
    "TRAINING_MACHINE_TYPE = \"n1-highmem-16\"\n",
    "TRAINING_ACCELERATOR_TYPE = \"NVIDIA_TESLA_V100\"\n",
    "TRAINING_ACCELERATOR_COUNT = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rsdAcBV-vlf"
   },
   "source": [
    "## 训练您的定制模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "获取数据集\n",
    "\n",
    "以下代码块使用[SST-2](https://nlp.stanford.edu/sentiment/index.html)（斯坦福情感树库）数据集，其中包含67,349条用于训练的电影评论和872条用于测试的电影评论。该数据集有两类：正面和负面的电影评论。正面评论标记为1，负面评论标记为0。\n",
    "\n",
    "SST-2数据集保存为TSV文件。TSV和CSV格式之间唯一的区别是TSV使用制表符`\\t`作为分隔符，而CSV使用逗号`,`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IndQ_m6ddUEM"
   },
   "outputs": [],
   "source": [
    "training_data_path = (\n",
    "    \"gs://mediapipe-tasks/text_classifier/SST-2/train.tsv\"  # @param {type:\"string\"}\n",
    ")\n",
    "validation_data_path = (\n",
    "    \"gs://mediapipe-tasks/text_classifier/SST-2/dev.tsv\"  # @param {type:\"string\"}\n",
    ")\n",
    "\n",
    "# The delimiter used in the dataset.\n",
    "delimiter = \"\\t\"  # @param {type:\"string\"}\n",
    "\n",
    "# Character used to quote fields that contain special characters\n",
    "# like the `delimiter`.\n",
    "quotechar = \"\\t\"  # @param {type:\"string\"}\n",
    "\n",
    "# Sequence of keys for the CSV columns (represented as a comma\n",
    "# separated list). If empty, the first row of the CSV file is used\n",
    "# as the keys\n",
    "fieldnames = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# Column name for the input text.\n",
    "text_column = \"sentence\"  # @param {type:\"string\"}\n",
    "\n",
    "# Column name for the labels.\n",
    "label_column = \"label\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaff6f5be7f6"
   },
   "source": [
    "### 设置微调选项\n",
    "\n",
    "您可以在不同的模型架构之间进行选择，以进一步定制您的训练：\n",
    "\n",
    "* 平均词嵌入模型\n",
    "* BERT分类器\n",
    "\n",
    "要设置模型架构和其他训练参数，请调整以下数值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "um_XKbmpTaHx"
   },
   "outputs": [],
   "source": [
    "model_architecture = (\n",
    "    \"average_word_embedding\"  # @param [\"average_word_embedding\", \"mobilebert\"]\n",
    ")\n",
    "\n",
    "# The learning rate to use for gradient descent-based\n",
    "# optimizers. Defaults to 3e-5 for the BERT-based classifier\n",
    "# and 0 for the average word-embedding classifier because\n",
    "# it does not need such an optimizer.\n",
    "learning_rate: float = 0.0  # @param {type:\"number\"}\n",
    "\n",
    "# Batch size for training. Defaults to 32 for the average\n",
    "# word-embedding classifier and 48 for the BERT-based\n",
    "# classifier.\n",
    "batch_size: int = 48  # @param {type:\"number\"}\n",
    "\n",
    "# Number of training iterations over the dataset. Defaults\n",
    "# to 10 for the average word-embedding classifier and 3\n",
    "# for the BERT-based classifier.\n",
    "epochs: int = 10  # @param {type:\"slider\", min:0, max:100, step:1}\n",
    "\n",
    "# An integer that indicates the number of training steps per\n",
    "# epoch. If set to 0, the training pipeline calculates the\n",
    "# default steps per epoch as the training dataset size\n",
    "# divided by batch size.\n",
    "steps_per_epoch: int = 0  # @param {type:\"number\"}\n",
    "\n",
    "# Controls whether the dataset is shuffled before training.\n",
    "shuffle: bool = False  # @param {type:\"boolean\"}\n",
    "\n",
    "# Length of the sequence to feed into the model.\n",
    "seq_len: int = 256  # @param {type:\"number\"}\n",
    "\n",
    "# Whether to convert all uppercase characters to lowercase\n",
    "# during preprocessing.\n",
    "do_lower_case: bool = True  # @param {type:\"boolean\"}\n",
    "\n",
    "# The rate for dropout.\n",
    "dropout_rate: float = 0.2  # @param {type:\"number\"}\n",
    "\n",
    "# Dimension of the word embedding. Only used for the Average Word\n",
    "# Embedding Model.\n",
    "wordvec_dim: int = 16  # @param {type:\"number\"}\n",
    "\n",
    "# Number of words to generate the vocabulary from data.\n",
    "# Only used for the Average Word Embedding Model.\n",
    "vocab_size: int = 10000  # @param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwcCjwlBTQIz"
   },
   "source": [
    "### 运行微调\n",
    "准备好你的训练数据集和微调选项后，你就可以开始微调过程了。这个过程需要大量资源，根据模型架构和你可用的计算资源，可能需要几分钟到几个小时不等。在使用GPU处理的Vertex AI上，下面示例的微调需要花费2-3分钟来训练一个在SST-2数据集上的平均词嵌入模型。\n",
    "\n",
    "要开始微调过程，请使用以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aec22792ee84"
   },
   "outputs": [],
   "source": [
    "model_export_path = EXPORTED_MODEL_OUTPUT_DIRECTORY\n",
    "evaluation_result_path = EVALUATION_RESULT_OUTPUT_DIRECTORY\n",
    "\n",
    "preprocessing_params = {\n",
    "    \"text_column\": text_column,\n",
    "    \"label_column\": label_column,\n",
    "    \"delimiter\": delimiter,\n",
    "    \"quotechar\": quotechar,\n",
    "}\n",
    "if fieldnames:\n",
    "    preprocessing_params[\"fieldnames\"] = [\n",
    "        fieldname.strip() for fieldname in fieldnames.split(\",\")\n",
    "    ]\n",
    "\n",
    "hparams = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs,\n",
    "    \"shuffle\": shuffle,\n",
    "}\n",
    "if steps_per_epoch:\n",
    "    hparams[\"steps_per_epoch\"] = steps_per_epoch\n",
    "\n",
    "model_options = {\n",
    "    \"dropout_rate\": dropout_rate,\n",
    "    \"wordvec_dim\": wordvec_dim,\n",
    "    \"do_lower_case\": do_lower_case,\n",
    "    \"vocab_size\": vocab_size,\n",
    "    \"dropout_rate\": dropout_rate,\n",
    "}\n",
    "\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": TRAINING_MACHINE_TYPE,\n",
    "            \"accelerator_type\": TRAINING_ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": TRAINING_ACCELERATOR_COUNT,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": TRAINING_CONTAINER,\n",
    "            \"command\": [],\n",
    "            \"args\": [\n",
    "                \"--task_name=text_classifier\",\n",
    "                \"--training_data_path=%s\" % training_data_path,\n",
    "                \"--validation_data_path=%s\" % validation_data_path,\n",
    "                \"--evaluation_result_path=%s\" % evaluation_result_path,\n",
    "                \"--model_export_path=%s\" % model_export_path,\n",
    "                \"--model_architecture=%s\" % model_architecture,\n",
    "                \"--preprocessing_params=%s\" % json.dumps(preprocessing_params),\n",
    "                \"--hparams=%s\" % json.dumps(hparams),\n",
    "                \"--model_options=%s\" % json.dumps(model_options),\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "training_job = aiplatform.CustomJob(\n",
    "    display_name=TRAINING_JOB_DISPLAY_NAME,\n",
    "    project=PROJECT_ID,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=STAGING_BUCKET,\n",
    ")\n",
    "\n",
    "training_job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXMF2tnV_WS0"
   },
   "source": [
    "## 导出模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0BGaofgsMsy"
   },
   "source": [
    "调整完毕后，你可以保存TensorFlow Lite模型，然后在MediaPipe Studio的[文本分类](https://mediapipe-studio.webapps.google.com/demo/text_classifier)演示中进行尝试，或者根据[文本分类任务指南](https://developers.google.com/mediapipe/solutions/text/text_classifier)将其集成到您的设备应用中。导出的模型包含所需的模型元数据，以及一个分类标签文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYuQowyZEtxK"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def copy_model(model_source, model_dest):\n",
    "    ! gsutil cp {model_source} {model_dest}\n",
    "\n",
    "copy_model(EXPORTED_MODEL_OUTPUT_FILE, \"text_classification_model.tflite\")\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import files\n",
    "\n",
    "    files.download(\"text_classification_model.tflite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkH2nrpdp4sp"
   },
   "source": [
    "清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ax6vQVZhp9pR"
   },
   "outputs": [],
   "source": [
    "# Delete training data and jobs.\n",
    "if training_job.list(filter=f'display_name=\"{TRAINING_JOB_DISPLAY_NAME}\"'):\n",
    "    training_job.delete()\n",
    "\n",
    "!gsutil rm -r {STAGING_BUCKET}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "model_garden_mediapipe_text_classification.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
