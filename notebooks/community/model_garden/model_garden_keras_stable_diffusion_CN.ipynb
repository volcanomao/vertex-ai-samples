{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TirJ-SGQseby"
   },
   "source": [
    "# Vertex AI 模型花园 Keras 稳定扩散\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_keras_stable_diffusion.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "    </a>\n",
    "  </td>\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_keras_stable_diffusion.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_keras_stable_diffusion.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    " 在 Vertex AI 工作台中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwGLvtIeECLK"
   },
   "source": [
    "**_注意_**: 该笔记本已在以下环境中进行了测试：\n",
    "\n",
    "* Python 版本 = 3.9\n",
    "\n",
    "您可以直接在 colab 中打开这个笔记本，或者创建 [google managed](https://cloud.google.com/vertex-ai/docs/workbench/managed/create-instance) 或 [user managed](https://cloud.google.com/vertex-ai/docs/workbench/user-managed/create-new) 的工作台实例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本笔记本演示了如何在Vertex AI Model Garden中使用[Keras Stable Diffusion](https://keras.io/api/keras_cv/models/stable_diffusion)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0z9r_mBmDeYh"
   },
   "source": [
    "### 目的\n",
    "\n",
    "- 在预训练或定制模型上进行本地推理\n",
    "- 在谷歌云Vertex AI上部署预训练或定制模型\n",
    "- 在谷歌云Vertex AI上微调模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxo28lDtDxn-"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "我们使用[Pokémon BLIP字幕数据集](https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions)来展示如何微调稳定的扩散模型。但是，我们将使用一个略有不同的版本，该版本是从原始数据集中衍生出来的，以更好地配合`tf.data`。有关更多详细信息，请参考[文档](https://huggingface.co/datasets/sayakpaul/pokemon-blip-original-version)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEnkHABrDijz"
   },
   "source": [
    "成本\n",
    "\n",
    "本教程使用Google Cloud的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI价格](https://cloud.google.com/vertex-ai/pricing)和 [Cloud Storage价格](https://cloud.google.com/storage/pricing)，并使用[Pricing计算器](https://cloud.google.com/products/calculator/)根据您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z__i0w0lCAsW"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装以下所需的软件包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jvqs-ehKlaYh"
   },
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    # Configs for colab notebooks.\n",
    "    ! pip3 install --upgrade --quiet google-cloud-aiplatform\n",
    "\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "\n",
    "    from google.colab import auth as google_auth\n",
    "\n",
    "    google_auth.authenticate_user()\n",
    "\n",
    "# Configs for all notebooks.\n",
    "! pip3 install --quiet keras-cv==0.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEukV6uRk_S3"
   },
   "source": [
    "##开始之前\n",
    "\n",
    "###设置您的Google Cloud项目\n",
    "\n",
    "**无论您使用哪种笔记本环境，都需要执行以下步骤。**\n",
    "\n",
    "1. [选择或创建Google Cloud项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建帐户时，您将获得$300的免费信用额度，可用于计算/存储成本。\n",
    "\n",
    "2. [确保您的项目已启用计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "3. [启用Vertex AI API和Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component)。\n",
    "\n",
    "4. 如果您在本地运行此笔记本，您需要安装[Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "5. [创建一个服务帐号](https://cloud.google.com/iam/docs/service-accounts-create#iam-service-accounts-create-console)，为部署优化模型到Vertex AI端点分配`Vertex AI用户`和`存储对象管理员`权限。\n",
    "\n",
    "6. 在下面的单元格中输入您的项目ID。然后运行该单元格，以确保Cloud SDK在本笔记本中的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter以`!`前缀运行带有shell命令行，它会将以`$`前缀的Python变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "### 设置您的项目、区域和存储桶\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下操作：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)\n",
    "\n",
    "您可以更改 Vertex AI 使用的 `REGION` 变量。了解更多关于 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations)。\n",
    "\n",
    "您可以创建一个存储桶来存储中间工件，例如数据集、训练模型等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjNCFxq0JxlA"
   },
   "outputs": [],
   "source": [
    "# The project and bucket are for experiments below.\n",
    "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "! gcloud config set project $PROJECT_ID\n",
    "\n",
    "# The form for BUCKET_URI is gs://<bucket-name>.\n",
    "BUCKET_URI = \"\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
    "\n",
    "import os\n",
    "\n",
    "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temporal\")\n",
    "EXPERIMENT_BUCKET = os.path.join(BUCKET_URI, \"keras\")\n",
    "DATA_BUCKET = os.path.join(EXPERIMENT_BUCKET, \"data\")\n",
    "MODEL_BUCKET = os.path.join(EXPERIMENT_BUCKET, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDjp76aaLZY9"
   },
   "source": [
    "### 初始化 Python 的 Vertex AI SDK\n",
    "\n",
    "为您的项目初始化 Python 的 Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uv7-iDKLbO0"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZFPe_GezXg8"
   },
   "source": [
    "定义常量和常用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcYUGwr-AJGY"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import storage\n",
    "from PIL import Image\n",
    "\n",
    "GCS_URI_PREFIX = \"gs://\"\n",
    "\n",
    "# Training constants.\n",
    "TRAINING_JOB_PREFIX = \"train\"\n",
    "TRAIN_CONTAINER_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/keras-train:latest\"\n",
    ")\n",
    "TRAIN_MACHINE_TYPE = \"a2-highgpu-1g\"\n",
    "TRAIN_ACCELERATOR_TYPE = \"NVIDIA_TESLA_A100\"\n",
    "TRAIN_NUM_GPU = 1\n",
    "RESOLUTION = 512\n",
    "\n",
    "# Prediction constants.\n",
    "PREDICTION_CONTAINER_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/keras-serve:latest\"\n",
    ")\n",
    "PREDICTION_ACCELERATOR_TYPE = \"NVIDIA_TESLA_V100\"\n",
    "PREDICTION_MACHINE_TYPE = \"n1-standard-8\"\n",
    "DEPLOY_JOB_PREFIX = \"deploy\"\n",
    "\n",
    "\n",
    "def get_job_name_with_datetime(prefix: str):\n",
    "    return prefix + datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "def download_data_to_gcs(tar_filepath, gcs_bucket):\n",
    "    filename_with_ext = os.path.basename(tar_filepath)\n",
    "    filename_without_ext = filename_with_ext.replace(\".tar.gz\", \"\")\n",
    "    print(\"Download files from: \", tar_filepath)\n",
    "    ! wget $tar_filepath -O $filename_with_ext\n",
    "    ! mkdir -p $filename_without_ext\n",
    "    ! tar -xvf $filename_with_ext -C .\n",
    "\n",
    "    ! gsutil -m cp -r $filename_without_ext $gcs_bucket/\n",
    "    gcs_path = os.path.join(gcs_bucket, filename_without_ext)\n",
    "    print(\"Upload files to: \", gcs_path)\n",
    "    return gcs_path\n",
    "\n",
    "\n",
    "def download_gcs_file_to_local(gcs_uri: str, local_path: str):\n",
    "    \"\"\"Download a gcs file to a local path.\n",
    "\n",
    "    Args:\n",
    "      gcs_uri: A string of file path on GCS.\n",
    "      local_path: A string of local file path.\n",
    "    \"\"\"\n",
    "    if not gcs_uri.startswith(GCS_URI_PREFIX):\n",
    "        raise ValueError(f\"{gcs_uri} is not a GCS path starting with {GCS_URI_PREFIX}.\")\n",
    "    client = storage.Client()\n",
    "    os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "    with open(local_path, \"wb\") as f:\n",
    "        client.download_blob_to_file(gcs_uri, f)\n",
    "\n",
    "\n",
    "def deploy_model(model_path, service_account):\n",
    "\n",
    "    deploy_model_name = get_job_name_with_datetime(DEPLOY_JOB_PREFIX)\n",
    "    print(\"The deployed job name is: \", deploy_model_name)\n",
    "    serving_env = {\n",
    "        \"MODEL_ID\": \"keras-stable-diffusion-v1-4-001\",\n",
    "        \"MODEL_PATH\": f\"{model_path}\",\n",
    "        \"IMAGE_WIDTH\": f\"{RESOLUTION}\",\n",
    "        \"IMAGE_HEIGHT\": f\"{RESOLUTION}\",\n",
    "        \"DEPLOY_SOURCE\": \"notebook\",\n",
    "    }\n",
    "\n",
    "    endpoint = aiplatform.Endpoint.create(display_name=f\"{deploy_model_name}-endpoint\")\n",
    "\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=deploy_model_name,\n",
    "        serving_container_image_uri=PREDICTION_CONTAINER_URI,\n",
    "        serving_container_ports=[8080],\n",
    "        serving_container_predict_route=\"/predict\",\n",
    "        serving_container_health_route=\"/ping\",\n",
    "        serving_container_environment_variables=serving_env,\n",
    "    )\n",
    "    model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        machine_type=PREDICTION_MACHINE_TYPE,\n",
    "        accelerator_type=PREDICTION_ACCELERATOR_TYPE,\n",
    "        accelerator_count=1,\n",
    "        min_replica_count=1,\n",
    "        max_replica_count=1,\n",
    "        deploy_request_timeout=1800,\n",
    "        service_account=service_account,\n",
    "    )\n",
    "    return model, endpoint\n",
    "\n",
    "\n",
    "def base64_to_image(image_str):\n",
    "    image = Image.open(BytesIO(base64.b64decode(image_str)))\n",
    "    return image\n",
    "\n",
    "\n",
    "def display_image(image):\n",
    "    _ = plt.figure(figsize=(20, 15))\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image)\n",
    "\n",
    "\n",
    "def display_image_grid(imgs, rows=2, cols=2):\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epo-RHXzcBBT"
   },
   "source": [
    "运行推断\n",
    "\n",
    "本节展示了如何使用Keras Stable Diffusion模型进行推断。\n",
    "\n",
    "1. 本地运行推断\n",
    "2. 使用serving dockers运行推断\n",
    "\n",
    "您可以使用Keras团队提供的预训练模型，也可以使用自己微调过的模型进行推断。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zsa9vnBHhvO"
   },
   "outputs": [],
   "source": [
    "# Sets the model_path to empty to load the pre-trained model from Keras team.\n",
    "# Sets the model_path to a gcs uri to load the finetuned models.\n",
    "model_path = \"\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ld39hkcIceE2"
   },
   "source": [
    "### 本地运行推断\n",
    "使用GPU，本地推断可以在几秒钟内完成。\n",
    "\n",
    "首先加载模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1nCKVSac3Y5"
   },
   "outputs": [],
   "source": [
    "from keras_cv.models import StableDiffusion\n",
    "\n",
    "model = StableDiffusion(img_height=RESOLUTION, img_width=RESOLUTION, jit_compile=True)\n",
    "if model_path.startswith(GCS_URI_PREFIX):\n",
    "    local_model_path = \"/tmp/saved_model.h5\"\n",
    "    download_gcs_file_to_local(model_path, local_model_path)\n",
    "    model.diffusion_model.load_weights(local_model_path)\n",
    "elif model_path:\n",
    "    model.diffusion_model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABaCSIWuP-_G"
   },
   "source": [
    "然后进行推理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnyeVsh8RNI5"
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "img = model.text_to_image(\n",
    "    prompt=\"a squirrel in Picasso style\",\n",
    "    batch_size=batch_size,  # How many images to generate at once\n",
    "    num_steps=25,  # Number of iterations (controls image quality)\n",
    "    seed=123,  # A fixed seed guarantees the same prompt always generates the same image\n",
    ")\n",
    "for i in range(batch_size):\n",
    "    display_image(img[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kY87SU9Adq4o"
   },
   "source": [
    "### 使用docker部署模型\n",
    "当使用docker部署模型时，我们将在Google Cloud Vertex AI中部署模型。默认设置将使用1个V100 GPU进行部署。\n",
    "\n",
    "如果您还没有，请为使用docker进行部署创建一个服务帐户。\n",
    "\n",
    "模型部署大约需要~10分钟才能完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yCB9vu7RenY6"
   },
   "outputs": [],
   "source": [
    "# The service account looks like:\n",
    "# '<account_name>@<project>.iam.gserviceaccount.com'\n",
    "# Please go to https://cloud.google.com/iam/docs/service-accounts-create#iam-service-accounts-create-console\n",
    "# and create service account with `Vertex AI User` and `Storage Object Admin` roles.\n",
    "SERVICE_ACCOUNT = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "model, endpoint = deploy_model(\n",
    "    model_path=model_path,\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    ")\n",
    "\n",
    "endpoint_id = endpoint.name\n",
    "print(\"endpoint id is: \", endpoint_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72_BW_BgfvYT"
   },
   "source": [
    "一旦部署完成，您可以发送一批文本提示到端点以生成图片。\n",
    "\n",
    "请注意，在进行新部署的第一个请求的推断过程中，需要更多的时间来处理，大约需要在一个V100 GPU上花费45秒。在一个V100 GPU上，每张图片的后续请求的推断时间大约为12秒。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_jrNcZ5eVbH"
   },
   "outputs": [],
   "source": [
    "# # Loads an existing endpoint as below.\n",
    "# endpoint_id = <An Existing Endpoint ID>\n",
    "# aip_endpoint_name = (\n",
    "#     f\"projects/{PROJECT_ID}/locations/{REGION}/endpoints/{endpoint_id}\"\n",
    "# )\n",
    "# endpoint = aiplatform.Endpoint(aip_endpoint_name)\n",
    "\n",
    "instances = [\n",
    "    {\"prompt\": \"a squirrel in Picasso style\"},\n",
    "    {\"prompt\": \"a dog in Picasso style\"},\n",
    "    {\"prompt\": \"a cat in Picasso style\"},\n",
    "    {\"prompt\": \"a deer in Picasso style\"},\n",
    "]\n",
    "\n",
    "parameters = {\n",
    "    \"batch_size\": 1,  # How many images to generate at once\n",
    "    \"num_steps\": 25,  # Number of iterations (controls image quality)\n",
    "    \"seed\": 123,  # A fixed seed guarantees the same prompt always generates the same image\n",
    "}\n",
    "response = endpoint.predict(instances=instances, parameters=parameters)\n",
    "# prediction['predicted_image'] will contains the prediction images in a batch.\n",
    "# The batch size in this example is 1, and the visualization only parses the\n",
    "# first predicted image.\n",
    "images = [\n",
    "    base64_to_image(prediction[\"predicted_image\"][0])\n",
    "    for prediction in response.predictions\n",
    "]\n",
    "display_image_grid(images, rows=2, cols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiQF7fm6f842"
   },
   "source": [
    "清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqJyypt-f9K6"
   },
   "outputs": [],
   "source": [
    "# Undeploys models and deletes endpoints.\n",
    "endpoint.delete(force=True)\n",
    "# Deletes models.\n",
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RB_xY9ipr7ZU"
   },
   "source": [
    "微调模型\n",
    "本节展示了如何使用训练docker来微调Keras Stable扩散模型。\n",
    "\n",
    "如果您想使用微调后的模型，请转到“运行推理”部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OD3TtaWs5b4v"
   },
   "source": [
    "### 下载数据\n",
    "我们将数据下载到 GCS 存储中，用于训练 docker 实验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2TVB8MU-5i-q"
   },
   "outputs": [],
   "source": [
    "# Skips this step if you have already downloaded the dataset.\n",
    "download_data_to_gcs(\n",
    "    \"https://huggingface.co/datasets/sayakpaul/pokemon-blip-original-version/resolve/main/pokemon_dataset.tar.gz\",\n",
    "    DATA_BUCKET,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee7Hzq8O5jgF"
   },
   "source": [
    "### 开始训练工作\n",
    "我们使用1个A100 GPU在1个时代中对512*512稳定扩散模型进行微调，使用默认设置大约需要15分钟完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riG_qUokg0XZ"
   },
   "outputs": [],
   "source": [
    "data_csv = os.path.join(DATA_BUCKET, \"pokemon_dataset/data.csv\")\n",
    "epochs = 1\n",
    "\n",
    "train_job_name = get_job_name_with_datetime(TRAINING_JOB_PREFIX)\n",
    "model_dir = os.path.join(MODEL_BUCKET, train_job_name)\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": TRAIN_MACHINE_TYPE,\n",
    "            \"accelerator_type\": TRAIN_ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": TRAIN_NUM_GPU,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"disk_spec\": {\n",
    "            \"boot_disk_type\": \"pd-ssd\",\n",
    "            \"boot_disk_size_gb\": 500,\n",
    "        },\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": TRAIN_CONTAINER_URI,\n",
    "            \"command\": [],\n",
    "            \"env\": [\n",
    "                {\n",
    "                    \"name\": \"RESOLUTION\",\n",
    "                    \"value\": f\"{RESOLUTION}\",\n",
    "                },\n",
    "            ],\n",
    "            \"args\": [\n",
    "                f\"--epochs={epochs}\",\n",
    "                f\"--input_csv_path={data_csv}\",\n",
    "                f\"--output_model_dir={model_dir}\",\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "train_job = aiplatform.CustomJob(\n",
    "    display_name=train_job_name,\n",
    "    project=PROJECT_ID,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=STAGING_BUCKET,\n",
    ")\n",
    "\n",
    "train_job.run()\n",
    "\n",
    "model_path = os.path.join(model_dir, \"saved_model.h5\")\n",
    "print(\"The trained model is saved as: \", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBlQ6FQlJhBi"
   },
   "source": [
    "训练结束后，您可以使用 `model_path`，然后转到上面的 `运行推断` 部分来进行预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkH2nrpdp4sp"
   },
   "source": [
    "### 清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ax6vQVZhp9pR"
   },
   "outputs": [],
   "source": [
    "train_job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dijQDiZWegt"
   },
   "source": [
    "## 参考资料\n",
    "\n",
    "- [微调稳定扩散](https://keras.io/examples/generative/finetune_stable_diffusion/)\n",
    "- [StableDiffusion图像生成模型](https://keras.io/api/keras_cv/models/stable_diffusion/)\n",
    "- [在KerasCV中使用稳定扩散进行高性能图像生成](https://keras.io/guides/keras_cv/generate_images_with_stable_diffusion/)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "model_garden_keras_stable_diffusion.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
