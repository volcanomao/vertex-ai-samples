{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-e1HpvsDh34Q"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5o1Ggr5h34U"
   },
   "source": [
    "# Vertex AI Model Garden - ZipNeRF (Pytorch) Notebook\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_zipnerf.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_zipnerf.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      查看 GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_pytorch_zipnerf.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "在 Vertex AI Workbench 中打开\n",
    "    </a>（建议使用 Python-3 CPU 笔记本）\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-SERmqUh34V"
   },
   "source": [
    "注意：此笔记本已在以下环境中测试过：\n",
    "\n",
    "* Python版本= 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6QmW0Doh34W"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本笔记本展示了一种[PyTorch实现](https://github.com/SuLvXiangXin/zipnerf-pytorch)的[Zip-NeRF：抗锯齿网格化神经辐射场](https://jonbarron.info/zipnerf/)，用于更有效地渲染神经辐射场（NeRFs）。它主要旨在解决传统NeRF技术的一些局限，传统NeRF技术虽然能够从2D图像创建详细的3D模型，但计算密集且速度较慢。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkSMThcKh34W"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何：\n",
    "\n",
    "- 使用[COLMAP](https://colmap.github.io/)执行运动结构（SfM）来估计场景的三维结构，从一系列二维图像中。\n",
    "- 使用[Vertex AI custom jobs](https://cloud.google.com/vertex-ai/docs/samples/aiplatform-create-custom-job-sample)来校准、训练和渲染NERF场景。\n",
    "- 使用一系列关键帧照片沿着自定义相机路径渲染视频。\n",
    "\n",
    "本教程使用以下谷歌云ML服务和资源：\n",
    "\n",
    "- Vertex AI 训练\n",
    "- Vertex AI 自定义作业"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myi4N60Xh34W"
   },
   "source": [
    "### 成本\n",
    "\n",
    "本教程使用 Google Cloud 的计费组件:\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解 [Vertex AI 定价](https://cloud.google.com/vertex-ai/pricing) 和 [Cloud Storage 定价](https://cloud.google.com/storage/pricing)，并使用 [定价计算器](https://cloud.google.com/products/calculator/) 根据您的预期使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beDl8cg1RNmb"
   },
   "source": [
    "## 设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0WVDnCSh34W"
   },
   "source": [
    "### 安装\n",
    "\n",
    "安装以下必需的包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SarHdTe6h34X"
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade pip\n",
    "! pip install google-cloud-aiplatform==1.38.1\n",
    "! pip install google-cloud-storage==2.14.0\n",
    "! pip install wget==3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqAlUIpTh34X"
   },
   "source": [
    "### 在开始之前\n",
    "\n",
    "**注意**：Jupyter 运行以 `!` 开头的行作为 shell 命令，并将以 `$` 开头的 Python 变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXesIn5Ph34X"
   },
   "source": [
    "只适用于Colab\n",
    "如果您使用的是Workbench，则请运行以下命令并跳过此部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxEFcySJh34Y"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    ! pip3 install --upgrade google-cloud-aiplatform\n",
    "    from google.colab import auth as google_auth\n",
    "\n",
    "    google_auth.authenticate_user()\n",
    "    # Install gdown for downloading example training images.\n",
    "    ! pip3 install gdown\n",
    "\n",
    "    # Restart the notebook kernel after installs.\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKwm8ghIh34Y"
   },
   "source": [
    "### 设置谷歌云项目\n",
    "\n",
    "1. [选择或创建一个谷歌云项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建一个账户时，您将获得$300的免费信用用于计算和存储成本。\n",
    "\n",
    "2. [确保为您的项目启用了计费功能](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "3. [启用Vertex AI API和Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component)。\n",
    "\n",
    "4. [创建一个云存储存储桶](https://cloud.google.com/storage/docs/creating-buckets) 用于存储实验输出。\n",
    "\n",
    "5. 如果您在本地运行这个笔记本，您需要安装[Cloud SDK](https://cloud.google.com/sdk)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuydf63fh34Z"
   },
   "source": [
    "### 认证您的Google Cloud帐户\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动进行认证。请按以下相关说明操作。\n",
    "\n",
    "**1. Vertex AI Workbench**\n",
    "* 不需要进行操作，因为您已经通过认证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfXC5K20WuSw"
   },
   "source": [
    "本地JupyterLab实例，请取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGAUWRyvWzjP"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2G5q1KaUh34Y"
   },
   "source": [
    "###设置您的项目参数\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下操作：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)\n",
    "\n",
    "您还可以更改由Vertex AI使用的`REGION`变量。了解有关[Vertex AI区域](https://cloud.google.com/vertex-ai/docs/general/locations)的更多信息。\n",
    "\n",
    "创建一个存储桶来存储诸如数据集等中间工件。推荐模式：`gs://cloudnerf-{PROJECT_ID}-unique`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qayv5ifRh34Y"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
    "\n",
    "# Enter the name of the bucket without gs://\n",
    "BUCKET_NAME = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "\n",
    "# Set the project id.\n",
    "! gcloud config set project {PROJECT_ID}\n",
    "\n",
    "# Create the bucket if it doesn't already exist.\n",
    "BUCKET_URI = os.path.join(\"gs://\", BUCKET_NAME)\n",
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSDay9zNh34a"
   },
   "source": [
    "### 初始化 Vertex AI SDK 用于 Python\n",
    "\n",
    "为您的项目初始化 Vertex AI SDK 用于 Python。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZseCTgCBh34a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "staging_bucket = os.path.join(BUCKET_URI, \"zipnerf_staging\")\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=staging_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUVTFBqgh34a"
   },
   "source": [
    "定义常数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOqMkJTeh34a"
   },
   "outputs": [],
   "source": [
    "# The pre-built calibration docker image.\n",
    "CALIBRATION_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-cloudnerf-calibrate:latest\"\n",
    "# The pre-built training docker image.\n",
    "TRAINING_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-cloudnerf-train:latest\"\n",
    "# The pre-built rendering docker image.\n",
    "RENDERING_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-cloudnerf-render:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWs4aw0nh34a"
   },
   "source": [
    "### 定义常见函数\n",
    "\n",
    "本节为以下内容定义函数：\n",
    "\n",
    "- 自定义作业命名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cq9oIwnDh34a"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from datetime import datetime\n",
    "from typing import Any, List\n",
    "\n",
    "IMAGE_EXTENSIONS = (\".png\", \".jpg\", \".jpeg\", \".gif\", \".bmp\")\n",
    "GCS_API_ENDPOINT = \"https://storage.cloud.google.com/\"\n",
    "\n",
    "\n",
    "def get_job_name_with_datetime(prefix: str) -> str:\n",
    "    \"\"\"Gets the job name with date time when triggering training or deployment\n",
    "    jobs in Vertex AI.\n",
    "    \"\"\"\n",
    "    return prefix + datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "def get_mp4_video_link(mp4_rendering_path: str) -> str:\n",
    "    # Define the gsutil command.\n",
    "    command = f\"gsutil ls {mp4_rendering_path}\"\n",
    "\n",
    "    # Run the command and capture the output.\n",
    "    try:\n",
    "        result = subprocess.check_output(command, shell=True, text=True)\n",
    "        # Split the result by newlines to get a list of files.\n",
    "        file_list = result.strip().split(\"\\n\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        file_list = []\n",
    "    mp4_video_link = file_list[0].replace(\"gs://\", GCS_API_ENDPOINT)\n",
    "    return mp4_video_link\n",
    "\n",
    "\n",
    "def write_keyframe_list_to_gcs(\n",
    "    bucket_path: str, output_gcs_file: str, max_files: int = 10\n",
    ") -> List[Any]:\n",
    "    # Get the list of files in the GCS bucket.\n",
    "    cmd = f\"gsutil ls {bucket_path}\"\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(\"Error listing GCS bucket:\", result.stderr)\n",
    "        return []\n",
    "\n",
    "    # Filter for image files and extract file names.\n",
    "    files = result.stdout.splitlines()\n",
    "    image_files = [\n",
    "        os.path.basename(f) for f in files if f.lower().endswith(IMAGE_EXTENSIONS)\n",
    "    ]\n",
    "\n",
    "    output_file = \"out.txt\"\n",
    "    with open(output_file, \"w\") as file:\n",
    "        for name in image_files[:max_files]:\n",
    "            file.write(name + \"\\n\")\n",
    "\n",
    "    cmd = f\"gsutil cp {output_file} {output_gcs_file}\"\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(\"Error listing GCS bucket:\", result.stderr)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Umz2XgIeh34a"
   },
   "source": [
    "## 准备数据集\n",
    "有必要准备数据集并将其存储在云存储中。以下示例说明了[mipnerf360](https://jonbarron.info/mipnerf360/)数据集中自行车场景的过程。为了方便起见，mipnerf360中的每个场景都提供了作为单独数据集的独特下载链接。Mip-NeRF 360数据集包含以下7个场景：\n",
    "\n",
    "- [`自行车`](http://storage.googleapis.com/gresearch/refraw360/bicycle.zip)\n",
    "- [`盆栽`](http://storage.googleapis.com/gresearch/refraw360/bonsai.zip)\n",
    "- [`柜台`](http://storage.googleapis.com/gresearch/refraw360/counter.zip)\n",
    "- [`花园`](http://storage.googleapis.com/gresearch/refraw360/garden.zip)\n",
    "- [`厨房`](http://storage.googleapis.com/gresearch/refraw360/kitchen.zip)\n",
    "- [`房间`](http://storage.googleapis.com/gresearch/refraw360/room.zip)\n",
    "- [`树桩`](http://storage.googleapis.com/gresearch/refraw360/stump.zip)\n",
    "\n",
    "每个场景都经过COLMAP信息预处理，所以下面部分中的校准步骤是可选的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBhvKerXh34a"
   },
   "outputs": [],
   "source": [
    "local_mipnerf_data_directory = \"./mipnerf360_dataset\"  # @param {type:\"string\"}\n",
    "MIPNERF_DATA_GCS_PATH = os.path.join(BUCKET_URI, \"mipnerf360_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThoLj-HDh34a"
   },
   "outputs": [],
   "source": [
    "# Download the bicycle scene data to a local directory.\n",
    "! rm -rf $local_mipnerf_data_directory\n",
    "! mkdir -p $local_mipnerf_data_directory\n",
    "! wget -P $local_mipnerf_data_directory http://storage.googleapis.com/gresearch/refraw360/bicycle.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hP8IsiqCh34a"
   },
   "outputs": [],
   "source": [
    "# Unzip the mipnerf360 dataset.\n",
    "! unzip $local_mipnerf_data_directory/bicycle.zip -d $local_mipnerf_data_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZ4C5kuyh34a"
   },
   "outputs": [],
   "source": [
    "# Move mipnerf360 data from local directory to Cloud Storage.\n",
    "# This step takes a few minutes to finish.\n",
    "! gsutil -m cp -R $local_mipnerf_data_directory/* $MIPNERF_DATA_GCS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdWHe-RmSEn6"
   },
   "source": [
    "NERF 管线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtcVGao6h34f"
   },
   "source": [
    "### 相机姿态估计\n",
    "如上所述，Mip-NeRF 360数据集中的所有场景都已经使用colmap信息进行了预处理。然而，为了展示如何在你自己的数据上完整运行管道，我们将使用`bicycle`场景来估计相机姿态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFkzzGq0h34f"
   },
   "outputs": [],
   "source": [
    "# Folder containing all the images of the bicycle scene.\n",
    "INPUT_IMAGES_FOLDER = f\"{MIPNERF_DATA_GCS_PATH}/bicycle/images\"  # @param {type:\"string\"}\n",
    "\n",
    "# Folder for storing experiment outputs for calibration, training and rendering.\n",
    "OUTPUT_FOLDER = f\"{MIPNERF_DATA_GCS_PATH}/exp/bicycle\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-rEdcdah34f"
   },
   "source": [
    "一旦数据和实验路径已配置好，运行以下自定义作业。\n",
    "\n",
    "需要以下参数：\n",
    "\n",
    "* `use_gpu`：是否使用GPU。\n",
    "* `gcs_dataset_path`：GCS数据集中图像文件夹的路径。\n",
    "* `gcs_experiment_path`：存储实验输出的GCS路径。\n",
    "* `camera`：使用的摄像头类型。透视是 `OPENCV`，鱼眼是 `OPENCV_FISHEYE`。\n",
    "\n",
    "自定义作业将在`gcs_dataset_path`文件夹中的图像上运行，并将colmap输出存储在`gcs_experiment_path/data`文件夹中。\n",
    "\n",
    "对于当前数据集中的场景，这一步大约需要30分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1evctm2h34g"
   },
   "outputs": [],
   "source": [
    "# This job will run colmap camera pose estimation.\n",
    "data_calibration_job_name = get_job_name_with_datetime(\"colmap\")\n",
    "\n",
    "# Worker pool spec.\n",
    "machine_type = \"n1-highmem-64\"\n",
    "num_nodes = 1\n",
    "gpu_type = \"NVIDIA_TESLA_V100\"\n",
    "num_gpus = 8\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": machine_type,\n",
    "            \"accelerator_type\": gpu_type,\n",
    "            \"accelerator_count\": num_gpus,\n",
    "        },\n",
    "        \"replica_count\": num_nodes,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": CALIBRATION_DOCKER_URI,\n",
    "            \"args\": [\n",
    "                \"-use_gpu\",\n",
    "                \"1\",\n",
    "                \"-gcs_dataset_path\",\n",
    "                INPUT_IMAGES_FOLDER,\n",
    "                \"-gcs_experiment_path\",\n",
    "                OUTPUT_FOLDER,\n",
    "                \"-camera\",\n",
    "                \"OPENCV\",\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "data_calibration_custom_job = aiplatform.CustomJob(\n",
    "    display_name=data_calibration_job_name,\n",
    "    project=PROJECT_ID,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=staging_bucket,\n",
    ")\n",
    "\n",
    "data_calibration_custom_job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3v-y3Sjh34g"
   },
   "source": [
    "### 训练ZipNeRF模型\n",
    "一旦Colmap姿态校准完成，我们就可以开始训练。\n",
    "\n",
    "需要以下参数：\n",
    "\n",
    "* `gcs_experiment_path`：用于加载处理过的数据集和存储实验结果的GCS路径。\n",
    "* `gin_config_file`：ZipNeRF网络的配置文件。当前选项包括：\n",
    "  * configs/360.gin：用于360重建的配置。\n",
    "  * configs/360_glo.gin：用于带[生成潜在优化]的360重建的配置。\n",
    "* `factor`：在预处理步骤中对图像进行下采样的因子，影响训练像素地面真实图像和渲染图像的分辨率或细节级别。室内场景建议使用2倍因子，室外场景建议使用4倍因子。**训练中使用的因子必须与渲染中使用的相同。**\n",
    "\n",
    "自定义作业将在`gcs_experiment_path/data` Colmap数据集中的图像上运行，并将结果输出到`gcs_experiment_path/checkpoints`文件夹中的检查点中。\n",
    "\n",
    "根据配置不同，此步骤可能需要多达3小时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7ZWhSpjh34g"
   },
   "outputs": [],
   "source": [
    "# This job will run zipnerf training.\n",
    "\n",
    "# This is the nerf training job name. You will use it to load the checkpoints\n",
    "# in the rendering job for the current run.\n",
    "nerf_training_job_name = get_job_name_with_datetime(\"nerf_training\")\n",
    "\n",
    "GIN_CONFIG_FILE = \"configs/360.gin\"  # @param {type:\"string\"}\n",
    "FACTOR = \"4\"  # @param {type:\"string\"}\n",
    "\n",
    "# Worker pool spec.\n",
    "machine_type = \"n1-highmem-64\"\n",
    "num_nodes = 1\n",
    "gpu_type = \"NVIDIA_TESLA_V100\"\n",
    "num_gpus = 8\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": machine_type,\n",
    "            \"accelerator_type\": gpu_type,\n",
    "            \"accelerator_count\": num_gpus,\n",
    "        },\n",
    "        \"replica_count\": num_nodes,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": TRAINING_DOCKER_URI,\n",
    "            \"args\": [\n",
    "                \"-training_job_name\",\n",
    "                nerf_training_job_name,\n",
    "                \"-gcs_experiment_path\",\n",
    "                OUTPUT_FOLDER,\n",
    "                \"-gin_config_file\",\n",
    "                GIN_CONFIG_FILE,\n",
    "                \"-factor\",\n",
    "                FACTOR,\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "nerf_training_custom_job = aiplatform.CustomJob(\n",
    "    display_name=nerf_training_job_name,\n",
    "    project=PROJECT_ID,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=staging_bucket,\n",
    ")\n",
    "\n",
    "nerf_training_custom_job.run(enable_web_access=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdw6bih8h34g"
   },
   "source": [
    "渲染ZipNeRF模型（360）\n",
    "完成Colmap姿态校准后，我们可以开始训练。\n",
    "\n",
    "需要以下参数：\n",
    "\n",
    "* `gcs_experiment_path`：用于加载处理后数据集和存储实验输出的GCS路径。\n",
    "* `gin_config_file`：ZipNeRF网络的配置文件。当前选项包括：\n",
    "  * configs/360.gin：用于360重建的配置。\n",
    "  * configs/360_glo.gin：用于带有[生成潜在优化](https://www.researchgate.net/publication/318527851_Optimizing_the_Latent_Space_of_Generative_Networks)的360重建的配置。\n",
    "* `render_video_fps`：渲染视频的帧率。\n",
    "* `render_path_frames`：需要渲染的路径帧数。\n",
    "* `factor`：在预处理阶段对降采样图像的影响分辨率或详细级别的因子，影响训练像素地面真值和渲染图像的分辨率。室内场景建议使用2倍因子，室外场景建议使用4倍因子。**训练中使用的因子必须与渲染中使用的相同。**\n",
    "\n",
    "定制作业将运行在`gcs_experiment_path/data` Colmap数据集中的图像上，并在`gcs_experiment_path/checkpoints`文件夹中输出检查点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7lufsDWzh34g"
   },
   "outputs": [],
   "source": [
    "# This job will run zipnerf rendering.\n",
    "nerf_rendering_job_name = get_job_name_with_datetime(\"nerf_rendering\")\n",
    "\n",
    "RENDER_PATH_FRAMES = \"120\"  # @param {type:\"string\"}\n",
    "RENDER_VIDEO_FPS = \"30\"  # @param {type:\"string\"}\n",
    "\n",
    "# Worker pool spec.\n",
    "machine_type = \"n1-highmem-64\"\n",
    "num_nodes = 1\n",
    "gpu_type = \"NVIDIA_TESLA_V100\"\n",
    "num_gpus = 8\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": machine_type,\n",
    "            \"accelerator_type\": gpu_type,\n",
    "            \"accelerator_count\": num_gpus,\n",
    "        },\n",
    "        \"replica_count\": num_nodes,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": RENDERING_DOCKER_URI,\n",
    "            \"args\": [\n",
    "                \"-rendering_job_name\",\n",
    "                nerf_rendering_job_name,\n",
    "                \"-training_job_name\",\n",
    "                nerf_training_job_name,\n",
    "                \"-gcs_experiment_path\",\n",
    "                OUTPUT_FOLDER,\n",
    "                \"-gin_config_file\",\n",
    "                GIN_CONFIG_FILE,\n",
    "                \"-render_video_fps\",\n",
    "                RENDER_VIDEO_FPS,\n",
    "                \"-render_path_frames\",\n",
    "                RENDER_PATH_FRAMES,\n",
    "                \"-factor\",\n",
    "                FACTOR,\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "nerf_rendering_custom_job = aiplatform.CustomJob(\n",
    "    display_name=nerf_rendering_job_name,\n",
    "    project=PROJECT_ID,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=staging_bucket,\n",
    ")\n",
    "\n",
    "nerf_rendering_custom_job.run(enable_web_access=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88Zv38QBh34g"
   },
   "source": [
    "显示来自GCS的渲染视频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifhDb9xeh34g"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "MP4_RENDERING_PATH = f\"{OUTPUT_FOLDER}/render/{nerf_rendering_job_name}/*color.mp4\"\n",
    "mp4_video_link = get_mp4_video_link(MP4_RENDERING_PATH)\n",
    "Video(mp4_video_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyWwIU9JbS7x"
   },
   "source": [
    "渲染ZipNeRF模型（自定义摄像机轨迹）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DY5YPVqDh34g"
   },
   "source": [
    "#### 为渲染自定义相机轨迹创建关键帧文件列表。\n",
    "\n",
    "要在神经辐射场（NeRF）模型中使用与训练时相同数据集的图片来创建自定义相机轨迹，您可以生成一个关键帧文件列表，其中每个关键帧对应于存储在谷歌云存储（GCS）存储桶中的图像文件的名称。本节将指导您创建此关键帧文件列表。\n",
    "\n",
    "#### 步骤1：识别关键帧图像\n",
    "首先，识别您数据集中想要用作关键帧的图像。这些图像应该理想地代表您希望相机轨迹包含的重要视图或角度。\n",
    "\n",
    "#### 步骤2：创建图像文件名称列表\n",
    "访问您的GCS存储桶：导航到存储数据集的GCS存储桶。\n",
    "\n",
    "选择图像文件：选择您希望用作关键帧的特定图像文件。请记住，这些文件应该是用于训练NeRF模型的文件，因为它们已经定义了相应的相机参数。\n",
    "\n",
    "编译文件名：创建这些选定图像的文件名列表（而不是路径）。确保每个文件名单独在一行上。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3uAT-uQ3h34g"
   },
   "outputs": [],
   "source": [
    "# This job will run zipnerf rendering.\n",
    "nerf_custom_rendering_job_name = get_job_name_with_datetime(\"nerf_custom_rendering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gai5cc-bh34g"
   },
   "outputs": [],
   "source": [
    "# Example usage.\n",
    "KEYFRAME_IMAGE_FILELIST = (\n",
    "    f\"{OUTPUT_FOLDER}/keyframe_list_{nerf_custom_rendering_job_name}.txt\"\n",
    ")\n",
    "max_files = 30  # Set this to the number of files you want\n",
    "write_keyframe_list_to_gcs(\n",
    "    INPUT_IMAGES_FOLDER, KEYFRAME_IMAGE_FILELIST, max_files=max_files\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQ6k_LdKh34h"
   },
   "source": [
    "#### 运行渲染\n",
    "\n",
    "一旦训练完成，我们可以进行渲染。\n",
    "\n",
    "需要以下参数：\n",
    "\n",
    "* `gcs_experiment_path`：用于加载处理过的数据集和存储实验输出的GCS路径。\n",
    "* `gin_config_file`：ZipNeRF网络的配置文件。目前的选项有：\n",
    "  * configs/360.gin：用于360重建的配置。\n",
    "  * configs/360_glo.gin：使用[生成潜在优化](https://www.researchgate.net/publication/318527851_Optimizing_the_Latent_Space_of_Generative_Networks)的360重建配置。\n",
    "* `render_video_fps`：渲染视频的帧率。\n",
    "* `factor`：在预处理步骤中影响训练像素地面真实度和渲染图像分辨率或细节级别的下采样图像的因子。室内场景建议使用2倍因子，室外场景建议使用4倍因子。**训练中使用的因子必须与渲染一致。**\n",
    "* `keyframe_image_list`：用于渲染自定义相机路径的每行一个图像文件名的列表。\n",
    "\n",
    "使用关键帧，生成插值路径。该路径代表连接指定关键帧相机姿势的平滑轮廓样条。该过程利用一个预设为默认值30的配置变量`render_spline_n_interp`。因此，最终的插值路径包括`render_spline_n_interp` * (n - 1)个姿势。在讨论的具体场景中，config.render_spline_n_interp配置为30。**如果输入30个关键帧，计算结果为30 * 29，总计870个姿势**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hi0oIbyZh34h"
   },
   "outputs": [],
   "source": [
    "# This job will run zipnerf rendering.\n",
    "# Worker pool spec.\n",
    "machine_type = \"n1-highmem-64\"\n",
    "num_nodes = 1\n",
    "gpu_type = \"NVIDIA_TESLA_V100\"\n",
    "num_gpus = 8\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": machine_type,\n",
    "            \"accelerator_type\": gpu_type,\n",
    "            \"accelerator_count\": num_gpus,\n",
    "        },\n",
    "        \"replica_count\": num_nodes,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": RENDERING_DOCKER_URI,\n",
    "            \"args\": [\n",
    "                \"-rendering_job_name\",\n",
    "                nerf_custom_rendering_job_name,\n",
    "                \"-training_job_name\",\n",
    "                nerf_training_job_name,\n",
    "                \"-gcs_experiment_path\",\n",
    "                OUTPUT_FOLDER,\n",
    "                \"-gin_config_file\",\n",
    "                GIN_CONFIG_FILE,\n",
    "                \"-render_video_fps\",\n",
    "                RENDER_VIDEO_FPS,\n",
    "                \"-factor\",\n",
    "                FACTOR,\n",
    "                \"-gcs_keyframes_file\",\n",
    "                KEYFRAME_IMAGE_FILELIST,\n",
    "                \"-render_path_frames\",\n",
    "                RENDER_PATH_FRAMES,\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "nerf_custom_rendering_custom_job = aiplatform.CustomJob(\n",
    "    display_name=nerf_custom_rendering_job_name,\n",
    "    project=PROJECT_ID,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=staging_bucket,\n",
    ")\n",
    "\n",
    "nerf_custom_rendering_custom_job.run(enable_web_access=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQHDoqn1h34h"
   },
   "source": [
    "#### 从GCS显示渲染视频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xeup-oLAh34h"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "MP4_RENDERING_PATH = (\n",
    "    f\"{OUTPUT_FOLDER}/render/{nerf_custom_rendering_job_name}/*color.mp4\"\n",
    ")\n",
    "mp4_video_link = get_mp4_video_link(MP4_RENDERING_PATH)\n",
    "Video(mp4_video_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsUREZ6jNmDP"
   },
   "source": [
    "## 清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9K-sK6INmDP"
   },
   "outputs": [],
   "source": [
    "# Delete pose estimation, training and rendering custom jobs.\n",
    "if data_calibration_custom_job.list(\n",
    "    filter=f'display_name=\"{data_calibration_job_name}\"'\n",
    "):\n",
    "    data_calibration_custom_job.delete()\n",
    "if nerf_training_custom_job.list(filter=f'display_name=\"{nerf_training_job_name}\"'):\n",
    "    nerf_training_custom_job.delete()\n",
    "if nerf_rendering_custom_job.list(filter=f'display_name=\"{nerf_rendering_job_name}\"'):\n",
    "    nerf_rendering_custom_job.delete()\n",
    "if nerf_custom_rendering_custom_job.list(\n",
    "    filter=f'display_name=\"{nerf_custom_rendering_job_name}\"'\n",
    "):\n",
    "    nerf_custom_rendering_custom_job.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "model_garden_pytorch_zipnerf.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
