{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TirJ-SGQseby"
   },
   "source": [
    "# 使用图像分类的 Vertex AI 模型花园 MediaPipe\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_mediapipe_image_classification.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "    </a>\n",
    "  </td>\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_mediapipe_image_classification.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_mediapipe_image_classification.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"> 在 Vertex AI Workbench 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwGLvtIeECLK"
   },
   "source": [
    "**注意**: 这个笔记本已在以下环境中进行了测试：\n",
    "\n",
    "* Python版本 = 3.9\n",
    "\n",
    "**注意**: 在此Colab中链接的检查点和数据集不是由谷歌拥有或分发的，而是由第三方提供。在使用检查点和数据之前，请先查阅第三方提供的条款和条件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本笔记本演示了如何使用[MediaPipe Model Maker](https://developers.google.com/mediapipe/solutions/model_maker)在Vertex AI模型花园中训练一个设备上的图像分类模型。\n",
    "\n",
    "### 目标\n",
    "\n",
    "* 训练新模型\n",
    "  * 将输入数据转换为训练格式\n",
    "  * 创建[自定义作业](https://cloud.google.com/vertex-ai/docs/training/create-custom-job)来训练新模型\n",
    "  * 导出模型\n",
    "\n",
    "* 清理资源\n",
    "\n",
    "### 成本\n",
    "\n",
    "本教程使用Google Cloud的收费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI价格](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage价格](https://cloud.google.com/storage/pricing)，并使用[Pricing Calculator](https://cloud.google.com/products/calculator/)根据您的预期使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEukV6uRk_S3"
   },
   "source": [
    "## 在开始之前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z__i0w0lCAsW"
   },
   "source": [
    "只有在Colab上运行时才能运行以下命令以安装依赖项并与Google Cloud进行身份验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jvqs-ehKlaYh"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade pip\n",
    "\n",
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    ! pip3 install --upgrade google-cloud-aiplatform\n",
    "\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "\n",
    "    from google.colab import auth as google_auth\n",
    "\n",
    "    google_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "将您的项目ID设置为####\n",
    "\n",
    "**如果您不知道您的项目ID**，请查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 区域\n",
    "\n",
    "您还可以更改 Vertex AI 使用的 `REGION` 变量。了解有关 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations) 的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTy1gX11kCJY"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
    "REGION_PREFIX = REGION.split(\"-\")[0]\n",
    "assert REGION_PREFIX in (\n",
    "    \"us\",\n",
    "    \"europe\",\n",
    "    \"asia\",\n",
    "), f'{REGION} is not supported. It must be prefixed by \"us\", \"asia\", or \"europe\".'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产物，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "只有在您的存储桶不存在时才能运行以下单元格来创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk,all"
   },
   "source": [
    "### 初始化顶点 AI SDK 用于 Python\n",
    "\n",
    "为您的项目初始化顶点 AI SDK 用于 Python。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wExiMUxFk91"
   },
   "outputs": [],
   "source": [
    "now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temp/%s\" % now)\n",
    "\n",
    "EVALUATION_RESULT_OUTPUT_DIRECTORY = os.path.join(STAGING_BUCKET, \"evaluation\")\n",
    "EVALUATION_RESULT_OUTPUT_FILE = os.path.join(\n",
    "    EVALUATION_RESULT_OUTPUT_DIRECTORY, \"evaluation.json\"\n",
    ")\n",
    "\n",
    "EXPORTED_MODEL_OUTPUT_DIRECTORY = os.path.join(STAGING_BUCKET, \"model\")\n",
    "EXPORTED_MODEL_OUTPUT_FILE = os.path.join(\n",
    "    EXPORTED_MODEL_OUTPUT_DIRECTORY, \"model.tflite\"\n",
    ")\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6IFz75WGCam"
   },
   "source": [
    "定义训练设备规格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riG_qUokg0XZ"
   },
   "outputs": [],
   "source": [
    "TRAINING_JOB_DISPLAY_NAME = \"mediapipe_image_classifier_%s\" % now\n",
    "TRAINING_CONTAINER = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/mediapipe-train\"\n",
    "TRAINING_MACHINE_TYPE = \"n1-highmem-16\"\n",
    "TRAINING_ACCELERATOR_TYPE = \"NVIDIA_TESLA_V100\"\n",
    "TRAINING_ACCELERATOR_COUNT = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rsdAcBV-vlf"
   },
   "source": [
    "训练您定制的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### 为训练准备输入数据\n",
    "\n",
    "对图像分类模型进行微调需要一个包含您希望完成模型能够识别的所有类别的数据集。您可以通过从公共数据集中仅保留与您的用例相关的类别、编制您自己的数据集，或两者结合的方式来实现这一点。数据集可以比从头开始训练新模型所需的数据集要小得多。例如，用于训练许多参考模型的 ImageNet 数据集包含数百万张图像，具有数千个类别。使用 Model Maker 进行迁移学习可以通过较小的数据集微调现有模型，并根据您的推断准确性目标表现良好。\n",
    "\n",
    "您可以重新使用现有数据集，例如 `gs://cloud-samples-data-us-central1/vision/automl_classification/flowers` 来微调模型，或者将您自己的数据集上传到 GCS。如果您使用自己的数据集，请确保您的图像目录包含多个子目录，每个子目录对应特定的类别标签。您的训练数据也应遵循这种模式：<image_path>/<label_name>/<image_names>。*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IndQ_m6ddUEM"
   },
   "outputs": [],
   "source": [
    "training_data_path = \"gs://cloud-samples-data-us-central1/vision/automl_classification/flowers\"  # @param {type:\"string\"}\n",
    "split_ratio = \"0.8,0.1,0.1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaff6f5be7f6"
   },
   "source": [
    "### 设置微调选项\n",
    "\n",
    "您可以在不同的模型架构之间进行选择，以进一步定制您的训练：\n",
    "\n",
    "* MobileNet-V2\n",
    "* EfficientNet-Lite0\n",
    "* EfficientNet-Lite2\n",
    "* EfficientNet-Lite4\n",
    "\n",
    "要设置模型架构和其他训练参数，请调整以下数值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "um_XKbmpTaHx"
   },
   "outputs": [],
   "source": [
    "model_architecture = \"mobilenet_v2\"  # @param [\"mobilenet_v2\", \"efficientnet_lite0\", \"efficientnet_lite2\", \"efficientnet_lite4\"]\n",
    "\n",
    "# The learning rate to use for gradient descent training.\n",
    "learning_rate: float = 0.01  # @param {type:\"number\"}\n",
    "# Batch size for training.\n",
    "batch_size: int = 2  # @param {type:\"number\"}\n",
    "# Number of training iterations over the dataset.\n",
    "epochs: int = 10  # @param {type:\"slider\", min:0, max:100, step:1}\n",
    "# If true, the base module is trained together with the classification layer on\n",
    "# top.\n",
    "do_fine_tuning: bool = False  # @param {type:\"boolean\"}\n",
    "# A regularizer that applies a L1 regularization penalty.\n",
    "l1_regularizer: float = 0.0  # @param {type:\"number\"}\n",
    "# A regularizer that applies a L2 regularization penalty.\n",
    "l2_regularizer: float = 0.0001  # @param {type:\"number\"}\n",
    "# Amount of label smoothing to apply. See tf.keras.losses for more details.\n",
    "label_smoothing: float = 0.1  # @param {type:\"number\"}\n",
    "# A boolean controlling whether the training dataset is augmented by randomly\n",
    "# distorting input images, including random cropping, flipping, etc. See\n",
    "# utils.image_preprocessing documentation for details.\n",
    "do_data_augmentation: bool = True  # @param {type:\"boolean\"}\n",
    "# Number of training samples used to calculate the decay steps\n",
    "# and create the training optimizer.\n",
    "decay_samples: int = 2560000  # @param {type:\"number\"}\n",
    "# Number of warmup steps for a linear increasing warmup schedule on learning\n",
    "# rate. Used to set up warmup schedule by model_util.WarmUp.\n",
    "warmup_epochs: int = 2  # @param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwcCjwlBTQIz"
   },
   "source": [
    "### 运行微调\n",
    "\n",
    "准备好您的训练数据集和微调选项后，您就可以开始微调过程了。这个过程需要大量资源，根据您可用的计算资源，可能需要几分钟到几个小时的时间。在使用GPU处理的Vertex AI上，下面的示例微调大约需要4-6分钟来训练约3700张图像。\n",
    "\n",
    "要开始微调过程，请使用以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aec22792ee84"
   },
   "outputs": [],
   "source": [
    "model_export_path = EXPORTED_MODEL_OUTPUT_DIRECTORY\n",
    "evaluation_result_path = EVALUATION_RESULT_OUTPUT_DIRECTORY\n",
    "\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": TRAINING_MACHINE_TYPE,\n",
    "            \"accelerator_type\": TRAINING_ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": TRAINING_ACCELERATOR_COUNT,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": TRAINING_CONTAINER,\n",
    "            \"command\": [],\n",
    "            \"args\": [\n",
    "                \"--task_name=image_classifier\",\n",
    "                \"--training_data_path=%s\" % training_data_path,\n",
    "                \"--model_export_path=%s\" % model_export_path,\n",
    "                \"--evaluation_result_path=%s\" % evaluation_result_path,\n",
    "                \"--split_ratio=%s\" % split_ratio,\n",
    "                \"--model_architecture=%s\" % model_architecture,\n",
    "                \"--hparams=%s\"\n",
    "                % json.dumps(\n",
    "                    {\n",
    "                        \"learning_rate\": learning_rate,\n",
    "                        \"batch_size\": batch_size,\n",
    "                        \"epochs\": epochs,\n",
    "                        \"do_fine_tuning\": do_fine_tuning,\n",
    "                        \"l1_regularizer\": l1_regularizer,\n",
    "                        \"l2_regularizer\": l2_regularizer,\n",
    "                        \"label_smoothing\": label_smoothing,\n",
    "                        \"do_data_augmentation\": do_data_augmentation,\n",
    "                        \"decay_samples\": decay_samples,\n",
    "                        \"warmup_epochs\": warmup_epochs,\n",
    "                    }\n",
    "                ),\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "training_job = aiplatform.CustomJob(\n",
    "    display_name=TRAINING_JOB_DISPLAY_NAME,\n",
    "    project=PROJECT_ID,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=STAGING_BUCKET,\n",
    ")\n",
    "\n",
    "training_job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXMF2tnV_WS0"
   },
   "source": [
    "## 评估并导出模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mV-Djz-frBni"
   },
   "source": [
    "### 评估性能\n",
    "\n",
    "在对模型进行微调后，我们将在测试数据集上评估训练结果，这通常是原始数据集中未在训练过程中使用的一部分。一般认为，准确度在0.8和0.9之间是非常好的，但您的使用情况要求可能有所不同。您还应考虑模型产生推断的速度。更高的准确度通常会以较长的推断时间为代价。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09Rz1AYspK19"
   },
   "outputs": [],
   "source": [
    "def get_evaluation_result(evaluation_result_path):\n",
    "    try:\n",
    "        with tensorflow.io.gfile.GFile(evaluation_result_path, \"r\") as input_file:\n",
    "            evalutation_result = json.loads(input_file.read())\n",
    "        return evalutation_result[\"accuracy\"], evalutation_result[\"loss\"]\n",
    "    except:\n",
    "        print(\n",
    "            \"Evaluation result not found. Your test dataset is likely \"\n",
    "            + \"empty. You can adjust the size of your test dataset or adjust \"\n",
    "            + \"how you split your dataset.\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "evaluation_result = get_evaluation_result(EVALUATION_RESULT_OUTPUT_FILE)\n",
    "\n",
    "if evaluation_result is not None:\n",
    "    print(\"Accuracy:\", evaluation_result[0])\n",
    "    print(\"Loss:\", evaluation_result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0BGaofgsMsy"
   },
   "source": [
    "### 导出模型\n",
    "在微调和评估模型后，您可以保存Tensorflow Lite模型，通过在MediaPipe Studio的[图像分类](https://mediapipe-studio.webapps.google.com/demo/image_classifier)演示中尝试它，或者通过按照[图像分类任务指南](https://developers.google.com/mediapipe/solutions/vision/image_classifier)将其集成到您的设备上的应用程序中。导出的模型包含所需的模型元数据生成，以及一个分类标签文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYuQowyZEtxK"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def copy_model(model_source, model_dest):\n",
    "    ! gsutil cp {model_source} {model_dest}\n",
    "\n",
    "copy_model(EXPORTED_MODEL_OUTPUT_FILE, \"image_classification_model.tflite\")\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import files\n",
    "\n",
    "    files.download(\"image_classification_model.tflite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkH2nrpdp4sp"
   },
   "source": [
    "清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ax6vQVZhp9pR"
   },
   "outputs": [],
   "source": [
    "# Delete training data and jobs.\n",
    "if training_job.list(filter=f'display_name=\"{TRAINING_JOB_DISPLAY_NAME}\"'):\n",
    "    training_job.delete()\n",
    "\n",
    "!gsutil rm -r {STAGING_BUCKET}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "model_garden_mediapipe_image_classification.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
