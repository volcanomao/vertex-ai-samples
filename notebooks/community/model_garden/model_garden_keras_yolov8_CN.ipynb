{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TirJ-SGQseby"
   },
   "source": [
    "# Vertex AI 模型花园 Keras YOLOv8\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_keras_yolov8.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "    </a>\n",
    "  </td>\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_keras_yolov8.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_keras_yolov8.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "在 Vertex AI Workbench 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwGLvtIeECLK"
   },
   "source": [
    "注意：此笔记本已在以下环境中测试过：\n",
    "\n",
    "* Python 版本 = 3.9\n",
    "\n",
    "您可以直接在 Colab 中打开此笔记本，或创建[谷歌托管](https://cloud.google.com/vertex-ai/docs/workbench/managed/create-instance)或[用户托管](https://cloud.google.com/vertex-ai/docs/workbench/user-managed/create-new)的 Workbench 实例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "这篇笔记展示了如何在Vertex AI Model Garden中使用[Keras YOLOv8](https://keras.io/api/keras_cv/models/tasks/yolo_v8_detector/)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0z9r_mBmDeYh"
   },
   "source": [
    "### 目标\n",
    "\n",
    "* 对预训练或定制模型进行本地推理\n",
    "\n",
    "* 在Google Cloud Vertex AI中部署预训练或定制模型\n",
    "\n",
    "* 在Google Cloud Vertex AI中微调模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEnkHABrDijz"
   },
   "source": [
    "### 成本\n",
    "\n",
    "本教程使用谷歌云的收费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* 云存储\n",
    "\n",
    "了解[Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing)和[云存储\n",
    "价格](https://cloud.google.com/storage/pricing)，并使用[Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)根据您的预期使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af989c0e437d"
   },
   "source": [
    "资料集\n",
    "\n",
    "本教程使用的数据集是[TensorFlow数据集](https://www.tensorflow.org/datasets/catalog/open_images_v4)中的沙拉类别 -Salads category-。此数据集不需要任何特征工程。在本教程中使用的数据集版本存储在一个公共云存储桶中。经过训练的模型可以预测图像中五种物品类别 -沙拉、海鲜、番茄、烘焙品或奶酪- 的边界框位置和相应类型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z__i0w0lCAsW"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装以下所需的包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jvqs-ehKlaYh"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Configs for Colab notebooks.\n",
    "    ! pip3 install --upgrade --quiet google-cloud-aiplatform\n",
    "\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "\n",
    "    from google.colab import auth as google_auth\n",
    "\n",
    "    google_auth.authenticate_user()\n",
    "\n",
    "# Configs for all notebooks.\n",
    "! pip3 install --quiet keras-cv==0.6.1\n",
    "! pip3 install --quiet keras-core==0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEukV6uRk_S3"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### 设置您的谷歌云项目\n",
    "\n",
    "**无论您使用的是哪种笔记本环境，都需要按照以下步骤操作。**\n",
    "\n",
    "1. [选择或创建谷歌云项目](https://console.cloud.google.com/cloud-resource-manager)。当您第一次创建账户时，您将获得300美元的免费信用额用于计算/存储成本。\n",
    "\n",
    "1. [确保为您的项目启用了计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "1. [启用 Vertex AI API 和 Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component)。\n",
    "\n",
    "1. 如果您在本地运行此笔记本，您需要安装 [Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "1. 在下面的单元格中输入您的项目 ID。然后运行该单元格，以确保\n",
    "Cloud SDK 在此笔记本中的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**: Jupyter 运行带有 `!` 前缀的行作为shell命令，并会将以 `$` 前缀的Python变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "### 设置您的项目、区域和存储桶\n",
    "\n",
    "**如果您不知道您的项目 ID**，请尝试以下操作：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 参考支持页面：[查找项目 ID](https://support.google.com/googleapi/answer/7014113)\n",
    "\n",
    "您可以更改Vertex AI使用的 `REGION` 变量。了解更多关于 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations) 的信息。\n",
    "\n",
    "您可以创建一个存储桶来存储中间产物，如数据集、训练模型等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjNCFxq0JxlA"
   },
   "outputs": [],
   "source": [
    "# The project and bucket are for experiments below.\n",
    "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "! gcloud config set project $PROJECT_ID\n",
    "\n",
    "# The form for BUCKET_URI is gs://<bucket-name>.\n",
    "BUCKET_URI = \"\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
    "\n",
    "import os\n",
    "\n",
    "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temporal\")\n",
    "MODEL_BUCKET = os.path.join(STAGING_BUCKET, \"keras_yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDjp76aaLZY9"
   },
   "source": [
    "### 初始化Python的Vertex AI SDK\n",
    "\n",
    "为您的项目初始化Python的Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uv7-iDKLbO0"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZFPe_GezXg8"
   },
   "source": [
    "### 定义常量和常见函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcYUGwr-AJGY"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import keras_cv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "from keras_cv import visualization\n",
    "from PIL import Image\n",
    "\n",
    "TRAIN_MACHINE_TYPE = \"n1-highmem-16\"\n",
    "TRAIN_ACCELERATOR_TYPE = \"NVIDIA_TESLA_V100\"\n",
    "TRAIN_NUM_GPU = 2\n",
    "TRAIN_CONTAINER_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/keras-yolov8-train\"\n",
    ")\n",
    "TRAINING_JOB_PREFIX = \"train_yolov8\"\n",
    "\n",
    "UPLOAD_JOB_PREFIX = \"upload_yolov8\"\n",
    "DEPLOY_JOB_PREFIX = \"deploy_yolov8\"\n",
    "SERVING_CONTAINER_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai-restricted/prediction/tf_opt-gpu.2-12:latest\"\n",
    ")\n",
    "SERVING_ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
    "SERVING_MACHINE_TYPE = \"n1-standard-4\"\n",
    "SERVING_CONTAINER_ARGS = [\"--allow_precompilation\", \"--allow_compression\"]\n",
    "\n",
    "RESOLUTION = 512\n",
    "\n",
    "\n",
    "def get_job_name_with_datetime(prefix: str):\n",
    "    \"\"\"Generates a job name with date time when triggering training or deployment\n",
    "    jobs in Vertex AI.\n",
    "    \"\"\"\n",
    "    return prefix + datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "def load_img(path):\n",
    "    \"\"\"Reads image from path and return PIL.Image instance.\"\"\"\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return Image.fromarray(np.uint8(img)).convert(\"RGB\")\n",
    "\n",
    "\n",
    "def decode_image(image_str_tensor: tf.string) -> tf.float32:\n",
    "    \"\"\"Converts and resizes image bytes to image tensor.\"\"\"\n",
    "    image = tf.io.decode_image(image_str_tensor, 3, expand_animations=False)\n",
    "    image = tf.image.resize(image, (RESOLUTION, RESOLUTION))\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_label_map(label_map_yaml_filepath):\n",
    "    \"\"\"Returns class id to label mapping given a filepath to the label map.\"\"\"\n",
    "    with tf.io.gfile.GFile(label_map_yaml_filepath, \"rb\") as input_file:\n",
    "        label_map = yaml.safe_load(input_file.read())[\"label_map\"]\n",
    "    return label_map\n",
    "\n",
    "\n",
    "def get_prediction_instances(test_filepath, new_width=-1):\n",
    "    \"\"\"Generate instance from image path to pass to Vertex AI Endpoint for prediction.\"\"\"\n",
    "    if new_width <= 0:\n",
    "        with tf.io.gfile.GFile(test_filepath, \"rb\") as input_file:\n",
    "            encoded_string = base64.b64encode(input_file.read()).decode(\"utf-8\")\n",
    "    else:\n",
    "        img = load_img(test_filepath)\n",
    "        width, height = img.size\n",
    "        print(\"original input image size: \", width, \" , \", height)\n",
    "        new_height = int(height * new_width / width)\n",
    "        new_img = img.resize((new_width, new_height))\n",
    "        print(\"resized input image size: \", new_width, \" , \", new_height)\n",
    "        buffered = io.BytesIO()\n",
    "        new_img.save(buffered, format=\"JPEG\")\n",
    "        encoded_string = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    instances = [\n",
    "        {\n",
    "            \"encoded_image\": {\"b64\": encoded_string},\n",
    "        }\n",
    "    ]\n",
    "    return instances\n",
    "\n",
    "\n",
    "def predict_custom_trained_model(\n",
    "    project: str,\n",
    "    endpoint_id: str,\n",
    "    instances: Union[Dict, List[Dict]],\n",
    "    location: str = \"us-central1\",\n",
    "):\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": f\"{location}-aiplatform.googleapis.com\"}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "    parameters_dict = {}\n",
    "    parameters = json_format.ParseDict(parameters_dict, Value())\n",
    "    endpoint = client.endpoint_path(\n",
    "        project=project, location=location, endpoint=endpoint_id\n",
    "    )\n",
    "    response = client.predict(\n",
    "        endpoint=endpoint, instances=instances, parameters=parameters\n",
    "    )\n",
    "    return response.predictions, response.deployed_model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epo-RHXzcBBT"
   },
   "source": [
    "## 使用预训练模型在本地进行推理\n",
    "\n",
    "本部分介绍如何使用在PascalVOC 2012目标检测任务上预训练的YOLOv8-M模型在本地运行推理，该任务包括20个类别。\n",
    "\n",
    "从云存储加载图像并解码为张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zsa9vnBHhvO"
   },
   "outputs": [],
   "source": [
    "test_filepath = \"\"  # @param {type:\"string\"}\n",
    "img_bytes = tf.io.read_file(test_filepath)\n",
    "image = tf.expand_dims(decode_image(img_bytes), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wC-pSYR0jjU"
   },
   "source": [
    "加载在PascalVOC 2012上预训练的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nvPEly_4Vm6"
   },
   "outputs": [],
   "source": [
    "model = keras_cv.models.YOLOV8Detector.from_preset(\n",
    "    \"yolo_v8_m_pascalvoc\",\n",
    "    bounding_box_format=\"xywh\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrijGrxT0lvC"
   },
   "source": [
    "然後進行推論並視覺化結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65yEa4N0xcTS"
   },
   "outputs": [],
   "source": [
    "decoded = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8-X3gA5xV_l"
   },
   "outputs": [],
   "source": [
    "# Classes in PascalVOC 2012 dataset.\n",
    "class_ids = [\n",
    "    \"Aeroplane\",\n",
    "    \"Bicycle\",\n",
    "    \"Bird\",\n",
    "    \"Boat\",\n",
    "    \"Bottle\",\n",
    "    \"Bus\",\n",
    "    \"Car\",\n",
    "    \"Cat\",\n",
    "    \"Chair\",\n",
    "    \"Cow\",\n",
    "    \"Dining Table\",\n",
    "    \"Dog\",\n",
    "    \"Horse\",\n",
    "    \"Motorbike\",\n",
    "    \"Person\",\n",
    "    \"Potted Plant\",\n",
    "    \"Sheep\",\n",
    "    \"Sofa\",\n",
    "    \"Train\",\n",
    "    \"Tvmonitor\",\n",
    "    \"Total\",\n",
    "]\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "\n",
    "visualization.plot_bounding_box_gallery(\n",
    "    image,\n",
    "    value_range=(0, 255),\n",
    "    rows=1,\n",
    "    cols=1,\n",
    "    y_pred=decoded,\n",
    "    scale=5,\n",
    "    font_scale=0.7,\n",
    "    bounding_box_format=\"xywh\",\n",
    "    class_mapping=class_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RB_xY9ipr7ZU"
   },
   "source": [
    "## 微调模型\n",
    "本部分展示了如何使用训练docker微调Keras YOLOv8模型，然后部署到Vertex AI端点资源。接受的数据集格式是CSV格式的，就像[AutoML图像目标检测](https://cloud.google.com/vertex-ai/docs/image-data/object-detection/prepare-data#input-files)的格式一样，不包含`ML_USE`列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkNc7jyq1js1"
   },
   "outputs": [],
   "source": [
    "input_csv_path = \"gs://cloud-samples-data/vision/salads.csv\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee7Hzq8O5jgF"
   },
   "source": [
    "###开始训练工作\n",
    "以下代码块显示了一些可能设置的超参数。这些设置仅供演示目的。在使用时，`batch_size`、`learning_rate`和`epochs`等参数可能被覆盖。`backbone`必须是以下之一：\n",
    "* `yolo_v8_xs_backbone`\n",
    "* `yolo_v8_s_backbone`\n",
    "* `yolo_v8_m_backbone`\n",
    "* `yolo_v8_l_backbone`\n",
    "* `yolo_v8_xl_backbone`\n",
    "* `yolo_v8_xs_backbone_coco`\n",
    "* `yolo_v8_s_backbone_coco`\n",
    "* `yolo_v8_m_backbone_coco`\n",
    "* `yolo_v8_l_backbone_coco`\n",
    "* `yolo_v8_xl_backbone_coco`\n",
    "\n",
    "如果要使用预训练权重的预设模型，请选择`yolo_v8_xs_backbone_coco`、`yolo_v8_s_backbone_coco`、`yolo_v8_m_backbone_coco`、`yolo_v8_l_backbone_coco`、`yolo_v8_xl_backbone_coco`中的一个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riG_qUokg0XZ"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 10\n",
    "learning_rate = 0.0005\n",
    "fpn_depth = 3\n",
    "confidence_threshold = 0.02\n",
    "iou_threshold = 0.3\n",
    "backbone = \"yolo_v8_xl_backbone_coco\"\n",
    "\n",
    "train_job_name = get_job_name_with_datetime(TRAINING_JOB_PREFIX)\n",
    "model_dir = os.path.join(MODEL_BUCKET, train_job_name)\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": TRAIN_MACHINE_TYPE,\n",
    "            \"accelerator_type\": TRAIN_ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": TRAIN_NUM_GPU,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"disk_spec\": {\n",
    "            \"boot_disk_type\": \"pd-ssd\",\n",
    "            \"boot_disk_size_gb\": 500,\n",
    "        },\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": TRAIN_CONTAINER_URI,\n",
    "            \"command\": [],\n",
    "            \"env\": [\n",
    "                {\n",
    "                    \"name\": \"RESOLUTION\",\n",
    "                    \"value\": f\"{RESOLUTION}\",\n",
    "                },\n",
    "            ],\n",
    "            \"args\": [\n",
    "                f\"--input_csv_path={input_csv_path}\",\n",
    "                f\"--output_model_dir={model_dir}\",\n",
    "                f\"--epochs={epochs}\",\n",
    "                f\"--pretrained_backbone={backbone}\",\n",
    "                f\"--fpn_depth={fpn_depth}\",\n",
    "                f\"--learning_rate={learning_rate}\",\n",
    "                f\"--confidence_threshold={confidence_threshold}\",\n",
    "                f\"--iou_threshold={iou_threshold}\",\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "train_job = aiplatform.CustomJob(\n",
    "    display_name=train_job_name,\n",
    "    project=PROJECT_ID,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=STAGING_BUCKET,\n",
    ")\n",
    "\n",
    "train_job.run()\n",
    "\n",
    "print(\"The trained model is saved in: \", model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KBJ0ySVYX47"
   },
   "source": [
    "### 预测\n",
    "本节展示如何部署模型并进行在线预测。\n",
    "\n",
    "1. 上传并部署模型\n",
    "2. 运行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6rUSSKmYZJ6"
   },
   "outputs": [],
   "source": [
    "upload_job_name = get_job_name_with_datetime(UPLOAD_JOB_PREFIX)\n",
    "\n",
    "serving_env = {\n",
    "    \"MODEL_ID\": \"keras-yolov8\",\n",
    "    \"DEPLOY_SOURCE\": \"notebook\",\n",
    "}\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=upload_job_name,\n",
    "    artifact_uri=model_dir,\n",
    "    serving_container_image_uri=SERVING_CONTAINER_URI,\n",
    "    serving_container_args=SERVING_CONTAINER_ARGS,\n",
    "    serving_container_environment_variables=serving_env,\n",
    ")\n",
    "\n",
    "print(\"The uploaded model name is: \", upload_job_name)\n",
    "\n",
    "deploy_model_name = get_job_name_with_datetime(DEPLOY_JOB_PREFIX)\n",
    "\n",
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name=deploy_model_name,\n",
    "    machine_type=SERVING_MACHINE_TYPE,\n",
    "    traffic_split={\"0\": 100},\n",
    "    accelerator_type=SERVING_ACCELERATOR_TYPE,\n",
    "    accelerator_count=1,\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=1,\n",
    ")\n",
    "print(\"The deployed job name is: \", deploy_model_name)\n",
    "\n",
    "endpoint_id = endpoint.name\n",
    "print(\"endpoint id is: \", endpoint_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a879effaf402"
   },
   "source": [
    "从云存储加载图像，调整大小并编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDznWEMmbwj4"
   },
   "outputs": [],
   "source": [
    "test_filepath = \"gs://cloud-ml-data/img/openimage/1302/4677521502_6f2767039c_o.jpg\"  # @param {type:\"string\"}\n",
    "image_bytes = tf.io.read_file(test_filepath)\n",
    "image_resized = tf.expand_dims(decode_image(image_bytes), axis=0)\n",
    "\n",
    "instances = get_prediction_instances(test_filepath, new_width=640)\n",
    "\n",
    "predictions, _ = predict_custom_trained_model(\n",
    "    project=PROJECT_ID, location=REGION, endpoint_id=endpoint_id, instances=instances\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14e889492871"
   },
   "source": [
    "使用端点运行在线预测并可视化结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bx1cW0IdXqp"
   },
   "outputs": [],
   "source": [
    "predictions_dict = {\n",
    "    \"boxes\": tf.expand_dims(predictions[0][\"boxes\"], axis=0),\n",
    "    \"classes\": tf.expand_dims(predictions[0][\"classes\"], axis=0),\n",
    "    \"confidence\": tf.expand_dims(predictions[0][\"confidence\"], axis=0),\n",
    "    \"num_detections\": predictions[0][\"num_detections\"],\n",
    "}\n",
    "\n",
    "label_map = get_label_map(os.path.join(model_dir, \"label_map.yaml\"))\n",
    "\n",
    "visualization.plot_bounding_box_gallery(\n",
    "    image_resized,\n",
    "    value_range=(0, 255),\n",
    "    rows=1,\n",
    "    cols=1,\n",
    "    y_pred=predictions_dict,\n",
    "    scale=5,\n",
    "    font_scale=0.7,\n",
    "    bounding_box_format=\"xywh\",\n",
    "    class_mapping=label_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkH2nrpdp4sp"
   },
   "source": [
    "### 清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ax6vQVZhp9pR"
   },
   "outputs": [],
   "source": [
    "# Deletes custom train jobs.\n",
    "train_job.delete()\n",
    "# Undeploys models and deletes endpoints.\n",
    "endpoint.delete(force=True)\n",
    "# Deletes models.\n",
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dijQDiZWegt"
   },
   "source": [
    "参考资料\n",
    "\n",
    "- [使用YOLOV8和KerasCV实现高效目标检测](https://keras.io/examples/vision/yolov8/)\n",
    "- [Keras YOLOv8 API文档](https://keras.io/api/keras_cv/models/tasks/yolo_v8_detector/)\n",
    "- [Keras YOLOv8主干网络](https://keras.io/api/keras_cv/models/backbones/yolo_v8/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "model_garden_keras_yolov8.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
