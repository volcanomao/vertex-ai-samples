{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ApNHZJmT2AMH"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfxrFG052AMI"
   },
   "source": [
    "# Vertex AI模型花园 - TIMM\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_timm.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_timm.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_pytorch_timm.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "在Vertex AI工作台中打开\n",
    "    </a>\n",
    "    (建议使用Python-3 CPU笔记本)\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76BCoQcm2AMJ"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本笔记本演示了使用[timm](https://github.com/rwightman/pytorch-image-models)库在本地运行推理，微调PyTorch [timm模型](https://github.com/huggingface/pytorch-image-models#models)，并在[Vertex AI](https://cloud.google.com/vertex-ai)上部署模型。\n",
    "\n",
    "### 目标\n",
    "\n",
    "- 设置环境。\n",
    "- 使用timm库在本地运行推理。\n",
    "- 在Vertex AI上创建一个自定义训练作业来训练或微调模型。\n",
    "- 在Vertex AI上部署模型进行在线预测。\n",
    "\n",
    "### 成本\n",
    "\n",
    "本教程使用Google Cloud的收费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* 云存储\n",
    "\n",
    "了解[Vertex AI定价](https://cloud.google.com/vertex-ai/pricing)和[云存储定价](https://cloud.google.com/storage/pricing)，并使用[Pricing Calculator](https://cloud.google.com/products/calculator/)根据您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iU1NKfh2AMJ"
   },
   "source": [
    "## 设置环境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7l3GN-QL2AMJ"
   },
   "source": [
    "### 设置云项目\n",
    "\n",
    "1. [选择或创建一个谷歌云项目](https://console.cloud.google.com/cloud-resource-manager)。当您第一次创建帐户时，您将获得300美元的免费信用额用于计算/存储成本。\n",
    "\n",
    "2. [确保您的项目已启用计费](https://cloud.google.com/billing/docs/how-to/modify-project)。了解[Vertex AI定价](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage定价](https://cloud.google.com/storage/pricing)，并使用[定价计算器](https://cloud.google.com/products/calculator/)基于您的预期使用量生成成本估算。\n",
    "\n",
    "3. [启用Artifact Registry](https://cloud.google.com/artifact-registry/docs/enable-service)并[创建存储Docker镜像的存储库](https://cloud.google.com/artifact-registry/docs/repositories/create-repos)。\n",
    "\n",
    "4. [创建一个用于存储实验输出的云存储桶](https://cloud.google.com/storage/docs/creating-buckets)。\n",
    "\n",
    "5. [启用Vertex AI API和Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component)。\n",
    "\n",
    "6. [创建一个服务账号](https://cloud.google.com/iam/docs/service-accounts-create#iam-service-accounts-create-console)，并分配`Vertex AI用户`和`存储对象管理员`角色，用于将优化模型部署到Vertex AI端点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyAQXmgf2AMK"
   },
   "source": [
    "### 配置所需库\n",
    "\n",
    "强烈建议在 [Vertex AI 工作台](https://cloud.google.com/vertex-ai-workbench) 上运行此笔记本，无需手动安装任何额外的库。\n",
    "\n",
    "如果您在本地运行此笔记本，您需要安装 [Cloud SDK](https://cloud.google.com/sdk) 和 [gsutil](https://cloud.google.com/storage/docs/gsutil_install)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ad1f36f4b5c3"
   },
   "source": [
    "### 安装库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb041d87f50a"
   },
   "outputs": [],
   "source": [
    "! pip3 install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uF7Kb112AMK"
   },
   "source": [
    "只在Colab上运行以下命令，如果你使用Workbench，请跳过这一部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2lP6dnfy2AMK"
   },
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    ! pip3 install --upgrade google-cloud-aiplatform\n",
    "\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "\n",
    "    from google.colab import auth as google_auth\n",
    "\n",
    "    google_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fo65Wg9Y2AMK"
   },
   "source": [
    "### 设置环境变量\n",
    "\n",
    "此笔记本支持位于 https://huggingface.co/docs/timm/models 中的模型。\n",
    "\n",
    "您还可以在本地运行\n",
    "`python -c \"from timm import list_models; print(list_models(pretrained=True))\"`\n",
    "以查看所有预训练模型。\n",
    "\n",
    "以下模型已手动验证可与此笔记本一起使用：\n",
    "\n",
    "* vit_tiny_patch16_224\n",
    "* beit_base_patch16_224\n",
    "* deit3_small_patch16_224\n",
    "* efficientnet_b2\n",
    "* mobilenetv2_100\n",
    "* resnet50\n",
    "* resnest50d\n",
    "* convnext_base\n",
    "* cspdarknet53\n",
    "* inception_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3msH2i5V2AMK"
   },
   "outputs": [],
   "source": [
    "# The cloud project id.\n",
    "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
    "# The region for running jobs.\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "# The model you want to train and serve. Please select a model from the verified model list above.\n",
    "# We use a ViT model as the example.\n",
    "MODEL_NAME = \"vit_tiny_patch16_224\"  # @param {type:\"string\"}\n",
    "\n",
    "# The Cloud Storage bucket name without gs:// prefix for training outputs.\n",
    "# For example: test_bucket\n",
    "GCS_BUCKET = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# The service account for deploying fine tuned model. It looks like:\n",
    "# '<account_name>@<project>.iam.gserviceaccount.com'\n",
    "# Follow step 6 above to create this account.\n",
    "SERVICE_ACCOUNT = \"\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14a500024b7b"
   },
   "source": [
    "## 运行本地推理\n",
    "\n",
    "本部分使用上面选择的模型在图像上运行本地推理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54859170c1ad"
   },
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7505a2bf3897"
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from PIL import Image\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17e6d8a0dac3"
   },
   "source": [
    "加载一个预先训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8b6bbe928998"
   },
   "outputs": [],
   "source": [
    "model = timm.create_model(MODEL_NAME, pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f2ce8fa5439"
   },
   "source": [
    "### 载入并预处理图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6390302c9761"
   },
   "outputs": [],
   "source": [
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "\n",
    "# The example downloads a test image. You can upload and use your own images\n",
    "# by changing IMAGE_FILENAME.\n",
    "! wget https://github.com/pytorch/hub/raw/master/images/dog.jpg -O test.jpg\n",
    "IMAGE_FILENAME = \"test.jpg\"  # @param {type:\"string\"}\n",
    "\n",
    "# You can also copy over images stored in a GCS bucket with the line below.\n",
    "# ! gsutil cp \"gs://path/to/image\" \"test.jpg\"\n",
    "\n",
    "img = Image.open(IMAGE_FILENAME).convert(\"RGB\")\n",
    "tensor = transform(img).unsqueeze(0)  # transform and add batch dimension\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8a6e2ea460ad"
   },
   "source": [
    "获取模型预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0a7a666a0aef"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(tensor)\n",
    "probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
    "print(probabilities.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "691139fc5789"
   },
   "source": [
    "获取前5个预测类别的名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "147249af5dec"
   },
   "outputs": [],
   "source": [
    "# Get imagenet class mappings\n",
    "url, filename = (\n",
    "    \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\",\n",
    "    \"imagenet_classes.txt\",\n",
    ")\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "with open(\"imagenet_classes.txt\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8740b668da6"
   },
   "source": [
    "### 每个图像打印出顶级类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f18bcd806f2"
   },
   "outputs": [],
   "source": [
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())\n",
    "# prints class names and probabilities like:\n",
    "# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4120d1585355"
   },
   "source": [
    "## 运行训练作业\n",
    "\n",
    "本部分在Vertex AI上运行常规的训练作业或超参数调整作业。\n",
    "\n",
    "在创建训练作业之前，您需要准备用于训练和评估的数据集。\n",
    "\n",
    "例如，您可以使用存储在云存储桶上的[ImageNet-1K](https://huggingface.co/datasets/imagenet-1k)作为输入数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qy4gKksX2AMK"
   },
   "outputs": [],
   "source": [
    "# The prebuilt training docker uri.\n",
    "TRAIN_DOCKER_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-timm-train\"\n",
    ")\n",
    "\n",
    "# The path to data directory on Cloud Storage without gs:// prefix.\n",
    "# In the form of: <bucket-name>/path-to-data\n",
    "GCS_DATA_DIR = \"\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DnlJhO72AMK"
   },
   "source": [
    "在 Vertex AI 上创建一个训练作业。如果您想创建一个超参数调整作业，可以跳过到下一节。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1R5JWJGS2AML"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "# Init common setup.\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)\n",
    "\n",
    "# Input and output path.\n",
    "data_dir = f\"/gcs/{GCS_DATA_DIR}\"\n",
    "output_dir = f\"/gcs/{GCS_BUCKET}/timm\"\n",
    "\n",
    "# Worker pool spec.\n",
    "# Single node with multiple GPUs.\n",
    "machine_type = \"n1-highmem-32\"\n",
    "num_nodes = 1\n",
    "gpu_type = \"NVIDIA_TESLA_P100\"  # @param {type:\"string\"}\n",
    "num_gpus = 4  # @param {type:\"integer\"}\n",
    "\n",
    "# Model specific config.\n",
    "job_name = f\"pytorch-{MODEL_NAME}\"\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=job_name,\n",
    "    container_uri=TRAIN_DOCKER_URI,\n",
    ")\n",
    "model = job.run(\n",
    "    args=[\n",
    "        \"--standalone\",\n",
    "        f\"--nnodes={num_nodes}\",\n",
    "        f\"--nproc_per_node={num_gpus}\",\n",
    "        \"train.py\",\n",
    "        data_dir,\n",
    "        f\"--model={MODEL_NAME}\",\n",
    "        \"--pretrained\",\n",
    "        f\"--output={output_dir}\",\n",
    "        f\"--batch-size={batch_size}\",\n",
    "        f\"--epochs={epochs}\",\n",
    "    ],\n",
    "    replica_count=num_nodes,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_type=gpu_type,\n",
    "    accelerator_count=num_gpus,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tf6P7ZI82AML"
   },
   "source": [
    "在Vertex AI上创建一个超参数调整作业\n",
    "\n",
    "您可以使用[超参数调整](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview)作业来找到您的超参数的最佳配置。\n",
    "\n",
    "如果您已在上一节训练了一个模型并且不想调整超参数，可以跳过此部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hy_aCff_2AML"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "\n",
    "# Init common setup.\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)\n",
    "\n",
    "# Input and output path.\n",
    "data_dir = f\"/gcs/{GCS_DATA_DIR}\"\n",
    "output_dir = f\"/gcs/{GCS_BUCKET}/timm\"\n",
    "\n",
    "# Model specific config.\n",
    "job_name = f\"pytorch-hp-{MODEL_NAME}\"\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "# Worker pool spec.\n",
    "machine_type = \"n1-highmem-16\"\n",
    "num_nodes = 1\n",
    "gpu_type = \"NVIDIA_TESLA_V100\"  # @param {type:\"string\"}\n",
    "num_gpus = 2  # @param {type:\"integer\"}\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": machine_type,\n",
    "            \"accelerator_type\": gpu_type,\n",
    "            \"accelerator_count\": num_gpus,\n",
    "        },\n",
    "        \"replica_count\": num_nodes,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": TRAIN_DOCKER_URI,\n",
    "            \"args\": [\n",
    "                \"--standalone\",\n",
    "                f\"--nnodes={num_nodes}\",\n",
    "                f\"--nproc_per_node={num_gpus}\",\n",
    "                \"train.py\",\n",
    "                data_dir,\n",
    "                f\"--model={MODEL_NAME}\",\n",
    "                \"--pretrained\",\n",
    "                f\"--output={output_dir}\",\n",
    "                f\"--batch-size={batch_size}\",\n",
    "                f\"--epochs={epochs}\",\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "# Hyperparameter job specs.\n",
    "metric_spec = {\"top1_accuracy\": \"maximize\"}\n",
    "parameter_spec = {\n",
    "    \"lr\": hpt.DoubleParameterSpec(min=0.001, max=0.05, scale=\"log\"),\n",
    "}\n",
    "max_trial_count = 2\n",
    "parallel_trial_count = 2\n",
    "\n",
    "# Launch jobs.\n",
    "training_job = aiplatform.CustomJob(\n",
    "    display_name=job_name, worker_pool_specs=worker_pool_specs\n",
    ")\n",
    "hp_job = aiplatform.HyperparameterTuningJob(\n",
    "    display_name=job_name,\n",
    "    custom_job=training_job,\n",
    "    metric_spec=metric_spec,\n",
    "    parameter_spec=parameter_spec,\n",
    "    max_trial_count=max_trial_count,\n",
    "    parallel_trial_count=parallel_trial_count,\n",
    ")\n",
    "hp_job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAyRWwqW2AML"
   },
   "source": [
    "## 为在线预测部署模型\n",
    "\n",
    "该部分将模型上传到 Model Registry 并部署到 Endpoint 资源上。\n",
    "\n",
    "模型部署步骤将需要大约 15 分钟才能完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbNbg0yR2AML"
   },
   "outputs": [],
   "source": [
    "# The prebuilt serving docker uri.\n",
    "SERVE_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/pytorch-timm-serve\"\n",
    "# The port number used by torchserve traffic.\n",
    "SERVE_PORT = 7080\n",
    "# The path to model checkpoint file, including gs:// prefix.\n",
    "MODEL_PT_PATH = \"gs://path_to_model_best.pth.tar\"  # @param {type:\"string\"}\n",
    "# [Optional] the path to index_to_name.json, including gs:// prefix.\n",
    "INDEX_TO_NAME_FILE = \"gs://path_to_index_to_name.json\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INPri3HQ2AML"
   },
   "source": [
    "### 在 Vertex AI 上上传和部署模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOvqoAaN2AML"
   },
   "outputs": [],
   "source": [
    "# Upload model.\n",
    "serving_env = {\n",
    "    \"MODEL_ID\": \"timm-mobilenetv2-100\",\n",
    "    \"MODEL_NAME\": MODEL_NAME,\n",
    "    \"MODEL_PT_PATH\": MODEL_PT_PATH,\n",
    "    \"INDEX_TO_NAME_FILE\": INDEX_TO_NAME_FILE,\n",
    "    \"DEPLOY_SOURCE\": \"notebook\",\n",
    "}\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_NAME,\n",
    "    serving_container_image_uri=SERVE_DOCKER_URI,\n",
    "    serving_container_ports=[SERVE_PORT],\n",
    "    serving_container_predict_route=\"/predictions/timm_serving\",\n",
    "    serving_container_health_route=\"/ping\",\n",
    "    serving_container_environment_variables=serving_env,\n",
    ")\n",
    "# Or reuse a pre-uploaded model.\n",
    "# model = aiplatform.Model('projects/123456789/locations/us-central1/models/123456789@1')\n",
    "\n",
    "# Create an endpoint.\n",
    "endpoint = aiplatform.Endpoint.create(display_name=\"pytorch-timm-endpoint\")\n",
    "# Or reuse a pre-created endpoint.\n",
    "# endpoint = aiplatform.Endpoint('projects/123456789/locations/us-central1/endpoints/123456789')\n",
    "\n",
    "# Deploy model to endpoint.\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    machine_type=\"n1-standard-8\",\n",
    "    accelerator_type=\"NVIDIA_TESLA_T4\",\n",
    "    accelerator_count=1,\n",
    "    traffic_percentage=100,\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2gnYFEJ2AML"
   },
   "source": [
    "您可以在[模型注册表](https://console.cloud.google.com/vertex-ai/models)中管理您上传的模型，并在[端点](https://console.cloud.google.com/vertex-ai/endpoints)中管理您的端点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UP84Q5R2AMM"
   },
   "source": [
    "### 在线预测测试\n",
    "\n",
    "您现在将测试部署的端点。请准备一张要预测的图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zL2Qbm2x2AMM"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# You can get the deployed endpoint object by its resource name returned by Endpoint.create(). For example:\n",
    "# endpoint = aiplatform.Endpoint('projects/816369962409/locations/us-central1/endpoints/8809168414485512192')\n",
    "\n",
    "# Please upload an image and enter its filename below.\n",
    "IMAGE_FILENAME = \"test.jpg\"  # @param {type:\"string\"}\n",
    "\n",
    "# Alternatively, uncomment the following line to download a cat image for demonstration.\n",
    "# ! wget http://images.cocodataset.org/val2017/000000039769.jpg -O test.jpg\n",
    "\n",
    "with open(IMAGE_FILENAME, \"rb\") as f:\n",
    "    image_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "instances = [{\"data\": {\"b64\": image_b64}}]\n",
    "\n",
    "prediction = endpoint.predict(instances=instances)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqSxSyT42AMM"
   },
   "source": [
    "清理资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMwdxiH-2AMM"
   },
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()\n",
    "model.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "model_garden_pytorch_timm.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
