{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TirJ-SGQseby"
   },
   "source": [
    "# Vertex AI 模型花园 TFVision 与图像分割\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_segmentation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "    </a>\n",
    "  </td>\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_segmentation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_tfvision_image_segmentation.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "在 Vertex AI Workbench 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwGLvtIeECLK"
   },
   "source": [
    "注意：此笔记本已在以下环境中进行测试：\n",
    "\n",
    "* Python版本 = 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "这本笔记本演示了如何在Vertex AI模型花园中使用[TFVision](https://github.com/tensorflow/models/blob/master/official/vision/MODEL_GARDEN.md)。\n",
    "\n",
    "### 目标\n",
    "\n",
    "* 训练新模型\n",
    "  * 将输入数据转换为训练格式\n",
    "  * 创建[超参数调整作业](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview)来训练新模型\n",
    "  * 查找并导出最佳模型\n",
    "\n",
    "* 测试训练好的模型\n",
    "  * 上传模型到模型注册表\n",
    "  * 部署已上传的模型\n",
    "  * 运行预测\n",
    "\n",
    "* 清理资源\n",
    "\n",
    "### 成本\n",
    "\n",
    "本教程使用谷歌云的收费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* 云存储\n",
    "\n",
    "了解[Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing)和[云存储 价格](https://cloud.google.com/storage/pricing)，并使用[价格计算器](https://cloud.google.com/products/calculator/)根据您的预期使用量生成费用估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEukV6uRk_S3"
   },
   "source": [
    "在你开始之前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z__i0w0lCAsW"
   },
   "source": [
    "只限Colab\n",
    "\n",
    "如果你使用工作台，请跳过本节并运行以下命令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jvqs-ehKlaYh"
   },
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    ! pip3 install --upgrade google-cloud-aiplatform\n",
    "\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "\n",
    "    from google.colab import auth as google_auth\n",
    "\n",
    "    google_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "### 设置您的谷歌云项目\n",
    "\n",
    "**无论您使用哪种笔记本环境，都需要按照以下步骤进行。**\n",
    "\n",
    "1. [选择或创建一个谷歌云项目](https://console.cloud.google.com/cloud-resource-manager)。当您第一次创建帐户时，您将获得$300的免费信用以抵消计算/存储成本。\n",
    "\n",
    "1. [确保为您的项目启用计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "1. [启用Vertex AI API和Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component)。\n",
    "\n",
    "1. 如果您在本地运行此笔记本，您将需要安装[Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "1. 在下面的单元格中输入您的项目ID。然后运行单元格，以确保Cloud SDK在此笔记本中的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter将以`!`为前缀的行视为shell命令，并将以`$`为前缀的Python变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wExiMUxFk91"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# The project and bucket are for experiments below.\n",
    "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# You can choose a region from https://cloud.google.com/about/locations.\n",
    "# Only regions prefixed by \"us\", \"asia\", or \"europe\" are supported.\n",
    "REGION = \"europe-west4\"  # @param {type:\"string\"}\n",
    "REGION_PREFIX = REGION.split(\"-\")[0]\n",
    "assert REGION_PREFIX in (\n",
    "    \"us\",\n",
    "    \"europe\",\n",
    "    \"asia\",\n",
    "), f'{REGION} is not supported. It must be prefixed by \"us\", \"asia\", or \"europe\".'\n",
    "\n",
    "! gcloud config set project $PROJECT_ID\n",
    "\n",
    "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temporal\")\n",
    "CHECKPOINT_BUCKET = os.path.join(BUCKET_URI, \"ckpt\")\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)\n",
    "\n",
    "# Download config files.\n",
    "CONFIG_DIR = os.path.join(BUCKET_URI, \"config\")\n",
    "! wget https://raw.githubusercontent.com/tensorflow/models/master/official/vision/configs/experiments/semantic_segmentation/deeplabv3plus_resnet101_cityscapes_gpu_multiworker_mirrored.yaml\n",
    "! gsutil cp deeplabv3plus_resnet101_cityscapes_gpu_multiworker_mirrored.yaml $CONFIG_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6IFz75WGCam"
   },
   "source": [
    "###定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riG_qUokg0XZ"
   },
   "outputs": [],
   "source": [
    "OBJECTIVE = \"isg\"\n",
    "\n",
    "# Data converter constants.\n",
    "DATA_CONVERTER_JOB_PREFIX = \"data_converter\"\n",
    "DATA_CONVERTER_CONTAINER = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/data-converter\"\n",
    "DATA_CONVERTER_MACHINE_TYPE = \"n1-highmem-8\"\n",
    "\n",
    "\n",
    "# Training constants.\n",
    "TRAINING_JOB_PREFIX = \"train\"\n",
    "TRAIN_CONTAINER_URI = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/tfvision-oss\"\n",
    "TRAIN_MACHINE_TYPE = \"n1-highmem-16\"\n",
    "TRAIN_ACCELERATOR_TYPE = \"NVIDIA_TESLA_V100\"\n",
    "TRAIN_NUM_GPU = 2\n",
    "TRAIN_DEEPLABV3PLUS_CONFIG = os.path.join(\n",
    "    CONFIG_DIR, \"deeplabv3plus_resnet101_cityscapes_gpu_multiworker_mirrored.yaml\"\n",
    ")\n",
    "\n",
    "# Evaluation constants.\n",
    "EVALUATION_METRIC = \"mean_iou\"\n",
    "\n",
    "# Export constants.\n",
    "EXPORT_JOB_PREFIX = \"export\"\n",
    "EXPORT_CONTAINER_URI = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/tfvision-model-export\"\n",
    "EXPORT_MACHINE_TYPE = \"n1-highmem-8\"\n",
    "\n",
    "# Prediction constants.\n",
    "# You can deploy models with\n",
    "#   pre-build-dockers: https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers.\n",
    "#   and optimized tensorflow runtime dockers: https://cloud.google.com/vertex-ai/docs/predictions/optimized-tensorflow-runtime.\n",
    "# The example in this notebook uses optimized tensorflow runtime dockers.\n",
    "# You can adjust accelerator types and machine types to get faster predictions.\n",
    "PREDICTION_CONTAINER_URI = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai-restricted/prediction/tf_opt-gpu.2-11:latest\"\n",
    "SERVING_CONTAINER_ARGS = [\"--allow_precompilation\", \"--allow_compression\"]\n",
    "PREDICTION_ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
    "PREDICTION_MACHINE_TYPE = \"n1-standard-4\"\n",
    "UPLOAD_JOB_PREFIX = \"upload\"\n",
    "DEPLOY_JOB_PREFIX = \"deploy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZFPe_GezXg8"
   },
   "source": [
    "### 定义常用库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcYUGwr-AJGY"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_job_name_with_datetime(prefix: str):\n",
    "    return prefix + datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "def predict_custom_trained_model(\n",
    "    project: str,\n",
    "    endpoint_id: str,\n",
    "    instances: Union[Dict, List[Dict]],\n",
    "    location: str = \"us-central1\",\n",
    "):\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": f\"{location}-aiplatform.googleapis.com\"}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "    parameters_dict = {}\n",
    "    parameters = json_format.ParseDict(parameters_dict, Value())\n",
    "    endpoint = client.endpoint_path(\n",
    "        project=project, location=location, endpoint=endpoint_id\n",
    "    )\n",
    "    response = client.predict(\n",
    "        endpoint=endpoint, instances=instances, parameters=parameters\n",
    "    )\n",
    "    return response.predictions, response.deployed_model_id\n",
    "\n",
    "\n",
    "def load_img(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return Image.fromarray(np.uint8(img)).convert(\"RGB\")\n",
    "\n",
    "\n",
    "def display_image(original_image, category_image_color, score_image_grayscale):\n",
    "    _, axarr = plt.subplots(1, 3, figsize=(20, 15))\n",
    "    axarr[0].imshow(original_image)\n",
    "    axarr[1].imshow(category_image_color)\n",
    "    axarr[2].imshow(score_image_grayscale.convert(\"RGB\"))\n",
    "\n",
    "\n",
    "def get_prediction_instances(test_filepath, new_width=-1):\n",
    "    if new_width <= 0:\n",
    "        with tf.io.gfile.GFile(test_filepath, \"rb\") as input_file:\n",
    "            encoded_string = base64.b64encode(input_file.read()).decode(\"utf-8\")\n",
    "    else:\n",
    "        img = load_img(test_filepath)\n",
    "        width, height = img.size\n",
    "        print(\"original input image size: \", width, \" , \", height)\n",
    "        new_height = int(height * new_width / width)\n",
    "        new_img = img.resize((new_width, new_height))\n",
    "        print(\"resized input image size: \", new_width, \" , \", new_height)\n",
    "        buffered = BytesIO()\n",
    "        new_img.save(buffered, format=\"JPEG\")\n",
    "        encoded_string = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    instances = [\n",
    "        {\n",
    "            \"encoded_image\": {\"b64\": encoded_string},\n",
    "        }\n",
    "    ]\n",
    "    return instances\n",
    "\n",
    "\n",
    "def get_label_map(label_map_yaml_filepath):\n",
    "    with tf.io.gfile.GFile(label_map_yaml_filepath, \"rb\") as input_file:\n",
    "        label_map = yaml.safe_load(input_file.read())\n",
    "    return label_map\n",
    "\n",
    "\n",
    "def get_best_trial(model_dir, max_trial_count, evaluation_metric):\n",
    "    best_trial_dir = \"\"\n",
    "    best_trial_evaluation_results = {}\n",
    "    best_performance = -1\n",
    "\n",
    "    for i in range(max_trial_count):\n",
    "        current_trial = i + 1\n",
    "        current_trial_dir = os.path.join(model_dir, \"trial_\" + str(current_trial))\n",
    "        current_trial_best_ckpt_dir = os.path.join(current_trial_dir, \"best_ckpt\")\n",
    "        current_trial_best_ckpt_evaluation_filepath = os.path.join(\n",
    "            current_trial_best_ckpt_dir, \"info.json\"\n",
    "        )\n",
    "        with tf.io.gfile.GFile(current_trial_best_ckpt_evaluation_filepath, \"rb\") as f:\n",
    "            eval_metric_results = json.load(f)\n",
    "            current_performance = eval_metric_results[evaluation_metric]\n",
    "            if current_performance > best_performance:\n",
    "                best_performance = current_performance\n",
    "                best_trial_dir = current_trial_dir\n",
    "                best_trial_evaluation_results = eval_metric_results\n",
    "    return best_trial_dir, best_trial_evaluation_results\n",
    "\n",
    "\n",
    "def create_coco_stuff_label_colormap():\n",
    "    \"\"\"Creates a label colormap used in COCO-Stuff segmentation benchmark.\n",
    "\n",
    "    Returns:\n",
    "      A colormap for visualizing segmentation results.\n",
    "    \"\"\"\n",
    "    return np.asarray(\n",
    "        [\n",
    "            [54, 178, 118],\n",
    "            [0, 85, 178],\n",
    "            [150, 178, 22],\n",
    "            [107, 0, 0],\n",
    "            [0, 0, 89],\n",
    "            [0, 117, 178],\n",
    "            [47, 178, 124],\n",
    "            [178, 116, 0],\n",
    "            [0, 0, 178],\n",
    "            [79, 178, 92],\n",
    "            [134, 0, 0],\n",
    "            [22, 178, 150],\n",
    "            [178, 87, 0],\n",
    "            [178, 146, 0],\n",
    "            [0, 5, 178],\n",
    "            [0, 0, 125],\n",
    "            [0, 53, 178],\n",
    "            [0, 132, 178],\n",
    "            [111, 178, 60],\n",
    "            [178, 131, 0],\n",
    "            [0, 29, 178],\n",
    "            [178, 109, 0],\n",
    "            [178, 35, 0],\n",
    "            [0, 148, 178],\n",
    "            [9, 172, 163],\n",
    "            [0, 0, 178],\n",
    "            [178, 124, 0],\n",
    "            [178, 102, 0],\n",
    "            [0, 156, 175],\n",
    "            [178, 43, 0],\n",
    "            [0, 0, 170],\n",
    "            [178, 94, 0],\n",
    "            [0, 0, 134],\n",
    "            [67, 178, 105],\n",
    "            [99, 178, 73],\n",
    "            [0, 37, 178],\n",
    "            [86, 178, 86],\n",
    "            [15, 178, 156],\n",
    "            [0, 0, 152],\n",
    "            [178, 21, 0],\n",
    "            [0, 124, 178],\n",
    "            [0, 61, 178],\n",
    "            [178, 50, 0],\n",
    "            [0, 109, 178],\n",
    "            [137, 178, 35],\n",
    "            [0, 13, 178],\n",
    "            [0, 101, 178],\n",
    "            [0, 0, 116],\n",
    "            [0, 45, 178],\n",
    "            [41, 178, 131],\n",
    "            [0, 0, 161],\n",
    "            [178, 72, 0],\n",
    "            [0, 0, 143],\n",
    "            [116, 0, 0],\n",
    "            [28, 178, 143],\n",
    "            [170, 6, 0],\n",
    "            [156, 178, 15],\n",
    "            [89, 0, 0],\n",
    "            [143, 178, 28],\n",
    "            [73, 178, 99],\n",
    "            [118, 178, 54],\n",
    "            [92, 178, 79],\n",
    "            [152, 0, 0],\n",
    "            [178, 153, 0],\n",
    "            [98, 0, 0],\n",
    "            [178, 65, 0],\n",
    "            [60, 178, 111],\n",
    "            [169, 175, 3],\n",
    "            [105, 178, 67],\n",
    "            [178, 13, 0],\n",
    "            [163, 178, 9],\n",
    "            [3, 164, 169],\n",
    "            [125, 0, 0],\n",
    "            [175, 168, 0],\n",
    "            [178, 138, 0],\n",
    "            [178, 28, 0],\n",
    "            [35, 178, 137],\n",
    "            [0, 140, 178],\n",
    "            [0, 0, 98],\n",
    "            [131, 178, 41],\n",
    "            [0, 77, 178],\n",
    "            [0, 0, 107],\n",
    "            [0, 93, 178],\n",
    "            [143, 0, 0],\n",
    "            [178, 58, 0],\n",
    "            [161, 0, 0],\n",
    "            [0, 69, 178],\n",
    "            [178, 160, 0],\n",
    "            [178, 80, 0],\n",
    "            [0, 21, 178],\n",
    "            [124, 178, 47],\n",
    "            [255, 214, 0],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_segmentation_prediction(prediction):\n",
    "    score_bytes = prediction[\"score_bytes\"]\n",
    "    score_image_grayscale = Image.open(\n",
    "        BytesIO(base64.b64decode(dict(score_bytes)[\"b64\"]))\n",
    "    )\n",
    "    category_bytes = prediction[\"category_bytes\"]\n",
    "    category_image_grayscale = Image.open(\n",
    "        BytesIO(base64.b64decode(dict(category_bytes)[\"b64\"]))\n",
    "    )\n",
    "\n",
    "    # Visualize category images.\n",
    "    color_map = create_coco_stuff_label_colormap()\n",
    "    category_image_grayscale_np = np.array(category_image_grayscale)\n",
    "    rendered_image_shape = category_image_grayscale_np.shape + (3,)\n",
    "    category_image_color_np = np.zeros(rendered_image_shape, dtype=np.uint8)\n",
    "    unique_labels = np.unique(category_image_grayscale_np)\n",
    "    for label in unique_labels:\n",
    "        if label == 0:\n",
    "            continue\n",
    "        category_image_color_np[category_image_grayscale_np == label] = color_map[\n",
    "            label % len(color_map)\n",
    "        ]\n",
    "    category_image_color = Image.fromarray(category_image_color_np)\n",
    "\n",
    "    return score_image_grayscale, category_image_color\n",
    "\n",
    "\n",
    "def upload_checkpoint_to_gcs(checkpoint_url):\n",
    "    filename = os.path.basename(checkpoint_url)\n",
    "    checkpoint_name = filename.replace(\".tar.gz\", \"\")\n",
    "    print(\"Download checkpoint from\", checkpoint_url, \"and store to\", CHECKPOINT_BUCKET)\n",
    "    ! wget $checkpoint_url -O $filename\n",
    "    ! mkdir -p $checkpoint_name\n",
    "    ! tar -xvzf $filename -C $checkpoint_name\n",
    "\n",
    "    # Search for relative path to the checkpoint.\n",
    "    checkpoint_path = None\n",
    "    for root, dirs, files in os.walk(checkpoint_name):\n",
    "        for file in files:\n",
    "            if file.endswith(\".index\"):\n",
    "                checkpoint_path = os.path.join(root, os.path.splitext(file)[0])\n",
    "                checkpoint_path = os.path.relpath(checkpoint_path, checkpoint_name)\n",
    "                break\n",
    "\n",
    "    ! gsutil cp -r $checkpoint_name $CHECKPOINT_BUCKET/\n",
    "    checkpoint_uri = os.path.join(CHECKPOINT_BUCKET, checkpoint_name, checkpoint_path)\n",
    "    print(\"Checkpoint uploaded to\", checkpoint_uri)\n",
    "    return checkpoint_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RB_xY9ipr7ZU"
   },
   "source": [
    "## 训练新模型\n",
    "本节展示如何训练新模型。\n",
    "1. 将输入数据转换为训练格式\n",
    "2. 创建超参数调整作业来训练新模型\n",
    "3. 查找并导出最佳模型\n",
    "\n",
    "如果您已经训练过模型，请转至“测试训练过的模型”部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### 为训练准备输入数据\n",
    "\n",
    "按照[这里](https://cloud.google.com/vertex-ai/docs/image-data/classification/prepare-data)描述的格式准备数据，然后将它们转换为以下的训练格式：\n",
    "\n",
    "* `input_file_path`：coco json格式的输入文件路径。\n",
    "* `split_ratio`：要拆分为训练/验证/测试数据的比例。\n",
    "* `num_shard`：用于训练/验证/测试的碎片数量。\n",
    "* `output_dir`：输出目录，其中包含准备好的训练/测试/验证数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IndQ_m6ddUEM"
   },
   "outputs": [],
   "source": [
    "# This job will convert input data as training format, with given split ratios\n",
    "# and number of shards on train/test/validation.\n",
    "data_converter_job_name = get_job_name_with_datetime(\n",
    "    DATA_CONVERTER_JOB_PREFIX + \"_\" + OBJECTIVE\n",
    ")\n",
    "\n",
    "input_file_path = \"\"  # @param {type:\"string\"}\n",
    "split_ratio = \"0.8,0.1,0.1\"\n",
    "num_shard = \"10,10,10\"\n",
    "data_converter_output_dir = os.path.join(BUCKET_URI, data_converter_job_name)\n",
    "\n",
    "\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": DATA_CONVERTER_MACHINE_TYPE,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": DATA_CONVERTER_CONTAINER,\n",
    "            \"command\": [],\n",
    "            \"args\": [\n",
    "                \"--input_file_path=%s\" % input_file_path,\n",
    "                \"--input_file_type=coco_json\",\n",
    "                \"--objective=%s\" % OBJECTIVE,\n",
    "                \"--num_shard=%s\" % num_shard,\n",
    "                \"--split_ratio=%s\" % split_ratio,\n",
    "                \"--output_dir=%s\" % data_converter_output_dir,\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "data_converter_custom_job = aiplatform.CustomJob(\n",
    "    display_name=data_converter_job_name,\n",
    "    project=PROJECT_ID,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=STAGING_BUCKET,\n",
    ")\n",
    "\n",
    "data_converter_custom_job.run()\n",
    "\n",
    "input_train_data_path = os.path.join(data_converter_output_dir, \"train.tfrecord*\")\n",
    "input_validation_data_path = os.path.join(data_converter_output_dir, \"val.tfrecord*\")\n",
    "label_map_path = os.path.join(data_converter_output_dir, \"label_map.yaml\")\n",
    "print(\"input_train_data_path for training: \", input_train_data_path)\n",
    "print(\"input_validation_data_path for training: \", input_validation_data_path)\n",
    "print(\"label_map_path for prediction: \", label_map_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6dU2IrIqW3H"
   },
   "source": [
    "### 使用超参数调整创建 Vertex AI 定制作业\n",
    "\n",
    "您可以使用 Vertex AI SDK 创建并运行具有 Vertex AI Model Garden Training Dockers 的超参数调整作业。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaff6f5be7f6"
   },
   "source": [
    "#### 定义以下规范\n",
    "* `worker_pool_specs`：指定机器类型和Docker镜像的字典。此示例定义了一个包含一个`n1-standard-4`机器和两个`NVIDIA_TESLA_T4` GPU的单节点集群。\n",
    "* `parameter_spec`：指定要优化的参数的字典。字典键是分配给训练应用程序代码中每个超参数的命令行参数的字符串，字典值是参数规范。参数规范包括超参数的类型、最小/最大值和缩放。\n",
    "* `metric_spec`：指定要优化的度量标准的字典。字典键是您在训练应用程序代码中设置的`hyperparameter_metric_tag`，值是优化目标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "um_XKbmpTaHx"
   },
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "\n",
    "label_map = get_label_map(label_map_path)\n",
    "num_classes = len(label_map[\"label_map\"]) + 1\n",
    "\n",
    "# Input train and validation datasets can be found from the section above\n",
    "# `Convert input data for training`.\n",
    "# Set prepared datasets if exists.\n",
    "# input_train_data_path = ''\n",
    "# input_validation_data_path = ''\n",
    "\n",
    "# Refer to https://github.com/tensorflow/models/blob/master/official/vision/MODEL_GARDEN.md\n",
    "# for more model details.\n",
    "experiment = \"deeplabv3plus\"  # @param [\"deeplabv3plus\"]\n",
    "\n",
    "train_job_name = get_job_name_with_datetime(TRAINING_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
    "model_dir = os.path.join(BUCKET_URI, train_job_name)\n",
    "\n",
    "# The arguments here are mainly for test purposes. Please update them\n",
    "# to get better performances.\n",
    "experiment_container_args_dict = {\n",
    "    # deeplabv3plus experiment args.\n",
    "    \"deeplabv3plus\": {\n",
    "        \"experiment\": \"seg_deeplabv3plus_pascal\",\n",
    "        \"config_file\": TRAIN_DEEPLABV3PLUS_CONFIG,\n",
    "        \"input_train_data_path\": input_train_data_path,\n",
    "        \"input_validation_data_path\": input_validation_data_path,\n",
    "        \"objective\": OBJECTIVE,\n",
    "        \"model_dir\": model_dir,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"global_batch_size\": 2,\n",
    "        \"prefetch_buffer_size\": 12,\n",
    "        \"train_steps\": 500,\n",
    "        \"output_size\": \"1024,2048\",\n",
    "        \"init_checkpoint\": \"https://storage.googleapis.com/tf_model_garden/vision/deeplabv3plus/dilated-resnet-101-deeplabv3plus.tar.gz\",\n",
    "    }\n",
    "}\n",
    "experiment_container_args = experiment_container_args_dict[experiment]\n",
    "\n",
    "# Copy checkpoint to GCS bucket if specified.\n",
    "init_checkpoint = experiment_container_args.get(\"init_checkpoint\")\n",
    "if init_checkpoint:\n",
    "    experiment_container_args[\"init_checkpoint\"] = upload_checkpoint_to_gcs(\n",
    "        init_checkpoint\n",
    "    )\n",
    "\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": TRAIN_MACHINE_TYPE,\n",
    "            \"accelerator_type\": TRAIN_ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": TRAIN_NUM_GPU,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": TRAIN_CONTAINER_URI,\n",
    "            \"args\": [\n",
    "                \"--mode=train_and_eval\",\n",
    "            ]\n",
    "            + [\"--{}={}\".format(k, v) for k, v in experiment_container_args.items()],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "metric_spec = {\"model_performance\": \"maximize\"}\n",
    "\n",
    "LEARNING_RATES = [0.001]\n",
    "# Models will be trained with each learning rate separately and max trial count is the number of learning rates.\n",
    "MAX_TRIAL_COUNT = len(LEARNING_RATES)\n",
    "parameter_spec = {\n",
    "    \"learning_rate\": hpt.DiscreteParameterSpec(values=LEARNING_RATES, scale=\"linear\"),\n",
    "}\n",
    "\n",
    "print(worker_pool_specs, metric_spec, parameter_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwcCjwlBTQIz"
   },
   "source": [
    "#### 运行超参数调整作业\n",
    "* `max_trial_count`: 设置服务将运行的试验数量的上限。推荐的做法是从较少数量的试验开始，了解您选择的超参数对结果的影响程度，然后再逐渐增加。\n",
    "\n",
    "* `parallel_trial_count`: 如果使用并行试验，服务将为多个训练处理集群提供资源。在创建作业时指定的工作池规范将用于每个单独的训练集群。增加并行试验的数量可缩短超参数调整作业运行所需的时间；但是，这可能会降低作业的整体有效性。因为默认的调整策略使用先前试验的结果来指导后续试验中数值的指定。\n",
    "\n",
    "* `search_algorithm`: 可用的搜索算法有grid、random或默认值（None）。默认选项应用贝叶斯优化来搜索可能超参数值的空间，是推荐的算法。\n",
    "\n",
    "单击输出中生成的链接以在Cloud控制台中查看您的运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aec22792ee84"
   },
   "outputs": [],
   "source": [
    "train_custom_job = aiplatform.CustomJob(\n",
    "    display_name=train_job_name,\n",
    "    project=PROJECT_ID,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=STAGING_BUCKET,\n",
    ")\n",
    "\n",
    "train_hpt_job = aiplatform.HyperparameterTuningJob(\n",
    "    display_name=train_job_name,\n",
    "    custom_job=train_custom_job,\n",
    "    metric_spec=metric_spec,\n",
    "    parameter_spec=parameter_spec,\n",
    "    max_trial_count=MAX_TRIAL_COUNT,\n",
    "    parallel_trial_count=1,\n",
    "    project=PROJECT_ID,\n",
    "    search_algorithm=None,\n",
    ")\n",
    "\n",
    "train_hpt_job.run()\n",
    "\n",
    "print(\"experiment is: \", experiment)\n",
    "print(\"model_dir is: \", model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mV-Djz-frBni"
   },
   "source": [
    "将最佳模型导出为TF Saved Model格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09Rz1AYspK19"
   },
   "outputs": [],
   "source": [
    "# This job will export models from TF checkpoints to TF saved model format.\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# model_dir is from the section above.\n",
    "best_trial_dir, best_trial_evaluation_results = get_best_trial(\n",
    "    model_dir, MAX_TRIAL_COUNT, EVALUATION_METRIC\n",
    ")\n",
    "print(\"best_trial_dir: \", best_trial_dir)\n",
    "print(\"best_trial_evaluation_results: \", best_trial_evaluation_results)\n",
    "\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": EXPORT_MACHINE_TYPE,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": EXPORT_CONTAINER_URI,\n",
    "            \"command\": [],\n",
    "            \"args\": [\n",
    "                \"--objective=%s\" % OBJECTIVE,\n",
    "                \"--experiment=%s\" % experiment_container_args[\"experiment\"],\n",
    "                \"--config_file=%s/params.yaml\" % best_trial_dir,\n",
    "                \"--checkpoint_path=%s/best_ckpt\" % best_trial_dir,\n",
    "                \"--export_dir=%s/best_model\" % model_dir,\n",
    "                \"--input_image_size=%s\" % experiment_container_args[\"output_size\"],\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "model_export_name = get_job_name_with_datetime(EXPORT_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
    "model_export_custom_job = aiplatform.CustomJob(\n",
    "    display_name=model_export_name,\n",
    "    project=PROJECT_ID,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=STAGING_BUCKET,\n",
    ")\n",
    "\n",
    "\n",
    "model_export_custom_job.run()\n",
    "\n",
    "print(\"best model is saved to: \", os.path.join(model_dir, \"best_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0BGaofgsMsy"
   },
   "source": [
    "## 测试训练好的模型\n",
    "这部分展示了如何使用训练好的模型进行测试。\n",
    "1. 上传和部署模型\n",
    "2. 运行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYuQowyZEtxK"
   },
   "outputs": [],
   "source": [
    "# @title Upload and deploy models\n",
    "# model_dir is from the section above.\n",
    "trained_model_dir = os.path.join(model_dir, \"best_model/saved_model\")\n",
    "\n",
    "upload_job_name = get_job_name_with_datetime(UPLOAD_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
    "\n",
    "serving_env = {\n",
    "    \"MODEL_ID\": \"deeplabv3plus-cityscapes-20230315\",\n",
    "    \"DEPLOY_SOURCE\": \"notebook\",\n",
    "}\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=upload_job_name,\n",
    "    artifact_uri=trained_model_dir,\n",
    "    serving_container_image_uri=PREDICTION_CONTAINER_URI,\n",
    "    serving_container_args=SERVING_CONTAINER_ARGS,\n",
    "    serving_container_environment_variables=serving_env,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(\"The uploaded model name is: \", upload_job_name)\n",
    "\n",
    "deploy_model_name = get_job_name_with_datetime(DEPLOY_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
    "print(\"The deployed job name is: \", deploy_model_name)\n",
    "\n",
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name=deploy_model_name,\n",
    "    machine_type=PREDICTION_MACHINE_TYPE,\n",
    "    traffic_split={\"0\": 100},\n",
    "    accelerator_type=PREDICTION_ACCELERATOR_TYPE,\n",
    "    accelerator_count=1,\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=1,\n",
    ")\n",
    "\n",
    "endpoint_id = endpoint.name\n",
    "print(\"endpoint id is: \", endpoint_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbIW9me1F2RY"
   },
   "outputs": [],
   "source": [
    "# @title Run predictions\n",
    "# endpoint_id was generated in the section above (`Upload and deploy models`).\n",
    "endpoint_id = endpoint.name\n",
    "\n",
    "# The test image file path.\n",
    "test_filepath = \"\"  # @param {type:\"string\"}\n",
    "score_threshold = 0.5  # @param {type:\"number\"}\n",
    "# If the input image is too large, we will resize it for prediction.\n",
    "instances = get_prediction_instances(test_filepath, new_width=1000)\n",
    "\n",
    "# The label map file was generated from the section above (`Convert input data for training`).\n",
    "label_map = get_label_map(label_map_path)[\"label_map\"]\n",
    "\n",
    "predictions, _ = predict_custom_trained_model(\n",
    "    project=PROJECT_ID, location=REGION, endpoint_id=endpoint_id, instances=instances\n",
    ")\n",
    "\n",
    "score_image_grayscale, category_image_color = parse_segmentation_prediction(\n",
    "    dict(predictions[0])\n",
    ")\n",
    "display_image(\n",
    "    load_img(test_filepath), category_image_color, score_image_grayscale.convert(\"RGB\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkH2nrpdp4sp"
   },
   "source": [
    "清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ax6vQVZhp9pR"
   },
   "outputs": [],
   "source": [
    "# Undeploy model and delete endpoint.\n",
    "endpoint.delete(force=True)\n",
    "# Delete models.\n",
    "model.delete()\n",
    "# Delete custom and hpt jobs.\n",
    "if data_converter_custom_job.list(filter=f'display_name=\"{data_converter_job_name}\"'):\n",
    "    data_converter_custom_job.delete()\n",
    "if train_hpt_job.list(filter=f'display_name=\"{train_job_name}\"'):\n",
    "    train_hpt_job.delete()\n",
    "if model_export_custom_job.list(filter=f'display_name=\"{model_export_name}\"'):\n",
    "    model_export_custom_job.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "model_garden_tfvision_image_segmentation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
