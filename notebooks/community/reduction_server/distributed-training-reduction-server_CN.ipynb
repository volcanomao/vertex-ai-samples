{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "使用降低服务器进行分布式培训"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本笔记本演示了如何使用 Vertex Training Reduction Server 优化大规模分布式训练工作。使用 TensorFlow Model Garden 中的 [TensorFlow NLP Modelling Toolkit](https://github.com/tensorflow/models/tree/master/official/nlp#tensorflow-nlp-modelling-toolkit) 预处理数据并创建模型和训练循环。使用 `tf.distribute` 模块中的 `MultiWorkerMirroredStrategy` 将模型训练分布式到多台机器上。\n",
    "\n",
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是 GLUE 基准测试中的 [Multi-Genre Natural Language Inference Corpus (MNLI)](https://www.tensorflow.org/datasets/catalog/glue#gluemnli)。从 Cloud Storage 存储桶中加载这个数据集的预处理版本，并用于微调 BERT 模型进行句子预测。\n",
    "\n",
    "### 目标\n",
    "\n",
    "在本笔记本中，您将在 Docker 容器中的 Python 脚本中创建一个自定义训练模型。您将学习如何配置、提交和监视一个使用 Reduction Server 优化网络带宽和梯度降低操作的 Vertex Training 作业。\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 创建一个使用 Reduction Server 的 Vertex 自定义训练作业。\n",
    "- 提交和监视作业。\n",
    "- 清理资源。\n",
    "\n",
    "### 成本\n",
    "\n",
    "此教程使用 Google Cloud 的付费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage 价格](https://cloud.google.com/storage/pricing)，并使用[Pricing Calculator](https://cloud.google.com/products/calculator/)根据您的预期使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ze4-nDLfK4pw"
   },
   "source": [
    "###设置本地开发环境\n",
    "\n",
    "**如果您正在使用Colab或Google Cloud笔记本**，您的环境已经满足运行此笔记本的所有要求。您可以跳过此步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCuSR8GkAgzl"
   },
   "source": [
    "否则，请确保您的环境符合本笔记本的要求。您需要以下内容：\n",
    "\n",
    "* Google Cloud SDK\n",
    "* Git\n",
    "* Python 3\n",
    "* virtualenv\n",
    "* 在使用Python 3的虚拟环境中运行的Jupyter笔记本\n",
    "\n",
    "Google Cloud指南 [设置Python开发环境](https://cloud.google.com/python/setup) 和 [Jupyter安装指南](https://jupyter.org/install) 提供了满足这些要求的详细说明。以下步骤提供了一套简洁的说明：\n",
    "\n",
    "1. [安装和初始化Cloud SDK。](https://cloud.google.com/sdk/docs/)\n",
    "\n",
    "2. [安装Python 3。](https://cloud.google.com/python/setup#installing_python)\n",
    "\n",
    "3. [安装virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv) 并创建一个使用Python 3的虚拟环境。激活虚拟环境。\n",
    "\n",
    "4. 要安装Jupyter，请在终端shell中运行 `pip3 install jupyter`。\n",
    "\n",
    "5. 要启动Jupyter，请在终端shell中运行 `jupyter notebook`。\n",
    "\n",
    "6. 在Jupyter Notebook Dashboard中打开本笔记本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "安装所需的软件包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b4ef9b72d43"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Google Cloud Notebook product has specific requirements\n",
    "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
    "\n",
    "# Google Cloud Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c04a3abc06e8"
   },
   "source": [
    "安装Python的最新版本的Vertex SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyy5Lbnzg5fi"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade google-cloud-aiplatform $USER_FLAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c1b8d6e0eaa"
   },
   "source": [
    "安装最新版本的Google Cloud Storage库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c491dc218314"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade google-cloud-storage $USER_FLAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhq5zEbGg0XX"
   },
   "source": [
    "### 重新启动内核\n",
    "\n",
    "安装额外包后，您需要重新启动笔记本内核，以便它能找到这些包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzrelQZ22IZj"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWEdiXsJg0XY"
   },
   "source": [
    "在你开始之前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "设置您的Google Cloud项目\n",
    "\n",
    "**无论您使用什么笔记本环境，都需要执行以下步骤。**\n",
    "\n",
    "1. [选择或创建一个Google Cloud项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建一个帐户时，您将获得$300的免费信用，可用于抵消计算/存储成本。\n",
    "\n",
    "2. [确保为您的项目启用了计费功能](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "3. [启用Vertex AI API和Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component)。\n",
    "\n",
    "4. 如果您在本地运行此笔记本，您需要安装[Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "5. 在下面的单元格中输入您的项目ID。然后运行该单元格以确保Cloud SDK为本笔记本中的所有命令使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter将以`!`前缀的行作为shell命令运行，并将以`$`前缀的Python变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用`gcloud`来获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"\"\n",
    "\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJYoRfYng0XZ"
   },
   "source": [
    "否则，在这里设置你的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riG_qUokg0XZ"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
    "    PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dr--iN2kAylZ"
   },
   "source": [
    "### 验证您的Google Cloud帐户\n",
    "\n",
    "**如果您正在使用Google Cloud笔记本**，您的环境已经经过验证。请跳过此步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBCra4QMA2wR"
   },
   "source": [
    "如果您正在使用Colab，请运行下面的单元格，并按照提示进行oAuth身份验证。\n",
    "\n",
    "否则，请按照以下步骤操作：\n",
    "\n",
    "1. 在Cloud控制台中，转到[**创建服务帐户密钥**页面](https://console.cloud.google.com/apis/credentials/serviceaccountkey)。\n",
    "\n",
    "2. 点击**创建服务帐户**。\n",
    "\n",
    "3. 在**服务帐户名称**字段中输入名称，然后点击**创建**。\n",
    "\n",
    "4. 在**授予此服务帐户对项目的访问权限**部分，点击**角色**下拉列表。在筛选框中输入\"Vertex AI\"，并选择**Vertex AI管理员**。在筛选框中输入\"Storage Object Admin\"，并选择**存储对象管理员**。\n",
    "\n",
    "5. 点击*创建*。一个包含您密钥的JSON文件将下载到您的本地环境。\n",
    "\n",
    "6. 在下面的单元格中将您的服务帐户密钥路径输入为`GOOGLE_APPLICATION_CREDENTIALS`变量，并运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "# The Google Cloud Notebook product has specific requirements\n",
    "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
    "\n",
    "# If on Google Cloud Notebooks, then don't execute this code\n",
    "if not IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### 创建云存储桶\n",
    "\n",
    "**无论您使用的是哪种笔记本环境，都需要完成以下步骤。**\n",
    "\n",
    "在此示例中，您的训练应用程序使用云存储来访问训练和验证数据集，并存储检查点。\n",
    "\n",
    "在下面设置您的云存储桶的名称。它必须在所有云存储桶中是唯一的。\n",
    "\n",
    "您也可以更改`REGION`变量，这将用于笔记本其余部分的操作。确保选择一个[支持 Vertex AI 服务的区域](https://cloud.google.com/vertex-ai/docs/general/locations#available_regions)。您不可以使用多区域存储桶来训练 Vertex AI。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "REGION = \"[your-region]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "只有在您的存储桶尚不存在时才能运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucvCsknMCims"
   },
   "source": [
    "最后，通过检查云存储桶中的内容验证对其的访问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhOb7YnwClBb"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf"
   },
   "source": [
    "导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRUOFELefqf1"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "247269093fb4"
   },
   "source": [
    "### 初始化 Vertex SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27570c702690"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c07485571228"
   },
   "source": [
    "### 设置数据集位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "345476813f4c"
   },
   "source": [
    "多种类自然语言推理语料库（MNLI）数据集已经被预处理为TensorFlow NLP建模工具包所需的格式，并上传到公共云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fd00263570c"
   },
   "outputs": [],
   "source": [
    "DATASET_LOCATION = \"gs://cloud-samples-data/vertex-ai/community-content/datasets/MNLI\"\n",
    "TRAIN_FILE = f\"{DATASET_LOCATION}/mnli_train.tf_record\"\n",
    "EVAL_FILE = f\"{DATASET_LOCATION}/mnli_valid.tf_record\"\n",
    "METADATA_FILE = f\"{DATASET_LOCATION}/metadata.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbaf7f8a792c"
   },
   "outputs": [],
   "source": [
    "# List the files\n",
    "\n",
    "! gsutil ls {DATASET_LOCATION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ea3b9ed322d"
   },
   "outputs": [],
   "source": [
    "# Examine dataset metadata\n",
    "\n",
    "! gsutil cat {METADATA_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd9941a9c5d5"
   },
   "source": [
    "### 创建一个训练容器\n",
    "#### 编写Dockerfile\n",
    "\n",
    "将代码容器化的第一步是创建一个Dockerfile。在Dockerfile中，您将包含所有需要运行镜像的命令，例如安装必要的库和设置训练代码的入口点。\n",
    "\n",
    "此Dockerfile使用顶点预构建的TensorFlow 2.5 GPU Docker镜像作为基础镜像。在下载该镜像后，此Dockerfile安装了TensorFlow官方模型和TensorFlow文本库。在基础镜像中预先安装了Reduction Server NCCL插件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9c5378a292a0"
   },
   "outputs": [],
   "source": [
    "# Create training image directory\n",
    "\n",
    "! mkdir training_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94530ed2c913"
   },
   "outputs": [],
   "source": [
    "%%writefile training_image/Dockerfile\n",
    "\n",
    "FROM us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-5:latest\n",
    "    \n",
    "WORKDIR /\n",
    "\n",
    "# Installs Official Models and Text libraries\n",
    "RUN pip install tf-models-official==2.5.1 tensorflow-text==2.5.0\n",
    "\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY trainer /trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "769d97f5bb46"
   },
   "source": [
    "#### 创建培训应用程序代码\n",
    "\n",
    "接下来，您将创建一个名为`training_image/trainer`的目录，其中包含一个名为`train.py`的脚本，该脚本包含了您的培训应用程序的代码。\n",
    "\n",
    "`train.py`培训脚本基于来自TensorFlow NLP建模工具包的[常用培训驱动程序](https://github.com/tensorflow/models/blob/master/official/nlp/docs/train.md)。常用培训驱动程序脚本支持多个NLP任务（例如，预培训、GLUE和SQuAD微调）和多个模型（例如，BERT、ALBERT）。\n",
    "\n",
    "针对特定NLP任务的一组配置称为实验。工具包包含一组预定义的实验。当您调用脚本时，您可以使用`--experiment`命令行参数来指定实验类型。有两种覆盖默认实验配置的选项：\n",
    "- 使用`--config_file`命令行参数指定一个或多个更新设置的YAML配置\n",
    "- 通过`--params_override`命令行参数将更新的设置提供为键/值对列表\n",
    "\n",
    "如果同时指定了`--config_file`和`--params_override`，则`--params_override`中的设置优先。\n",
    "\n",
    "检索默认实验配置并合并用户提供的设置封装在来自TensorFlow Model Garden的`official.core.train_utils.parse_configuration`实用函数中。\n",
    "\n",
    "在下面的单元格中，[共享培训驱动程序脚本](https://github.com/tensorflow/models/blob/master/official/nlp/train.py)已经经过适应，可以无缝地在运行Vertex培训作业时在分布式计算环境上运行。TensorFlow NLP建模工具包使用[Orbit](https://github.com/tensorflow/models/tree/master/orbit)来实施自定义训练循环。自定义训练循环保存检查点，编写Tensorboard摘要，并将训练好的模型保存到通过`--model-dir`命令行参数指定的存储位置。\n",
    "\n",
    "请注意，当在分布式设置中使用基本的共享培训驱动程序时，每个工作者都使用相同的基本存储位置。为避免多个工作者同时向同一存储位置写入时发生冲突，驱动程序代码已被修改，使每个工作者根据其在Vertex计算集群中的角色使用不同的存储位置。此逻辑实现在`_get_model_dir`实用函数中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24a2466976fb"
   },
   "outputs": [],
   "source": [
    "# Create trainer directory\n",
    "\n",
    "! mkdir training_image/trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ac9bbcec38fd"
   },
   "outputs": [],
   "source": [
    "%%writefile training_image/trainer/train.py\n",
    "\n",
    "# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"TFM common training driver.\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "import gin\n",
    "from official.common import distribute_utils\n",
    "from official.common import flags as tfm_flags\n",
    "from official.common import registry_imports\n",
    "from official.core import task_factory\n",
    "from official.core import train_lib\n",
    "from official.core import train_utils\n",
    "from official.modeling import performance\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "def _get_model_dir(model_dir):\n",
    "  \"\"\"Defines utility functions for model saving.\n",
    "\n",
    "  In a multi-worker scenario, the chief worker will save to the\n",
    "  desired model directory, while the other workers will save the model to\n",
    "  temporary directories. It’s important that these temporary directories\n",
    "  are unique in order to prevent multiple workers from writing to the same\n",
    "  location. Saving can contain collective ops, so all workers must save and\n",
    "  not just the chief.\n",
    "  \"\"\"\n",
    "\n",
    "  def _is_chief(task_type, task_id):\n",
    "    return ((task_type == 'chief' and task_id == 0) or task_type is None)\n",
    "\n",
    "  tf_config = os.getenv('TF_CONFIG')\n",
    "  if tf_config:\n",
    "    tf_config = json.loads(tf_config)\n",
    "\n",
    "    if not _is_chief(tf_config['task']['type'], tf_config['task']['index']):\n",
    "      model_dir = os.path.join(model_dir,\n",
    "                               'worker-{}').format(tf_config['task']['index'])\n",
    "\n",
    "  logging.info('Setting model_dir to: %s', model_dir)\n",
    "\n",
    "  return model_dir\n",
    "\n",
    "\n",
    "def main(_):\n",
    "\n",
    "  model_dir = _get_model_dir(FLAGS.model_dir)\n",
    "\n",
    "  gin.parse_config_files_and_bindings(FLAGS.gin_file, FLAGS.gin_params)\n",
    "  params = train_utils.parse_configuration(FLAGS)\n",
    "\n",
    "  if 'train' in FLAGS.mode:\n",
    "    # Pure eval modes do not output yaml files. Otherwise continuous eval job\n",
    "    # may race against the train job for writing the same file.\n",
    "    train_utils.serialize_config(params, model_dir)\n",
    "\n",
    "  # Sets mixed_precision policy. Using 'mixed_float16' or 'mixed_bfloat16'\n",
    "  # can have significant impact on model speeds by utilizing float16 in case of\n",
    "  # GPUs, and bfloat16 in the case of TPUs. loss_scale takes effect only when\n",
    "  # dtype is float16\n",
    "  if params.runtime.mixed_precision_dtype:\n",
    "    performance.set_mixed_precision_policy(params.runtime.mixed_precision_dtype)\n",
    "  distribution_strategy = distribute_utils.get_distribution_strategy(\n",
    "      distribution_strategy=params.runtime.distribution_strategy,\n",
    "      all_reduce_alg=params.runtime.all_reduce_alg,\n",
    "      num_gpus=params.runtime.num_gpus,\n",
    "      tpu_address=params.runtime.tpu,\n",
    "      **params.runtime.model_parallelism())\n",
    "  with distribution_strategy.scope():\n",
    "    task = task_factory.get_task(params.task, logging_dir=model_dir)\n",
    "\n",
    "  train_lib.run_experiment(\n",
    "      distribution_strategy=distribution_strategy,\n",
    "      task=task,\n",
    "      mode=FLAGS.mode,\n",
    "      params=params,\n",
    "      model_dir=model_dir)\n",
    "\n",
    "  train_utils.save_gin_config(FLAGS.mode, model_dir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tfm_flags.define_flags()\n",
    "  app.run(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a481e8683121"
   },
   "source": [
    "####  为MNLI微调实验创建基本设置\n",
    "\n",
    "TensorFlow NLP建模工具包包括一组文本分类任务的预定义实验，即`bert/sentence_prediction`实验。 `bert/sentence_prediction`实验中的基本设置需要针对您在此示例中执行的MNLI微调任务进行更新。\n",
    "\n",
    "在下一个单元格中，您可以通过创建一个YAML配置文件来更新这些设置，该文件在调用训练脚本时将被引用。正如前面所述，您可以使用`--params_override`标志进一步微调这些设置，以用于每次训练运行。\n",
    "\n",
    "配置文件包含三个部分：`task`，`trainer`和`runtime`。\n",
    "* `task`部分包含特定于机器学习任务的设置，包括指向预训练BERT模型的URI，训练和验证数据集设置以及评估指标。\n",
    "* `trainer`部分配置控制自定义训练循环的设置，例如检查点间隔或训练步骤数量。\n",
    "* `runtime`部分包括用于训练运行时的设置：分布式训练策略、GPU配置等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d66c492b923c"
   },
   "outputs": [],
   "source": [
    "%%writefile training_image/trainer/glue_mnli_matched.yaml\n",
    "\n",
    "task:\n",
    "  hub_module_url: 'https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4'\n",
    "  model:\n",
    "    num_classes: 3\n",
    "  init_checkpoint: ''\n",
    "  metric_type: 'accuracy'\n",
    "  train_data:\n",
    "    drop_remainder: true\n",
    "    global_batch_size: 32\n",
    "    input_path: ''\n",
    "    is_training: true\n",
    "    seq_length: 128\n",
    "    label_type: 'int'\n",
    "  validation_data:\n",
    "    drop_remainder: false\n",
    "    global_batch_size: 32\n",
    "    input_path: ''\n",
    "    is_training: false\n",
    "    seq_length: 128\n",
    "    label_type: 'int'\n",
    "trainer:\n",
    "  checkpoint_interval: 3000\n",
    "  optimizer_config:\n",
    "    learning_rate:\n",
    "      polynomial:\n",
    "        # 100% of train_steps.\n",
    "        decay_steps: 36813\n",
    "        end_learning_rate: 0.0\n",
    "        initial_learning_rate: 3.0e-05\n",
    "        power: 1.0\n",
    "      type: polynomial\n",
    "    optimizer:\n",
    "      type: adamw\n",
    "    warmup:\n",
    "      polynomial:\n",
    "        power: 1\n",
    "        # ~10% of train_steps.\n",
    "        warmup_steps: 3681\n",
    "      type: polynomial\n",
    "  steps_per_loop: 1000\n",
    "  summary_interval: 1000\n",
    "  # Training data size 392,702 examples, 3 epochs.\n",
    "  train_steps: 36813\n",
    "  validation_interval: 6135\n",
    "  # Eval data size = 9815 examples.\n",
    "  validation_steps: 307\n",
    "  best_checkpoint_export_subdir: 'best_ckpt'\n",
    "  best_checkpoint_eval_metric: 'cls_accuracy'\n",
    "  best_checkpoint_metric_comp: 'higher'\n",
    "runtime:\n",
    "  distribution_strategy: 'multi_worker_mirrored'\n",
    "  all_reduce_alg: 'nccl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22dae83d50c5"
   },
   "source": [
    "### 构建容器\n",
    "\n",
    "在接下来的单元格中，您将构建容器并推送到Google容器注册表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f7015f17eea"
   },
   "outputs": [],
   "source": [
    "TRAIN_IMAGE = f\"gcr.io/{PROJECT_ID}/mnli_finetuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0247689ca75e"
   },
   "outputs": [],
   "source": [
    "! docker build -t {TRAIN_IMAGE} training_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7887a8df1345"
   },
   "outputs": [],
   "source": [
    "! docker push {TRAIN_IMAGE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc35446749b5"
   },
   "source": [
    "### 创建自定义训练作业\n",
    "\n",
    "在使用 Vertex AI 运行分布式训练作业时，您需要在一个训练集群中指定多台机器（节点）。训练服务会为您指定的机器类型分配资源。在特定节点上运行的作业被称为一个副本。具有相同配置的一组副本被称为一个 worker 池。Vertex Training 提供了 4 个 worker 池，用于执行不同类型的机器任务。要使用 Reduction Server，您需要使用其中的 3 个 worker 池中的一个。\n",
    "\n",
    "* **Worker 池 0** 配置主要节点、主导节点、调度节点或“主节点”。这个 worker 通常会执行一些额外的工作，如保存检查点和编写摘要文件。在一个集群中只会有一个主节点，因此您在 worker 池 0 中的 worker 计数始终为 1。\n",
    "\n",
    "* **Worker 池 1** 是配置集群中其余工作者的地方。\n",
    "\n",
    "* **Worker 池 2** 管理 Reduction Server 的 reducer。\n",
    "\n",
    "Worker 池 0 和 1 运行您在上一步创建的自定义训练容器。Worker 池 2 使用 Vertex AI 提供的 Reduction Server 镜像。\n",
    "\n",
    "下面的辅助函数使用描述的 worker 池拓扑来创建 worker 池规格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7a924769c205"
   },
   "outputs": [],
   "source": [
    "def prepare_worker_pool_specs(\n",
    "    image_uri,\n",
    "    args,\n",
    "    cmd,\n",
    "    replica_count=1,\n",
    "    machine_type=\"n1-standard-4\",\n",
    "    accelerator_count=0,\n",
    "    accelerator_type=\"ACCELERATOR_TYPE_UNSPECIFIED\",\n",
    "    reduction_server_count=0,\n",
    "    reduction_server_machine_type=\"n1-highcpu-16\",\n",
    "    reduction_server_image_uri=\"us-docker.pkg.dev/vertex-ai-restricted/training/reductionserver:latest\",\n",
    "):\n",
    "\n",
    "    if accelerator_count > 0:\n",
    "        machine_spec = {\n",
    "            \"machine_type\": machine_type,\n",
    "            \"accelerator_type\": accelerator_type,\n",
    "            \"accelerator_count\": accelerator_count,\n",
    "        }\n",
    "    else:\n",
    "        machine_spec = {\"machine_type\": machine_type}\n",
    "\n",
    "    container_spec = {\n",
    "        \"image_uri\": image_uri,\n",
    "        \"args\": args,\n",
    "        \"command\": cmd,\n",
    "    }\n",
    "\n",
    "    chief_spec = {\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": machine_spec,\n",
    "        \"container_spec\": container_spec,\n",
    "    }\n",
    "\n",
    "    worker_pool_specs = [chief_spec]\n",
    "    if replica_count > 1:\n",
    "        workers_spec = {\n",
    "            \"replica_count\": replica_count - 1,\n",
    "            \"machine_spec\": machine_spec,\n",
    "            \"container_spec\": container_spec,\n",
    "        }\n",
    "        worker_pool_specs.append(workers_spec)\n",
    "\n",
    "    if reduction_server_count > 1:\n",
    "        workers_spec = {\n",
    "            \"replica_count\": reduction_server_count,\n",
    "            \"machine_spec\": {\n",
    "                \"machine_type\": reduction_server_machine_type,\n",
    "            },\n",
    "            \"container_spec\": {\"image_uri\": reduction_server_image_uri},\n",
    "        }\n",
    "        worker_pool_specs.append(workers_spec)\n",
    "\n",
    "    return worker_pool_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a753112e1484"
   },
   "source": [
    "配置工作池\n",
    "\n",
    "在选择减少器的数量和类型时，您应考虑减少器副本的机器类型支持的网络带宽。在GCP中，虚拟机的机器类型定义了其最大可能的出口带宽。例如，`n1-highcpu-16` 机器类型的出口带宽被限制在 32 Gbps。\n",
    "\n",
    "由于减少器执行非常有限的功能，即聚合梯度块，因此它们可以在相对低功耗和成本效益的机器上运行。即使有大量梯度，此计算也不需要加速硬件或高CPU或内存资源。但是，为避免网络瓶颈，减少器工作池中所有副本的总聚合带宽必须大于或等于主机 GPU 工作器池 0 和 1 中所有副本的总聚合带宽。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84c6a7f3b1bd"
   },
   "outputs": [],
   "source": [
    "REPLICA_COUNT = 2\n",
    "WORKER_MACHINE_TYPE = \"a2-highgpu-4g\"\n",
    "ACCELERATOR_TYPE = \"NVIDIA_TESLA_A100\"\n",
    "PER_MACHINE_ACCELERATOR_COUNT = 4\n",
    "PER_REPLICA_BATCH_SIZE = 32\n",
    "\n",
    "REDUCTION_SERVER_COUNT = 4\n",
    "REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "254ff1d16134"
   },
   "source": [
    "调整 MNLI 实验设置\n",
    "\n",
    "MNLI 微调实验的默认设置已经在之前步骤中创建的 YAML 配置文件中进行了配置。要覆盖特定训练运行的默认设置，请使用 `--params_override` 标志。\n",
    "\n",
    "`params_override` 接受一个包含每个要覆盖的参数的逗号分隔键/值对的字符串。\n",
    "\n",
    "在下一个单元格中，您可以更新以下设置：\n",
    "\n",
    "- `trainer.train_step` - 训练步数。\n",
    "- `trainer.steps_per_loop` - 训练脚本每 `steps_per_loop` 打印出关于训练进度的更新。\n",
    "- `trainer.summary_interval` - 训练脚本每 `summary_interval` 记录 Tensorboard 摘要。\n",
    "- `trainer.validation_interval` - 训练脚本每 `validation_interval` 运行一次验证。\n",
    "- `trainer.checkpoint_interval` - 训练脚本每 `checkpoint_interval` 创建一个检查点。\n",
    "- `task.train_data.global_batch_size` - 训练数据的全局批量大小。\n",
    "- `task.validation_data.global_batch_size` - 验证数据的全局批量大小。\n",
    "- `task.train_data.input_path` - 训练数据集的位置。\n",
    "- `task.validation_data.input_path` - 验证数据集的位置。\n",
    "- `runtime.num_gpus` - 每个工作节点要使用的 GPU 数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f3c4229ce93"
   },
   "outputs": [],
   "source": [
    "PARAMS_OVERRIDE = \",\".join(\n",
    "    [\n",
    "        \"trainer.train_steps=2000\",\n",
    "        \"trainer.steps_per_loop=100\",\n",
    "        \"trainer.summary_interval=100\",\n",
    "        \"trainer.validation_interval=2000\",\n",
    "        \"trainer.checkpoint_interval=2000\",\n",
    "        \"task.train_data.global_batch_size=\"\n",
    "        + str(REPLICA_COUNT * PER_REPLICA_BATCH_SIZE * PER_MACHINE_ACCELERATOR_COUNT),\n",
    "        \"task.validation_data.global_batch_size=\"\n",
    "        + str(REPLICA_COUNT * PER_REPLICA_BATCH_SIZE * PER_MACHINE_ACCELERATOR_COUNT),\n",
    "        \"task.train_data.input_path=\" + TRAIN_FILE,\n",
    "        \"task.validation_data.input_path=\" + EVAL_FILE,\n",
    "        \"runtime.num_gpus=\" + str(PER_MACHINE_ACCELERATOR_COUNT),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1b92d8c86d8"
   },
   "source": [
    "### 提交和监控作业\n",
    "\n",
    "在实验和工作人员池配置参数已经定义好之后，使用 Python 的 Vertex SDK 来提交和监控训练作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dd69814c1d5"
   },
   "outputs": [],
   "source": [
    "JOB_NAME = \"MNLI_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "MODEL_DIR = f\"{BUCKET_NAME}/{JOB_NAME}/model\"\n",
    "\n",
    "WORKER_CMD = [\"python\", \"trainer/train.py\"]\n",
    "WORKER_ARGS = [\n",
    "    \"--experiment=bert/sentence_prediction\",\n",
    "    \"--mode=train\",\n",
    "    \"--model_dir=\" + MODEL_DIR,\n",
    "    \"--config_file=trainer/glue_mnli_matched.yaml\",\n",
    "    \"--params_override=\" + PARAMS_OVERRIDE,\n",
    "]\n",
    "\n",
    "worker_pool_specs = prepare_worker_pool_specs(\n",
    "    image_uri=TRAIN_IMAGE,\n",
    "    args=WORKER_ARGS,\n",
    "    cmd=WORKER_CMD,\n",
    "    replica_count=REPLICA_COUNT,\n",
    "    machine_type=WORKER_MACHINE_TYPE,\n",
    "    accelerator_count=PER_MACHINE_ACCELERATOR_COUNT,\n",
    "    accelerator_type=ACCELERATOR_TYPE,\n",
    "    reduction_server_count=REDUCTION_SERVER_COUNT,\n",
    "    reduction_server_machine_type=REDUCTION_SERVER_MACHINE_TYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caeb74cdba20"
   },
   "outputs": [],
   "source": [
    "job = aiplatform.CustomJob(\n",
    "    display_name=JOB_NAME,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    ")\n",
    "job.run(sync=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于本教程的[Google Cloud 项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在本教程中创建的各个资源："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "# Delete Cloud Storage objects that were created\n",
    "! gsutil -m rm -r {BUCKET_NAME}\n",
    "\n",
    "# Delete the training job\n",
    "delete_training_job = True\n",
    "job.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "distributed-training-reduction-server.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
