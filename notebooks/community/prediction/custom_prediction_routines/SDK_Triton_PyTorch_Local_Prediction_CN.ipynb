{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/prediction/custom_prediction_routines/SDK_Triton_PyTorch_Local_Prediction.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/prediction/custom_prediction_routines/SDK_Triton_PyTorch_Local_Prediction.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何使用Vertex AI SDK本地测试[NVIDIA Triton推理服务器](https://developer.nvidia.com/nvidia-triton-inference-server)，以提供PyTorch模型并将其部署到Vertex AI Predictions。\n",
    "\n",
    "\n",
    "### 数据集\n",
    "\n",
    "本教程使用R.A. Fisher的鸢尾花数据集，这是一个小数据集，非常流行用于尝试机器学习技术。每个实例具有四个数值特征，这些特征是对花的不同测量，以及一个目标标签，将其标记为三种类型的鸢尾花之一：山鸢尾、变色鸢尾或维吉尼亚鸢尾。\n",
    "\n",
    "本教程使用[鸢尾花数据集](https://archive.ics.uci.edu/ml/machine-learning-databases/iris)。\n",
    "\n",
    "\n",
    "### 目标\n",
    "\n",
    "目标是：\n",
    "- 使用花的测量作为输入训练一个PyTorch模型，以预测其是什么类型的鸢尾花。\n",
    "- 保存模型。\n",
    "- 本地测试NVIDIA Triton推理服务器。\n",
    "- 将Triton推理服务器作为自定义容器上传并部署到Vertex Prediction。\n",
    "\n",
    "本教程更侧重于使用Vertex AI部署此模型，而不是设计模型本身。\n",
    "\n",
    "\n",
    "### 成本\n",
    "\n",
    "本教程使用Google Cloud的收费组件：\n",
    "\n",
    "* Vertex AI\n",
    "\n",
    "了解[Vertex AI定价](https://cloud.google.com/vertex-ai/pricing)，并使用[定价计算器](https://cloud.google.com/products/calculator/)根据您的预期使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ze4-nDLfK4pw"
   },
   "source": [
    "### 设置您的本地开发环境\n",
    "\n",
    "**如果您正在使用Vertex AI工作台笔记本**，则您的环境已满足运行此笔记本的所有要求。您可以跳过此步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCuSR8GkAgzl"
   },
   "source": [
    "否则，请确保您的环境符合此笔记本的要求。\n",
    "您需要以下内容：\n",
    "\n",
    "* Docker\n",
    "* Git\n",
    "* Google Cloud SDK （gcloud）\n",
    "* Python 3\n",
    "* virtualenv\n",
    "* 在使用 Python 3 的虚拟环境中运行的 Jupyter 笔记本\n",
    "\n",
    "Google Cloud 的 [设置 Python 开发环境指南](https://cloud.google.com/python/setup) 和 [Jupyter 安装指南](https://jupyter.org/install) 提供了满足这些要求的详细说明。以下步骤提供了一套简洁的说明：\n",
    "\n",
    "1. [安装并初始化 Cloud SDK。](https://cloud.google.com/sdk/docs/)\n",
    "\n",
    "1. [安装 Python 3。](https://cloud.google.com/python/setup#installing_python)\n",
    "\n",
    "1. [安装 virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv) 并创建一个使用 Python 3 的虚拟环境。激活虚拟环境。\n",
    "\n",
    "1. 要安装 Jupyter，在终端 shell 中的命令行中运行 `pip install jupyter`。\n",
    "\n",
    "1. 要启动 Jupyter，在终端 shell 的命令行中运行 `jupyter notebook`。\n",
    "\n",
    "1. 在 Jupyter Notebook 仪表板中打开此笔记本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### 安装额外的包\n",
    "\n",
    "安装在您的笔记本环境中未安装的附加包依赖项，例如 NumPy、Scikit-learn、FastAPI、Uvicorn 和 joblib。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6d0fb1cd95f4"
   },
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "pandas\n",
    "torch==1.11.0\n",
    "google-cloud-storage>=1.26.0,<2.0.0dev\n",
    "google-cloud-aiplatform[prediction]>=1.16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "356f45ac7942"
   },
   "source": [
    "你部署的模型将预先安装了一组与笔记本环境不同的依赖项。你不应该假设因为笔记本里的功能正常运行，它们也会在模型中正常工作。相反，你应该通过在requirements.txt中列出依赖项，然后使用`pip install`来在笔记本中安装完全相同的依赖项。当然，请注意，有可能你在requirements.txt中漏掉了笔记本中已存在的依赖项。如果是这种情况，功能将在笔记本中运行，但在模型中不会。为了防范这种情况，在部署到云端之前，你将在本地测试模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7cbec0adc49"
   },
   "outputs": [],
   "source": [
    "# Install the same dependencies used in the serving container in the notebook\n",
    "# environment.\n",
    "%pip install -U --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhq5zEbGg0XX"
   },
   "source": [
    "重新启动内核\n",
    "\n",
    "在安装了额外包之后，你需要重新启动笔记本的内核，这样它才能找到这些包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1464805870e"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWEdiXsJg0XY"
   },
   "source": [
    "在你开始之前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64a0a87c5b66"
   },
   "source": [
    "### 在这个示例中设置日志记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "348ca5392459"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "### 设置您的Google Cloud项目\n",
    "\n",
    "**无论您使用的是哪种笔记本环境，以下步骤都是必需的。**\n",
    "\n",
    "1. [选择或创建一个Google Cloud项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建帐户时，您将获得$300的免费信用用于计算/存储成本。\n",
    "\n",
    "1. [确保您的项目已启用计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "1. [启用Vertex AI API和Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component)。\n",
    "\n",
    "1. 如果您是在本地运行此笔记本，则需要安装[Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "1. 在下面的单元格中输入您的项目ID。然后运行该单元格以确保\n",
    "Cloud SDK在本笔记本中的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter会将以`!`或`%`开头的行视为shell命令，并将Python变量插入这些命令中的`$`或`{}`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以使用 `gcloud` 获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"\"\n",
    "\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJYoRfYng0XZ"
   },
   "source": [
    "否则，请在这里设置您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riG_qUokg0XZ"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
    "    PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "## 区域\n",
    "\n",
    "您还可以更改 `REGION` 变量，该变量用于此笔记本其余部分的操作。以下是Vertex AI支持的区域。我们建议您选择距离您最近的区域。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太地区：`asia-east1`\n",
    "\n",
    "您可能不会使用多区域存储桶来训练Vertex AI。并非所有区域都支持所有Vertex AI服务。\n",
    "\n",
    "了解有关[Vertex AI区域](https://cloud.google.com/vertex-ai/docs/general/locations)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf"
   },
   "source": [
    "###配置项目和资源名称"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUISYGKYuO6D"
   },
   "source": [
    "如果您在直播教程会话中，您可能会使用一个共享的测试帐户或项目。为了避免用户在创建的资源之间发生名称冲突，您需要为每个实例会话创建一个时间戳，并将其附加到您在本教程中创建的资源的名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0-_FM9ZuJRG"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xgn_h2xRuJ1h"
   },
   "source": [
    "配置GCP资源名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "MODEL_ARTIFACT_DIR = \"triton-pytorch\"  # @param {type:\"string\"}\n",
    "REPOSITORY = \"custom-container-prediction-sdk\"  # @param {type:\"string\"}\n",
    "IMAGE = \"triton-pytorch\"  # @param {type:\"string\"}\n",
    "MODEL_DISPLAY_NAME = \"triton-pytorch\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ca1a915d641d"
   },
   "source": [
    "`MODEL_ARTIFACT_DIR` - 在云存储桶中指向模型工件的文件夹目录路径，例如：\"my-models/fraud-detection/trial-4\"\n",
    "\n",
    "`REPOSITORY` - 要创建或使用的工件存储库的名称。\n",
    "\n",
    "`IMAGE` - 将要推送的容器映像的名称。\n",
    "\n",
    "`MODEL_DISPLAY_NAME` - Vertex AI 模型资源的显示名称。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "**无论你使用什么笔记本环境，都需要按照以下步骤进行。**\n",
    "\n",
    "如果要更新模型工件而不重新构建容器，您必须将模型工件和任何自定义代码上传到云存储中。\n",
    "\n",
    "在下面设置您的云存储桶的名称。它必须在所有云存储桶中是唯一的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hODsLSwV6We"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cf221059d072"
   },
   "outputs": [],
   "source": [
    "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"[your-bucket-name]\":\n",
    "    BUCKET_NAME = PROJECT_ID + \"-aip-\" + TIMESTAMP\n",
    "    BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "只有在您的存储桶不存在时才运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucvCsknMCims"
   },
   "source": [
    "最后，通过检查云存储桶的内容来验证访问权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhOb7YnwClBb"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c2d091d9e73"
   },
   "source": [
    "建立目录."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCou_jfQV6Wg"
   },
   "source": [
    "决定放置模型工件的目录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3njoTraV6Wg"
   },
   "outputs": [],
   "source": [
    "LOCAL_MODEL_ARTIFACTS_DIR = \"model_artifacts\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6e74556ea0b4"
   },
   "outputs": [],
   "source": [
    "%mkdir $LOCAL_MODEL_ARTIFACTS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8b6a08d0d97"
   },
   "source": [
    "## 训练一个 PyTorch 模型\n",
    "\n",
    "### 下载鸢尾花数据\n",
    "在这个例子中，你想要为简单的[鸢尾花数据集](https://archive.ics.uci.edu/ml/datasets/iris)构建一个分类器。因此，首先你需要将数据的 csv 文件下载到本地。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2d231f9e522"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"data_iris\"\n",
    "\n",
    "%mkdir $DATA_DIR\n",
    "\n",
    "LOCAL_DATA_FILE = f\"{DATA_DIR}/iris.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86cda068907b"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "urlretrieve(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\",\n",
    "    LOCAL_DATA_FILE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "059236726bb9"
   },
   "source": [
    "构建一个PyTorch神经网络分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4b816cd52f4b"
   },
   "source": [
    "确保已安装PyTorch软件包。[点击此处安装](https://pytorch.org/get-started/locally/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43e47249f736"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "print(\"PyTorch Version: {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6732994d86ef"
   },
   "source": [
    "#### 步骤 1. 加载数据\n",
    "\n",
    "在这一步中，你需要：\n",
    "1. 将数据加载到 Pandas 数据框中。\n",
    "2. 将类别特征（种类）从字符串转换为数值指示器。\n",
    "3. 将数据框分割为输入特征（xtrain）和目标特征（ytrain）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6259129f102c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CLASS_VOCAB = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "\n",
    "datatrain = pd.read_csv(\n",
    "    LOCAL_DATA_FILE,\n",
    "    names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"],\n",
    ")\n",
    "\n",
    "# change string value to numeric\n",
    "datatrain.loc[datatrain[\"species\"] == \"Iris-setosa\", \"species\"] = 0\n",
    "datatrain.loc[datatrain[\"species\"] == \"Iris-versicolor\", \"species\"] = 1\n",
    "datatrain.loc[datatrain[\"species\"] == \"Iris-virginica\", \"species\"] = 2\n",
    "datatrain = datatrain.apply(pd.to_numeric)\n",
    "\n",
    "# change dataframe to array\n",
    "datatrain_array = datatrain.values\n",
    "\n",
    "# split x and y (feature and target)\n",
    "xtrain = datatrain_array[:, :4]\n",
    "ytrain = datatrain_array[:, 4]\n",
    "\n",
    "input_features = xtrain.shape[1]\n",
    "num_classes = len(CLASS_VOCAB)\n",
    "\n",
    "print(\"Records loaded: {}\".format(len(xtrain)))\n",
    "print(\"Number of input features: {}\".format(input_features))\n",
    "print(\"Number of classes: {}\".format(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1fb3cfa67a2"
   },
   "source": [
    "第二步。设置模型参数\n",
    "您可以尝试不同的值来调整**hidden_units**或**learning_rate**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b964ab7b0826"
   },
   "outputs": [],
   "source": [
    "HIDDEN_UNITS = 10\n",
    "LEARNING_RATE = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83767e4aa8ec"
   },
   "source": [
    "步骤3. 定义PyTorch神经网络模型\n",
    "在这里，您建立一个具有一个隐藏层和一个Softmax输出层用于分类的神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "665b1a79e813"
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_features, HIDDEN_UNITS),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(HIDDEN_UNITS, num_classes),\n",
    "    torch.nn.Softmax(),\n",
    ")\n",
    "\n",
    "loss_metric = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e74dd9676f18"
   },
   "source": [
    "步骤4. 训练模型\n",
    "您将训练模型进行 **num_epoch** 个周期。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ff929fcd864"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10000\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    x = Variable(torch.Tensor(xtrain).float())\n",
    "    y = Variable(torch.Tensor(ytrain).long())\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = loss_metric(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch) % 1000 == 0:\n",
    "        print(\n",
    "            \"Epoch [{}/{}] Loss: {}\".format(\n",
    "                epoch + 1, NUM_EPOCHS, round(loss.item(), 3)\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(\"Epoch [{}/{}] Loss: {}\".format(epoch + 1, NUM_EPOCHS, round(loss.item(), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb6f316f99ea"
   },
   "source": [
    "步骤5. 保存模型\n",
    "\n",
    "Triton推理服务器要求将PyTorch模型保存为[TorchScript格式](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18db4fa0de42"
   },
   "outputs": [],
   "source": [
    "# An example input you would normally provide to your model's forward() method.\n",
    "example = torch.rand(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "504874630adf"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"pytorch\"\n",
    "LOCAL_MODEL_DIRECTORY = f\"{LOCAL_MODEL_ARTIFACTS_DIR}/{MODEL_NAME}\"\n",
    "LOCAL_MODEL_VERSION_1 = f\"{LOCAL_MODEL_DIRECTORY}/1\"\n",
    "\n",
    "%mkdir $LOCAL_MODEL_DIRECTORY\n",
    "%mkdir $LOCAL_MODEL_VERSION_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7f95dcdd29d9"
   },
   "outputs": [],
   "source": [
    "LOCAL_MODEL_FILE = f\"{LOCAL_MODEL_VERSION_1}/model.pt\"\n",
    "\n",
    "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "traced_script_module = torch.jit.trace(model, example)\n",
    "\n",
    "# Save the TorchScript model\n",
    "traced_script_module.save(LOCAL_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40d0d3e86a2f"
   },
   "source": [
    "#### 第六步。测试加载的TorchScript模型进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c260e0606bcd"
   },
   "outputs": [],
   "source": [
    "iris_classifier = torch.jit.load(LOCAL_MODEL_FILE)\n",
    "\n",
    "\n",
    "def predict_class(instances):\n",
    "    instances = torch.Tensor(instances)\n",
    "    output = iris_classifier(instances)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    return predicted\n",
    "\n",
    "\n",
    "predicted = predict_class(xtrain[0:5])\n",
    "print([CLASS_VOCAB[class_index] for class_index in predicted])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7781d51a090"
   },
   "source": [
    "准备 Triton 模型配置\n",
    "\n",
    "[model 仓库](https://github.com/triton-inference-server/server/blob/main/docs/model_repository.md) 中的每个模型都必须包括一个[model 配置](https://github.com/triton-inference-server/server/blob/main/docs/model_configuration.md)，提供有关模型的必需和可选信息。Triton 后端是执行模型的实现，可以是深度学习框架的包装器。只要符合[后端 API](https://github.com/triton-inference-server/backend/blob/main/README.md#triton-backend-api)，后端还可以实现任何您想要的功能。Triton 使用这个 API 向后端发送执行请求，后端使用 API 与 Triton 通信。每个模型都必须与后端关联。模型的后端在模型配置中使用`backend`和`platform`设置来指定。\n",
    "\n",
    "[要加载 PyTorch 模型](https://github.com/triton-inference-server/backend/blob/main/README.md#backends)，模型配置需要将`backend`和`platform`设置为`pytorch`和`pytorch_libtorch`。PyTorch 后端也有[特殊约定](https://github.com/triton-inference-server/server/blob/main/docs/model_configuration.md)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05da1e885e08"
   },
   "outputs": [],
   "source": [
    "%%writefile $LOCAL_MODEL_DIRECTORY/config.pbtxt\n",
    "backend: \"pytorch\"\n",
    "platform: \"pytorch_libtorch\"\n",
    "max_batch_size: 8\n",
    "input {\n",
    "    name: \"INPUT__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 4 ]\n",
    "}\n",
    "output {\n",
    "    name: \"OUTPUT__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1 ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd"
   },
   "source": [
    "## 将模型工件上传到云存储\n",
    "\n",
    "在您部署模型进行服务之前，Vertex AI 需要访问 Cloud Storage 中的以下文件：\n",
    "\n",
    "* `model.pt`（模型工件）\n",
    "* `config.pbtxt`（模型配置）\n",
    "\n",
    "运行以下命令来上传您的文件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ca67ee52d4d9"
   },
   "outputs": [],
   "source": [
    "!gsutil cp -r {LOCAL_MODEL_ARTIFACTS_DIR}/* {BUCKET_URI}/{MODEL_ARTIFACT_DIR}/\n",
    "!gsutil ls {BUCKET_URI}/{MODEL_ARTIFACT_DIR}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "490ee68c86c4"
   },
   "source": [
    "使用NVIDIA Triton推理服务器\n",
    "\n",
    "使用NVIDIA Triton推理服务器初始化本地模型。在本教程中，您将使用[NVIDIA Triton推理服务器](https://developer.nvidia.com/nvidia-triton-inference-server)来提供PyTorch模型。图像托管在`nvcr.io`上，并且所有发布的标签都可以在[此链接](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver/tags)中找到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63e14c94ed75"
   },
   "outputs": [],
   "source": [
    "TRITON_VERSION = \"21.08\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a039b5368233"
   },
   "source": [
    "通过自定义预测程序功能，Vertex AI SDK允许您加载现有的图像进行本地测试，然后轻松部署到Vertex AI预测中。\n",
    "\n",
    "要在Vertex AI上使用Triton推理服务器，您需要设置所需的参数，如预测路由、健康路由、端口和参数。默认情况下，Triton监听端口 `8000` 上的HTTP请求。可以在这里找到Triton的快速入门：[链接](https://github.com/triton-inference-server/server/blob/main/docs/quickstart.md#run-triton)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "697b4a2bb11e"
   },
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform.prediction import LocalModel\n",
    "\n",
    "local_model = LocalModel(\n",
    "    serving_container_image_uri=f\"nvcr.io/nvidia/tritonserver:{TRITON_VERSION}-py3\",\n",
    "    serving_container_predict_route=f\"/v2/models/{MODEL_NAME}/infer\",\n",
    "    serving_container_health_route=f\"/v2/models/{MODEL_NAME}\",\n",
    "    serving_container_ports=[8000],\n",
    "    serving_container_args=[\"tritonserver\", \"--model-repository=$(AIP_STORAGE_URI)\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "155e6838aa70"
   },
   "source": [
    "你可以查看图片中的服务容器规格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6c427921a9ce"
   },
   "outputs": [],
   "source": [
    "local_model.get_serving_container_spec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b62ddf1def3"
   },
   "source": [
    "### 保存测试实例\n",
    "\n",
    "要了解如何在JSON中格式化输入实例，[阅读文档。](https://cloud.google.com/vertex-ai/docs/predictions/online-predictions-custom-models#request-body-details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7d93f7e01e04"
   },
   "outputs": [],
   "source": [
    "INPUT_FILE = \"instances.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6605e9e6186"
   },
   "outputs": [],
   "source": [
    "%%writefile $INPUT_FILE\n",
    "{\n",
    "    \"id\": \"0\",\n",
    "    \"inputs\": [\n",
    "        {\n",
    "            \"name\": \"INPUT__0\",\n",
    "            \"shape\": [2, 4],\n",
    "            \"datatype\": \"FP32\",\n",
    "            \"data\": [[6.7, 3.1, 4.7, 1.5], [4.6, 3.1, 1.5, 0.2]]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87f8d4d7a9f6"
   },
   "source": [
    "### 本地运行和测试容器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a213b08fcf4"
   },
   "source": [
    "自定义预测例程提供两种方法来下载模型工件，以便在本地测试图像。\n",
    "1. 本地路径。\n",
    "2. GCS路径。\n",
    "\n",
    "要使用本地路径，您的“Predictor”需要支持加载模型的两种方式，以便在本地进行测试并部署到Vertex AI预测服务。SDK提供了一个名为`download_model_artifacts`的方法在[prediction_utils.py](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/utils/prediction_utils.py)中支持这两种方式，您可以在`Predictor`中的`load`函数中调用该方法。\n",
    "\n",
    "如果要使用GCS路径在本地测试图像，您需要按照说明设置凭据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8phJWBhe7u9u"
   },
   "source": [
    "设置凭证\n",
    "\n",
    "设置凭证仅在本地使用GCS路径运行自定义服务容器时才需要。设置凭证是执行“预测者”中的“加载”函数所必需的，该函数会从Google Cloud Storage下载模型工件。\n",
    "\n",
    "要访问项目中的Google Cloud Storage，您需要通过以下方式之一设置凭证：\n",
    "\n",
    "1.用户账号\n",
    "\n",
    "2. 服务账号\n",
    "\n",
    "您可以在[这里](https://cloud.google.com/docs/authentication#principals)了解更多关于以上每种方式的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5261966581d2"
   },
   "source": [
    "选项1. 使用Google用户凭据\n",
    "\n",
    "首先授权Google auth库使用Google用户凭据访问Cloud平台。这一步涉及一个交互式提示，需要用户输入。如果您正在使用非交互式shell，您应该打开一个终端来运行这个命令。请参阅[这里](https://jupyterlab.readthedocs.io/en/stable/user/terminal.html)了解在Vertex Workbench笔记本环境中如何打开终端。\n",
    "\n",
    "请注意，如果您在没有窗口管理器/浏览器的计算机上运行下面的命令，它会提示您运行命令`gcloud auth application-default login --remote-bootstrap=\"...\"`。只有可以启动网络浏览器的计算机，例如笔记本电脑或工作站，才被允许运行这个命令。在使用浏览器完成验证步骤之后，您需要将验证代码复制粘贴回原始终端以继续登录流程。如果您在支持网络浏览器的计算机上运行这个命令，就不需要使用单独的计算机。\n",
    "\n",
    "这个命令会将凭据文件打印为`Credentials saved to file: [CREDENTIALS_FILE]`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2f9d26108e4c"
   },
   "outputs": [],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90808ec3bb54"
   },
   "source": [
    "指定凭证文件，该文件是一个json文件，作为路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "816b9864614c"
   },
   "outputs": [],
   "source": [
    "CREDENTIALS_FILE = \"[CREDENTIALS_FILE]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfba3a7a8907"
   },
   "source": [
    "接下来，授权gcloud使用Google用户凭据访问Cloud平台。用户凭证需要在项目中具有`setIamPolicy`权限。有关更多详细信息，请参阅[此处](https://cloud.google.com/resource-manager/docs/access-control-proj)。\n",
    "\n",
    "与之前的步骤类似，这也需要用户输入。之前步骤的说明同样适用于这里。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfe6dae6464c"
   },
   "outputs": [],
   "source": [
    "!gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff5fc2640fff"
   },
   "source": [
    "授予用户帐户角色。使用您在gcloud auth步骤中使用的电子邮件地址，例如`myemail@gmail.com`。由于您将使用此用户帐户从Google Cloud Storage下载模型工件，因此您授予用户帐户**Storage Object Viewer**角色。有关更多详细信息，请参阅[Cloud Storage的IAM角色](https://cloud.google.com/storage/docs/access-control/iam-roles)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15e6a2d55290"
   },
   "outputs": [],
   "source": [
    "USER_ACCOUNT = \"[USER_ACCOUNT]\"  # @param {type:\"string\"}\n",
    "\n",
    "!gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "    --member=user:$USER_ACCOUNT --role=roles/storage.objectViewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49516700e7fd"
   },
   "source": [
    "使用项目 ID 初始化 Vertex AI SDK，这是使用用户凭据所必需的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a919f3d1a0e7"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23907a99baa7"
   },
   "source": [
    "选项2. 使用Google服务账号凭据\n",
    "\n",
    "如果您已经完成了上面的选项1，请跳过这一步。如果IAM API尚未启用，请首先启用它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mERTlLb6dluB"
   },
   "outputs": [],
   "source": [
    "!gcloud services enable iam.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "set_service_account"
   },
   "source": [
    "服务账号\n",
    "\n",
    "在本地运行容器时，您可以使用服务帐号来下载模型构件。如果您不想使用项目的计算引擎服务帐号，请将`SERVICE_ACCOUNT`设置为另一个服务帐号ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hs-_LvqHV6Wo"
   },
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = \"[your-service-account]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_service_account"
   },
   "outputs": [],
   "source": [
    "if (\n",
    "    SERVICE_ACCOUNT == \"\"\n",
    "    or SERVICE_ACCOUNT is None\n",
    "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
    "):\n",
    "    # Get your service account from gcloud\n",
    "    if not IS_COLAB:\n",
    "        shell_output = !gcloud auth list 2>/dev/null\n",
    "        SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\n",
    "\n",
    "    else:  # IS_COLAB:\n",
    "        shell_output = ! gcloud projects describe  $PROJECT_ID\n",
    "        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
    "        SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
    "\n",
    "    print(\"Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c57086a991ef"
   },
   "source": [
    "创建服务账号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aec4edb3bb32"
   },
   "outputs": [],
   "source": [
    "!gcloud iam service-accounts create $SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9676dfef3d3b"
   },
   "source": [
    "授权gcloud使用Google用户凭据访问Cloud Platform。用户凭据需要在项目中具有`setIamPolicy`权限。更多详情请参见[此链接](https://cloud.google.com/resource-manager/docs/access-control-proj)。\n",
    "\n",
    "这一步涉及互动提示，需要用户输入。如果您正在使用非互动shell，您应该打开终端来运行此命令。请参见[此链接](https://jupyterlab.readthedocs.io/en/stable/user/terminal.html)了解如何在Vertex Workbench笔记本环境中打开终端。\n",
    "\n",
    "请注意，如果您在没有窗口管理器/浏览器的机器上运行下面的命令，它将提示您运行命令`gcloud auth application-default login --remote-bootstrap=\"...\"`。只有可以启动Web浏览器的机器，例如笔记本电脑或工作站，才允许运行此命令。完成使用浏览器的身份验证步骤后，您需要将验证代码复制并粘贴回原始终端以继续登录流程。如果您在有Web浏览器支持的机器上运行此命令，则无需使用单独的机器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afca052d7d07"
   },
   "outputs": [],
   "source": [
    "!gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3017a89b1e05"
   },
   "source": [
    "将角色授予服务帐户。由于您将使用此服务帐户从Google云存储中下载模型文件，因此您应授予服务帐户**Storage Object Viewer**角色。有关更多详情，请参阅[Cloud Storage的IAM角色](https://cloud.google.com/storage/docs/access-control/iam-roles)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11ee24d335bf"
   },
   "outputs": [],
   "source": [
    "!gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "    --member=serviceAccount:{SERVICE_ACCOUNT}@{PROJECT_ID}.iam.gserviceaccount.com \\\n",
    "    --role=roles/storage.objectViewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d65aba7673b"
   },
   "source": [
    "指定服务账号密钥文件名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e4dea3da627"
   },
   "outputs": [],
   "source": [
    "CREDENTIALS_FILE = \"./credentials.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62b7259652b3"
   },
   "source": [
    "生成服务账号密钥文件。在本地运行自定义服务容器时将使用此文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bb3770c1ec1"
   },
   "outputs": [],
   "source": [
    "!gcloud iam service-accounts keys create $CREDENTIALS_FILE \\\n",
    "    --iam-account=\"{SERVICE_ACCOUNT}@{PROJECT_ID}.iam.gserviceaccount.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJe8TCr4ec4F"
   },
   "source": [
    "#### 在本地运行并发送请求到容器\n",
    "\n",
    "通过自定义预测例程功能，可以很容易地在本地测试容器。\n",
    "\n",
    "在这个例子中，容器执行一个预测请求和一个健康检查。\n",
    "\n",
    "注意：第一次运行以下命令会有点慢，因为您需要从`nvcr.io`拉取图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84d432d67e2b"
   },
   "source": [
    "选项1. 通过本地路径传递\n",
    "\n",
    "该选项要求`Predictor`中的`load`函数支持从GCS路径和本地路径加载模型文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62ed2d334d0f"
   },
   "outputs": [],
   "source": [
    "with local_model.deploy_to_local_endpoint(\n",
    "    artifact_uri=f\"{LOCAL_MODEL_ARTIFACTS_DIR}\",\n",
    ") as local_endpoint:\n",
    "    predict_response = local_endpoint.predict(\n",
    "        request_file=INPUT_FILE,\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "\n",
    "    health_check_response = local_endpoint.run_health_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "236e1704871d"
   },
   "source": [
    "打印出预测的响应以及其内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce629eea32fd"
   },
   "outputs": [],
   "source": [
    "print(predict_response, predict_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bf6c7d044bc"
   },
   "source": [
    "将健康检查的响应和内容打印出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56986f93438e"
   },
   "outputs": [],
   "source": [
    "print(health_check_response, health_check_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a29fcbbe0188"
   },
   "source": [
    "也打印出所有容器日志。您将看到容器启动、处理请求和容器关闭的日志。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cd47d55bbd0"
   },
   "outputs": [],
   "source": [
    "local_endpoint.print_container_logs(show_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e16789f2025b"
   },
   "source": [
    "选项2. 传递GCS路径\n",
    "\n",
    "如果你想传递GCS路径，你需要在之前的步骤中设置好凭证，并且在运行容器时传递路径给凭证。服务账户应该拥有**存储对象查看者**权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5f3af366697"
   },
   "outputs": [],
   "source": [
    "with local_model.deploy_to_local_endpoint(\n",
    "    artifact_uri=f\"{BUCKET_URI}/{MODEL_ARTIFACT_DIR}\",\n",
    "    credential_path=CREDENTIALS_FILE,\n",
    ") as local_endpoint:\n",
    "    predict_response = local_endpoint.predict(\n",
    "        request_file=INPUT_FILE,\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "\n",
    "    health_check_response = local_endpoint.run_health_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "120d9382c22f"
   },
   "source": [
    "打印出预测的响应及其内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDhahk8jV6Wr"
   },
   "outputs": [],
   "source": [
    "print(predict_response, predict_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfe9c701b0e8"
   },
   "source": [
    "打印出健康检查的响应和内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53PJx1DaV6Ws"
   },
   "outputs": [],
   "source": [
    "print(health_check_response, health_check_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9WZtEYPV6Ws"
   },
   "source": [
    "也打印出所有容器日志。您将看到容器启动、请求处理和容器关闭的日志。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d312a6136b56"
   },
   "outputs": [],
   "source": [
    "local_endpoint.print_container_logs(show_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d713c4cc90b4"
   },
   "source": [
    "### 将图像URI更改为Artifact Registry\n",
    "\n",
    "由于Vertex AI Prediction当前不支持`nvcr.io`存储库，因此您需要将图像复制到Artifact Registry。您可以使用复制的图像轻松启动另一个本地模型实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0e7e847b15b5"
   },
   "outputs": [],
   "source": [
    "local_model_ar = local_model.copy_image(\n",
    "    f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60ea52c3bc5b"
   },
   "source": [
    "打印出新的Local 模型实例的服务容器规范。图像的 URI 应更改为 Artifact Registry。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c46cc423b8ee"
   },
   "outputs": [],
   "source": [
    "local_model_ar.get_serving_container_spec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "212b2935ea12"
   },
   "source": [
    "将容器推送到工件注册表\n",
    "\n",
    "配置Docker以访问工件注册表。然后将您的容器镜像推送到您的工件注册表存储库。\n",
    "\n",
    "打印出项目中所有已启用的服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSFXCj3LdluJ"
   },
   "outputs": [],
   "source": [
    "!gcloud services list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABE9UpwSdluK"
   },
   "source": [
    "如果您的项目中未启用`artifactregistry.googleapis.com`，请在继续之前启用该API。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDhLoQMydluK"
   },
   "outputs": [],
   "source": [
    "!gcloud services enable artifactregistry.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09ffe2434e3d"
   },
   "outputs": [],
   "source": [
    "!gcloud artifacts repositories create {REPOSITORY} \\\n",
    "    --repository-format=docker \\\n",
    "    --location=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "293437024749"
   },
   "outputs": [],
   "source": [
    "!gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "873892f3dbc7"
   },
   "source": [
    "使用SDK推送图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dd7448f4703"
   },
   "outputs": [],
   "source": [
    "local_model_ar.push_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b438bfa2129f"
   },
   "source": [
    "部署到Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ae19df6a33e"
   },
   "source": [
    "### 上传NVIDIA Triton推理服务器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8d682d8388ec"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "574fb82d3eed"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4879e61a1978"
   },
   "source": [
    "使用LocalModel实例来上传模型。它会自动为您填充容器规范。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2738154345d5"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    local_model=local_model_ar,\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=f\"{BUCKET_URI}/{MODEL_ARTIFACT_DIR}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd1b85afc7df"
   },
   "source": [
    "### 在 Vertex AI 上部署模型\n",
    "完成此步骤后，模型已部署并准备好进行在线预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62cf66498a28"
   },
   "outputs": [],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6883e7b07143"
   },
   "source": [
    "发送预测\n",
    "\n",
    "需要使用[原始预测](https://cloud.google.com/sdk/gcloud/reference/ai/endpoints/raw-predict)来发送任意有效负载。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "356d9ee4f53d"
   },
   "source": [
    "使用REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ddd5e816996"
   },
   "outputs": [],
   "source": [
    "ENDPOINT_ID = endpoint.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ad52431aecc"
   },
   "outputs": [],
   "source": [
    "! curl \\\n",
    "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "--data-binary @$INPUT_FILE \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{REGION}/endpoints/{ENDPOINT_ID}:rawPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于教程的[Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "# Undeploy model and delete endpoint\n",
    "endpoint.delete(force=True)\n",
    "\n",
    "# Delete the model resource\n",
    "model.delete()\n",
    "\n",
    "# Delete the container image from Artifact Registry\n",
    "!gcloud artifacts docker images delete \\\n",
    "    --quiet \\\n",
    "    --delete-tags \\\n",
    "    {REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}\n",
    "\n",
    "delete_bucket = False\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "SDK_Triton_PyTorch_Local_Prediction.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
