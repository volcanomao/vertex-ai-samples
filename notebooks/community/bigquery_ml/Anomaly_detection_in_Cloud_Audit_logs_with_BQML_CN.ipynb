{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "使用BQML检测安全日志中的异常行为\n",
    "\n",
    "在Colab中运行GitHub仓库中的代码\n",
    "\n",
    "在GitHub上查看代码\n",
    "\n",
    "在Vertex AI Workbench中打开笔记本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24743cf4a1e1"
   },
   "source": [
    "**_注意_**: 这个笔记本已在以下环境中测试过：\n",
    "\n",
    "* Python 版本 = 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "这个Colab笔记本展示了如何使用BigQuery ML来检测Cloud Audit日志中的异常。我们将使用两种不同的预先构建的ML模型进行无监督的异常检测，即K均值聚类和自编码器，以帮助我们识别异常值，例如任何用户身份的不常见API使用。在审计日志中识别异常对于云管理员和运营商来说至关重要，以识别从特权升级到API滥用的潜在威胁。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何：\n",
    "\n",
    "* 通过预处理云审计日志应用特征工程技术\n",
    "* 在云审计日志中使用 BigQuery ML 进行无监督异常检测\n",
    "* 训练和评估 ML 模型，如 K-means 聚类和自编码器\n",
    "* 提取和分析异常值\n",
    "\n",
    "本教程使用以下 Google Cloud ML 服务和资源：\n",
    "\n",
    "- BigQuery\n",
    "- 云存储\n",
    "- 日志分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Po3_GwJTcJAb"
   },
   "source": [
    "### 先决条件\n",
    "如果您尚未这样做，唯一的要求是[升级您现有的日志存储桶](https://cloud.google.com/logging/docs/buckets#upgrade-bucket)以使用Log Analytics，这为您提供了一个链接的BigQuery数据集，其中包含您自己可查询的日志数据。这是一个**仅需一次点击步骤而不会产生额外费用**。默认情况下，Cloud Audit Admin活动日志已启用，在每个项目的`_Required`存储桶中摄取和存储，而无需任何费用。\n",
    "\n",
    "![仅需一次点击的先决条件](https://services.google.com/fh/files/misc/upgrade_log_bucket.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08d289fa873f"
   },
   "source": [
    "数据集\n",
    "\n",
    "在这份笔记中，您将分析您自己的云审计日志，例如管理员活动日志，默认情况下在每个谷歌云项目中启用和存储。与合成数据不同，分析您自己的真实数据将为您提供实际的见解，但结果会有所不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aed92deeb4a0"
   },
   "source": [
    "费用\n",
    "\n",
    "本教程使用 Google Cloud 的可计费组件：\n",
    "\n",
    "* BigQuery\n",
    "\n",
    "了解 [BigQuery 定价](https://cloud.google.com/bigquery/pricing) 并使用 [定价计算器](https://cloud.google.com/products/calculator/) 根据您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "## 在开始之前\n",
    "\n",
    "### 设置您的谷歌云项目\n",
    "\n",
    "**无论您使用的是哪种笔记本环境，都需要执行以下步骤。**\n",
    "\n",
    "1. [选择或创建一个谷歌云项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建帐户时，您将获得300美元的免费信用额用于支付计算/存储成本。\n",
    "\n",
    "2. [确保为您的项目启用了计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "3. [启用 BigQuery API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。\n",
    "\n",
    "4. 如果您是在本地运行此笔记本，您需要安装[Cloud SDK](https://cloud.google.com/sdk)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "### 设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下操作：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}\n",
    "%env GOOGLE_CLOUD_PROJECT=$PROJECT_ID\n",
    "!echo project_id = $PROJECT_ID > ~/.bigqueryrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "区域\n",
    "\n",
    "您还可以更改 Vertex AI 使用的 `REGION` 变量。了解有关 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations) 的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERhr_dYSaOYp"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvNw41proyjI"
   },
   "source": [
    "提供项目、BigQuery数据集和存储审计日志的BigQuery表格。您可以从[日志存储页面](https://console.cloud.google.com/logs/storage)找到日志存储桶的关联BigQuery数据集ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJmMKlpgolG_"
   },
   "outputs": [],
   "source": [
    "logSourceProject = \"[your-log-source-project-id]\"  # @param {type:\"string\"} custom\n",
    "logSourceBqDataset = \"[your-log-source-dataset]\"  # @param {type:\"string\"} custom\n",
    "logSourceBqTable = \"[your-log-source-table]\"  # @param {type:\"string\"} custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgGogNfOpC2k"
   },
   "source": [
    "这是存储预处理训练数据集的BigQuery数据集和BigQuery表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2o5lto2fxc9-"
   },
   "outputs": [],
   "source": [
    "BQ_DATASET_NAME = \"bqml_approach\"  # @param {type:\"string\"} custom\n",
    "BQ_TABLE_NAME = \"training_data\"  # @param {type:\"string\"} custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHFuwMb4pVbM"
   },
   "source": [
    "提供BQML模型名称；这些模型将被保存在上述提到的BQ数据集下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aclo9Ll9pg1n"
   },
   "outputs": [],
   "source": [
    "KMEANS_MODEL = \"KMEANS_HTUNED\"  # @param {type:\"string\"} custom\n",
    "AUTO_ENCODER_MODEL = \"AUTOENCODER_HTUNED\"  # @param {type:\"string\"} custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBCra4QMA2wR"
   },
   "source": [
    "### 验证您的Google Cloud账户\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动进行身份验证。请按照以下相关指示进行操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74ccc9e52986"
   },
   "source": [
    "1. 顶点 AI 工作台\n",
    "* 无需操作，因为您已经通过身份验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de775a3773ba"
   },
   "source": [
    "2. 本地JupyterLab实例，取消注释并运行:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "254614fa0c46"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef21552ccea8"
   },
   "source": [
    "3.协作，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "603adbbf0532"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbV46JXUqb3E"
   },
   "source": [
    "训练数据准备和分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RA2QEcAt-945"
   },
   "source": [
    "云审计日志包含大量重要信息，但其数量、速度和多样性使得难以进行规模化分析。每个日志条目都有一个相对复杂的架构，这使得在其原始格式下进一步分析更具挑战性。\n",
    "\n",
    "在运行ML模型之前，您需要从这些日志中提取相关字段，并按**天**、**执行者**、**动作**和**源IP**进行汇总（计数）。由于我们主要关注确定用户异常行为，这些特征都很重要并且集体上足够用于我们的分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gzrfp-_jqlxH"
   },
   "outputs": [],
   "source": [
    "# This helper function executes the sql query, wait for query execution completion and returns the results as dataframe\n",
    "def execute_sql(sql_query: str):\n",
    "    \"\"\"The executes the sql.\n",
    "    Args:\n",
    "        sql_query:(:obj:`str`): SQL query to execute\n",
    "    \"\"\"\n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    client = bigquery.Client()\n",
    "    import traceback\n",
    "\n",
    "    try:\n",
    "        client = bigquery.Client()\n",
    "        start = time.time()\n",
    "        query_job = client.query(sql_query)  # Make an API request.\n",
    "        print(\"Query Executed.Waiting for completion\")\n",
    "        results = query_job.result()  # Waits for job to complete.\n",
    "        end = time.time()\n",
    "        print(\"Query Execution completed\")\n",
    "        print(\"Time taken to execute:\", end - start)\n",
    "        if results.total_rows > 0:\n",
    "            df = results.to_dataframe()\n",
    "            df.head()\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        error = traceback.format_exc()\n",
    "        print(error)\n",
    "        print(e)\n",
    "        raise RuntimeError(f\"Can't execute the query {sql_query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AlJyrIh42G7"
   },
   "source": [
    "以下的UDF提取了根据审计日志条目执行操作的资源ID。在审计日志条目中，资源ID根据资源类型在不同的资源标签字段中指定。这就是为什么需要这个UDF来规范化资源ID字段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpU-wlxq4wv3"
   },
   "outputs": [],
   "source": [
    "# Deduce resource ID from a log entry resource field\n",
    "UDF_NAME = \"getResourceId\"\n",
    "\n",
    "sql = \"\"\"\n",
    "CREATE OR REPLACE FUNCTION `{}.{}.{}`(\n",
    "  type STRING,\n",
    "  labels JSON\n",
    ")\n",
    "RETURNS STRING\n",
    "AS (\n",
    " COALESCE(\n",
    "  JSON_VALUE(labels.email_id),     # service_account\n",
    "  JSON_VALUE(labels.pod_id),       # container\n",
    "  JSON_VALUE(labels.instance_id),  # gce_instance, spanner_instance, redis_instance, ...\n",
    "  JSON_VALUE(labels.subnetwork_id),# gce_subnetwork,\n",
    "  JSON_VALUE(labels.network_id),   # gce_network, gce_network_region, ...\n",
    "  JSON_VALUE(labels.topic_id),     # pubsub_topic\n",
    "  JSON_VALUE(labels.subscription_id), # pubsub_subscription\n",
    "  JSON_VALUE(labels.endpoint_id),  # aiplatform.googleapis.com/Endpoint\n",
    "  JSON_VALUE(labels.job_id),       # dataflow_step\n",
    "  JSON_VALUE(labels.dataset_id),   # bigquery_dataset\n",
    "  JSON_VALUE(labels.project_id),\n",
    "  JSON_VALUE(labels.organization_id),\n",
    "  JSON_VALUE(labels.id),\n",
    "  \"other\")\n",
    ");\"\"\".format(\n",
    "    PROJECT_ID, BQ_DATASET_NAME, UDF_NAME\n",
    ")\n",
    "\n",
    "execute_sql(sql)\n",
    "print(f\"Created UDF {PROJECT_ID}.{BQ_DATASET_NAME}.{UDF_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqVkSSEM6dXa"
   },
   "source": [
    "以下UDF通过审计日志条目推断用户或系统操作发生的位置。例如，操作可能是通过云控制台、使用gcloud命令行界面，或通过Terraform脚本或其他未知的客户端或渠道发生的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqNnOlF96a9a"
   },
   "outputs": [],
   "source": [
    "# Deduce channel from a log entry request user agent\n",
    "UDF_NAME = \"getChannelType\"\n",
    "\n",
    "sql = \"\"\"CREATE OR REPLACE FUNCTION `{}.{}.{}`(\n",
    "  caller_supplied_user_agent STRING\n",
    ")\n",
    "RETURNS STRING\n",
    "AS (\n",
    "  CASE\n",
    "    WHEN caller_supplied_user_agent LIKE \"Mozilla/%\" THEN 'Cloud Console'\n",
    "    WHEN caller_supplied_user_agent LIKE \"google-cloud-sdk gcloud/%\" THEN 'gcloud CLI'\n",
    "    WHEN caller_supplied_user_agent LIKE \"google-api-go-client/% Terraform/%\" THEN 'Terraform'\n",
    "    ELSE 'other'\n",
    "  END\n",
    ");\"\"\".format(\n",
    "    PROJECT_ID, BQ_DATASET_NAME, UDF_NAME\n",
    ")\n",
    "\n",
    "execute_sql(sql)\n",
    "print(f\"Created UDF {PROJECT_ID}.{BQ_DATASET_NAME}.{UDF_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BciIe3NEGn7c"
   },
   "source": [
    "查询日志来源以提取感兴趣字段的训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pO3BxDg8rKWx"
   },
   "outputs": [],
   "source": [
    "# Query to extract training data with fields of interest\n",
    "query_str = \"\"\" SELECT\n",
    "    EXTRACT(DATE FROM timestamp) AS day,\n",
    "    IFNULL(proto_payload.audit_log.authentication_info.principal_email, \"unknown\") as principal_email,\n",
    "    IFNULL(proto_payload.audit_log.method_name, \"unknown\") as action,\n",
    "    IFNULL(resource.type, \"unknown\") as resource_type,\n",
    "    {3}.getResourceId(resource.type, resource.labels) AS resource_id,\n",
    "    -- proto_payload.audit_log.resource_name as resource_name,\n",
    "    SPLIT(log_name, '/')[SAFE_OFFSET(0)] as container_type,\n",
    "    SPLIT(log_name, '/')[SAFE_OFFSET(1)] as container_id,\n",
    "    {3}.getChannelType(proto_payload.audit_log.request_metadata.caller_supplied_user_agent) AS channel,\n",
    "    IFNULL(proto_payload.audit_log.request_metadata.caller_ip, \"unknown\") as ip,\n",
    "    COUNT(*) counter,\n",
    "    -- ANY_VALUE(resource) as resource,           -- for debugging\n",
    "    -- ANY_VALUE(proto_payload) as proto_payload  -- for debugging\n",
    "  FROM  `{0}.{1}.{2}`\n",
    "  WHERE\n",
    "    -- log_id = \"cloudaudit.googleapis.com/activity\" AND\n",
    "    timestamp > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 360 DAY)\n",
    "  GROUP BY\n",
    "    day, principal_email, action, resource_type, resource_id, container_type, container_id, channel, ip, log_name\n",
    "  ORDER BY\n",
    "    day DESC, principal_email, action\"\"\".format(\n",
    "    logSourceProject, logSourceBqDataset, logSourceBqTable, BQ_DATASET_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAOZwnhOG2Jf"
   },
   "source": [
    "查看训练数据的数据框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljnUdPUsq5YU"
   },
   "outputs": [],
   "source": [
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "df = client.query(query_str).to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQN-5qq5RyeP"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elBU2zTJHEIL"
   },
   "source": [
    "在BQ中使用提取的数据创建一张表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PC1WGinBR305"
   },
   "outputs": [],
   "source": [
    "create_training_data_table = (\n",
    "    \"\"\" CREATE OR REPLACE TABLE `{}.{}.{}` AS\"\"\".format(\n",
    "        PROJECT_ID, BQ_DATASET_NAME, BQ_TABLE_NAME\n",
    "    )\n",
    "    + query_str\n",
    ")\n",
    "client.query(create_training_data_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQiEbspFSFjz"
   },
   "source": [
    "K均值聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNhRilT_HOtJ"
   },
   "source": [
    "使用训练数据创建K-Means聚类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-mhz2iSSLGF"
   },
   "source": [
    "模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HS0GSJ2USOmC"
   },
   "outputs": [],
   "source": [
    "train_kmeans = \"\"\"CREATE MODEL IF NOT EXISTS `{0}.{1}`\n",
    "OPTIONS(MODEL_TYPE = 'KMEANS',\n",
    "NUM_CLUSTERS = HPARAM_RANGE(2, 10),\n",
    "KMEANS_INIT_METHOD = 'KMEANS++',\n",
    "DISTANCE_TYPE = 'COSINE',\n",
    "STANDARDIZE_FEATURES = TRUE,\n",
    "MAX_ITERATIONS = 10,\n",
    "EARLY_STOP = TRUE,\n",
    "NUM_TRIALS = 10\n",
    ") AS\n",
    "SELECT * FROM `{0}.{2}`;\"\"\".format(\n",
    "    BQ_DATASET_NAME, KMEANS_MODEL, BQ_TABLE_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4IvGcCdSTE1"
   },
   "outputs": [],
   "source": [
    "execute_sql(train_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGFbQGIFTR8G"
   },
   "source": [
    "###模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHj8TRavTNeB"
   },
   "outputs": [],
   "source": [
    "eval_kmeans = \"\"\"SELECT * FROM ML.EVALUATE(MODEL `{}.{}`);\"\"\".format(\n",
    "    BQ_DATASET_NAME, KMEANS_MODEL\n",
    ")\n",
    "model_evalution = execute_sql(eval_kmeans)\n",
    "model_evalution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2_c3shTTcOP"
   },
   "source": [
    "异常值分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUOn36mzS0iB"
   },
   "outputs": [],
   "source": [
    "# --- DETECT ANOMALIES --- #\n",
    "detect_anomaly = \"\"\"SELECT * FROM ML.DETECT_ANOMALIES(MODEL `{0}.{1}.{2}`,\n",
    "STRUCT(0.001 AS contamination),\n",
    "TABLE `{0}.{1}.{3}`)\n",
    "WHERE is_anomaly=true\n",
    "ORDER BY normalized_distance DESC;\"\"\".format(\n",
    "    PROJECT_ID, BQ_DATASET_NAME, KMEANS_MODEL, BQ_TABLE_NAME\n",
    ")\n",
    "\n",
    "kmeans_outliers = execute_sql(detect_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpsyWaLoP7ae"
   },
   "outputs": [],
   "source": [
    "kmeans_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmy2mzsQUiQK"
   },
   "source": [
    "## 自动编码器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISBDtEM7UkSs"
   },
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcPB70AuUoYL"
   },
   "outputs": [],
   "source": [
    "train_auto_encoder = \"\"\"\n",
    "CREATE MODEL IF NOT EXISTS `{0}.{1}`\n",
    "OPTIONS(\n",
    "MODEL_TYPE='autoencoder',\n",
    "L1_REG_ACTIVATION = HPARAM_CANDIDATES([0.001, 0.01, 0.1]),\n",
    "LEARN_RATE = HPARAM_CANDIDATES([0.001, 0.01, 0.1]),\n",
    "OPTIMIZER = HPARAM_CANDIDATES(['ADAGRAD', 'ADAM', 'FTRL', ''RMSPROP', 'SGD']),\n",
    "ACTIVATION_FN='relu',\n",
    "BATCH_SIZE = HPARAM_CANDIDATES([16, 32, 64]),\n",
    "DROPOUT = HPARAM_CANDIDATES([0.1, 0.2]),\n",
    "HIDDEN_UNITS=HPARAM_CANDIDATES([struct([[16, 8, 4, 8, 16]]), struct([[32, 16, 4, 16, 32]])]),\n",
    "TF_VERSION = '2.8.0',\n",
    "EARLY_STOP = TRUE,\n",
    "MIN_REL_PROGRESS = 0.01,\n",
    "MAX_ITERATIONS=20,\n",
    "WARM_START = TRUE,\n",
    "NUM_TRIALS = 60,\n",
    "MAX_PARALLEL_TRIALS = 1,\n",
    "HPARAM_TUNING_ALGORITHM =  'VIZIER_DEFAULT',\n",
    "HPARAM_TUNING_OBJECTIVES = MEAN_SQUARED_ERROR\n",
    ") AS\n",
    "SELECT\n",
    "*\n",
    "FROM `{0}.{2}`;\"\"\".format(\n",
    "    BQ_DATASET_NAME, AUTO_ENCODER_MODEL, BQ_TABLE_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nds2Sm-QUrgv"
   },
   "outputs": [],
   "source": [
    "execute_sql(train_auto_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d596XDbHU9dM"
   },
   "source": [
    "### 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0x_U039VA3c"
   },
   "outputs": [],
   "source": [
    "eval_auto_encoder = \"\"\"SELECT * FROM ML.EVALUATE(MODEL `{}.{}`);\"\"\".format(\n",
    "    BQ_DATASET_NAME, AUTO_ENCODER_MODEL\n",
    ")\n",
    "model_evalution = execute_sql(eval_auto_encoder)\n",
    "model_evalution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clGMuJcLVIFO"
   },
   "source": [
    "异常值分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fy9v8TQCVKZz"
   },
   "outputs": [],
   "source": [
    "# --- DETECT ANOMALIES --- #\n",
    "detect_anomaly_auto_encoder = \"\"\"SELECT * FROM ML.DETECT_ANOMALIES(MODEL `{0}.{1}.{2}`,\n",
    "STRUCT(0.001 AS contamination),\n",
    "TABLE `{0}.{1}.{3}`)\n",
    "WHERE is_anomaly=true order by mean_squared_error desc;\"\"\".format(\n",
    "    PROJECT_ID, BQ_DATASET_NAME, AUTO_ENCODER_MODEL, BQ_TABLE_NAME\n",
    ")\n",
    "# print(detect_anomaly_auto_encoder)\n",
    "autoencoder_outliers = execute_sql(detect_anomaly_auto_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwmJ9unfXiT8"
   },
   "outputs": [],
   "source": [
    "autoencoder_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AM6bvT03YM8o"
   },
   "source": [
    "常见的异常值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNiCl-VHWpUJ"
   },
   "source": [
    "查找两个模型报告的异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZ6uKD4BvMAi"
   },
   "outputs": [],
   "source": [
    "df1 = kmeans_outliers[\n",
    "    [\n",
    "        \"day\",\n",
    "        \"principal_email\",\n",
    "        \"action\",\n",
    "        \"resource_type\",\n",
    "        \"resource_id\",\n",
    "        \"container_type\",\n",
    "        \"container_id\",\n",
    "        \"channel\",\n",
    "        \"ip\",\n",
    "        \"counter\",\n",
    "    ]\n",
    "]\n",
    "df2 = autoencoder_outliers[\n",
    "    [\n",
    "        \"day\",\n",
    "        \"principal_email\",\n",
    "        \"action\",\n",
    "        \"resource_type\",\n",
    "        \"resource_id\",\n",
    "        \"container_type\",\n",
    "        \"container_id\",\n",
    "        \"channel\",\n",
    "        \"ip\",\n",
    "        \"counter\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qR9WAT32XeH3"
   },
   "outputs": [],
   "source": [
    "common_outliers = df1.merge(\n",
    "    df2,\n",
    "    how=\"inner\",\n",
    "    on=[\n",
    "        \"day\",\n",
    "        \"principal_email\",\n",
    "        \"action\",\n",
    "        \"resource_type\",\n",
    "        \"resource_id\",\n",
    "        \"container_type\",\n",
    "        \"container_id\",\n",
    "        \"channel\",\n",
    "        \"ip\",\n",
    "        \"counter\",\n",
    "    ],\n",
    ")  # Replace 'column_name' if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kRTiFEyXtFg"
   },
   "outputs": [],
   "source": [
    "common_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qgBA3HYVViz"
   },
   "outputs": [],
   "source": [
    "common_outliers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bscC9pxUBU8z"
   },
   "source": [
    "将检测到的异常值上传至BQ表格进行进一步分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YP8ptrh2Nj0E"
   },
   "source": [
    "创建一个名为'common_outliers'的表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3qT5Ck3XNryf"
   },
   "outputs": [],
   "source": [
    "OUTLIERS_TABLE = \"[your-common-outliers-table]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-BfJ8Ew0tex"
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "\n",
    "def create_table(client, table_id, schema):\n",
    "    table = bigquery.Table(table_id, schema=schema)\n",
    "    table = client.create_table(table, exists_ok=True)  # Make an API request\n",
    "    print(\n",
    "        \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "    )\n",
    "\n",
    "\n",
    "def upload_df_into_bq(client, table_id, df):\n",
    "    job_config = bigquery.LoadJobConfig(schema=schema)\n",
    "    job_config.write_disposition = (\n",
    "        bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "    )  # If the table already exists, BigQuery overwrites the data, removes the constraints and uses the schema from the load job.\n",
    "    job_config.autodetect = False\n",
    "    job = client.load_table_from_dataframe(df, table_id, job_config=job_config)\n",
    "    job.result()\n",
    "    print(\"Uploaded dataframe into table {}.{}\".format(PROJECT_ID, table_id))\n",
    "\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"day\", \"DATE\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"principal_email\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"action\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"resource_type\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"resource_id\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"container_type\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"container_id\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"channel\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"ip\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"counter\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "]\n",
    "client = bigquery.Client(PROJECT_ID)\n",
    "\n",
    "table_id = \"{}.{}.{}\".format(PROJECT_ID, BQ_DATASET_NAME, OUTLIERS_TABLE)\n",
    "\n",
    "create_table(client, table_id, schema)\n",
    "\n",
    "upload_df_into_bq(client, table_id, common_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "整理\n",
    "\n",
    "要清理此项目中使用的所有Google云资源，您可以删除用于本教程的[Google云项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "# Delete the BigQuery dataset (including the models created & the tables)\n",
    "dataset_to_be_deleted = \"test\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tk9D2KRRCXrz"
   },
   "outputs": [],
   "source": [
    "!bq rm -r -f {PROJECT_ID}:{dataset_to_be_deleted}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Anomaly_detection_in_Cloud_Audit_logs_with_BQML.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
