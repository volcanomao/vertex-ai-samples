{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zB_PYUGd7-ko"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bcfa29cc2be"
   },
   "source": [
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/master/notebooks/community/vertex_endpoints/tf_hub_obj_detection/deploy_tfhub_object_detection_on_vertex_endpoints.ipynb\"\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/master/notebooks/community/vertex_endpoints/tf_hub_obj_detection/deploy_tfhub_object_detection_on_vertex_endpoints.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/master/notebooks/community/vertex_endpoints/tf_hub_obj_detection/deploy_tfhub_object_detection_on_vertex_endpoints.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/images/products/ai/ai-solutions-icon.svg\" alt=\"Vertex AI Workbench notebook\"> 在 Vertex AI Workbench 中打开\n",
    "    </a>\n",
    "  </td> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmDKdOFh8Ko8"
   },
   "source": [
    "使用Vertex AI端点部署TensorFlow Hub目标检测模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTe0sT1p8SHy"
   },
   "source": [
    "概述\n",
    "本教程演示了如何获取一个 TensorFlow Hub 目标检测模型，添加一个预处理层，并将其部署到 Vertex AI 端点进行在线预测。\n",
    "\n",
    "由于目标检测模型接受张量作为输入，我们将添加一个预处理层来接受jpeg字符串并解码它们。这样客户端就可以更容易地调用端点，而无需实现他们自己的 TensorFlow 逻辑。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8OldBdp8VeZ"
   },
   "source": [
    "## 模型\n",
    "本教程使用的模型是从[TensorFlow Hub开源模型仓库](https://tfhub.dev/tensorflow/centernet/hourglass_512x512_kpts/1)中获取的`CenterNet HourGlass104 Keypoints 512x512`模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DU7F8BCg8WgZ"
   },
   "source": [
    "## 目标\n",
    "\n",
    "执行的步骤包括：\n",
    "- 从 TensorFlow Hub 下载一个目标检测模型。\n",
    "- 使用 @tf.function 创建一个预处理层。\n",
    "- 将模型上传到 Vertex AI 的 `Models`。\n",
    "- 创建一个 Vertex AI 的 `Endpoint`。\n",
    "- 使用 `Python Vertex AI SDK` 和通过 `CURL` 命令行调用端点。\n",
    "- 卸载端点并删除模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KT8PQtz68aRa"
   },
   "source": [
    "费用\n",
    "本教程使用Google Cloud的计费组件：\n",
    "- Vertex AI\n",
    "- 云存储\n",
    "\n",
    "了解[Vertex AI定价](https://cloud.google.com/vertex-ai/pricing)和[云存储定价](https://cloud.google.com/storage/pricing)，并使用[定价计算器](https://cloud.google.com/products/calculator/)根据您的预期使用量生成费用估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHC5aja38dPU"
   },
   "source": [
    "## 安装\n",
    "安装最新版本的Python用的Vertex SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NdnlHDb8gk7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Google Cloud Notebook product has specific requirements\n",
    "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
    "\n",
    "# Google Cloud Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0E-rLjd8kPJ"
   },
   "outputs": [],
   "source": [
    "! pip install {USER_FLAG} --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCNy-5A19Iu8"
   },
   "source": [
    "安装TensorFlow。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZUC9iJa9TPd"
   },
   "outputs": [],
   "source": [
    "!pip install -U \"tensorflow>=2.7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyv85kWHvkQ2"
   },
   "source": [
    "重新启动内核\n",
    "\n",
    "安装完成后，您需要重新启动笔记本内核，以便它可以找到包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "av0sLWCDvmL6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Peg2Bwy_v2fe"
   },
   "source": [
    "在开始之前\n",
    "\n",
    "设置您的Google Cloud项目\n",
    "\n",
    "**无论您使用哪种笔记本环境，都需要完成以下步骤。**\n",
    "\n",
    "1. [选择或创建Google Cloud项目](https://console.cloud.google.com/cloud-resource-manager)。首次创建帐户时，您将获得$300的免费信用额度来支付计算/存储成本。\n",
    "\n",
    "2. [确保您的项目已启用计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "3. [启用Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。\n",
    "\n",
    "4. 如果您在本地运行这个笔记本，您需要安装[Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "5. 在下面的单元格中输入您的项目ID。然后运行该单元格，以确保Cloud SDK为本笔记本中的所有命令使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter以`!`为前缀的行作为shell命令运行，并将以`$`为前缀的Python变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NRbJL7iwTwm"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以尝试使用`gcloud`获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVrtnNtuwOgv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"\"\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Get your Google Cloud project ID from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHaNeGniwQwf"
   },
   "source": [
    "否则，请在这里设置您的项目 ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wU5w8-WwakX"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
    "    PROJECT_ID = \"\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3YQn1FNv7I9"
   },
   "source": [
    "时间戳\n",
    "\n",
    "如果您在直播教程会话中，可能会使用共享测试账户或项目。为了避免用户在创建的资源之间发生名称冲突，为每个实例会话创建一个时间戳，并将其附加到您在本教程中创建的资源名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TU_3QS-Rwk0v"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlLFGqlov_Ht"
   },
   "source": [
    "### 验证您的谷歌云帐户\n",
    "\n",
    "**如果您正在使用谷歌云笔记本**，您的环境已经通过验证。跳过这一步。\n",
    "\n",
    "**如果您正在使用Colab**，运行下面的单元格，并按提示进行帐户oAuth验证。\n",
    "\n",
    "**否则**，请按照以下步骤操作：\n",
    "\n",
    "1. 在云控制台中，转到[**创建服务帐户密钥**页面](https://console.cloud.google.com/apis/credentials/serviceaccountkey)。\n",
    "\n",
    "2. 点击**创建服务帐户**。\n",
    "\n",
    "3. 在**服务帐户名称**字段中输入一个名称，然后点击**创建**。\n",
    "\n",
    "4. 在**授予此服务帐户对项目的访问权限**部分，点击**角色**下拉列表。在筛选框中输入\"Vertex AI\"，并选择**Vertex AI管理员**。在筛选框中输入\"Storage Object Admin\"，并选择**存储对象管理员**。\n",
    "\n",
    "5. 点击*创建*。一个包含您密钥的JSON文件将下载到您的本地环境中。\n",
    "\n",
    "6. 在下面的单元格中输入您的服务帐户密钥的路径，并将其作为`GOOGLE_APPLICATION_CREDENTIALS`变量运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBTUnqS1wqHo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "# The Google Cloud Notebook product has specific requirements\n",
    "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
    "\n",
    "# If on Google Cloud Notebooks, then don't execute this code\n",
    "if not IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPrx2LnU8vFU"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "**无论您使用哪种笔记本环境，以下步骤都是必需的。**\n",
    "\n",
    "首先将模型文件上传到一个云存储桶中。使用这个模型 artifact，然后您就可以\n",
    "创建 Vertex AI 模型和端点资源，以便提供\n",
    "在线预测。\n",
    "\n",
    "在下方设置您的云存储桶的名称。它必须在所有\n",
    "云存储桶中是唯一的。\n",
    "\n",
    "您还可以更改 `REGION` 变量，这将影响\n",
    "笔记本中其他操作。请确保 [选择 Vertex AI 服务可用的区域](https://cloud.google.com/vertex-ai/docs/general/locations#available_regions)。您可能\n",
    "不能将多区域存储桶用于与 Vertex AI 的训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ef0nYMRKxvDV"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ti_79ErvxxeF"
   },
   "outputs": [],
   "source": [
    "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_NAME = \"gs://\" + PROJECT_ID + \"aip-\" + TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ig18nZMtmuGH"
   },
   "outputs": [],
   "source": [
    "print(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCZRfgA9x0Mz"
   },
   "source": [
    "只有当您的存储桶不存在时：运行以下单元格以创建您的云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDX_aWtjxzSN"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -p $PROJECT_ID -l $REGION $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7IDVRdwx4hd"
   },
   "source": [
    "最后，通过检查存储桶的内容来验证对您的云存储桶的访问权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iA6Uqvqxx8Ls"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "me1llTRsyImc"
   },
   "source": [
    "## 下载并解压模型\n",
    "TensorFlow Hub中有各种物体检测模型。我们将使用`CenterNet HourGlass104 Keypoints 512x512`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6dmPQqxzGZp"
   },
   "outputs": [],
   "source": [
    "# Download and extract model\n",
    "!wget https://tfhub.dev/tensorflow/centernet/hourglass_512x512_kpts/1?tf-hub-format=compressed\n",
    "!tar xvzf 1?tf-hub-format=compressed\n",
    "!mkdir obj_detect_model\n",
    "!mv ./saved_model.pb obj_detect_model/\n",
    "!mv ./variables obj_detect_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qAF8aH4HzXEY"
   },
   "source": [
    "可视化工具\n",
    "为了展示具有正确检测框、关键点和分割的图像，我们将使用TensorFlow目标检测API。为了安装它，我们将克隆存储库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fV_q5QTakk4H"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from six import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sztJl5lE0Lxd"
   },
   "outputs": [],
   "source": [
    "# Clone the tensorflow models repository\n",
    "!git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYF0OD280SF-"
   },
   "source": [
    "安装目标检测API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3m_twvfY0U9k"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sudo apt install -y protobuf-compiler\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "cp object_detection/packages/tf2/setup.py .\n",
    "pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awZo_FXg1dkn"
   },
   "source": [
    "现在我们可以导入以后会用到的依赖项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5aDl_EEH1lHh"
   },
   "outputs": [],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaXIEr4W52QY"
   },
   "source": [
    "加载标签映射数据（用于绘图）。\n",
    "标签映射将索引号对应到类别名称，因此当我们的卷积网络预测为5时，我们知道这对应飞机。在这里我们使用内部实用函数，但任何返回将整数映射到适当字符串标签的字典的函数都可以。\n",
    "\n",
    "为简单起见，我们将从我们加载Object Detection API代码的存储库中加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6e52z_Wi5Ar9"
   },
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = \"./models/research/object_detection/data/mscoco_label_map.pbtxt\"\n",
    "category_index = label_map_util.create_category_index_from_labelmap(\n",
    "    PATH_TO_LABELS, use_display_name=True\n",
    ")\n",
    "print(category_index[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swaDX8uE6Ksn"
   },
   "source": [
    "加载模型\n",
    "在这里，我们将把下载好的模型加载到内存中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0eejzM26QXb"
   },
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(\"obj_detect_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckNI8ZRW63od"
   },
   "source": [
    "加载一张图片并使用模型进行推理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-J2YDW6r6_wO"
   },
   "outputs": [],
   "source": [
    "image_path = \"models/research/object_detection/test_images/image2.jpg\"\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    image_data = tf.io.gfile.GFile(path, \"rb\").read()\n",
    "    image = Image.open(BytesIO(image_data))\n",
    "\n",
    "    (width, height) = image.size\n",
    "    return np.array(image.getdata()).reshape((1, height, width, 3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "image_np = load_image_into_numpy_array(image_path)\n",
    "plt.figure(figsize=(24, 32))\n",
    "plt.imshow(image_np[0])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "results = model(image_np)\n",
    "result = {key: value.numpy() for key, value in results.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zMDFKfM7vuT"
   },
   "source": [
    "可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FRV_-Q8x7uye"
   },
   "outputs": [],
   "source": [
    "COCO17_HUMAN_POSE_KEYPOINTS = [\n",
    "    (0, 1),\n",
    "    (0, 2),\n",
    "    (1, 3),\n",
    "    (2, 4),\n",
    "    (0, 5),\n",
    "    (0, 6),\n",
    "    (5, 7),\n",
    "    (7, 9),\n",
    "    (6, 8),\n",
    "    (8, 10),\n",
    "    (5, 6),\n",
    "    (5, 11),\n",
    "    (6, 12),\n",
    "    (11, 12),\n",
    "    (11, 13),\n",
    "    (13, 15),\n",
    "    (12, 14),\n",
    "    (14, 16),\n",
    "]\n",
    "\n",
    "label_id_offset = 0\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "# Use keypoints if available in detections\n",
    "keypoints, keypoint_scores = None, None\n",
    "if \"detection_keypoints\" in result:\n",
    "    keypoints = result[\"detection_keypoints\"][0]\n",
    "    keypoint_scores = result[\"detection_keypoint_scores\"][0]\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np_with_detections[0],\n",
    "    result[\"detection_boxes\"][0],\n",
    "    (result[\"detection_classes\"][0] + label_id_offset).astype(int),\n",
    "    result[\"detection_scores\"][0],\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=200,\n",
    "    min_score_thresh=0.30,\n",
    "    agnostic_mode=False,\n",
    "    keypoints=keypoints,\n",
    "    keypoint_scores=keypoint_scores,\n",
    "    keypoint_edges=COCO17_HUMAN_POSE_KEYPOINTS,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(24, 32))\n",
    "plt.imshow(image_np_with_detections[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb4xge9UE-ka"
   },
   "source": [
    "## 为Vertex AI服务创建一个预处理函数。\n",
    "模型期望以numpy数组作为输入。这为我们的端点创建了两个问题：\n",
    "* Vertex AI公共端点的最大请求大小为1.5 MB。图片远大于此大小。\n",
    "* 对于使用其他编程语言的客户端来构建请求会更加困难。\n",
    "\n",
    "通过构建一个预处理函数并将其附加到我们的模型，这两个限制可以得到解决。\n",
    "\n",
    "我们将创建一个预处理函数，该函数接收一个jpeg编码的图片，将其调整大小为模型所需的最小输入，并将这个预处理输入传递给模型。然后我们将保存带有预处理函数的模型，该模型将准备好上传到我们的Vertex AI端点。\n",
    "\n",
    "图片将作为一个base64编码的jpeg字符串传递给我们的端点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5U3eLrbK3oH"
   },
   "outputs": [],
   "source": [
    "VERTEX_MODEL_PATH = \"obj_detect_model_vertex/\"\n",
    "\n",
    "\n",
    "def _preprocess(bytes_inputs):\n",
    "    decoded = tf.io.decode_jpeg(bytes_inputs, channels=3)\n",
    "    resized = tf.image.resize(decoded, size=(512, 512))\n",
    "    return tf.cast(resized, dtype=tf.uint8)\n",
    "\n",
    "\n",
    "def _get_serve_image_fn(model):\n",
    "    @tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "    def serve_image_fn(bytes_inputs):\n",
    "        decoded_images = tf.map_fn(_preprocess, bytes_inputs, dtype=tf.uint8)\n",
    "        return model(decoded_images)\n",
    "\n",
    "    return serve_image_fn\n",
    "\n",
    "\n",
    "signatures = {\n",
    "    \"serving_default\": _get_serve_image_fn(model).get_concrete_function(\n",
    "        tf.TensorSpec(shape=[None], dtype=tf.string)\n",
    "    )\n",
    "}\n",
    "\n",
    "tf.saved_model.save(model, VERTEX_MODEL_PATH, signatures=signatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPVVu5xcMTtm"
   },
   "source": [
    "我们将使用`saved_model_cli`命令在原模型和Vertex AI准备的模型上验证输入是否正确修改。\n",
    "\n",
    "`serving_default`签名的结果应该如下。\n",
    "\n",
    "原模型：\n",
    "\n",
    "```\n",
    "signature_def['serving_default']:\n",
    "  给定的SavedModel SignatureDef 包含以下输入：\n",
    "    inputs['input_tensor'] tensor_info:\n",
    "        dtype: DT_UINT8\n",
    "        shape: (1, -1, -1, 3)\n",
    "        name: serving_default_input_tensor:0\n",
    "```\n",
    "\n",
    "Vertex AI模型：\n",
    "\n",
    "```\n",
    "signature_def['serving_default']:\n",
    "  给定的SavedModel SignatureDef 包含以下输入：\n",
    "    inputs['bytes_inputs'] tensor_info:\n",
    "        dtype: DT_STRING\n",
    "        shape: (-1)\n",
    "        name: serving_default_bytes_inputs:0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJ1x3YISNWuH"
   },
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir obj_detect_model --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trfpB2A8NS9k"
   },
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir obj_detect_model_vertex --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2vgZvn2NA2h"
   },
   "source": [
    "让我们通过传递一个 base 64 编码的 jpeg 图像来测试预处理函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GT55Kj_NGfC"
   },
   "outputs": [],
   "source": [
    "vertex_model = tf.saved_model.load(VERTEX_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2f8z6G7yNPaJ"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "\n",
    "def encode_image(image):\n",
    "    with open(image, \"rb\") as image_file:\n",
    "        encoded_string = base64.urlsafe_b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    return encoded_string\n",
    "\n",
    "\n",
    "results = vertex_model([_preprocess(tf.io.decode_base64(encode_image(image_path)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwntQ3m1O8s_"
   },
   "source": [
    "查看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hjSVSWiO-Qh"
   },
   "outputs": [],
   "source": [
    "# different object detection models have additional results\n",
    "# all of them are explained in the documentation\n",
    "result = {key: value.numpy() for key, value in results.items()}\n",
    "\n",
    "label_id_offset = 0\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "# Use keypoints if available in detections\n",
    "keypoints, keypoint_scores = None, None\n",
    "if \"detection_keypoints\" in result:\n",
    "    keypoints = result[\"detection_keypoints\"][0]\n",
    "    keypoint_scores = result[\"detection_keypoint_scores\"][0]\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np_with_detections[0],\n",
    "    result[\"detection_boxes\"][0],\n",
    "    (result[\"detection_classes\"][0] + label_id_offset).astype(int),\n",
    "    result[\"detection_scores\"][0],\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=200,\n",
    "    min_score_thresh=0.30,\n",
    "    agnostic_mode=False,\n",
    "    keypoints=keypoints,\n",
    "    keypoint_scores=keypoint_scores,\n",
    "    keypoint_edges=COCO17_HUMAN_POSE_KEYPOINTS,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(24, 32))\n",
    "plt.imshow(image_np_with_detections[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43uTMJaQScuf"
   },
   "source": [
    "创建一个顶点AI端点\n",
    "在这个部分，我们将把模型上传到Google Cloud Storage，并在Vertex AI中引用它用于端点部署。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJg_8vLblmzQ"
   },
   "outputs": [],
   "source": [
    "!gsutil cp -r $VERTEX_MODEL_PATH $BUCKET_NAME/obj_detection_model_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTKUaAyznRow"
   },
   "outputs": [],
   "source": [
    "!gsutil ls $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKdYthMAnok9"
   },
   "source": [
    "在Vertex AI中创建一个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKfDMn_Enqpn"
   },
   "outputs": [],
   "source": [
    "!gcloud ai models upload \\\n",
    "--region=us-central1 \\\n",
    "--project=$PROJECT_ID \\\n",
    "--display-name=object-detection \\\n",
    "--container-image-uri=us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-5:latest \\\n",
    "--artifact-uri=$BUCKET_NAME/obj_detection_model_vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxIgOjsltxdE"
   },
   "source": [
    "创建终端点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvGJgk8TulMl"
   },
   "outputs": [],
   "source": [
    "!gcloud ai endpoints create \\\n",
    "--project=$PROJECT_ID \\\n",
    "--region=$REGION \\\n",
    "--display-name=object-detection-endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2cda10ebd5e"
   },
   "source": [
    "检索MODEL_ID和ENDPOINT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bff0694f6581"
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$REGION\" \"$PROJECT_ID\" --out MODEL_ID\n",
    "MODEL_ID=`gcloud ai models list --region=$1 --project=$2 | grep object-detection`\n",
    "echo $MODEL_ID | cut -d' ' -f1 | tr -d '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8e1ea39293ec"
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$REGION\" \"$PROJECT_ID\" --out ENDPOINT_ID\n",
    "ENDPOINT_ID=`gcloud ai endpoints list --region=$1 --project=$2 | sed -n 2p`\n",
    "echo $ENDPOINT_ID | cut -d' ' -f1 | tr -d '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KB3pJ-nDt0gj"
   },
   "outputs": [],
   "source": [
    "!gcloud ai endpoints deploy-model $ENDPOINT_ID \\\n",
    "--project=$PROJECT_ID \\\n",
    "--region=$REGION \\\n",
    "--model=$MODEL_ID \\\n",
    "--display-name=object-detection-endpoint \\\n",
    "--traffic-split=0=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcFSSWAmIevj"
   },
   "source": [
    "将请求写入一个json文件，并使用Curl调用端点。\n",
    "\n",
    "首先，我们需要减少图像的内存占用。截至2022年2月，Vertex AI端点的最大请求大小为1.5mb。这样做是为了确保在高负载时期，端点后面的容器不会崩溃。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hK2sGh95KtpA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.stat(image_path).st_size)\n",
    "\n",
    "im = Image.open(image_path)\n",
    "im.save(\"image2.jpg\", quality=95)\n",
    "print(os.stat(\"image2.jpg\").st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOPq1R2y6AvP"
   },
   "outputs": [],
   "source": [
    "!echo {\"\\\"\"instances\"\\\"\" : [{\"\\\"\"bytes_inputs\"\\\"\" : {\"\\\"\"b64\"\\\"\" : \"\\\"\"$(base64 \"image2.jpg\")\"\\\"\"}}]} > instances.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHbKrb7uw9Qn"
   },
   "outputs": [],
   "source": [
    "!curl POST  \\\n",
    "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "https://us-central1-aiplatform.googleapis.com/v1/projects/$PROJECT_ID/locations/us-central1/endpoints/$ENDPOINT_ID:predict \\\n",
    "-d @instances.json > results.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrG91gkiFd8E"
   },
   "source": [
    "使用Vertex SDK进行预测\n",
    "Vertex SDK具有方便的方法来调用端点以进行预测。\n",
    "首先，我们从模型中获取用于服务的输入。这是端点期望的base64编码图像的密钥。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPDEyXplFiOr"
   },
   "outputs": [],
   "source": [
    "# Get the input key\n",
    "serving_input = list(\n",
    "    vertex_model.signatures[\"serving_default\"].structured_input_signature[1].keys()\n",
    ")[0]\n",
    "print(\"Serving input :\", serving_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjAKDKKuJWJA"
   },
   "source": [
    "加载一个端点对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZAbDHD4FlJd"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aip_endpoint_name = (\n",
    "    f\"projects/{PROJECT_ID}/locations/us-central1/endpoints/{ENDPOINT_ID}\"\n",
    ")\n",
    "endpoint = aiplatform.Endpoint(aip_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DBC_WUG7HDFe"
   },
   "outputs": [],
   "source": [
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "\n",
    "# Endpoints will do the base64 decoding, so we change the function to encode the image a bit.\n",
    "def encode_image_bytes(image_path):\n",
    "    bytes = tf.io.read_file(image_path)\n",
    "    return base64.b64encode(bytes.numpy()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "instances_list = [{serving_input: {\"b64\": encode_image_bytes(\"image2.jpg\")}}]\n",
    "instances = [json_format.ParseDict(s, Value()) for s in instances_list]\n",
    "results = endpoint.predict(instances=instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRMUoG9zJg0_"
   },
   "source": [
    "查看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARTQn8dRHV-P"
   },
   "outputs": [],
   "source": [
    "# different object detection models have additional results\n",
    "# all of them are explained in the documentation\n",
    "prediction_results = results.predictions[0]\n",
    "result = {key: np.array([value]) for key, value in prediction_results.items()}\n",
    "\n",
    "label_id_offset = 0\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "# Use keypoints if available in detections\n",
    "keypoints, keypoint_scores = None, None\n",
    "if \"detection_keypoints\" in result:\n",
    "    keypoints = result[\"detection_keypoints\"][0]\n",
    "    keypoint_scores = result[\"detection_keypoint_scores\"][0]\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np_with_detections[0],\n",
    "    result[\"detection_boxes\"][0],\n",
    "    (result[\"detection_classes\"][0] + label_id_offset).astype(int),\n",
    "    result[\"detection_scores\"][0],\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=200,\n",
    "    min_score_thresh=0.30,\n",
    "    agnostic_mode=False,\n",
    "    keypoints=keypoints,\n",
    "    keypoint_scores=keypoint_scores,\n",
    "    keypoint_edges=COCO17_HUMAN_POSE_KEYPOINTS,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(24, 32))\n",
    "plt.imshow(image_np_with_detections[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c83b5cf6819"
   },
   "source": [
    "整理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于本教程的[Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aokup0x_ZiJK"
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$ENDPOINT_ID\" \"$REGION\" \"$PROJECT_ID\" --out ENDPOINT_MODEL_ID\n",
    "ENDPOINT_MODEL_ID=$(gcloud ai endpoints describe $1 --region=$2 --project=$3 | grep \"id:\")\n",
    "ENDPOINT_MODEL_ID=`echo $ENDPOINT_MODEL_ID | cut -d' ' -f2`\n",
    "echo $ENDPOINT_MODEL_ID | tr -d \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35348dd21acd"
   },
   "outputs": [],
   "source": [
    "# Undeploy endpoint\n",
    "! gcloud ai endpoints undeploy-model $ENDPOINT_ID \\\n",
    "--project=$PROJECT_ID \\\n",
    "--region=$REGION \\\n",
    "--deployed-model-id=$ENDPOINT_MODEL_ID \\\n",
    "\n",
    "# Delete endpoint resource\n",
    "! gcloud ai endpoints delete $ENDPOINT_ID \\\n",
    "--project=$PROJECT_ID \\\n",
    "--region=$REGION \\\n",
    "--quiet\n",
    "\n",
    "# Delete model resource\n",
    "! gcloud ai models delete $MODEL_ID \\\n",
    "--project=$PROJECT_ID \\\n",
    "--region=$REGION \\\n",
    "--quiet\n",
    "\n",
    "# Delete Cloud Storage objects that were created\n",
    "#! gsutil -m rm -r $BUCKET_NAME"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "deploy_tfhub_object_detection_on_vertex_endpoints.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
