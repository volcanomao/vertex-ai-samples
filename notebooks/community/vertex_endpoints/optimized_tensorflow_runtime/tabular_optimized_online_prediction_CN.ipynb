{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/vertex_endpoints/optimized_tensorflow_runtime/tabular_optimized_online_prediction.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/vertex_endpoints/optimized_tensorflow_runtime/tabular_optimized_online_prediction.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/vertex_endpoints/optimized_tensorflow_runtime/tabular_optimized_online_prediction.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在 Vertex AI Workbench 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19cdbb1b1c83"
   },
   "source": [
    "利用优化的TensorFlow运行时训练一个表格形式的Criteo模型，并部署到Vertex AI Predictions。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "在这个示例中，您将学习如何使用TensorFlow Keras或Estimator API使用Criteo Kaggle数据集训练表格模型。\n",
    "接下来，您将使用基于开源的TensorFlow 2.7容器和经过优化的TensorFlow运行时容器将训练好的模型导出到Vertex AI预测服务，运行这些模型的性能评估并比较预测结果。\n",
    "\n",
    "有关Vertex AI预测优化的TensorFlow运行时容器的更多信息，请参考https://cloud.google.com/vertex-ai/docs/predictions/optimized-tensorflow-runtime。\n",
    "\n",
    "### 数据集\n",
    "\n",
    "在这个示例中，您将使用Criteo Kaggle数据集，数据集大小约为4GB。\n",
    "\n",
    "\n",
    "### 目标\n",
    "\n",
    "在这个笔记本中，您将学习如何使用优化的TensorFlow运行时将训练好的表格模型部署到Vertex AI预测，并将其性能与基于开源的TensorFlow容器进行比较。\n",
    "\n",
    "执行的步骤包括：\n",
    "* 下载并解压Criteo Kaggle数据集\n",
    "* 使用Keras API构建和训练模型\n",
    "* 设置私有端点\n",
    "* 使用TensorFlow 2.7容器将模型部署到Vertex AI预测\n",
    "* 使用优化的TensorFlow容器将模型部署到Vertex AI预测\n",
    "* 对两个模型进行基准测试并验证它们的预测结果\n",
    "\n",
    "您可以在Colab中训练模型并将其上传到Vertex AI预测。由于本教程使用私有端点演示Vertex AI预测，您必须使用Jupyter VM来运行基准测试。\n",
    "\n",
    "### 成本\n",
    "\n",
    "本教程使用Google Cloud的以下可计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* 云存储\n",
    "\n",
    "了解有关[Vertex AI价格](https://cloud.google.com/vertex-ai/pricing)和[云存储价格](https://cloud.google.com/storage/pricing)，并使用[定价计算器](https://cloud.google.com/products/calculator/)生成基于您预期使用情况的成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ze4-nDLfK4pw"
   },
   "source": [
    "### 设置本地开发环境\n",
    "\n",
    "**如果您正在使用Colab或Vertex AI Workbench笔记本**，您的环境满足运行此笔记本的要求。您可以跳过此步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCuSR8GkAgzl"
   },
   "source": [
    "如果您没有在使用Colab或Vertex AI Workbench笔记本，则您的环境必须具备以下条件才能满足此笔记本的要求。\n",
    "\n",
    "- Google Cloud SDK\n",
    "- Git\n",
    "- Python 3\n",
    "- virtualenv\n",
    "- 在使用Python 3的虚拟环境中运行Jupyter笔记本\n",
    "\n",
    "Google Cloud指南提供了[设置Python开发环境的详细说明](https://cloud.google.com/python/setup)和[Jupyter安装指南](https://jupyter.org/install)来满足这些要求。以下是简要说明：\n",
    "\n",
    "1. [安装并初始化Cloud SDK。](https://cloud.google.com/sdk/docs/)\n",
    "2. [安装Python 3。](https://cloud.google.com/python/setup#installing_python)\n",
    "3. [安装virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv)，并创建一个使用Python 3的虚拟环境。激活虚拟环境。\n",
    "4. 要安装Jupyter，请在终端shell中运行`pip3 install jupyter`。\n",
    "5. 要启动Jupyter，请在终端shell中运行`jupyter notebook`。\n",
    "6. 在Jupyter Notebook Dashboard中打开此笔记本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "安装额外的软件包\n",
    "\n",
    "安装额外的软件包依赖项，这些依赖项未在您的笔记本环境中安装，例如TensorFlow Serving API、Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b4ef9b72d43"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
    "\n",
    "# Vertex AI Workbench Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyy5Lbnzg5fi"
   },
   "outputs": [],
   "source": [
    "! pip3 install {USER_FLAG} --upgrade tensorflow==2.7.0 -q\n",
    "! pip3 install {USER_FLAG} --upgrade tensorflow-serving-api==2.7.0 -q\n",
    "! pip3 install {USER_FLAG} --upgrade google-cloud-aiplatform -q\n",
    "! pip3 install {USER_FLAG} --upgrade google-cloud-storage -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhq5zEbGg0XX"
   },
   "source": [
    "重启内核\n",
    "\n",
    "在安装了额外的包之后，您必须重新启动笔记本内核，以便它可以找到这些包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzrelQZ22IZj"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWEdiXsJg0XY"
   },
   "source": [
    "在你开始之前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "## 设置你的 Google Cloud 项目\n",
    "\n",
    "**无论你使用哪种笔记本环境，以下步骤都是必须的。**\n",
    "\n",
    "1. [选择或创建一个 Google Cloud 项目](https://console.cloud.google.com/cloud-resource-manager)。当你第一次创建一个账号时，你将获得$300的信用用于计算和存储成本。\n",
    "\n",
    "1. [确保你的项目启用了结算功能](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "1. [启用 Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。\n",
    "\n",
    "1. [启用 Service Networking API](https://console.cloud.google.com/flows/enableapi?apiid=servicenetworking.googleapis.com)。\n",
    "\n",
    "1. [启用 Cloud DNS API](https://console.cloud.google.com/flows/enableapi?apiid=dns.googleapis.com)。\n",
    "\n",
    "1. 如果你在本地运行这个笔记本，你必须安装[Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "1. 在下面的单元格中输入你的项目 ID。然后运行这个单元格，确保\n",
    "Cloud SDK 在本笔记本中的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**: Jupyter 运行以 `!` 开头的命令作为 shell 命令，并且它会将以 `$` 开头的 Python 变量插入到这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，您可以尝试使用`gcloud`获取您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"\"\n",
    "\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJYoRfYng0XZ"
   },
   "source": [
    "将你的项目ID设置在这里。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riG_qUokg0XZ"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
    "    PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06571eb4063b"
   },
   "source": [
    "时间戳\n",
    "\n",
    "如果您正在进行实时教程会话，可能会使用共享的测试账户或项目。为了避免用户之间在创建的资源上发生名称冲突，请为每个实例会话创建一个时间戳，然后将其附加到您在本教程中创建的资源名称中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "697568e92bd6"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dr--iN2kAylZ"
   },
   "source": [
    "### 验证您的 Google Cloud 帐户\n",
    "\n",
    "**如果您正在使用 Vertex AI Workbench 笔记本**，您的环境已经进行了验证。请跳过此步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBCra4QMA2wR"
   },
   "source": [
    "如果您正在使用Colab，请运行下面的单元格，并按提示进行身份验证以通过oAuth验证您的帐户。\n",
    "\n",
    "否则，请按照以下步骤操作：\n",
    "\n",
    "1. 在Cloud Console中，转到[**创建服务帐号密钥**页面](https://console.cloud.google.com/apis/credentials/serviceaccountkey)。\n",
    "\n",
    "2. 点击**创建服务帐号**。\n",
    "\n",
    "3. 在**服务帐号名称**字段中输入名称，然后点击**创建**。\n",
    "\n",
    "4. 在**授予此服务帐号对项目的访问权限**部分，点击**角色**下拉列表。在过滤框中输入\"Vertex AI\"，并选择**Vertex AI管理员**。在过滤框中输入\"存储对象管理员\"，并选择**存储对象管理员**。\n",
    "\n",
    "5. 点击**创建**。包含您密钥的JSON文件将下载到本地环境。\n",
    "\n",
    "6. 将您的服务帐号密钥路径输入为下一个单元格中的`GOOGLE_APPLICATION_CREDENTIALS`变量，然后运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
    "\n",
    "# If on Vertex AI Workbench Notebooks, then don't execute this code\n",
    "if not IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### 创建云存储桶\n",
    "\n",
    "**以下步骤适用于所有笔记本环境。**\n",
    "\n",
    "要使Vertex AI Prediction为您的模型提供服务，必须首先将其上传到云存储桶。\n",
    "\n",
    "在下面的单元格中设置您的云存储桶的名称。它必须在所有的云存储桶中是唯一的。\n",
    "\n",
    "您可以更改 `REGION` 变量，该变量用于本笔记本其余部分的操作。我们建议您[选择一个Vertex AI服务可用的地区](https://cloud.google.com/vertex-ai/docs/general/locations#available_regions)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = \"gs://[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "REGION = \"[your-region]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cf221059d072"
   },
   "outputs": [],
   "source": [
    "if BUCKET_URI == \"\" or BUCKET_URI is None or BUCKET_URI == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_URI = \"gs://\" + PROJECT_ID + \"aip-\" + TIMESTAMP\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "只有当您的存储桶尚不存在时：运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucvCsknMCims"
   },
   "source": [
    "你的云存储桶的最后一步是通过检查其内容来验证对云存储桶的访问权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhOb7YnwClBb"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf"
   },
   "source": [
    "导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRUOFELefqf1"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import grpc\n",
    "import numpy as np\n",
    "import requests as r\n",
    "import tensorflow as tf\n",
    "from tensorflow_serving.apis import (predict_pb2, prediction_log_pb2,\n",
    "                                     prediction_service_pb2_grpc)\n",
    "\n",
    "logging = tf.get_logger()\n",
    "logging.propagate = False\n",
    "logging.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xS8EWC5gLBGE"
   },
   "outputs": [],
   "source": [
    "LOCAL_DIRECTORY = \"~/criteo\"  # @param {type:\"string\"}\n",
    "HIDDEN_LAYERS_STR = \"2048,2048,1024,512,256\"  # @param {type:\"string\"}\n",
    "\n",
    "HIDDEN_LAYERS = list(map(lambda x: int(x), HIDDEN_LAYERS_STR.split(\",\")))\n",
    "LOCAL_DIRECTORY_FULL = os.path.expanduser(LOCAL_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ee07345bcc6"
   },
   "source": [
    "下载数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pr_KdfVtM7k5"
   },
   "source": [
    "请按照[Criteo网站](https://labs.criteo.com/2014/02/kaggle-display-advertising-challenge-dataset/)上的说明下载数据。\n",
    "\n",
    "如果数据不可用，您可以使用以下网址下载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QjMxvFCC5A7"
   },
   "outputs": [],
   "source": [
    "!mkdir -p $LOCAL_DIRECTORY_FULL/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkRouSvKaAbB"
   },
   "outputs": [],
   "source": [
    "!cd $LOCAL_DIRECTORY_FULL/data && curl -O https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/10082655/dac.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGfU1kNx_oz6"
   },
   "outputs": [],
   "source": [
    "!cd $LOCAL_DIRECTORY_FULL/data && tar xvzf dac.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-t27rnXAAtka"
   },
   "outputs": [],
   "source": [
    "!head -n 3 $LOCAL_DIRECTORY_FULL/data/train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ng-Nrc8UdbP2"
   },
   "source": [
    "## 读取和转换数据集\n",
    "\n",
    "在模型可以训练之前，变量必须进行预处理。\n",
    "\n",
    "数值通过减去它们的平均值并除以它们的标准差进行归一化处理。\n",
    "每个数值特征的平均值和标准差都是预先计算的。每个分类特征的词汇大小也是预先计算的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmOWgpbWddbW"
   },
   "outputs": [],
   "source": [
    "COLUMN_NAMES = [\n",
    "    \"label\",\n",
    "    \"int1\",\n",
    "    \"int2\",\n",
    "    \"int3\",\n",
    "    \"int4\",\n",
    "    \"int5\",\n",
    "    \"int6\",\n",
    "    \"int7\",\n",
    "    \"int8\",\n",
    "    \"int9\",\n",
    "    \"int10\",\n",
    "    \"int11\",\n",
    "    \"int12\",\n",
    "    \"int13\",\n",
    "    \"cat1\",\n",
    "    \"cat2\",\n",
    "    \"cat3\",\n",
    "    \"cat4\",\n",
    "    \"cat5\",\n",
    "    \"cat6\",\n",
    "    \"cat7\",\n",
    "    \"cat8\",\n",
    "    \"cat9\",\n",
    "    \"cat10\",\n",
    "    \"cat11\",\n",
    "    \"cat12\",\n",
    "    \"cat13\",\n",
    "    \"cat14\",\n",
    "    \"cat15\",\n",
    "    \"cat16\",\n",
    "    \"cat17\",\n",
    "    \"cat18\",\n",
    "    \"cat19\",\n",
    "    \"cat20\",\n",
    "    \"cat21\",\n",
    "    \"cat22\",\n",
    "    \"cat23\",\n",
    "    \"cat24\",\n",
    "    \"cat25\",\n",
    "    \"cat26\",\n",
    "]\n",
    "\n",
    "# Precalculated, see\n",
    "# https://github.com/vlasenkoalexey/criteo_nbdev/blob/master/04_data_reader.ipynb\n",
    "NUM_AVERAGE = {\n",
    "    \"int1\": 3.5024133170753995,\n",
    "    \"int2\": 105.8484197976657,\n",
    "    \"int3\": 26.91304102061112,\n",
    "    \"int4\": 7.322680248873331,\n",
    "    \"int5\": 18538.99166487135,\n",
    "    \"int6\": 116.06185085211605,\n",
    "    \"int7\": 16.333130032135013,\n",
    "    \"int8\": 12.517042137556762,\n",
    "    \"int9\": 106.10982343805145,\n",
    "    \"int10\": 0.6175294977722183,\n",
    "    \"int11\": 2.7328343170173173,\n",
    "    \"int12\": 0.9910356287721245,\n",
    "    \"int13\": 8.21746116117401,\n",
    "}\n",
    "NUM_STDDEV = {\n",
    "    \"int1\": 9.429076407105086,\n",
    "    \"int2\": 391.4578226870704,\n",
    "    \"int3\": 397.97258302273474,\n",
    "    \"int4\": 8.793230712645805,\n",
    "    \"int5\": 69394.60184622335,\n",
    "    \"int6\": 382.5664493712363,\n",
    "    \"int7\": 66.0497552451171,\n",
    "    \"int8\": 16.688884567787586,\n",
    "    \"int9\": 220.28309398647906,\n",
    "    \"int10\": 0.6840505553977025,\n",
    "    \"int11\": 5.199070884811354,\n",
    "    \"int12\": 5.597723872237179,\n",
    "    \"int13\": 16.211932558173785,\n",
    "}\n",
    "VOCABULARY_SIZE = {\n",
    "    \"cat1\": 1460,\n",
    "    \"cat2\": 583,\n",
    "    \"cat3\": 10131226,\n",
    "    \"cat4\": 2202607,\n",
    "    \"cat5\": 305,\n",
    "    \"cat6\": 23,\n",
    "    \"cat7\": 12517,\n",
    "    \"cat8\": 633,\n",
    "    \"cat9\": 3,\n",
    "    \"cat10\": 93145,\n",
    "    \"cat11\": 5683,\n",
    "    \"cat12\": 8351592,\n",
    "    \"cat13\": 3194,\n",
    "    \"cat14\": 27,\n",
    "    \"cat15\": 14992,\n",
    "    \"cat16\": 5461305,\n",
    "    \"cat17\": 10,\n",
    "    \"cat18\": 5652,\n",
    "    \"cat19\": 2172,\n",
    "    \"cat20\": 3,\n",
    "    \"cat21\": 7046546,\n",
    "    \"cat22\": 17,\n",
    "    \"cat23\": 15,\n",
    "    \"cat24\": 286180,\n",
    "    \"cat25\": 104,\n",
    "    \"cat26\": 142571,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6D2awii4dkfn"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def transform_row(*row_tuple):\n",
    "    row_dict = dict(\n",
    "        zip(list(column_name for column_name in COLUMN_NAMES), list(row_tuple))\n",
    "    )\n",
    "    dict_without_label = dict(row_dict)\n",
    "    label = dict_without_label.pop(\"label\")\n",
    "    return (dict_without_label, label)\n",
    "\n",
    "\n",
    "def read_gcs(batch_size=64):\n",
    "    file_name = os.path.join(LOCAL_DIRECTORY_FULL, \"data\", \"train.txt\")\n",
    "    record_defaults = list(\n",
    "        tf.int64\n",
    "        if column_name == \"label\"\n",
    "        else tf.constant(0, dtype=tf.int64)\n",
    "        if column_name.startswith(\"int\")\n",
    "        else tf.constant(\"\", dtype=tf.string)\n",
    "        for column_name in COLUMN_NAMES\n",
    "    )\n",
    "    dataset = tf.data.experimental.CsvDataset(\n",
    "        file_name, record_defaults, field_delim=\"\\t\", header=False\n",
    "    )\n",
    "\n",
    "    transformed_ds = (\n",
    "        dataset.batch(batch_size).shuffle(500).map(transform_row).prefetch(50)\n",
    "    )\n",
    "\n",
    "    return transformed_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLf5zmpYdmaP"
   },
   "outputs": [],
   "source": [
    "for row in read_gcs(batch_size=3).take(2):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyfLNpj_dvyi"
   },
   "source": [
    "训练和保存Keras模型\n",
    "\n",
    "有关如何使用TensorFlow Keras API训练表格模型的概述，请参阅https://github.com/tensorflow/docs/blob/r2.4/site/en/tutorials/structured_data/feature_columns.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKFTc57Hd17L"
   },
   "outputs": [],
   "source": [
    "def make_norm_fn(column_name):\n",
    "    avg = NUM_AVERAGE[column_name]\n",
    "    stddev = NUM_STDDEV[column_name]\n",
    "    return lambda v: (tf.dtypes.cast(v, tf.float32) - avg) / stddev\n",
    "\n",
    "\n",
    "def create_feature_columns():\n",
    "    linear_feature_columns = []\n",
    "    categorical_feature_columns = []\n",
    "\n",
    "    for column_name in COLUMN_NAMES:\n",
    "        if column_name.startswith(\"int\"):\n",
    "            linear_feature_columns.append(\n",
    "                tf.feature_column.numeric_column(\n",
    "                    column_name,\n",
    "                    dtype=tf.dtypes.int64,\n",
    "                    normalizer_fn=make_norm_fn(column_name),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if column_name.startswith(\"cat\"):\n",
    "            column_vocabulary_size = VOCABULARY_SIZE[column_name]\n",
    "            hash_bucket_size = min(column_vocabulary_size, 100000)\n",
    "            embedding_dimension = int(\n",
    "                min(50, math.floor(6 * column_vocabulary_size**0.25))\n",
    "            )\n",
    "            categorical_feature_columns.append(\n",
    "                tf.feature_column.embedding_column(\n",
    "                    tf.feature_column.categorical_column_with_hash_bucket(\n",
    "                        column_name, hash_bucket_size, dtype=tf.dtypes.string\n",
    "                    ),\n",
    "                    embedding_dimension,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return linear_feature_columns + categorical_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jgTZP1zd4Bb"
   },
   "outputs": [],
   "source": [
    "def create_keras_model_sequential():\n",
    "    feature_columns = create_feature_columns()\n",
    "\n",
    "    feature_layer = tf.keras.layers.DenseFeatures(feature_columns, name=\"feature_layer\")\n",
    "    Dense = tf.keras.layers.Dense\n",
    "    Dropout = tf.keras.layers.Dropout\n",
    "    BatchNormalization = tf.keras.layers.BatchNormalization\n",
    "    dense_layers = []\n",
    "    for c in HIDDEN_LAYERS:\n",
    "        dense_layers.append(BatchNormalization())\n",
    "        dense_layers.append(Dense(c, activation=tf.nn.relu))\n",
    "        dense_layers.append(Dropout(0.05))\n",
    "    model = tf.keras.Sequential(\n",
    "        [feature_layer] + dense_layers + [Dense(1, activation=tf.nn.sigmoid)]\n",
    "    )\n",
    "\n",
    "    logging.info(\"compiling sequential keras model\")\n",
    "    # Compile Keras model\n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_keras_model_sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfvQSOmofI6B"
   },
   "source": [
    "训练模型。预期损失约为0.35。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCanYbuJd5-S"
   },
   "outputs": [],
   "source": [
    "model.fit(read_gcs(batch_size=256).take(1000), epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HcxyuOMfMdn"
   },
   "source": [
    "验证模型。预期损失约为0.45。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GsVEleWfOPM"
   },
   "outputs": [],
   "source": [
    "model.evaluate(read_gcs(batch_size=256).skip(1000).take(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyyP4msGfPyZ"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9sx-tFBfRq3"
   },
   "outputs": [],
   "source": [
    "model.save(os.path.join(LOCAL_DIRECTORY_FULL, \"keras\"), include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVibdmrufYRA"
   },
   "source": [
    "请检查模型签名以查看预测请求应具有哪些字段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MG4kerVsfVzI"
   },
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir $LOCAL_DIRECTORY_FULL/keras --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKi0_T-bfaMT"
   },
   "source": [
    "##（可选）训练和保存评估器模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11cf00aa9298"
   },
   "source": [
    "训练模型的另一个选择是使用TensorFlow的Estimator API。更多信息请参见https://github.com/tensorflow/docs/blob/r2.4/site/en/tutorials/estimator/premade.ipynb\n",
    "\n",
    "以下代码仅供示例目的。您可以使用Keras模型进行部署。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fe8234cffb0"
   },
   "outputs": [],
   "source": [
    "feature_columns = create_feature_columns()\n",
    "estimator = tf.estimator.DNNClassifier(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=HIDDEN_LAYERS,\n",
    "    dropout=0.05,\n",
    "    batch_norm=True,\n",
    "    n_classes=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35654a928cf7"
   },
   "outputs": [],
   "source": [
    "tf.estimator.train_and_evaluate(\n",
    "    estimator,\n",
    "    train_spec=tf.estimator.TrainSpec(\n",
    "        input_fn=lambda: read_gcs(batch_size=256).take(2000)\n",
    "    ),\n",
    "    eval_spec=tf.estimator.EvalSpec(input_fn=lambda: read_gcs().skip(500).take(100)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "457484fce156"
   },
   "outputs": [],
   "source": [
    "!rm -r -f $LOCAL_DIRECTORY_FULL/estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7a3f512b9f3e"
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()  # You'll have to restart Runtime after running this\n",
    "spec_dict = {}\n",
    "for column_name in COLUMN_NAMES:\n",
    "    if column_name.startswith(\"int\"):\n",
    "        spec_dict[column_name] = tf.compat.v1.placeholder(\n",
    "            name=column_name, shape=(1,), dtype=tf.int64\n",
    "        )\n",
    "    if column_name.startswith(\"cat\"):\n",
    "        spec_dict[column_name] = tf.compat.v1.placeholder(\n",
    "            name=column_name, shape=(), dtype=tf.string\n",
    "        )\n",
    "\n",
    "serving_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(spec_dict)\n",
    "estimator_base_path = os.path.join(LOCAL_DIRECTORY_FULL, \"estimator\")\n",
    "estimator_path = estimator.export_saved_model(estimator_base_path, serving_input_fn)\n",
    "estimator_path = estimator_path.decode(\"ascii\")\n",
    "estimator_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e796d225e740"
   },
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir $estimator_path --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd4c3d9bf3aa"
   },
   "source": [
    "## 生成预测请求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "953eb5e1e86e"
   },
   "source": [
    "现在我们可以生成发送到我们的模型进行推断的请求。\n",
    "请求是以JSON Lines格式生成的，每行一个请求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e07ab9e6213b"
   },
   "outputs": [],
   "source": [
    "!mkdir -p $LOCAL_DIRECTORY_FULL/requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5313e9d6b90"
   },
   "outputs": [],
   "source": [
    "def wrap_value(value, wrap_value):\n",
    "    if wrap_value:\n",
    "        return [value]\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "\n",
    "def row_to_dict(row, wrap_values):\n",
    "    d = {}\n",
    "    for key, value in row[0].items():\n",
    "        if \"int\" in key:\n",
    "            d[key] = [wrap_value(v, wrap_values) for v in value.numpy().tolist()]\n",
    "        if \"cat\" in key:\n",
    "            d[key] = [\n",
    "                wrap_value(v.decode(), wrap_values) for v in value.numpy().tolist()\n",
    "            ]\n",
    "    return d\n",
    "\n",
    "\n",
    "def export_requests_jsonl(file_name, rows=100, batch_size=64, wrap_values=True):\n",
    "    with tf.io.gfile.GFile(file_name, mode=\"w\") as f:\n",
    "        for row in read_gcs(batch_size):\n",
    "            d = row_to_dict(row, wrap_values)\n",
    "            f.write(json.dumps(d))\n",
    "            f.write(\"\\n\")\n",
    "            rows -= 1\n",
    "            if rows == 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6b400bd17be6"
   },
   "outputs": [],
   "source": [
    "export_requests_jsonl(\n",
    "    os.path.join(LOCAL_DIRECTORY_FULL, \"requests\", \"requests_1_1.jsonl\"),\n",
    "    rows=1,\n",
    "    batch_size=1,\n",
    ")\n",
    "export_requests_jsonl(\n",
    "    os.path.join(LOCAL_DIRECTORY_FULL, \"requests\", \"requests_1_512.jsonl\"),\n",
    "    rows=1,\n",
    "    batch_size=512,\n",
    ")\n",
    "export_requests_jsonl(\n",
    "    os.path.join(LOCAL_DIRECTORY_FULL, \"requests\", \"requests_10_1.jsonl\"),\n",
    "    rows=10,\n",
    "    batch_size=1,\n",
    ")\n",
    "export_requests_jsonl(\n",
    "    os.path.join(LOCAL_DIRECTORY_FULL, \"requests\", \"requests_10_512.jsonl\"),\n",
    "    rows=10,\n",
    "    batch_size=512,\n",
    ")\n",
    "export_requests_jsonl(\n",
    "    os.path.join(LOCAL_DIRECTORY_FULL, \"requests\", \"requests_10_1024.jsonl\"),\n",
    "    rows=10,\n",
    "    batch_size=1024,\n",
    ")\n",
    "export_requests_jsonl(\n",
    "    os.path.join(LOCAL_DIRECTORY_FULL, \"requests\", \"requests_100_1.jsonl\"),\n",
    "    rows=100,\n",
    "    batch_size=1,\n",
    ")\n",
    "export_requests_jsonl(\n",
    "    os.path.join(LOCAL_DIRECTORY_FULL, \"requests\", \"requests_100_512.jsonl\"),\n",
    "    rows=100,\n",
    "    batch_size=512,\n",
    ")\n",
    "export_requests_jsonl(\n",
    "    os.path.join(LOCAL_DIRECTORY_FULL, \"requests\", \"requests_100_1024.jsonl\"),\n",
    "    rows=100,\n",
    "    batch_size=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9523fd4d23c1"
   },
   "source": [
    "如果您想要导出Estimator模型的请求，您必须将`wrap_values`设置为`False`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "319505cb75db"
   },
   "outputs": [],
   "source": [
    "export_requests_jsonl(\n",
    "    os.path.join(LOCAL_DIRECTORY_FULL, \"requests\", \"requests_estimator_10_1.jsonl\"),\n",
    "    rows=10,\n",
    "    batch_size=1,\n",
    "    wrap_values=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c17522fcfd37"
   },
   "source": [
    "##（可选）生成热身请求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9c75a550809d"
   },
   "source": [
    "TensorFlow运行时具有延迟初始化的组件。懒惰初始化可能会导致在加载模型后发送给模型的第一个请求的延迟很高。这种延迟可能比单个推理请求的延迟高出几个数量级。\n",
    "\n",
    "有关SavedModel预热的更多信息，请参阅https://www.tensorflow.org/tfx/serving/saved_model_warmup。\n",
    "\n",
    "对于使用优化的TensorFlow运行时的Vertex AI预测，当模型预编译时，针对每个新批量大小的第一个请求会有较高的延迟。当`allow_precompilation`标志设置为true时启用预编译。\n",
    "\n",
    "为了减少高延迟，提供一个热身请求，让运行时在启动时加载。热身文件应包含你预期在生产中接收的各种批量大小。\n",
    "\n",
    "请注意，使用多个批量大小提供热身请求会增加每个节点启动的时间。\n",
    "\n",
    "如果您希望模型接收多个批量大小，可以使用一组`allowed_batch_sizes` 使用自动服务器端请求批处理。有关更多信息，请参阅https://www.tensorflow.org/tfx/serving/serving_config#batching_configuration。\n",
    "\n",
    "要为在Vertex AI预测上运行的模型启用自动批处理，请将批处理配置放入与 saved_model.pb 相同的GCS目录下的[config/batching_parameters_config](https://cloud.google.com/vertex-ai/docs/training/exporting-model-artifacts#enable_server-side_request_batching_for_tensorflow) 文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2238dc7c4d93"
   },
   "outputs": [],
   "source": [
    "!mkdir -p $LOCAL_DIRECTORY_FULL/keras/assets.extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a45ace218017"
   },
   "outputs": [],
   "source": [
    "def build_grpc_request(\n",
    "    row_dict, model_name=\"default\", signature_name=\"serving_default\"\n",
    "):\n",
    "    \"\"\"Generate gRPC inference request with payload.\"\"\"\n",
    "\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = model_name\n",
    "    request.model_spec.signature_name = signature_name\n",
    "    for key, value in row_dict.items():\n",
    "        proto = None\n",
    "        if \"cat\" in key:\n",
    "            proto = tf.make_tensor_proto(value, dtype=tf.string)\n",
    "        else:\n",
    "            proto = tf.make_tensor_proto(value, dtype=tf.int64)\n",
    "        request.inputs[key].CopyFrom(proto)\n",
    "    return request\n",
    "\n",
    "\n",
    "def export_warmup_file(\n",
    "    request_files, export_path, model_name=\"default\", signature_name=\"serving_default\"\n",
    "):\n",
    "    with tf.io.TFRecordWriter(export_path) as writer:\n",
    "        for request_file_path in request_files:\n",
    "            with open(request_file_path) as f:\n",
    "                row_dict = json.loads(f.readline())\n",
    "                request = build_grpc_request(row_dict, model_name, signature_name)\n",
    "            log = prediction_log_pb2.PredictionLog(\n",
    "                predict_log=prediction_log_pb2.PredictLog(request=request)\n",
    "            )\n",
    "            writer.write(log.SerializeToString())\n",
    "\n",
    "\n",
    "export_warmup_file(\n",
    "    [\n",
    "        os.path.join(LOCAL_DIRECTORY_FULL, \"requests\", \"requests_1_1.jsonl\"),\n",
    "        os.path.join(LOCAL_DIRECTORY_FULL, \"requests\", \"requests_1_512.jsonl\"),\n",
    "    ],\n",
    "    os.path.join(\n",
    "        LOCAL_DIRECTORY_FULL, \"keras\", \"assets.extra\", \"tf_serving_warmup_requests\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0054f6d6206a"
   },
   "source": [
    "将模型部署到Vertex AI预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af77cccd3307"
   },
   "source": [
    "要将模型部署到Vertex AI预测服务，您必须将其放入一个GCS存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUJePRU3LDcR"
   },
   "outputs": [],
   "source": [
    "!gsutil rm -r $BUCKET_URI/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31d89fa9f121"
   },
   "outputs": [],
   "source": [
    "!gsutil cp -r $LOCAL_DIRECTORY_FULL/keras/* $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f3eb65dbb82"
   },
   "source": [
    "将Vertex AI Python客户端库导入到您的笔记本环墍中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85c1b7a3f0f5"
   },
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform import gapic as aip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc88fefba44a"
   },
   "source": [
    "定义节点类型以用于部署。有关 Vertex AI 预测选项的更多信息，请查看 [配置计算资源](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76432d97918e"
   },
   "outputs": [],
   "source": [
    "DEPLOY_COMPUTE = \"n1-standard-16\"\n",
    "DEPLOY_GPU = aip.AcceleratorType.NVIDIA_TESLA_T4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "285371d048e1"
   },
   "source": [
    "AI 平台 Python 客户端库以客户端/服务器模型运行。\n",
    "\n",
    "在此示例中使用以下客户端:\n",
    "- 模型服务用于管理模型。\n",
    "- 端点服务用于部署。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "549bd6acf87c"
   },
   "outputs": [],
   "source": [
    "API_ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\"\n",
    "PARENT = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "\n",
    "client_options = {\"api_endpoint\": API_ENDPOINT}\n",
    "model_service_client = aip.ModelServiceClient(client_options=client_options)\n",
    "endpoint_service_client = aip.EndpointServiceClient(client_options=client_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3e4d12f7374"
   },
   "source": [
    "### 设置私有端点用于在线预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d259d62f8a4"
   },
   "source": [
    "您训练的Criteo模型的吞吐量和延迟对网络性能敏感。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60667c66da2f"
   },
   "source": [
    "请注意，批量大小为512的单个请求占用约200Kb的空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7d54a9f02769"
   },
   "outputs": [],
   "source": [
    "!ls -alh $LOCAL_DIRECTORY_FULL/requests/requests_1_512.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64268dc47d5c"
   },
   "source": [
    "为了获得最佳性能，请使用Vertex AI预测私有端点。\n",
    "\n",
    "要使用私有端点，请在您的项目和托管虚拟机运行您的模型的Vertex AI预测服务项目之间设置VPC对等网络。这样可以消除网络流量中的额外跳跃，并允许使用高效的gRPC协议。\n",
    "\n",
    "有关私有端点的更多信息，请参阅https://cloud.google.com/vertex-ai/docs/predictions/using-private-endpoints。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf4685ec69fd"
   },
   "source": [
    "有关Vertex AI中VPC对等连接的更多信息，请参阅https://cloud.google.com/vertex-ai/docs/general/vpc-peering。\n",
    "\n",
    "**重要提示：每个VPC网络只能设置一个到servicenetworking.googleapis.com的VPC对等连接。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "743b3af8f747"
   },
   "source": [
    "为简单起见，您可以将VPC互连设置为默认网络。您可以为您的项目创建不同的网络。\n",
    "\n",
    "如果您要与任何其他网络建立VPC互连，请确保该网络已经存在，并且您的虚拟机正在该网络上运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bab19db69297"
   },
   "outputs": [],
   "source": [
    "# This is for display only; you can name the range anything.\n",
    "PEERING_RANGE_NAME = \"vertex-ai-prediction-peering-range\"\n",
    "NETWORK = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43f7a7c2eed6"
   },
   "outputs": [],
   "source": [
    "# NOTE: `prefix-length=16` means a CIDR block with mask /16 will be\n",
    "# reserved for use by Google services, such as Vertex AI.\n",
    "!gcloud compute addresses create $PEERING_RANGE_NAME \\\n",
    "  --global \\\n",
    "  --prefix-length=16 \\\n",
    "  --description=\"peering range for Google service\" \\\n",
    "  --network=$NETWORK \\\n",
    "  --purpose=VPC_PEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "824f75d1dc95"
   },
   "source": [
    "创建 VPC 连接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "338f4e58bb6b"
   },
   "outputs": [],
   "source": [
    "!gcloud services vpc-peerings connect \\\n",
    "  --service=servicenetworking.googleapis.com \\\n",
    "  --network=$NETWORK \\\n",
    "  --ranges=$PEERING_RANGE_NAME \\\n",
    "  --project=$PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2be23c201b8"
   },
   "source": [
    "如果在运行此命令时收到权限错误，请尝试使用您的用户帐户运行它。\n",
    "\n",
    "要使用您的用户帐户运行此命令，请执行以下操作：\n",
    "- 在上面的单元格中的命令之前添加 `echo` (`echo gcloud services vpc-peering ...`)。\n",
    "- 运行该单元格并复制其输出\n",
    "- 打开新的终端窗口，并运行 `gcloud auth login` 以使用您的用户帐户进行身份验证。\n",
    "- 粘贴并运行在终端中复制的命令。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de727b998161"
   },
   "source": [
    "检查您对等连接的状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38b48cc436cb"
   },
   "outputs": [],
   "source": [
    "!gcloud compute networks peerings list --network $NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9b09bb49bc1"
   },
   "source": [
    "### 上传模型到Vertex AI预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYFkS2H9dDfd"
   },
   "source": [
    "了解有关[model_service.upload_model](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.services.model_service.ModelServiceClient#google_cloud_aiplatform_v1_services_model_service_ModelServiceClient_upload_model)的更多信息。\n",
    "\n",
    "`artifact_uri`参数应指向保存您的模型的`saved_model.pb`文件所在的GCS路径。\n",
    "\n",
    "`image_uri`指定要使用的docker镜像。在此处，我们使用TF2.7 GPU和Vertex AI Prediction优化的TensorFlow运行时镜像上传相同的模型。\n",
    "\n",
    "为了能够通过gRPC发送请求到您的模型，您需要设置`model_name`参数，并相应地更新`predict_route`和`health_route`。\n",
    "\n",
    "请注意，Vertex AI Prediction中的gRPC支持仍处于实验阶段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91038811953e"
   },
   "outputs": [],
   "source": [
    "tf27_cpu_model_dict = {\n",
    "    \"display_name\": \"Criteo Kaggle TF2.7 CPU model\",\n",
    "    \"artifact_uri\": BUCKET_URI,\n",
    "    \"container_spec\": {\n",
    "        \"image_uri\": \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest\",\n",
    "        \"args\": [\n",
    "            \"--port=8500\",\n",
    "            \"--rest_api_port=8080\",\n",
    "            \"--model_name=default\",\n",
    "            \"--model_base_path=$(AIP_STORAGE_URI)\",\n",
    "        ],\n",
    "        \"ports\": [{\"container_port\": 8080}],\n",
    "        \"predict_route\": \"/v1/models/default:predict\",\n",
    "        \"health_route\": \"/v1/models/default\",\n",
    "    },\n",
    "}\n",
    "tf27_cpu_model = (\n",
    "    model_service_client.upload_model(parent=PARENT, model=tf27_cpu_model_dict)\n",
    "    .result(timeout=180)\n",
    "    .model\n",
    ")\n",
    "tf27_cpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5439eae4099"
   },
   "outputs": [],
   "source": [
    "tf27_gpu_model_dict = {\n",
    "    \"display_name\": \"Criteo Kaggle TF2.7 GPU model\",\n",
    "    \"artifact_uri\": BUCKET_URI,\n",
    "    \"container_spec\": {\n",
    "        \"image_uri\": \"us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-7:latest\",\n",
    "        \"args\": [\n",
    "            \"--port=8500\",\n",
    "            \"--rest_api_port=8080\",\n",
    "            \"--model_name=default\",\n",
    "            \"--model_base_path=$(AIP_STORAGE_URI)\",\n",
    "        ],\n",
    "        \"ports\": [{\"container_port\": 8080}],\n",
    "        \"predict_route\": \"/v1/models/default:predict\",\n",
    "        \"health_route\": \"/v1/models/default\",\n",
    "    },\n",
    "}\n",
    "tf27_gpu_model = (\n",
    "    model_service_client.upload_model(parent=PARENT, model=tf27_gpu_model_dict)\n",
    "    .result(timeout=180)\n",
    "    .model\n",
    ")\n",
    "tf27_gpu_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b12af8ec4912"
   },
   "source": [
    "要使用Vertex AI Prediction优化的TensorFlow运行时部署模型，请使用`us-docker.pkg.dev/vertex-ai-restricted/prediction/tf_opt-gpu.nightly:latest`容器。\n",
    "\n",
    "模型应用了两种优化选项。\n",
    "- *allow_precompilation* - 启用模型预编译以提高性能。请注意，当第一个具有新批量大小的请求到达时，模型预编译会发生，并且在预编译完成后发送该请求的响应。为了减轻这一问题，请指定一个热身文件（请参阅此colab中的之前部分）。模型预编译适用于不同类型的模型，在大多数情况下对性能有积极影响。但我们建议您在生产环境中启用之前先为您的模型尝试一下。\n",
    "- *allow_precision_affecting_optimizations* - 启用影响精度的优化。在某些情况下，这会使模型运行速度明显加快，但损失对模型预测能力的影响非常小。使用此优化时，您应该评估对模型的精度影响。\n",
    "\n",
    "有关可用优化的TensorFlow运行时容器和选项列表，请参阅https://cloud.google.com/vertex-ai/docs/predictions/optimized-tensorflow-runtime。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8a2837ac245"
   },
   "outputs": [],
   "source": [
    "tf_opt_gpu_model_dict = {\n",
    "    \"display_name\": \"Criteo Kaggle optimized TensorFlow runtime GPU model\",\n",
    "    \"artifact_uri\": BUCKET_URI,\n",
    "    \"container_spec\": {\n",
    "        \"image_uri\": \"us-docker.pkg.dev/vertex-ai-restricted/prediction/tf_opt-gpu.nightly:latest\",\n",
    "        \"args\": [\n",
    "            \"--model_name=default\",\n",
    "            \"--allow_precompilation=true\",\n",
    "            \"--allow_precision_affecting_optimizations=false\",\n",
    "        ],\n",
    "        \"predict_route\": \"/v1/models/default:predict\",\n",
    "        \"health_route\": \"/v1/models/default\",\n",
    "    },\n",
    "}\n",
    "\n",
    "tf_opt_gpu_model = (\n",
    "    model_service_client.upload_model(parent=PARENT, model=tf_opt_gpu_model_dict)\n",
    "    .result(timeout=180)\n",
    "    .model\n",
    ")\n",
    "tf_opt_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3f21fd3203e"
   },
   "outputs": [],
   "source": [
    "tf_opt_lossy_gpu_model_dict = {\n",
    "    \"display_name\": \"Criteo Kaggle optimized TensorFlow runtime GPU model with lossy optimizations\",\n",
    "    \"artifact_uri\": BUCKET_URI,\n",
    "    \"container_spec\": {\n",
    "        \"image_uri\": \"us-docker.pkg.dev/vertex-ai-restricted/prediction/tf_opt-gpu.nightly:latest\",\n",
    "        \"args\": [\n",
    "            \"--model_name=default\",\n",
    "            \"--allow_precompilation=true\",\n",
    "            \"--allow_precision_affecting_optimizations=true\",\n",
    "        ],\n",
    "        \"predict_route\": \"/v1/models/default:predict\",\n",
    "        \"health_route\": \"/v1/models/default\",\n",
    "    },\n",
    "}\n",
    "\n",
    "tf_opt_lossy_gpu_model = (\n",
    "    model_service_client.upload_model(parent=PARENT, model=tf_opt_lossy_gpu_model_dict)\n",
    "    .result(timeout=180)\n",
    "    .model\n",
    ")\n",
    "tf_opt_lossy_gpu_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a07f1e5b393d"
   },
   "source": [
    "列出所有的型号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e904929d4c38"
   },
   "outputs": [],
   "source": [
    "model_service_client.list_models(parent=PARENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f674f8c2d0a"
   },
   "source": [
    "创建端点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4279643c2cf"
   },
   "source": [
    "了解更多关于[endpoint_service.create_endpoint](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.services.endpoint_service.EndpointServiceClient#google_cloud_aiplatform_v1_services_endpoint_service_EndpointServiceClient_create_endpoint)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4efb545e0439"
   },
   "outputs": [],
   "source": [
    "project_number = re.match(r\"projects/(\\d+)/.+\", tf27_cpu_model)[1]\n",
    "full_network_name = f\"projects/{project_number}/global/networks/{NETWORK}\"\n",
    "full_network_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3860a1c4004"
   },
   "outputs": [],
   "source": [
    "tf27_cpu_endpoint_dict = {\n",
    "    \"display_name\": \"Criteo Kaggle TF2.7 CPU private endpoint\",\n",
    "    \"network\": full_network_name,\n",
    "}\n",
    "tf27_cpu_endpoint = (\n",
    "    endpoint_service_client.create_endpoint(\n",
    "        parent=PARENT, endpoint=tf27_cpu_endpoint_dict\n",
    "    )\n",
    "    .result(timeout=300)\n",
    "    .name\n",
    ")\n",
    "tf27_cpu_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7da2c558e020"
   },
   "outputs": [],
   "source": [
    "tf27_gpu_endpoint_dict = {\n",
    "    \"display_name\": \"Criteo Kaggle TF2.7 GPU private endpoint\",\n",
    "    \"network\": full_network_name,\n",
    "}\n",
    "tf27_gpu_endpoint = (\n",
    "    endpoint_service_client.create_endpoint(\n",
    "        parent=PARENT, endpoint=tf27_gpu_endpoint_dict\n",
    "    )\n",
    "    .result(timeout=300)\n",
    "    .name\n",
    ")\n",
    "tf27_gpu_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20f684d17e01"
   },
   "outputs": [],
   "source": [
    "tf_opt_gpu_endpoint_dict = {\n",
    "    \"display_name\": \"Criteo Kaggle optimized TensorFlow runtime GPU private endpoint\",\n",
    "    \"network\": full_network_name,\n",
    "}\n",
    "tf_opt_gpu_endpoint = (\n",
    "    endpoint_service_client.create_endpoint(\n",
    "        parent=PARENT, endpoint=tf_opt_gpu_endpoint_dict\n",
    "    )\n",
    "    .result(timeout=300)\n",
    "    .name\n",
    ")\n",
    "tf_opt_gpu_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7e666cd56510"
   },
   "outputs": [],
   "source": [
    "tf_opt_lossy_gpu_endpoint_dict = {\n",
    "    \"display_name\": \"Criteo Kaggle optimized TensorFlow runtime GPU with lossy optimizations private endpoint\",\n",
    "    \"network\": full_network_name,\n",
    "}\n",
    "tf_opt_lossy_gpu_endpoint = (\n",
    "    endpoint_service_client.create_endpoint(\n",
    "        parent=PARENT, endpoint=tf_opt_lossy_gpu_endpoint_dict\n",
    "    )\n",
    "    .result(timeout=300)\n",
    "    .name\n",
    ")\n",
    "tf_opt_lossy_gpu_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56ade2bea05a"
   },
   "source": [
    "部署模型到端点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8586711566b"
   },
   "source": [
    "了解有关[enpoint_service.deploy_model](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.services.endpoint_service.EndpointServiceClient#google_cloud_aiplatform_v1_services_endpoint_service_EndpointServiceClient_deploy_model)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ac48f638e2e"
   },
   "outputs": [],
   "source": [
    "tf27_cpu_deployed_model_dict = {\n",
    "    \"model\": tf27_cpu_model,\n",
    "    \"display_name\": \"Criteo Kaggle TF2.7 CPU deployed model\",\n",
    "    \"dedicated_resources\": {\n",
    "        \"min_replica_count\": 1,\n",
    "        \"max_replica_count\": 1,\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": DEPLOY_COMPUTE,\n",
    "            \"accelerator_count\": 0,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "tf27_cpu_deployed_model = endpoint_service_client.deploy_model(\n",
    "    endpoint=tf27_cpu_endpoint, deployed_model=tf27_cpu_deployed_model_dict\n",
    ").result()\n",
    "tf27_cpu_deployed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "104eb9495a6b"
   },
   "outputs": [],
   "source": [
    "tf27_gpu_deployed_model_dict = {\n",
    "    \"model\": tf27_gpu_model,\n",
    "    \"display_name\": \"Criteo Kaggle TF2.7 GPU deployed model\",\n",
    "    \"dedicated_resources\": {\n",
    "        \"min_replica_count\": 1,\n",
    "        \"max_replica_count\": 1,\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": DEPLOY_COMPUTE,\n",
    "            \"accelerator_type\": DEPLOY_GPU,\n",
    "            \"accelerator_count\": 1,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "tf27_gpu_deployed_model = endpoint_service_client.deploy_model(\n",
    "    endpoint=tf27_gpu_endpoint, deployed_model=tf27_gpu_deployed_model_dict\n",
    ").result()\n",
    "tf27_gpu_deployed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d5d7dc432e8"
   },
   "outputs": [],
   "source": [
    "tf_opt_gpu_deployed_model_dict = {\n",
    "    \"model\": tf_opt_gpu_model,\n",
    "    \"display_name\": \"Criteo Kaggle optimized TensorFlow runtime GPU model\",\n",
    "    \"dedicated_resources\": {\n",
    "        \"min_replica_count\": 1,\n",
    "        \"max_replica_count\": 1,\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": DEPLOY_COMPUTE,\n",
    "            \"accelerator_type\": DEPLOY_GPU,\n",
    "            \"accelerator_count\": 1,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "tf_opt_gpu_deployed_model = endpoint_service_client.deploy_model(\n",
    "    endpoint=tf_opt_gpu_endpoint, deployed_model=tf_opt_gpu_deployed_model_dict\n",
    ").result()\n",
    "tf_opt_gpu_deployed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ca51ac94a1c7"
   },
   "outputs": [],
   "source": [
    "tf_opt_lossy_gpu_deployed_model_dict = {\n",
    "    \"model\": tf_opt_lossy_gpu_model,\n",
    "    \"display_name\": \"Criteo Kaggle optimized TensorFlow runtime GPU model with lossy optimizations\",\n",
    "    \"dedicated_resources\": {\n",
    "        \"min_replica_count\": 1,\n",
    "        \"max_replica_count\": 1,\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": DEPLOY_COMPUTE,\n",
    "            \"accelerator_type\": DEPLOY_GPU,\n",
    "            \"accelerator_count\": 1,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "tf_opt_lossy_gpu_deployed_model = endpoint_service_client.deploy_model(\n",
    "    endpoint=tf_opt_lossy_gpu_endpoint,\n",
    "    deployed_model=tf_opt_lossy_gpu_deployed_model_dict,\n",
    ").result()\n",
    "tf_opt_lossy_gpu_deployed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c91265a78a97"
   },
   "source": [
    "比较部署模型的性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c264b3b6eb3f"
   },
   "source": [
    "要访问私有端点，发送请求的虚拟机必须部署在您设置VPC对等连接的同一网络中。因此，您不能从Colab发送请求到使用私有端点部署的模型。\n",
    "\n",
    "为了获得最佳性能，请确保虚拟机与您的模型位于同一地区。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04ea66e6c6e2"
   },
   "source": [
    "导入用于对模型进行基准测试的辅助函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81f72b64c8e5"
   },
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/vertex_endpoints/optimized_tensorflow_runtime/benchmark.py -o benchmark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cd21d1afb38"
   },
   "outputs": [],
   "source": [
    "from benchmark import benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81380aabcda7"
   },
   "source": [
    "该代码以给定的QPS异步且均匀地发送指定数量的请求，然后记录观察到的延迟。接下来，将对延迟结果进行汇总并计算百分位数。\n",
    "模型能够处理的`实际QPS`是指模型处理发送请求所需的时间除以请求数量得出的值。\n",
    "通过为`send_request`和`build_request`函数提供不同的实现，可以在本地或使用gRPC和REST协议在Vertex AI Prediction上运行的模型进行基准测试。\n",
    "\n",
    "该基准测试的主要目标是测量模型在不同负载下的延迟和模型能够处理的最大吞吐量。为了找到最大吞吐量，逐渐增加QPS直到`实际QPS`停止增加并且延迟急剧增加。\n",
    "\n",
    "在生产部署中，工作负载并不均匀，因此最大模型吞吐量可能会较低。\n",
    "我们并不试图在此模拟生产工作负载。该基准测试旨在比较在不同环境中运行的同一模型的延迟和吞吐量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "664ec5c32fdb"
   },
   "source": [
    "关于部署模型的详细信息可以使用[endpoint_service_client.get_endpoint](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.services.endpoint_service.EndpointServiceClient#google_cloud_aiplatform_v1_services_endpoint_service_EndpointServiceClient_get_endpoint) API来访问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f238380d9a7"
   },
   "outputs": [],
   "source": [
    "tf_opt_gpu_endpoint_dict = endpoint_service_client.get_endpoint(\n",
    "    name=tf_opt_gpu_endpoint\n",
    ")\n",
    "tf_opt_gpu_endpoint_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fa9f6cb522c"
   },
   "source": [
    "首先，请验证您是否可以访问您的模型。【Shǒuxiān, qǐng yànzhèng nín shìfǒu kěyǐ fǎngwèn nín de móxíng。】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5394c8f5636"
   },
   "outputs": [],
   "source": [
    "health_url = tf_opt_gpu_endpoint_dict.deployed_models[\n",
    "    0\n",
    "].private_endpoints.health_http_uri\n",
    "health_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a377f25e675c"
   },
   "outputs": [],
   "source": [
    "!curl $health_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0ee794df447"
   },
   "source": [
    "定义助手方法，使用REST协议针对私有端点运行基准测试。\n",
    "应该发送请求的URI可以在`deployed_model.private_endpoints.predict_http_uri`中找到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89eb67cef6df"
   },
   "outputs": [],
   "source": [
    "def build_rest_request(\n",
    "    row_dict, model_name=\"default\", signature_name=\"serving_default\"\n",
    "):\n",
    "    payload = json.dumps({\"signature_name\": signature_name, \"inputs\": row_dict})\n",
    "    return payload\n",
    "\n",
    "\n",
    "def benchmark_rest_private_endpoint(\n",
    "    endpoint_name, qps_list, model_name=None, duration_seconds=5\n",
    "):\n",
    "    endpoint_dict = endpoint_service_client.get_endpoint(name=endpoint_name)\n",
    "    predict_uri = endpoint_dict.deployed_models[0].private_endpoints.predict_http_uri\n",
    "\n",
    "    def send_rest_request(request):\n",
    "        res = r.post(predict_uri, data=request)\n",
    "        assert res.status_code == 200\n",
    "        return res\n",
    "\n",
    "    return benchmark(\n",
    "        send_rest_request,\n",
    "        build_rest_request,\n",
    "        f\"{LOCAL_DIRECTORY_FULL}/requests/requests_100_512.jsonl\",\n",
    "        qps_list,\n",
    "        duration_seconds,\n",
    "        model_name=model_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdsHDlq-bYuG"
   },
   "source": [
    "您还可以使用gRPC协议在私有端点上部署的模型进行基准测试。\n",
    "\n",
    "gRPC地址与`predict_http_uri`或`predict_http_uri`的主机名相同。\n",
    "gRPC目的地的格式为`<endpoint_id>-<deployed_model_id>`，作为“grpc_destination”头部传递。\n",
    "\n",
    "请注意，在Vertex AI预测中，对gRPC的支持仍处于实验阶段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSOEYXR1b0k2"
   },
   "outputs": [],
   "source": [
    "def parse_endpoint_dict(endpoint_dict):\n",
    "    endpoint_id = re.match(r\".+/endpoints/(\\d+)\", endpoint_dict.name)[1]\n",
    "    deployed_model_id = endpoint_dict.deployed_models[0].id\n",
    "    grpc_destination = f\"{endpoint_id}-{deployed_model_id}\"\n",
    "    predict_uri = urlparse(\n",
    "        endpoint_dict.deployed_models[0].private_endpoints.predict_http_uri\n",
    "    )\n",
    "    grpc_uri = f\"{predict_uri.netloc}:8500\"\n",
    "    return (grpc_uri, grpc_destination)\n",
    "\n",
    "\n",
    "def benchmark_grpc_private_endpoint(endpoint_name, qps_list, duration_seconds=5):\n",
    "    endpoint_dict = endpoint_service_client.get_endpoint(name=endpoint_name)\n",
    "    grpc_uri, grpc_destinaion = parse_endpoint_dict(endpoint_dict)\n",
    "\n",
    "    grpc_metadata = []\n",
    "    grpc_metadata.append((\"grpc-destination\", grpc_destinaion))\n",
    "    grpc_channel = grpc.insecure_channel(grpc_uri)\n",
    "    grpc_stub = prediction_service_pb2_grpc.PredictionServiceStub(grpc_channel)\n",
    "\n",
    "    def send_grpc_request(request):\n",
    "        return grpc_stub.Predict(request, 60, metadata=grpc_metadata)\n",
    "\n",
    "    return benchmark(\n",
    "        send_grpc_request,\n",
    "        build_grpc_request,\n",
    "        f\"{LOCAL_DIRECTORY_FULL}/requests/requests_100_512.jsonl\",\n",
    "        qps_list,\n",
    "        duration_seconds,\n",
    "        model_name=\"default\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dcf9f454988"
   },
   "source": [
    "现在我们可以为每个端点运行基准测试，并比较结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8a2fc956ff69"
   },
   "outputs": [],
   "source": [
    "tf27_cpu_results = benchmark_grpc_private_endpoint(\n",
    "    tf27_cpu_endpoint, [10, 20, 30, 40, 50, 55]\n",
    ")\n",
    "tf27_cpu_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cda3c1184b5c"
   },
   "outputs": [],
   "source": [
    "tf27_gpu_results = benchmark_grpc_private_endpoint(\n",
    "    tf27_gpu_endpoint, [10, 20, 30, 40, 50, 60, 70, 75]\n",
    ")\n",
    "tf27_gpu_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb7bf5263c5a"
   },
   "outputs": [],
   "source": [
    "tf_opt_gpu_results = benchmark_grpc_private_endpoint(\n",
    "    tf_opt_gpu_endpoint, [10, 50, 100, 150, 200, 250, 275, 300, 325, 350]\n",
    ")\n",
    "tf_opt_gpu_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f96bb0e8cb0c"
   },
   "outputs": [],
   "source": [
    "tf_opt_lossy_gpu_results = benchmark_grpc_private_endpoint(\n",
    "    tf_opt_lossy_gpu_endpoint, [10, 50, 100, 200, 300, 400, 500, 600, 700, 800]\n",
    ")\n",
    "tf_opt_lossy_gpu_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41548dbecd5b"
   },
   "source": [
    "合并并可视化结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92405bdd7163"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def build_graph(x_key, y_key, results_dict, axis):\n",
    "    matplotlib.rcParams[\"figure.figsize\"] = [10.0, 7.0]\n",
    "\n",
    "    fig, ax = plt.subplots(facecolor=(1, 1, 1))\n",
    "    ax.set_xlabel(\"QPS\")\n",
    "    ax.set_ylabel(\"Latency(ms)\")\n",
    "    for title, results in results_dict.items():\n",
    "        x = np.array(results[x_key])\n",
    "        y = np.array(results[y_key])\n",
    "        ax.plot(x, y, label=title)\n",
    "    ax.legend()\n",
    "    ax.axis(axis)\n",
    "    ax.set_title(f\"Criteo model {y_key} latency, batch size 512\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "df3b8ac16b0c"
   },
   "outputs": [],
   "source": [
    "fig = build_graph(\n",
    "    \"actual_qps\",\n",
    "    \"p50\",\n",
    "    {\n",
    "        \"TF2.7 CPU\": tf27_cpu_results,\n",
    "        \"TF2.7 GPU\": tf27_gpu_results,\n",
    "        \"TF opt GPU\": tf_opt_gpu_results,\n",
    "        \"TF opt GPU lossy\": tf_opt_lossy_gpu_results,\n",
    "    },\n",
    "    (0, 800, 0, 60),\n",
    ")\n",
    "fig.savefig(\"criteo_p50_latency_512.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8593b878feab"
   },
   "outputs": [],
   "source": [
    "fig = build_graph(\n",
    "    \"actual_qps\",\n",
    "    \"p99\",\n",
    "    {\n",
    "        \"TF2.7 CPU\": tf27_cpu_results,\n",
    "        \"TF2.7 GPU\": tf27_gpu_results,\n",
    "        \"TF opt GPU\": tf_opt_gpu_results,\n",
    "        \"TF opt GPU lossy\": tf_opt_lossy_gpu_results,\n",
    "    },\n",
    "    (0, 800, 0, 100),\n",
    ")\n",
    "fig.savefig(\"criteo_p99_latency_512.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aac5ebde1803"
   },
   "source": [
    "您可以看到Vertex AI Prediction优化的TensorFlow运行时与TensorFlow 2.7相比，具有显着更高的吞吐量和更低的延迟。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f369366c0af"
   },
   "source": [
    "## （可选）使用MLPerf推理loadgen比较部署模型的性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfd210c97934"
   },
   "source": [
    "MLPerf 推断是一个基准套件，用于衡量系统在各种部署场景中运行模型的速度。MLPerf 现在是衡量模型性能的行业标准方式。您可以按照 https://github.com/tensorflow/tpu/tree/master/models/experimental/inference/load_test 上的说明来运行已部署模型的 MLPerf 推断基准测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fdbaecb0fdc"
   },
   "source": [
    "## (Optional) 比较预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8a16b45477f1"
   },
   "source": [
    "在本样本中，使用优化的TensorFlow运行时进行顶点预测，设置`allow_precision_affecting_optimizations`标志为`true`以获得额外的加速。现在让我们检查这些优化如何影响预测结果。\n",
    "\n",
    "我们比较在优化的TensorFlow运行时上对51200个请求进行模型预测的结果，该运行时在TF2.7上进行了损失优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59ffec627b59"
   },
   "outputs": [],
   "source": [
    "def get_predictions(endpoint, requests_file_path):\n",
    "    responses = []\n",
    "\n",
    "    endpoint_dict = endpoint_service_client.get_endpoint(name=endpoint)\n",
    "    pridict_uri = endpoint_dict.deployed_models[0].private_endpoints.predict_http_uri\n",
    "\n",
    "    with tf.io.gfile.GFile(requests_file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            row_dict = json.loads(line)\n",
    "            request = build_rest_request(row_dict)\n",
    "            response = r.post(pridict_uri, data=request)\n",
    "            for output in json.loads(response.text)[\"outputs\"]:\n",
    "                responses.append(output[0])\n",
    "\n",
    "    return np.array(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01fe427a6211"
   },
   "outputs": [],
   "source": [
    "tf27_gpu_predictions = get_predictions(\n",
    "    tf27_gpu_endpoint, f\"{LOCAL_DIRECTORY_FULL}/requests/requests_100_512.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94686b1b90a9"
   },
   "outputs": [],
   "source": [
    "tf_opt_lossy_gpu_predictions = get_predictions(\n",
    "    tf_opt_lossy_gpu_endpoint, f\"{LOCAL_DIRECTORY_FULL}/requests/requests_100_512.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3577df0bf00"
   },
   "outputs": [],
   "source": [
    "np.average(tf_opt_lossy_gpu_predictions - tf27_gpu_predictions) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cbdc0444957e"
   },
   "outputs": [],
   "source": [
    "np.max(np.abs(tf_opt_lossy_gpu_predictions - tf27_gpu_predictions)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29235c879dc5"
   },
   "source": [
    "您可以看到，平均结果在少于0.0016%的情况下是不同的。在最坏的情况下，差异为0.05%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1807d423c612"
   },
   "source": [
    "清理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b3132d3f788"
   },
   "source": [
    "完成后，可以安全地移除您创建的端点和部署的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64d8ee827276"
   },
   "outputs": [],
   "source": [
    "def cleanup(endpoint, model_name, deployed_model_id):\n",
    "    response = endpoint_service_client.undeploy_model(\n",
    "        endpoint=endpoint, deployed_model_id=deployed_model_id\n",
    "    )\n",
    "    print(\"running undeploy_model operation:\", response.operation.name)\n",
    "    print(response.result())\n",
    "\n",
    "    response = endpoint_service_client.delete_endpoint(name=endpoint)\n",
    "    print(\"running delete_endpoint operation:\", response.operation.name)\n",
    "    print(response.result())\n",
    "\n",
    "    response = model_service_client.delete_model(name=model_name)\n",
    "    print(\"running delete_model operation:\", response.operation.name)\n",
    "    print(response.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afd94ff1ed76"
   },
   "outputs": [],
   "source": [
    "cleanup(tf27_cpu_endpoint, tf27_cpu_model, tf27_cpu_deployed_model)\n",
    "cleanup(tf27_gpu_endpoint, tf27_gpu_model, tf27_gpu_deployed_model)\n",
    "cleanup(tf_opt_gpu_endpoint, tf_opt_gpu_model, tf_opt_gpu_deployed_model)\n",
    "cleanup(\n",
    "    tf_opt_lossy_gpu_endpoint, tf_opt_lossy_gpu_model, tf_opt_lossy_gpu_deployed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c37975fdc894"
   },
   "source": [
    "您现在也可以从GCS存储桶中删除模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "29d1d5458d73"
   },
   "outputs": [],
   "source": [
    "# Set this to true only if you'd like to delete your bucket\n",
    "delete_bucket = False\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    !gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tabular_optimized_online_prediction.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
