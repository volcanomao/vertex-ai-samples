{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18ebbd838e32"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64f7165bd1ac"
   },
   "source": [
    "# 在Vertex AI上的电信用户流失预测\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/workbench/subscriber_churn_prediction/telecom-subscriber-churn-prediction.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "    <td>\n",
    "        <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/workbench/subscriber_churn_prediction/telecom-subscriber-churn-prediction.ipynb\">\n",
    "        <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\\\" alt=\"Colab logo\"> 在Colab中运行\n",
    "        </a>\n",
    "  </td>\n",
    "  <td>\n",
    "<a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/workbench/subscriber_churn_prediction/telecom-subscriber-churn-prediction.ipynb\" target='_blank'>\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ccb933a1de0"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本示例演示了在[电信客户流失数据集](https://www.kaggle.com/c/customer-churn-prediction-2020/overview)上构建订阅者流失预测模型。生成的流失模型进一步部署到 Vertex AI 端点，并使用 Vertex AI 的可解释 AI 功能生成解释。\n",
    "\n",
    "了解更多关于[Vertex AI Workbench](https://cloud.google.com/vertex-ai/docs/workbench/introduction)和[Vertex Explainable AI](https://cloud.google.com/vertex-ai/docs/explainable-ai/overview)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c7726146192"
   },
   "source": [
    "### 目标\n",
    "\n",
    "本教程向您展示如何对表格型流失数据集进行探索性数据分析，预处理数据，训练，部署并从流失预测模型中获取预测。本教程的目标如下：\n",
    "\n",
    "本教程使用以下 Google Cloud ML 服务和资源：\n",
    "\n",
    "- `Vertex AI Model` 资源\n",
    "- `Vertex AI Endpoint` 资源\n",
    "- `Vertex Explainable AI`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 从 Cloud 存储路径加载数据\n",
    "- 执行探索性数据分析（EDA）\n",
    "- 预处理数据\n",
    "- 训练一个 scikit-learn 模型\n",
    "- 评估 scikit-learn 模型\n",
    "- 将模型保存到 Cloud 存储路径\n",
    "- 在 Vertex AI 中创建一个模型和一个端点\n",
    "- 部署训练好的模型到一个端点\n",
    "- 在托管模型上生成对测试数据的预测和解释\n",
    "- 关闭模型资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bae972f3229"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程中使用的数据集是在Kaggle上公开提供的电信客户流失数据集。请参阅[2020年客户流失预测](https://www.kaggle.com/c/customer-churn-prediction-2020/data)。本数据集用于在这个笔记本中使用Vertex AI构建和部署流失预测模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "556bf343c423"
   },
   "source": [
    "### 成本\n",
    "\n",
    "本教程使用 Google Cloud 的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "请了解 [Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing) 和 [Cloud Storage 价格](https://cloud.google.com/storage/pricing)，并使用 [定价计算器](https://cloud.google.com/products/calculator/) 根据您的预期使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0b0e0803638"
   },
   "source": [
    "### 设置您的本地开发环境\n",
    "\n",
    "**如果您正在使用Colab或者Vertex AI Workbench笔记本**，您的环境已满足运行此笔记本的所有要求。您可以跳过这一步。\n",
    "\n",
    "**_注意_**：此笔记已在以下环境中经过测试：\n",
    "\n",
    "* Python版本 = 3.9\n",
    "\n",
    "**否则**，请确保您的环境满足此笔记本的要求。您需要以下内容：\n",
    "\n",
    "* Google Cloud SDK\n",
    "\n",
    "Google Cloud指南中的[设置Python开发环境](https://cloud.google.com/python/setup)和[Jupyter安装指南](https://jupyter.org/install)提供了详细的说明以满足这些要求。以下步骤提供了简洁的指导：\n",
    "\n",
    "1. [安装并初始化Cloud SDK。](https://cloud.google.com/sdk/docs/)\n",
    "\n",
    "2. [安装Python 3。](https://cloud.google.com/python/setup#installing_python)\n",
    "\n",
    "3. [安装virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv)并创建一个使用Python 3的虚拟环境。激活虚拟环境。\n",
    "\n",
    "4. 要安装Jupyter，请在终端中的命令行上运行 `pip3 install jupyter`。\n",
    "\n",
    "5. 要启动Jupyter，请在终端中的命令行上运行 `jupyter notebook`。\n",
    "\n",
    "6. 在Jupyter Notebook仪表板中打开此笔记本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44b8ae8e2d19"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装以下所需的包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ab450121b368"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "    \n",
    "! pip3 install {USER_FLAG} --upgrade google-cloud-aiplatform \\\n",
    "                                    google-cloud-storage \\\n",
    "                                    category_encoders \\\n",
    "                                    seaborn \\\n",
    "                                    scikit-learn \\\n",
    "                                    pandas \\\n",
    "                                    fsspec \\\n",
    "                                    gcsfs -q "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b24902cde81b"
   },
   "source": [
    "重新启动内核\n",
    "\n",
    "在安装了额外的软件包之后，您需要重新启动笔记本内核以便它能找到这些软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c61d171395d7"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b012ef94ce80"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### 设置您的Google Cloud项目\n",
    "\n",
    "**无论您使用哪种笔记本环境，以下步骤都是必需的。**\n",
    "\n",
    "1. [选择或创建Google Cloud项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建帐户时，您将获得$300的免费信用，可用于支付计算/存储成本。\n",
    "\n",
    "2. [确保您的项目已启用结算](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "3. [启用Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。\n",
    "\n",
    "4. 如果您在本地运行此笔记本，您需要安装[Cloud SDK](https://cloud.google.com/sdk)。\n",
    "\n",
    "5. 在下面的单元格中输入您的项目ID。然后运行该单元格，以确保Cloud SDK在本笔记本中的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter通过以`!`为前缀的行作为shell命令运行，并将以`$`为前缀的Python变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96ff17f75e21"
   },
   "source": [
    "设置您的项目 ID\n",
    "\n",
    "**如果您不知道您的项目 ID**，可以使用 `gcloud` 来获取您的项目 ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2e80fda2ea2"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6855b42885bf"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2e3c0f2cbfb"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60d535f443ac"
   },
   "source": [
    "区域\n",
    "\n",
    "您还可以更改“REGION”变量，该变量用于整个笔记本的操作。以下是Vertex AI支持的区域。建议您选择最接近您的区域。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太地区：`asia-east1`\n",
    "\n",
    "您可能无法使用多区域存储桶来进行Vertex AI的训练。并非所有区域都支持所有Vertex AI服务。\n",
    "\n",
    "了解更多关于[Vertex AI区域](https://cloud.google.com/vertex-ai/docs/general/locations)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3aaadaaf9b30"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e663bd062c6f"
   },
   "source": [
    "UUID\n",
    "\n",
    "如果您正在参加实况教程会话，则可能正在使用共享的测试帐户或项目。为了避免所创建资源上的用户之间的名称冲突，您需要为每个实例会话创建一个uuid，并将其附加到您在本教程中创建的资源的名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "953fa6e5ddda"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ffa6b6c7cdb"
   },
   "source": [
    "###验证您的Google Cloud帐户\n",
    "\n",
    "**如果您正在使用Vertex AI Workbench笔记本**，则您的环境已经经过身份验证。\n",
    "\n",
    "**如果您正在使用Colab**，请运行下面的单元格，并按提示进行身份验证，通过oAuth验证您的帐户。\n",
    "\n",
    "**否则**，请按照以下步骤操作：\n",
    "\n",
    "1. 在Cloud Console中，转到[**创建服务帐户密钥**页面](https://console.cloud.google.com/apis/credentials/serviceaccountkey)。\n",
    "\n",
    "2. 单击**创建服务帐户**。\n",
    "\n",
    "3. 在**服务帐户名称**字段中输入名称，然后单击**创建**。\n",
    "\n",
    "4. 在**授予此服务帐户对项目的访问权限**部分，单击**角色**下拉列表。在过滤框中键入“Vertex AI”，并选择**Vertex AI管理员**。在过滤框中键入“Storage Object Admin”，并选择**Storage Object Admin**。\n",
    "\n",
    "5. 单击*创建*。包含您密钥的JSON文件将下载到您的本地环境。\n",
    "\n",
    "6. 在下面的单元格中，将您的服务帐户密钥路径输入为`GOOGLE_APPLICATION_CREDENTIALS`变量，然后运行该单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b72272258fc"
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS '[your-service-account-key-path]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "637c90fe1062"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "**无论您的笔记本环境如何，都需要执行以下步骤。**\n",
    "\n",
    "在 Vertex AI 中使用 Cloud SDK 创建模型时，您需要提供一个 Cloud Storage 路径，用以保存训练好的模型。\n",
    "在本教程中，Vertex AI 将训练好的模型保存到一个云存储桶中。使用这个模型构件，您可以创建 Vertex AI 模型和端点资源，以便提供在线预测。\n",
    "\n",
    "请在下方设置您的 Cloud Storage 桶的名称。它必须在所有 Cloud Storage 桶中是唯一的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65e1e634c920"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68d1f4908641"
   },
   "outputs": [],
   "source": [
    "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"[your-bucket-name]\":\n",
    "    BUCKET_NAME = PROJECT_ID + \"aip-\" + UUID\n",
    "    BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cb016da6de3"
   },
   "source": [
    "**只有在您的存储桶不存在时**：运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e66f36b71bc3"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51a8afe42b5e"
   },
   "source": [
    "最后，通过检查云存储桶的内容来验证访问权限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "835bf2f84d86"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91a6f77f3d94"
   },
   "source": [
    "## 教程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b02bcf983b82"
   },
   "source": [
    "### 导入所需的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1c9e504395c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "# configure to don't display the warnings\n",
    "import warnings\n",
    "\n",
    "import category_encoders as ce\n",
    "import seaborn as sns\n",
    "from google.cloud import aiplatform, storage\n",
    "from google.cloud.aiplatform_v1.types import SampledShapleyAttribution\n",
    "from google.cloud.aiplatform_v1.types.explanation import ExplanationParameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, plot_roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e37354341588"
   },
   "source": [
    "### 使用 Pandas 从云存储加载数据\n",
    "\n",
    "[Kaggle](https://www.kaggle.com/c/customer-churn-prediction-2020/overview) 上的 Telecom-Customer Churn 数据集可在一个公共云存储桶上找到：\n",
    "\n",
    "```gs://cloud-samples-data/vertex-ai/managed_notebooks/telecom_churn_prediction/train.csv```\n",
    "\n",
    "使用 Pandas 直接从该 URI 读取数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d949de05d3e3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"gs://cloud-samples-data/vertex-ai/managed_notebooks/telecom_churn_prediction/train.csv\"\n",
    ")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ca1a5b9da481"
   },
   "source": [
    "进行数据探索分析 (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fc64740bd98"
   },
   "source": [
    "检查字段的数据类型和空值计数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1305e25e8c85"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cabae9da850"
   },
   "source": [
    "当前数据集中没有任何空或空白字段。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c95d9008b0e"
   },
   "source": [
    "检查类别不平衡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a12839626b40"
   },
   "outputs": [],
   "source": [
    "df[\"churn\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2473365db828"
   },
   "source": [
    "数据中有14％的流失用户，对于训练流失预测模型来说并不算太糟糕。如果类别不平衡的情况比较严重，可以考虑使用过度取样或欠取样技术来平衡类别分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa0f8adef6f2"
   },
   "source": [
    "将分类和数值列分开。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1c94426e3b2"
   },
   "outputs": [],
   "source": [
    "categ_cols = [\"state\", \"area_code\", \"international_plan\", \"voice_mail_plan\"]\n",
    "target = \"churn\"\n",
    "num_cols = [i for i in df.columns if i not in categ_cols and i != target]\n",
    "print(len(categ_cols), len(num_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1c1f4744269d"
   },
   "source": [
    "绘制分类列的水平分布图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bb016790dcdc"
   },
   "outputs": [],
   "source": [
    "for i in categ_cols:\n",
    "    df[i].value_counts().plot(kind=\"bar\")\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7c1eaf4363f"
   },
   "outputs": [],
   "source": [
    "print(num_cols)\n",
    "df[\"number_vmail_messages\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7024efb18a27"
   },
   "source": [
    "检查数值列的分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11165f493bbc"
   },
   "outputs": [],
   "source": [
    "for i in num_cols:\n",
    "    # check the Price field's distribution\n",
    "    _, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    df[i].plot(kind=\"box\", ax=ax[0])\n",
    "    df[i].plot(kind=\"hist\", ax=ax[1])\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eec92dc756a9"
   },
   "outputs": [],
   "source": [
    "# check pairplots for selected features\n",
    "selected_features = [\n",
    "    \"total_day_calls\",\n",
    "    \"total_eve_calls\",\n",
    "    \"number_customer_service_calls\",\n",
    "    \"number_vmail_messages\",\n",
    "    \"account_length\",\n",
    "    \"total_day_charge\",\n",
    "    \"total_eve_charge\",\n",
    "]\n",
    "sns.pairplot(df[selected_features])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56c8911c7588"
   },
   "source": [
    "绘制数字特征的相关矩阵热图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79fdafb9e5a6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df[num_cols].corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19ef89810012"
   },
   "source": [
    "### EDA观察\n",
    "\n",
    "- 在分类字段<b>state</b>中有许多级别/类别。在进一步的步骤中，为这个字段创建一个独热编码向量会大幅增加列数，因此将考虑使用二进制编码技术来编码这个字段。\n",
    "- 数据中仅有9%的客户拥有国际套餐。\n",
    "- 仅有少数客户频繁致电客服。\n",
    "- 只有25%的客户至少拥有16条语音信箱消息，因此`number_vmail_messages`字段的分布存在偏斜。\n",
    "- 在成对绘图中，大多数特征组合显示出循环模式，表明相应的两个特征之间几乎没有相关性。\n",
    "- 分钟数和费用之间似乎存在高度相关性。可以丢弃其中一个以避免数据中的多重共线性或冗余特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28f0b40ea577"
   },
   "source": [
    "### 预处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7dd6ade12cd"
   },
   "source": [
    "删除与高度相关的特征对应的字段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bb46ec159a3"
   },
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    \"total_day_charge\",\n",
    "    \"total_eve_charge\",\n",
    "    \"total_night_charge\",\n",
    "    \"total_intl_charge\",\n",
    "]\n",
    "df.drop(columns=drop_cols, inplace=True)\n",
    "num_cols = list(set(num_cols).difference(set(drop_cols)))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcc77c18541c"
   },
   "source": [
    "对状态特征进行二进制编码（因为有许多级别/类别）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9f8e1fdcbb8"
   },
   "outputs": [],
   "source": [
    "encoder = ce.BinaryEncoder(cols=[\"state\"], return_df=True)\n",
    "data_encoded = encoder.fit_transform(df)\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c59a90d8961c"
   },
   "source": [
    "对其余的分类变量进行一独热编码（删除第一级列以避免虚拟变量陷阱情况）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21c8c6262dbc"
   },
   "outputs": [],
   "source": [
    "def encode_cols(data, col):\n",
    "    # Creating a dummy variable for the variable 'CategoryID' and dropping the first one.\n",
    "    categ = pd.get_dummies(data[col], prefix=col, drop_first=True)\n",
    "    # Adding the results to the master dataframe\n",
    "    data = pd.concat([data, categ], axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "for i in categ_cols + [target]:\n",
    "    if i != \"state\":\n",
    "        data_encoded = encode_cols(data_encoded, i)\n",
    "        data_encoded.drop(columns=[i], inplace=True)\n",
    "\n",
    "data_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7ee5d51d900"
   },
   "source": [
    "检查数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "980c42c98f3a"
   },
   "outputs": [],
   "source": [
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b402c7db5d1a"
   },
   "source": [
    "检查列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7e67c06b9938"
   },
   "outputs": [],
   "source": [
    "data_encoded.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a809e0c43ff"
   },
   "source": [
    "将数据分成训练集和测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17aaffef959d"
   },
   "outputs": [],
   "source": [
    "X = data_encoded[[i for i in data_encoded.columns if i not in [\"churn_yes\"]]].copy()\n",
    "y = data_encoded[\"churn_yes\"].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.7, test_size=0.3, random_state=100\n",
    ")\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1875f9ec661f"
   },
   "source": [
    "使用`MinMaxScaler`对数值数据进行缩放。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ed095d60fa47"
   },
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "X_train.loc[:, num_cols] = sc.fit_transform(X_train[num_cols])\n",
    "X_test.loc[:, num_cols] = sc.transform(X_test[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "229cfba1fd32"
   },
   "source": [
    "使用 scikit-learn 训练一个逻辑回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37a536623470"
   },
   "source": [
    "`class_weight`参数可以调整类别的权重以匹配目标特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7acc267ad4c1"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight=\"balanced\")\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18e23a047402"
   },
   "source": [
    "## 评估训练好的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e59e96403fdf"
   },
   "source": [
    "绘制ROC曲线并显示训练集和测试集上的AUC值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "038852060275"
   },
   "source": [
    "将模型在训练数据上的ROC曲线绘制出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "482d7eb78295"
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(model, X_train, y_train, drop_intermediate=False)\n",
    "plt.show()\n",
    "\n",
    "# plot the ROC for the model on test data\n",
    "plot_roc_curve(model, X_test, y_test, drop_intermediate=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb393fe2f3c4"
   },
   "source": [
    "确定二元分类的最佳阈值\n",
    "\n",
    "一般来说，逻辑回归模型输出介于0和1之间的概率分数，需要确定一个阈值来分配类别标签。根据模型的敏感度（真阳性率）和特异性（真阴性率），可以确定最佳阈值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9482b0a4d3a"
   },
   "source": [
    "使用10个不同的概率截断值创建列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f19ea3f3a2ce"
   },
   "outputs": [],
   "source": [
    "y_train_pred = model.predict_proba(X_train)[:, 1]\n",
    "numbers = [float(x) / 10 for x in range(10)]\n",
    "y_train_pred_df = pd.DataFrame({\"true\": y_train, \"pred\": y_train_pred})\n",
    "for i in numbers:\n",
    "    y_train_pred_df[i] = y_train_pred_df.pred.map(lambda x: 1 if x > i else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cff355e58790"
   },
   "source": [
    "现在计算不同概率截断点下的准确率、灵敏度和特异性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "572a9dc237f6"
   },
   "outputs": [],
   "source": [
    "cutoff_df = pd.DataFrame(columns=[\"prob\", \"accuracy\", \"sensitivity\", \"specificity\"])\n",
    "\n",
    "# compute the parameters for each threshold considered\n",
    "for i in numbers:\n",
    "    cm1 = confusion_matrix(y_train_pred_df.true, y_train_pred_df[i])\n",
    "    total1 = sum(sum(cm1))\n",
    "    accuracy = (cm1[0, 0] + cm1[1, 1]) / total1\n",
    "\n",
    "    speci = cm1[0, 0] / (cm1[0, 0] + cm1[0, 1])\n",
    "    sensi = cm1[1, 1] / (cm1[1, 0] + cm1[1, 1])\n",
    "    cutoff_df.loc[i] = [i, accuracy, sensi, speci]\n",
    "\n",
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "cutoff_df.plot.line(x=\"prob\", y=[\"accuracy\", \"sensitivity\", \"specificity\"])\n",
    "plt.title(\"Comparison of performance across various thresholds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ae7362a31f0"
   },
   "source": [
    "通常情况下，具有平衡敏感度和特异性的模型是首选。在当前情况下，敏感度和特异性曲线相交的阈值可以被认为是最佳阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95d07b5422a6"
   },
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "# Evaluate train and test sets\n",
    "y_test_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# to get the performance stats, lets define a handy function\n",
    "\n",
    "\n",
    "def print_stats(y_true, y_pred):\n",
    "    # Confusion matrix\n",
    "\n",
    "    confusion = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "    print(\"Confusion Matrix: \")\n",
    "    print(confusion)\n",
    "\n",
    "    TP = confusion[1, 1]  # true positive\n",
    "    TN = confusion[0, 0]  # true negatives\n",
    "    FP = confusion[0, 1]  # false positives\n",
    "    FN = confusion[1, 0]  # false negatives\n",
    "\n",
    "    # Let's see the sensitivity or recall of our logistic regression model\n",
    "    sensitivity = TP / float(TP + FN)\n",
    "    print(\"sensitivity = \", sensitivity)\n",
    "    # Let us calculate specificity\n",
    "    specificity = TN / float(TN + FP)\n",
    "    print(\"specificity = \", specificity)\n",
    "    # Calculate false postive rate - predicting conversion when customer didn't convert\n",
    "    fpr = FP / float(TN + FP)\n",
    "    print(\"False positive rate = \", fpr)\n",
    "    # positive predictive value\n",
    "    precision = TP / float(TP + FP)\n",
    "    print(\"precision = \", precision)\n",
    "    # accuracy\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print(\"accuracy = \", accuracy)\n",
    "    return\n",
    "\n",
    "\n",
    "y_train_pred_sm = [1 if i > threshold else 0 for i in y_train_pred]\n",
    "y_test_pred_sm = [1 if i > threshold else 0 for i in y_test_pred]\n",
    "# Print the metrics for the model\n",
    "# on train data\n",
    "print(\"Train Data : \")\n",
    "print_stats(y_train, y_train_pred_sm)\n",
    "print(\"\\n\", \"*\" * 30, \"\\n\")\n",
    "# on test data\n",
    "print(\"Test Data : \")\n",
    "print_stats(y_test, y_test_pred_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b64f7190aad6"
   },
   "source": [
    "虽然模型的敏感性和特异性看起来还可以，但精确度可以被认为是低的。这种情况可能在一定程度上是可以接受的，因为从电信行业的商业角度来看，即使意味着有一些非流失客户被错误分类为流失客户，仍然有必要识别出流失客户。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7fc7b467b6f"
   },
   "source": [
    "将模型保存到云存储路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ae43e214775f"
   },
   "source": [
    "将训练好的模型保存到本地文件`model.pkl`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94ad4c932974"
   },
   "outputs": [],
   "source": [
    "FILE_NAME = \"model.pkl\"\n",
    "with open(FILE_NAME, \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "# Upload the saved model file to Cloud Storage\n",
    "BLOB_PATH = (\n",
    "    \"[your-blob-path]\"  # leave blank if no folders inside the bucket are needed.\n",
    ")\n",
    "\n",
    "if BLOB_PATH == (\"[your-blob-path]\"):\n",
    "    BLOB_PATH = \"\"\n",
    "\n",
    "BLOB_NAME = BLOB_PATH + FILE_NAME\n",
    "\n",
    "bucket = storage.Client().bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(BLOB_NAME)\n",
    "blob.upload_from_filename(FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aa045b28545b"
   },
   "source": [
    "在Vertex AI中创建支持可解释AI的模型\n",
    "\n",
    "在创建模型之前，配置模型解释。更多详情，请参阅[在Vertex AI中配置解释](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations#scikit-learn-and-xgboost-pre-built-containers)。\n",
    "\n",
    "为模型资源设置显示名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a90b693b0a17"
   },
   "outputs": [],
   "source": [
    "# Set the model display name\n",
    "MODEL_DISPLAY_NAME = \"[your-model-display-name]\"  # @param {type:\"string\"}\n",
    "\n",
    "if MODEL_DISPLAY_NAME == \"[your-model-display-name]\":\n",
    "    MODEL_DISPLAY_NAME = \"subscriber_churn_model\"\n",
    "\n",
    "ARTIFACT_GCS_PATH = f\"gs://{BUCKET_NAME}/{BLOB_PATH}\"\n",
    "\n",
    "# Feature-name(Inp_feature) and Output-name(Model_output) can be arbitrary\n",
    "exp_metadata = {\"inputs\": {\"Inp_feature\": {}}, \"outputs\": {\"Model_output\": {}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d28c0b203200"
   },
   "outputs": [],
   "source": [
    "# Create a Vertex AI model resource with support for explanations\n",
    "\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=ARTIFACT_GCS_PATH,\n",
    "    serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\",\n",
    "    explanation_metadata=exp_metadata,\n",
    "    explanation_parameters=ExplanationParameters(\n",
    "        sampled_shapley_attribution=SampledShapleyAttribution(path_count=25)\n",
    "    ),\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3db48702657f"
   },
   "source": [
    "或者，可以使用以下`gcloud`命令来创建模型资源。`explanation-metadata.json`文件包含用于配置模型资源解释的元数据。\n",
    "\n",
    "```\n",
    "gcloud beta ai models upload \\\n",
    "  --region=$REGION \\\n",
    "  --display-name=$MODEL_DISPLAY_NAME \\\n",
    "  --container-image-uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\" \\\n",
    "  --artifact-uri=$ARTIFACT_GCS_PATH \\\n",
    "  --explanation-method=sampled-shapley \\\n",
    "  --explanation-path-count=25 \\\n",
    "  --explanation-metadata-file=explanation-metadata.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab34c4b7183c"
   },
   "source": [
    "创建一个端点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2330cab1093"
   },
   "outputs": [],
   "source": [
    "ENDPOINT_DISPLAY_NAME = \"[your-endpoint-display-name]\"  # @param {type:\"string\"}\n",
    "if ENDPOINT_DISPLAY_NAME == \"[your-endpoint-display-name]\":\n",
    "    ENDPOINT_DISPLAY_NAME = \"subsc_churn_endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42306a0791e6"
   },
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint.create(\n",
    "    display_name=ENDPOINT_DISPLAY_NAME, project=PROJECT_ID, location=REGION\n",
    ")\n",
    "\n",
    "print(endpoint.display_name)\n",
    "print(endpoint.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84a64b2a7399"
   },
   "source": [
    "### 部署模型到创建的端点\n",
    "\n",
    "为部署配置部署名称、机器类型和其他部署参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eb1c5e1a2fdf"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_MODEL_NAME = \"[deployment-model-name]\"  # @param {type:\"string\"}\n",
    "MACHINE_TYPE = \"n1-standard-4\"\n",
    "\n",
    "if DEPLOYED_MODEL_NAME == \"[deployment-model-name]\":\n",
    "    DEPLOYED_MODEL_NAME = \"subsc_churn_deployment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ed6f6aefea51"
   },
   "outputs": [],
   "source": [
    "# deploy the model to the endpoint\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=DEPLOYED_MODEL_NAME,\n",
    "    machine_type=MACHINE_TYPE,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "359c43e630cb"
   },
   "source": [
    "为了确保模型已部署，可以使用`endpoint.list_models()`方法来检查已部署模型的ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bb578a29d01"
   },
   "outputs": [],
   "source": [
    "endpoint.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21a50d4e9946"
   },
   "source": [
    "从部署的模型中获取解释说明##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b50c31e0552"
   },
   "source": [
    "从托管模型获取测试实例的解释。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52cb8915b41c"
   },
   "outputs": [],
   "source": [
    "# format a test instance as the request's payload\n",
    "test_json = [X_test.iloc[0].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e476d770667"
   },
   "source": [
    "获取解释并绘制特征归因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81804daa141e"
   },
   "outputs": [],
   "source": [
    "features = X_train.columns.to_list()\n",
    "\n",
    "\n",
    "def plot_attributions(attrs):\n",
    "    \"\"\"\n",
    "    Function to plot the features and their attributions for an instance\n",
    "    \"\"\"\n",
    "    rows = {\"feature_name\": [], \"attribution\": []}\n",
    "    for i, val in enumerate(features):\n",
    "        rows[\"feature_name\"].append(val)\n",
    "        rows[\"attribution\"].append(attrs[\"Inp_feature\"][i])\n",
    "    attr_df = pd.DataFrame(rows).set_index(\"feature_name\")\n",
    "    attr_df.plot(kind=\"bar\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def explain_tabular_sample(project: str, location: str, endpoint, instances: list):\n",
    "    \"\"\"\n",
    "    Function to make an explanation request for the specified payload and generate feature attribution plots\n",
    "    \"\"\"\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    # endpoint = aiplatform.Endpoint(endpoint_id)\n",
    "\n",
    "    response = endpoint.explain(instances=instances)\n",
    "    print(\"#\" * 10 + \"Explanations\" + \"#\" * 10)\n",
    "    for explanation in response.explanations:\n",
    "        print(\" explanation\")\n",
    "        # Feature attributions.\n",
    "        attributions = explanation.attributions\n",
    "\n",
    "        for attribution in attributions:\n",
    "            print(\"  attribution\")\n",
    "            print(\"   baseline_output_value:\", attribution.baseline_output_value)\n",
    "            print(\"   instance_output_value:\", attribution.instance_output_value)\n",
    "            print(\"   output_display_name:\", attribution.output_display_name)\n",
    "            print(\"   approximation_error:\", attribution.approximation_error)\n",
    "            print(\"   output_name:\", attribution.output_name)\n",
    "            output_index = attribution.output_index\n",
    "            for output_index in output_index:\n",
    "                print(\"   output_index:\", output_index)\n",
    "\n",
    "            plot_attributions(attribution.feature_attributions)\n",
    "\n",
    "    print(\"#\" * 10 + \"Predictions\" + \"#\" * 10)\n",
    "    for prediction in response.predictions:\n",
    "        print(prediction)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# Get explanations for the test instance\n",
    "prediction = explain_tabular_sample(PROJECT_ID, REGION, endpoint, test_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20dd765c9e30"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于本教程的[Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源：\n",
    "* Vertex AI模型\n",
    "* Vertex AI端点\n",
    "* Cloud Storage存储桶\n",
    "\n",
    "将`delete_bucket`设置为*True*以删除Cloud Storage存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98f3a1d74d02"
   },
   "outputs": [],
   "source": [
    "# Undeploy model\n",
    "endpoint.undeploy_all()\n",
    "\n",
    "# Delete the endpoint\n",
    "endpoint.delete()\n",
    "\n",
    "# Delete the model\n",
    "model.delete()\n",
    "\n",
    "# Delete the Cloud Storage bucket\n",
    "delete_bucket = True\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil -m rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "telecom-subscriber-churn-prediction.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
