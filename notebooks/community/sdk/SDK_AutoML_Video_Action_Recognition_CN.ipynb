{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "humanitarian-petite"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "corporate-remains"
   },
   "source": [
    "# 反馈或问题？\n",
    "\n",
    "如果有任何反馈或问题，请打开一个[问题](https://github.com/googleapis/python-aiplatform/issues)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "first-dietary"
   },
   "source": [
    "Python的Vertex SDK：AutoML视频动作识别示例\n",
    "要使用这个Jupyter笔记本，将笔记本复制到已安装Tensorflow的Google Cloud笔记本实例中并打开它。您可以运行每个步骤或单元，并查看其结果。要运行一个单元，使用Shift+Enter。Jupyter会自动显示每个单元最后一行的返回值。有关在Google Cloud笔记本中运行笔记本的更多信息，请参阅[Google Cloud笔记本指南](https://cloud.google.com/vertex-ai/docs/general/notebooks)。\n",
    "\n",
    "本笔记本演示了如何使用Vertex AI视频数据集创建AutoML视频动作识别模型，以及如何为批量预测提供模型。您需要提供一个存储数据集的存储桶。\n",
    "\n",
    "注意：在测试此SDK时，您可能会因培训、预测、存储或使用其他GCP产品而产生费用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "critical-twenty"
   },
   "source": [
    "### 为 Python 安装 Vertex SDK\n",
    "\n",
    "\n",
    "安装 SDK 后，内核将会自动重新启动。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "precious-produce"
   },
   "outputs": [],
   "source": [
    "!pip3 uninstall -y google-cloud-aiplatform\n",
    "!pip3 install google-cloud-aiplatform\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "finished-roller"
   },
   "source": [
    "###输入您的项目和GCS存储桶\n",
    "\n",
    "在下面的单元格中输入您的项目ID。然后运行该单元格，以确保云SDK在此笔记本中的所有命令中使用正确的项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "limiting-costume"
   },
   "outputs": [],
   "source": [
    "MY_PROJECT = \"YOUR PROJECT ID\"\n",
    "MY_STAGING_BUCKET = \"gs://YOUR BUCKET\"  # bucket should be in same region as ucaip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3GKWBB_Y6So"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    import os\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()\n",
    "    os.environ[\"GOOGLE_CLOUD_PROJECT\"] = MY_PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "entire-fleece"
   },
   "source": [
    "### 设置您的任务名称和GCS前缀\n",
    "\n",
    "如果您想要将所有输入和输出文件集中在GCS位置下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "micro-administration"
   },
   "outputs": [],
   "source": [
    "TASK_TYPE = \"mbsdk_automl-video-training\"\n",
    "PREDICTION_TYPE = \"action_recognition\"\n",
    "MODEL_TYPE = \"CLOUD\"\n",
    "\n",
    "TASK_NAME = f\"{TASK_TYPE}_{PREDICTION_TYPE}\"\n",
    "BUCKET_NAME = MY_STAGING_BUCKET.split(\"gs://\")[1]\n",
    "GCS_PREFIX = TASK_NAME\n",
    "\n",
    "print(f\"Bucket Name:    {BUCKET_NAME}\")\n",
    "print(f\"Task Name:      {TASK_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "capable-sitting"
   },
   "source": [
    "# HMDB：一个庞大的人体运动数据库\n",
    "我们为演示准备了一些训练数据和预测数据，使用[HMDB数据集](https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database)。\n",
    "\n",
    "HMDB数据集根据知识共享署名4.0国际许可证许可。要查看此许可证的副本，请访问https://creativecommons.org/licenses/by/4.0/\n",
    "\n",
    "有关此数据集的更多信息，请访问：https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NQwynxpDMrN"
   },
   "outputs": [],
   "source": [
    "automl_video_demo_train_data = \"gs://automl-video-demo-data/hmdb_golf_swing_all.csv\"\n",
    "automl_video_demo_batch_prediction_data = (\n",
    "    \"gs://automl-video-demo-data/hmdb_golf_swing_predict.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "catholic-financing"
   },
   "source": [
    "### 复制 AutoML 视频演示训练数据以创建托管数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coastal-engineering"
   },
   "outputs": [],
   "source": [
    "gcs_source_train = f\"gs://{BUCKET_NAME}/{TASK_NAME}/data/video_action_recognition.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acoustic-wonder"
   },
   "outputs": [],
   "source": [
    "!gsutil cp $automl_video_demo_train_data $gcs_source_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accepting-setup"
   },
   "source": [
    "使用托管视频数据集运行AutoML视频训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "terminal-better"
   },
   "source": [
    "## 初始化Python的Vertex SDK\n",
    "\n",
    "为Vertex AI初始化*client*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trying-mixture"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=MY_PROJECT, staging_bucket=MY_STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nonprofit-client"
   },
   "source": [
    "## 在 Vertex AI 上创建数据集\n",
    "现在我们将使用之前准备好的 csv 文件来创建一个 Vertex AI 视频数据集。请选择以下选项之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rXbKPQHT_YS"
   },
   "source": [
    "Option 1: 使用MBSDK VideoDataset 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "labeled-heating"
   },
   "outputs": [],
   "source": [
    "dataset = aiplatform.VideoDataset.create(\n",
    "    display_name=f\"temp-{TASK_NAME}\",\n",
    "    gcs_source=gcs_source_train,\n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.video.action_recognition,\n",
    "    sync=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RwF8f8yURIb"
   },
   "source": [
    "选项2：使用MBSDK数据集类\n",
    "```\n",
    "dataset = aiplatform.Dataset.create(\n",
    "    display_name=f'temp-{TASK_NAME}',\n",
    "    metadata_schema_uri=aiplatform.schema.dataset.metadata.video,\n",
    "    gcs_source=gcs_source_train, \n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.video.action_recognition,\n",
    "    sync=False\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kl4mKHXgVWcS"
   },
   "outputs": [],
   "source": [
    "dataset.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "above-police"
   },
   "source": [
    "在Vertex AI上启动一个训练任务并创建一个模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "headed-saturn"
   },
   "source": [
    "###配置一个培训任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sexual-hayes"
   },
   "outputs": [],
   "source": [
    "job = aiplatform.AutoMLVideoTrainingJob(\n",
    "    display_name=f\"temp-{TASK_NAME}\",\n",
    "    prediction_type=PREDICTION_TYPE,\n",
    "    model_type=MODEL_TYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "determined-report"
   },
   "source": [
    "运行训练任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exciting-vision"
   },
   "outputs": [],
   "source": [
    "model = job.run(\n",
    "    dataset=dataset,\n",
    "    training_fraction_split=0.8,\n",
    "    test_fraction_split=0.2,\n",
    "    model_display_name=f\"temp-{TASK_NAME}\",\n",
    "    sync=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fundamental-guess"
   },
   "outputs": [],
   "source": [
    "model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pregnant-charlotte"
   },
   "source": [
    "# 在模型上进行批量预测任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "outdoor-courtesy"
   },
   "source": [
    "### 复制 AutoML 视频演示预测数据，用于创建批量预测作业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quarterly-sheep"
   },
   "outputs": [],
   "source": [
    "gcs_source_batch_prediction = f\"gs://{BUCKET_NAME}/{TASK_NAME}/data/video_action_recognition_batch_prediction.jsonl\"\n",
    "gcs_destination_prefix_batch_prediction = (\n",
    "    f\"gs://{BUCKET_NAME}/{TASK_NAME}/batch_prediction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "declared-mexico"
   },
   "outputs": [],
   "source": [
    "!gsutil cp $automl_video_demo_batch_prediction_data $gcs_source_batch_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hollywood-clearing"
   },
   "outputs": [],
   "source": [
    "batch_predict_job = model.batch_predict(\n",
    "    job_display_name=f\"temp-{TASK_NAME}\",\n",
    "    gcs_source=gcs_source_batch_prediction,\n",
    "    gcs_destination_prefix=gcs_destination_prefix_batch_prediction,\n",
    "    sync=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thorough-yellow"
   },
   "outputs": [],
   "source": [
    "batch_predict_job.wait()\n",
    "bp_iter_outputs = batch_predict_job.iter_outputs()\n",
    "\n",
    "prediction_results = list()\n",
    "for blob in bp_iter_outputs:\n",
    "    if blob.name.split(\"/\")[-1].startswith(\"prediction\"):\n",
    "        prediction_results.append(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "instructional-assumption"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tags = list()\n",
    "for prediction_result in prediction_results:\n",
    "    gfile_name = f\"gs://{bp_iter_outputs.bucket.name}/{prediction_result}\"\n",
    "    with tf.io.gfile.GFile(name=gfile_name, mode=\"r\") as gfile:\n",
    "        for line in gfile.readlines():\n",
    "            line = json.loads(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "processed-brooklyn"
   },
   "outputs": [],
   "source": [
    "line"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AI_Platform_(Unified)_SDK_AutoML_Video_Action_Recognition.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
