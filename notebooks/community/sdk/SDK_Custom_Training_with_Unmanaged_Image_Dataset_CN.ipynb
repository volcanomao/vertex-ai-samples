{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2020 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1c955a52adac"
   },
   "source": [
    "反馈或问题？\n",
    "如有任何反馈或问题，请打开一个问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHLV0D7Y5jtU"
   },
   "source": [
    "# Python的Vertex SDK：使用未管理的图像数据集进行自定义训练示例\n",
    "\n",
    "要使用这个Colaboratory笔记本，您需要将笔记本复制到您自己的谷歌云端硬盘中，并使用Colaboratory（或Colab）打开它。您可以运行每个步骤或单元，并查看其结果。要运行一个单元，使用Shift+Enter。Colab会自动显示每个单元中最后一行的返回值。要获取有关在Colab中运行笔记本的更多信息，请参阅[Colab欢迎页面](https://colab.research.google.com/notebooks/welcome.ipynb)。\n",
    "\n",
    "这个笔记本演示了如何基于图像数据集创建一个自定义模型。您需要提供一个存储数据集的存储桶。\n",
    "\n",
    "注意：在测试此SDK时，您可能要支付用于训练、预测、储存或使用其他GCP产品的费用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lld3eeJUs5yM"
   },
   "source": [
    "# 安装用于Python的Vertex SDK，进行身份验证，然后将数据集上传到您的GCS存储桶\n",
    "\n",
    "安装完SDK后，内核将会自动重新启动。您可能会看到这个错误信息“您的会话因为未知原因而崩溃”，这是正常的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBfZtR4X1Dr_"
   },
   "outputs": [],
   "source": [
    "!pip3 uninstall -y google-cloud-aiplatform\n",
    "!pip3 install google-cloud-aiplatform\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0SNmTBeD2nV"
   },
   "source": [
    "### 输入您的项目和GCS存储桶\n",
    "\n",
    "在下面的单元格中输入您的项目 ID。然后运行该单元格，确保 Cloud SDK 在本笔记本中的所有命令中使用正确的项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5be5dce7259"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kng9iKBwqcS5"
   },
   "outputs": [],
   "source": [
    "MY_PROJECT = \"YOUR PROJECT\"\n",
    "MY_STAGING_BUCKET = \"gs://YOUR BUCKET\"  # bucket should be in same region as ucaip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rk43VP_IqcTE"
   },
   "source": [
    "初始化Vertex SDK的Python版\n",
    "\n",
    "为Vertex AI初始化*client*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCiC9gBWqcTF"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=MY_PROJECT, staging_bucket=MY_STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcEOYYolqcTN"
   },
   "source": [
    "# 编写您的训练脚本\n",
    "- 将此单元格写入作为一个文件，该文件将用于自定义训练。\n",
    "- 通过'run'函数的'args'参数传入一个Tensorflow Dataset URI，而不是使用托管的数据集。脚本将在训练时从URI下载数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78SHpd0tt8UQ"
   },
   "outputs": [],
   "source": [
    "%%writefile training_script.py\n",
    "\n",
    "# Source: https://cloud.google.com/vertex-ai/docs/tutorials/image-recognition-custom\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "IMG_WIDTH = 128\n",
    "\n",
    "def normalize_img(image):\n",
    "    \"\"\"Normalizes image.\n",
    "\n",
    "    * Resizes image to IMG_WIDTH x IMG_WIDTH pixels\n",
    "    * Casts values from `uint8` to `float32`\n",
    "    * Scales values from [0, 255] to [0, 1]\n",
    "\n",
    "    Returns:\n",
    "      A tensor with shape (IMG_WIDTH, IMG_WIDTH, 3). (3 color channels)\n",
    "    \"\"\"\n",
    "    image = tf.image.resize_with_pad(image, IMG_WIDTH, IMG_WIDTH)\n",
    "    return image / 255.\n",
    "\n",
    "\n",
    "def normalize_img_and_label(image, label):\n",
    "    \"\"\"Normalizes image and label.\n",
    "\n",
    "    * Performs normalize_img on image\n",
    "    * Passes through label unchanged\n",
    "\n",
    "    Returns:\n",
    "      Tuple (image, label) where\n",
    "      * image is a tensor with shape (IMG_WIDTH, IMG_WIDTH, 3). (3 color\n",
    "        channels)\n",
    "      * label is an unchanged integer [0, 4] representing flower type\n",
    "    \"\"\"\n",
    "    return normalize_img(image), label\n",
    "\n",
    "def get_args():\n",
    "  \"\"\"Argument parser.\n",
    "  Returns:\n",
    "    Dictionary of arguments.\n",
    "  \"\"\"\n",
    "  parser = argparse.ArgumentParser(description='Flower classification sample')\n",
    "  parser.add_argument(\n",
    "      '--tfds',\n",
    "      default=None,\n",
    "      help='The tfds URI from https://www.tensorflow.org/datasets/ to load the data from')\n",
    "\n",
    "  args = parser.parse_args()\n",
    "  return args\n",
    "\n",
    "# Training settings\n",
    "args = get_args()\n",
    "\n",
    "if 'AIP_MODEL_DIR' not in os.environ:\n",
    "    raise KeyError(\n",
    "        'The `AIP_MODEL_DIR` environment variable has not been' +\n",
    "        'set. See https://cloud.google.com/vertex-ai/docs/tutorials/image-recognition-custom/training'\n",
    "    )\n",
    "output_directory = os.environ['AIP_MODEL_DIR']\n",
    "\n",
    "logging.info('Loading and preprocessing data ...')\n",
    "dataset = tfds.load(args.tfds,\n",
    "                    split='train',\n",
    "                    try_gcs=True,\n",
    "                    shuffle_files=True,\n",
    "                    as_supervised=True)\n",
    "dataset = dataset.map(normalize_img_and_label,\n",
    "                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(1000)\n",
    "dataset = dataset.batch(128)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "logging.info('Creating and training model ...')\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,\n",
    "                           3,\n",
    "                           padding='same',\n",
    "                           activation='relu',\n",
    "                           input_shape=(IMG_WIDTH, IMG_WIDTH, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(5)  # 5 classes\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "model.fit(dataset, epochs=10)\n",
    "\n",
    "logging.info(f'Exporting SavedModel to: {output_directory}')\n",
    "# Add softmax layer for intepretability\n",
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "probability_model.save(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-bBqipfqcTS"
   },
   "source": [
    "启动一个训练任务来创建一个模型\n",
    "\n",
    "一旦我们定义了您的训练脚本，我们将创建一个模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btb6d48lqcTT"
   },
   "outputs": [],
   "source": [
    "job = aiplatform.CustomTrainingJob(\n",
    "    display_name=\"train-flowers-dist-1-replica\",\n",
    "    script_path=\"training_script.py\",\n",
    "    container_uri=\"gcr.io/cloud-aiplatform/training/tf-cpu.2-2:latest\",\n",
    "    requirements=[\"gcsfs==0.7.1\"],\n",
    "    model_serving_container_image_uri=\"gcr.io/cloud-aiplatform/prediction/tf2-cpu.2-2:latest\",\n",
    ")\n",
    "model = job.run(\n",
    "    args=[\"--tfds\", \"tf_flowers:3.*.*\"],\n",
    "    replica_count=1,\n",
    "    model_display_name=\"flowers-model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vhDsMJNqcTW"
   },
   "source": [
    "部署您的模型，然后等待模型部署完成后再进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9GH72wWqcTX"
   },
   "outputs": [],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIw1ifPuqcTb"
   },
   "source": [
    "在终端上进行预测\n",
    "要进行预测，您需要一些花卉图片。您可以下载一些花朵照片，或使用下面提供的图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wn8fUtq389r4"
   },
   "outputs": [],
   "source": [
    "!gsutil -m cp -R gs://cloud-ml-data/img/flower_photos/daisy/14221848160_7f0a37c395.jpg .\n",
    "!gsutil -m cp -R gs://cloud-ml-data/img/flower_photos/tulips/13289268363_b9337d751e.jpg .\n",
    "!gsutil -m cp -R gs://cloud-ml-data/img/flower_photos/sunflowers/14623719696_1bb7970208_n.jpg ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ktakP9r7mCt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "daisy_floats = np.array(Image.open(\"14221848160_7f0a37c395.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzGidweY8Dgy"
   },
   "outputs": [],
   "source": [
    "small_image = np.array(Image.fromarray(np.uint8(daisy_floats)).resize((128, 128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cL6VdVufgH8a"
   },
   "outputs": [],
   "source": [
    "endpoint.predict(instances=[small_image.tolist()])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AI_Platform_(Unified)_SDK_Custom_Training_with_Unmanaged_Image_Dataset.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
