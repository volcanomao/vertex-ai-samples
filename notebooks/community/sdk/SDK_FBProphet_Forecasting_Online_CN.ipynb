{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# 使用FBProphet和Vertex AI训练和部署销售预测模型\n",
    "\n",
    "<table align=\"left\">\n",
    "   <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/sdk/SDK_FBProphet_Forecasting_Online.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "    <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/sdk/SDK_FBProphet_Forecasting_Online.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "   </td>\n",
    "  <td>\n",
    "<a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/sdk/SDK_FBProphet_Forecasting_Online.ipynb\" target='_blank'>\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a487542cabb1"
   },
   "source": [
    "## 概览\n",
    "\n",
    "本教程将指导您构建一个自定义容器来为 Vertex AI 上的 Facebook Prophet 模型提供服务。您将使用 FastAPI Python Web 服务器框架来创建一个预测端点。这个笔记本是对 [在 Vertex AI 上为 scikit-learn 模型提供服务的示例](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/sdk/SDK_Custom_Container_Prediction.ipynb) 进行修改的版本。\n",
    "\n",
    "了解有关如何从 [testdriven.io 的文章部署和托管机器学习模型与 FastAPI 和 Heroku](https://testdriven.io/blog/fastapi-machine-learning/) 中了解有关为 FBProphet 模型提供服务的更多信息。\n",
    "\n",
    "了解更多关于 [自定义训练](https://cloud.google.com/vertex-ai/docs/training/custom-training) 和 [Vertex AI 预测](https://cloud.google.com/vertex-ai/docs/predictions/get-predictions)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eca202a7fb5"
   },
   "source": [
    "### 目标\n",
    "\n",
    "这份笔记本的目标是在Vertex AI上创建、部署和提供一个自定义的预测模型。这份笔记本更专注于部署模型而不是模型本身的设计。\n",
    "\n",
    "本教程使用以下 Google Cloud ML 服务和资源：\n",
    "\n",
    "- Vertex AI 模型注册表\n",
    "- Vertex AI 端点\n",
    "\n",
    "执行的步骤包括：\n",
    "- 在本地训练一个模型，用于预测给定天数的销售额。\n",
    "- 训练另一个模型，使用销售额和天气数据进行销售预测。\n",
    "- 保存这两个模型。\n",
    "- 构建一个FastAPI服务器，用于处理所选模型的预测。\n",
    "- 使用模型工件构建一个用于提供应用程序的自定义容器映像。\n",
    "- 将模型上传到Vertex AI模型注册表。\n",
    "- 将模型部署到一个Vertex AI端点。\n",
    "- 向部署的模型发送在线预测请求。\n",
    "- 清理本次会话创建的资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caf4820f730c"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用了爱荷华州在 2020 年 01 月 01 日至 2022 年 01 月 01 日期间的历史酒类销售数据，数据来源为 BigQuery 中的一个公共数据集：`bigquery-public-data:iowa_liquor_sales.sales`，并训练并部署了一个针对给定时间窗口的销售预测模型。\n",
    "\n",
    "每个实例包括 2 个特征，一个日期时间戳和该时间段的调整后销售额。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "### 成本\n",
    "\n",
    "本教程使用Google Cloud的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "* Artifact Registry\n",
    "* Cloud Build\n",
    "\n",
    "了解[Vertex AI定价](https://cloud.google.com/vertex-ai/pricing)，[Cloud Storage定价](https://cloud.google.com/storage/pricing)，[Artifact Registry定价](https://cloud.google.com/artifact-registry/pricing)和[Cloud Build定价](https://cloud.google.com/build/pricing)，并使用[Pricing Calculator](https://cloud.google.com/products/calculator/)根据您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "## 安装\n",
    "\n",
    "在您的笔记本环境中安装此教程所需的软件包依赖项，例如NumPy、pystan、pandas、plotly、fbprophet、FastAPI、Uvicorn和joblib。本笔记本为每个库使用了特定版本，但通常建议使用每个软件包的最新主要GA版本。请注意，在后续步骤构建服务容器时也会使用`requirements.txt文件`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "747f59abb3a5"
   },
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "joblib==1.1.0\n",
    "google-cloud-storage==2.4.0\n",
    "google-cloud-aiplatform==1.16.0\n",
    "google-cloud-bigquery==2.34.4\n",
    "numpy\n",
    "pandas==2.0.3\n",
    "plotly==5.9.0\n",
    "pyarrow==8.0.0\n",
    "fastapi~=0.63\n",
    "pystan\n",
    "'shapely<2'\n",
    "prophet==1.1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56a5cca6a565"
   },
   "outputs": [],
   "source": [
    "# install dependencies from requirements.txt\n",
    "! pip3 install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### 仅限Colab：取消注释以下单元格以重启内核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-ZBOjErv5mM"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfEglUHQk9S3"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### 设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下操作：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 区域\n",
    "\n",
    "您还可以更改 Vertex AI 使用的 `REGION` 变量。了解有关 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations) 的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 验证你的谷歌云账户\n",
    "\n",
    "根据你的Jupyter环境，你可能需要手动进行身份验证。请按照下面的相关说明进行操作。\n",
    "\n",
    "**1. Vertex AI Workbench**\n",
    "* 无需操作，因为你已经验证过了。\n",
    "\n",
    "**2. 本地JupyterLab 实例，取消注释并运行:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce6043da7b33"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0367eac06a10"
   },
   "source": [
    "3. 协作、取消注释并运行:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21ad4dbb4a61"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c13224697bfb"
   },
   "source": [
    "请查看如何在https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples为您的服务帐号授予Cloud Storage权限。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间工件，比如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有在您的存储桶尚不存在时才需要运行以下单元格来创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2e91d1c775f"
   },
   "source": [
    "### 为您的模型产物创建一个本地目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6e74556ea0b4"
   },
   "outputs": [],
   "source": [
    "%mkdir -p app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "028b4d2f6d52"
   },
   "source": [
    "### 配置模型、存储库和构件名称\n",
    "\n",
    "针对模型配置以下参数：\n",
    "\n",
    "- `MODEL_ARTIFACT_DIR` - 模型构件在云存储存储桶中的文件夹目录路径，例如：\"my-models/fraud-detection/trial-4\"。\n",
    "- `REPOSITORY` - 要创建或使用的构件存储库的名称。\n",
    "- `IMAGE` - 推送的容器镜像的名称。\n",
    "- `MODEL_NAME` - 模型的名称。\n",
    "- `MODEL_DISPLAY_NAME` - 模型的显示名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "MODEL_ARTIFACT_DIR = \"[your-model-artifact-dir-name]\"  # @param {type:\"string\"}\n",
    "REPOSITORY = \"[your-repository-name]\"  # @param {type:\"string\"}\n",
    "IMAGE = \"[your-image-name]\"  # @param {type:\"string\"}\n",
    "MODEL_NAME = \"[your-model-name]\"  # @param {type:\"string\"}\n",
    "MODEL_DISPLAY_NAME = \"[your-model-display-name]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77273f981a1f"
   },
   "outputs": [],
   "source": [
    "# Otherwise, choose deafult names\n",
    "if MODEL_ARTIFACT_DIR == \"[your-model-artifact-dir-name]\":\n",
    "    MODEL_ARTIFACT_DIR = \"custom-fb-container-prediction-model\"\n",
    "if REPOSITORY == \"[your-repository-name]\":\n",
    "    REPOSITORY = \"custom-fb-container-prediction\"\n",
    "if IMAGE == \"[your-image-name]\":\n",
    "    IMAGE = \"custom-fb-fastapi-server\"\n",
    "if MODEL_NAME == \"[your-model-name]\":\n",
    "    MODEL_NAME = \"fb_custom_container\"\n",
    "if MODEL_DISPLAY_NAME == \"[your-model-display-name]\":\n",
    "    MODEL_DISPLAY_NAME = \"FB Prophet Forecast\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf"
   },
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRUOFELefqf1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import google.auth\n",
    "import joblib\n",
    "from google.cloud import aiplatform, bigquery\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c25ef9ce9d29"
   },
   "source": [
    "初始化BigQuery客户端和Python的Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0a52d5ce5c6"
   },
   "outputs": [],
   "source": [
    "credentials, _ = google.auth.default(\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    ")\n",
    "bqclient = bigquery.Client(\n",
    "    credentials=credentials,\n",
    "    project=PROJECT_ID,\n",
    ")\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4b816cd52f4b"
   },
   "source": [
    "## 训练和保存模型\n",
    "接下来，您将定义使用fbprophet训练时间序列模型的函数，针对一些销售类别。\n",
    "\n",
    "在接下来的步骤中定义了两种类型的预测函数。一种只使用销售数据，另一种使用[天气变量作为额外的回归器](https://facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html)进行预测。\n",
    "\n",
    "天气数据来自BigQuery中的一个公共数据集。了解更多关于[天气数据](https://cloud.google.com/blog/products/gcp/global-historical-daily-weather-data-now-available-in-bigquery)的信息。\n",
    "\n",
    "最后，这些函数将使用joblib将您训练好的模型导出为一个（`.sav`）文件。\n",
    "\n",
    "### 定义销售模型训练函数\n",
    "\n",
    "在接下来的单元格中，您将定义一个函数，用于从BigQuery中获取酒类销售数据，处理数据并训练和保存预测模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdea16cf6401"
   },
   "outputs": [],
   "source": [
    "def train(category):\n",
    "    # Download query results. # change to Data, Adj_Close\n",
    "    query_string = f\"\"\"\n",
    "    SELECT date as Date, upper(category_name) as category_name, sum(sale_dollars) as sales\n",
    "    FROM `bigquery-public-data.iowa_liquor_sales.sales`\n",
    "    where upper(category_name) = '{category}'\n",
    "      and date >= '2020-01-01' \n",
    "      and date < '2022-01-01'\n",
    "    group by Date, category_name\n",
    "    \"\"\"\n",
    "\n",
    "    data = bqclient.query(query_string).result().to_dataframe()\n",
    "    data.plot(title=f\"{category} Daily Sales\", x=\"Date\", y=\"sales\")\n",
    "\n",
    "    # Copy results into a dataframe with two columns ds=Date, y=value\n",
    "    df_forecast = data.copy()\n",
    "    df_forecast.reset_index(inplace=True)\n",
    "    df_forecast[\"ds\"] = df_forecast[\"Date\"]\n",
    "    df_forecast[\"y\"] = df_forecast[\n",
    "        \"sales\"\n",
    "    ]  # Add underscore as BQ changes this field name\n",
    "    df_forecast = df_forecast[[\"ds\", \"y\"]]\n",
    "\n",
    "    # Train the Prophet model\n",
    "    model = Prophet()\n",
    "    model.fit(df_forecast)\n",
    "\n",
    "    # Save the model locally\n",
    "    joblib.dump(model, \"{}.sav\".format(category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b63f09eb501"
   },
   "source": [
    "### 为两个样本类别训练和保存模型\n",
    "\n",
    "运行训练函数，为 *加拿大威士忌* 和 *美国伏特加* 生成销售预测模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "937f21278d5d"
   },
   "outputs": [],
   "source": [
    "%cd app/\n",
    "\n",
    "# Train a sales forecast model for CANADIAN WHISKIES\n",
    "train(\"CANADIAN WHISKIES\")\n",
    "# Train a sales forecast model for AMERICAN VODKAS\n",
    "train(\"AMERICAN VODKAS\")\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fdef44fddc6"
   },
   "source": [
    "### 为销售和天气模型定义训练函数\n",
    "\n",
    "创建一个考虑天气数据的训练函数。用于获取天气数据的SQL查询从BigQuery的公共天气数据集`bigquery-public-data.ghcn_d`中检索了两年的数据。该查询使用移动平均值生成了100个未来的天气数据点。\n",
    "\n",
    "在获取天气数据之后，它被保存在`temp`列中，并作为额外的回归器传递给预测模型。\n",
    "\n",
    "了解更多关于[FBProphet回归器](https://facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2c911ccc4a57"
   },
   "outputs": [],
   "source": [
    "def train_w_regressor(category):\n",
    "    # Download query results. # change to Data, Adj_Close\n",
    "    query_string = \"\"\"\n",
    "    SELECT date as Date, upper(category_name) as category_name, sum(sale_dollars) as sales\n",
    "    FROM `bigquery-public-data.iowa_liquor_sales.sales`\n",
    "    where upper(category_name) = '{CATEGORY}'\n",
    "      and date >= '2020-01-01'\n",
    "      and date < '2022-01-01'\n",
    "    group by Date, category_name\n",
    "    \"\"\".format(\n",
    "        CATEGORY=category\n",
    "    )\n",
    "\n",
    "    query_string_regressor = \"\"\"\n",
    "    WITH history as\n",
    "    (\n",
    "    SELECT\n",
    "      wx.date as ds,\n",
    "      AVG(wx.value/10) AS temp\n",
    "    FROM\n",
    "      `bigquery-public-data.ghcn_d.ghcnd_stations` AS stn\n",
    "    JOIN\n",
    "      `bigquery-public-data.ghcn_d.ghcnd_2021` AS wx ON wx.id = stn.id\n",
    "    WHERE\n",
    "      stn.state = 'AZ'\n",
    "      AND wx.element = 'TMIN'\n",
    "      AND wx.qflag IS NULL\n",
    "    GROUP by wx.date\n",
    "    union all\n",
    "    SELECT\n",
    "      wx.date as ds,\n",
    "      AVG(wx.value/10) AS temp\n",
    "    FROM\n",
    "      `bigquery-public-data.ghcn_d.ghcnd_stations` AS stn\n",
    "    JOIN\n",
    "      `bigquery-public-data.ghcn_d.ghcnd_2020` AS wx ON wx.id = stn.id\n",
    "    WHERE\n",
    "      stn.state = 'AZ'\n",
    "      AND wx.element = 'TMIN'\n",
    "      AND wx.qflag IS NULL\n",
    "    GROUP by wx.date\n",
    "    )\n",
    "    ,next_100_days as\n",
    "    (\n",
    "    SELECT DATE_ADD(max(stn.date) over (order by 1), INTERVAL row_number() over (order by stn.id) DAY) as ds, null as temp\n",
    "    FROM `bigquery-public-data.ghcn_d.ghcnd_2021` AS stn\n",
    "    LIMIT 100\n",
    "    )\n",
    "    ,combined_data as\n",
    "    (\n",
    "    select *\n",
    "    from history\n",
    "    union all\n",
    "    select * from next_100_days\n",
    "    )\n",
    "    select c.ds\n",
    "          ,case when temp is null then AVG(c.temp) OVER (ORDER BY c.ds ASC ROWS 100 PRECEDING)\n",
    "           else temp end as temp\n",
    "    from combined_data c;\n",
    "    \"\"\"\n",
    "\n",
    "    data = bqclient.query(query_string).result().to_dataframe()\n",
    "    data.plot(title=f\"{category} Daily Sales\", x=\"Date\", y=\"sales\")\n",
    "\n",
    "    # Copy results into a dataframe with two columns ds=Date, y=value\n",
    "    df_forecast = data.copy()\n",
    "    df_forecast.reset_index(inplace=True)\n",
    "    df_forecast[\"ds\"] = df_forecast[\"Date\"]\n",
    "    df_forecast[\"y\"] = df_forecast[\n",
    "        \"sales\"\n",
    "    ]  # Add underscore as BQ changes this field name\n",
    "    df_forecast = df_forecast[[\"ds\", \"y\"]]\n",
    "\n",
    "    # Return the weather data from BQ\n",
    "    data_regressor = bqclient.query(query_string_regressor).result().to_dataframe()\n",
    "    df_regressor = data_regressor.copy()\n",
    "\n",
    "    # Deal with any NaN values using fillna\n",
    "    df_regressor_out = df_regressor.fillna(method=\"pad\")\n",
    "    df_regressor_out.to_csv(f\"{category}_weather.csv\", index=False)\n",
    "\n",
    "    # Add a temp column to the df_forecast dataframe, and populate it from the df_regressor dataframe\n",
    "    df_forecast[\"temp\"] = df_forecast.ds.map(\n",
    "        df_regressor.set_index(\"ds\")[\"temp\"].to_dict()\n",
    "    )\n",
    "\n",
    "    df_forecast.loc[:, \"temp\"] = df_forecast.fillna(method=\"pad\").fillna(\n",
    "        method=\"backfill\"\n",
    "    )  # Address NaN values of temp\n",
    "\n",
    "    # Train the Prophet model with the regressor\n",
    "    model = Prophet()\n",
    "    model = model.add_regressor(\"temp\")\n",
    "    model.fit(df_forecast)\n",
    "\n",
    "    # Save the model locally, with _weather appended to the file name\n",
    "    joblib.dump(model, f\"{category}_weather.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3294eacdf0d7"
   },
   "source": [
    "使用天气数据对两个样本类别进行模型训练和保存\n",
    "\n",
    "对*加拿大威士忌*和*美国伏特加*运行训练函数，并将模型保存在本地。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3a0602230122"
   },
   "outputs": [],
   "source": [
    "%cd app/\n",
    "\n",
    "# Train a sales forecast model(with weather data) for CANADIAN WHISKIES\n",
    "train_w_regressor(\"CANADIAN WHISKIES\")\n",
    "# Train a sales forecast model(with weather data) for AMERICAN VODKAS\n",
    "train_w_regressor(\"AMERICAN VODKAS\")\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd"
   },
   "source": [
    "### 将模型工件和自定义代码上传到云存储\n",
    "\n",
    "在部署模型进行服务之前，Vertex AI 需要访问云存储中的以下文件：\n",
    "\n",
    "* 对于您想要检索预测的每个销售类别，需要 `{category}.sav`（模型工件）。\n",
    "* `*.csv` - 在预测时需要天气回归器的数据。\n",
    "\n",
    "运行以下单元格将您的文件上传到亲亲云存储。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ca67ee52d4d9"
   },
   "outputs": [],
   "source": [
    "%cd app\n",
    "!gsutil cp *.sav *.csv {BUCKET_URI}/{MODEL_ARTIFACT_DIR}/\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "480a1d88ecdb"
   },
   "source": [
    "## 本地模型测试\n",
    "\n",
    "在下面的单元格中测试训练好的预测模型（包括具有和不具有天气回归器的模型）。\n",
    "\n",
    "设置环境变量。\n",
    "\n",
    "### 测试销售模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2d09851b501"
   },
   "outputs": [],
   "source": [
    "%cd app\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "\n",
    "gcs_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Set a sample category and number of days to test with\n",
    "category = \"CANADIAN WHISKIES\"\n",
    "days = 7\n",
    "\n",
    "# Load the sales model\n",
    "fname = f\"{category}.sav\"\n",
    "model = joblib.load(f\"{category}.sav\")\n",
    "\n",
    "# Create a dataframe that ranges from 2020 to Today + the number of days set above\n",
    "TODAY = datetime.date.today()\n",
    "future = TODAY + datetime.timedelta(days=days)\n",
    "\n",
    "dates = pd.date_range(\n",
    "    start=\"2020-01-01\",\n",
    "    end=future.strftime(\"%m/%d/%Y\"),\n",
    ")\n",
    "df = pd.DataFrame({\"ds\": dates})\n",
    "\n",
    "# Run a prediction for these dates and save it to a forecast dataframe\n",
    "forecast = model.predict(df)\n",
    "\n",
    "model.plot(forecast).savefig(f\"{category}_plot.png\")\n",
    "model.plot_components(forecast).savefig(f\"{category}_plot_components.png\")\n",
    "\n",
    "forecast.tail(days).to_dict(\"records\")\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d411890f8d45"
   },
   "source": [
    "### 测试销售和天气模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d156e7c5632"
   },
   "outputs": [],
   "source": [
    "%cd app\n",
    "\n",
    "gcs_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Set a sample category and number of days to test with\n",
    "category = \"CANADIAN WHISKIES_weather\"\n",
    "days = 7\n",
    "\n",
    "# Load the sales and weather model\n",
    "fname = f\"{category}.sav\"\n",
    "model = joblib.load(f\"{category}.sav\")\n",
    "\n",
    "# Load the data\n",
    "fname_csv = f\"{category}.csv\"\n",
    "df_regressor = pd.read_csv(fname_csv)\n",
    "\n",
    "# Return the data from the regressor that ranges from 2020 to Today + the number of days set above\n",
    "TODAY = datetime.date.today()\n",
    "future = TODAY + datetime.timedelta(days=days)\n",
    "\n",
    "start = \"2020-01-01\"\n",
    "after_start_date = df_regressor[\"ds\"] >= start\n",
    "before_end_date = df[\"ds\"] <= future.strftime(\"%m/%d/%Y\")\n",
    "between_two_dates = after_start_date & before_end_date\n",
    "df_final = df_regressor.loc[between_two_dates]\n",
    "df_final.tail()\n",
    "\n",
    "# Run a prediction for these dates and the regressor\n",
    "forecast = model.predict(df_final)\n",
    "\n",
    "model.plot(forecast).savefig(f\"{category}_plot.png\")\n",
    "model.plot_components(forecast).savefig(f\"{category}_plot_components.png\")\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "480a1d88ecdb"
   },
   "source": [
    "构建一个FastAPI服务器\n",
    "\n",
    "为了服务于这两个模型的预测结果，构建一个FastAPI服务器应用程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94af0ba5eadd"
   },
   "outputs": [],
   "source": [
    "%%writefile app/main.py\n",
    "from fastapi import FastAPI, Request\n",
    "from fastapi.exceptions import RequestValidationError\n",
    "from fastapi.responses import JSONResponse\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import errno\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "app = FastAPI()\n",
    "gcs_client = storage.Client()\n",
    "\n",
    "@app.exception_handler(Exception)\n",
    "async def validation_exception_handler(request, err):\n",
    "    base_error_message = f\"Failed to execute: {request.method}: {request.url}\"\n",
    "    # Change here to LOGGER\n",
    "    return JSONResponse(status_code=400, content={\"message\": f\"{base_error_message}. Detail: {err}\"})\n",
    "\n",
    "    \n",
    "def download_model(category=\"CANADIAN WHISKIES\", regressor=\"\"): #defaults to \"CANADIAN WHISKIES\"\n",
    "    if not category:\n",
    "        raise HTTPException(status_code=400, detail=f\"category not found. category={category}\")\n",
    "    fname = f\"{category}{regressor}.sav\"\n",
    "    with open(f\"{fname}\", 'wb') as model_g:\n",
    "        gcs_client.download_blob_to_file(\n",
    "            f\"{os.environ['AIP_STORAGE_URI']}/{fname}\", model_g\n",
    "        )\n",
    "    model = joblib.load (fname)\n",
    "    return model\n",
    "    \n",
    "def predict_in(model, days=7, regressor=\"\", category=\"CANADIAN WHISKIES\"):\n",
    "    TODAY = datetime.date.today()\n",
    "    future = TODAY + datetime.timedelta(days=days)\n",
    "\n",
    "    dates = pd.date_range(start=\"2020-01-01\", end=future.strftime(\"%m/%d/%Y\"),)\n",
    "    df = pd.DataFrame({\"ds\": dates})\n",
    "\n",
    "    if (regressor > \"\"):\n",
    "        fname_csv = f\"{category}{regressor}.csv\"\n",
    "        with open(f\"{fname_csv}\", 'wb') as model_csv:\n",
    "            gcs_client.download_blob_to_file(\n",
    "                f\"{os.environ['AIP_STORAGE_URI']}/{fname_csv}\", model_csv\n",
    "            )\n",
    "\n",
    "        df_regressor = pd.read_csv(fname_csv)\n",
    "        start=\"2020-01-01\"\n",
    "        after_start_date = df_regressor[\"ds\"] >= start\n",
    "        before_end_date = df[\"ds\"] <= future.strftime(\"%m/%d/%Y\")\n",
    "        between_two_dates = after_start_date & before_end_date\n",
    "        df_final = df_regressor.loc[between_two_dates]\n",
    "        df_final.tail()\n",
    "        \n",
    "        forecast = model.predict(df_final)\n",
    "    \n",
    "    else:\n",
    "        forecast = model.predict(df)\n",
    "\n",
    "    model.plot(forecast).savefig(\"model_plot.png\")\n",
    "    model.plot_components(forecast).savefig(\"model_plot_components.png\")    \n",
    "    \n",
    "    return forecast.tail(days).to_dict(\"records\")\n",
    "\n",
    "\n",
    "def convert(prediction_list):\n",
    "    output = {}\n",
    "    for data in prediction_list:\n",
    "        date = data[\"ds\"].strftime(\"%m/%d/%Y\")\n",
    "        output[date] = data[\"trend\"]\n",
    "    return output\n",
    "\n",
    "\n",
    "@app.get(os.environ['AIP_HEALTH_ROUTE'], status_code=200)\n",
    "def health():\n",
    "    return {}\n",
    "\n",
    "\n",
    "@app.post(os.environ['AIP_PREDICT_ROUTE'])\n",
    "async def predict(request: Request):\n",
    "    body = await request.json()\n",
    "    try:\n",
    "        if type(body) is list:\n",
    "            body = body[0]\n",
    "    except:\n",
    "        None #Do Nothing\n",
    "    print (body)\n",
    "    instances = body[\"instances\"]\n",
    "\n",
    "    try:\n",
    "        if type(instances) is list:\n",
    "            instances = instances[0]\n",
    "    except:\n",
    "        None #Do Nothing\n",
    "    print(instances)    \n",
    "    category = instances[\"category\"] \n",
    "    days = instances[\"days\"]\n",
    "    regressor = instances[\"regressor\"]\n",
    "    \n",
    "    try:\n",
    "        if type(category) is list:\n",
    "            category = category[0]\n",
    "    except:\n",
    "        None #Do Nothing\n",
    "    print(category) \n",
    "\n",
    "    try:\n",
    "        if type(days) is list:\n",
    "            days = days[0]\n",
    "    except:\n",
    "        None #Do Nothing\n",
    "    print(days) \n",
    "\n",
    "    try:\n",
    "        if type(regressor) is list:\n",
    "            regressor = regressor[0]\n",
    "    except:\n",
    "        None #Do Nothing\n",
    "    print(regressor) \n",
    "    \n",
    "    model_download = download_model (category, regressor)\n",
    "    prediction_list = predict_in(model_download, days, regressor, category)  \n",
    "    \n",
    "    if not prediction_list:\n",
    "        raise HTTPException(status_code=400, detail=\"Model not found.\")\n",
    "    \n",
    "    prediction_output = convert(prediction_list)\n",
    "    final_output = [(k, v) for k, v in prediction_output.items()] \n",
    "    \n",
    "    return {\"predictions\": final_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "150cf819687b"
   },
   "source": [
    "### 添加预启动脚本\n",
    "FastAPI 在启动服务器之前执行此脚本。为了在与 Vertex AI 预期相同的端口上运行 FastAPI，将 `PORT` 环境变量设置为等于 `AIP_HTTP_PORT`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69f438aca35b"
   },
   "outputs": [],
   "source": [
    "%%writefile app/prestart.sh\n",
    "export PORT=$AIP_HTTP_PORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b62ddf1def3"
   },
   "source": [
    "### 创建测试实例\n",
    "要了解有关在 JSON 中格式化输入实例的更多信息，请[阅读文档。](https://cloud.google.com/ai-platform-unified/docs/predictions/online-predictions-custom-models#request-body-details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6605e9e6186"
   },
   "outputs": [],
   "source": [
    "%%writefile instances.json\n",
    "{\"instances\": [{\"category\":[\"CANADIAN WHISKIES\"], \"days\": [30], \"regressor\": [\"_weather\"]}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51e149fdec1b"
   },
   "source": [
    "构建并推送容器至 Artifact Registry\n",
    "\n",
    "使用`tiangolo/uvicorn-gunicorn-fastapi`作为基础镜像编写`Dockerfile`。这将自动使用Gunicorn和Uvicorn为您运行FastAPI。\n",
    "\n",
    "了解更多关于[使用Docker部署FastAPI服务器](https://fastapi.tiangolo.com/deployment/docker/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3d3a6b9ed22b"
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.9\n",
    "\n",
    "COPY ./app /app\n",
    "COPY requirements.txt requirements.txt\n",
    "\n",
    "RUN pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "240578ec9efe"
   },
   "source": [
    "### 本地构建镜像（可选）\n",
    "\n",
    "使用docker在本地构建镜像。日志存储在`logs.txt`中。\n",
    "\n",
    "**注意：** Docker仅用于在本地测试容器。用于部署到Artifact注册表的是Cloud-Build。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1e7d639b9cc"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def build_image():\n",
    "    ! sudo docker build --tag=\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}\" . > logs.txt\n",
    "\n",
    "\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if not IS_COLAB and not os.getenv(\"IS_TESTING\"):\n",
    "    print(\"Building the image...\")\n",
    "    build_image()\n",
    "    print(\"Process completed !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "147a555f6c93"
   },
   "source": [
    "### 在本地运行并测试容器（可选）\n",
    "\n",
    "在后台模式下测试在本地运行容器，并提供容器所需的环境变量。这些环境变量在容器部署到 Vertex AI 后由 Vertex AI Predictions 提供。测试 `/health` 和 `/predict` 路由，然后停止运行的镜像。\n",
    "\n",
    "**注意**: 本节测试容器的本地运行。但是，如果底层环境是Colab，则`docker`命令会被自动跳过。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62ed2d334d0f"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB and not os.getenv(\"IS_TESTING\"):\n",
    "    ! sudo docker stop local-ts\n",
    "    ! sudo docker rm local-ts\n",
    "    ! sudo docker run -d -p 80:8080 \\\n",
    "        --name=local-ts \\\n",
    "        -e AIP_HTTP_PORT=8080 \\\n",
    "        -e AIP_HEALTH_ROUTE=/health \\\n",
    "        -e AIP_PREDICT_ROUTE=/predict \\\n",
    "        -e AIP_STORAGE_URI={BUCKET_URI}/{MODEL_ARTIFACT_DIR} \\\n",
    "        \"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa65e36b749b"
   },
   "source": [
    "评估健康路线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce629eea32fd"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB and not os.getenv(\"IS_TESTING\"):\n",
    "    ! curl localhost/health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5e424e3cef51"
   },
   "source": [
    "### 测试预测路线（可选）\n",
    "\n",
    "传递 `instances.json` 并测试预测路线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56986f93438e"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB and not os.getenv(\"IS_TESTING\"):\n",
    "    ! curl -X POST \\\n",
    "      -d @instances.json \\\n",
    "      -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "      localhost/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c3590595868"
   },
   "source": [
    "现在，存储一个没有`regressor`的实例，并测试预测路线。这将从训练模型中获取没有天气回归变量的预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6235f235355"
   },
   "outputs": [],
   "source": [
    "%%writefile instances.json\n",
    "{\"instances\": [{\"category\":[\"CANADIAN WHISKIES\"], \"days\": [30], \"regressor\": [\"\"]}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ac42740a39d"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB and not os.getenv(\"IS_TESTING\"):\n",
    "    ! curl -X POST \\\n",
    "      -d @instances.json \\\n",
    "      -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "      localhost/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fc13c7a6d7f"
   },
   "source": [
    "停止并在本地删除容器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a29fcbbe0188"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB and not os.getenv(\"IS_TESTING\"):\n",
    "    ! sudo docker stop local-ts\n",
    "    ! sudo docker rm local-ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2d242773d707"
   },
   "source": [
    "#### 启用 Artifact Registry API\n",
    "您必须启用项目的 Artifact Registry API 服务。\n",
    "\n",
    "<a href=\"https://cloud.google.com/artifact-registry/docs/enable-service\">了解更多关于启用服务的信息</a>。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d72f89cabd5"
   },
   "outputs": [],
   "source": [
    "! gcloud services enable artifactregistry.googleapis.com\n",
    "\n",
    "if os.getenv(\"IS_TESTING\"):\n",
    "    ! sudo apt-get update --yes && sudo apt-get --only-upgrade --yes install google-cloud-sdk-cloud-run-proxy google-cloud-sdk-harbourbridge google-cloud-sdk-cbt google-cloud-sdk-gke-gcloud-auth-plugin google-cloud-sdk-kpt google-cloud-sdk-local-extract google-cloud-sdk-minikube google-cloud-sdk-app-engine-java google-cloud-sdk-app-engine-go google-cloud-sdk-app-engine-python google-cloud-sdk-spanner-emulator google-cloud-sdk-bigtable-emulator google-cloud-sdk-nomos google-cloud-sdk-package-go-module google-cloud-sdk-firestore-emulator kubectl google-cloud-sdk-datastore-emulator google-cloud-sdk-app-engine-python-extras google-cloud-sdk-cloud-build-local google-cloud-sdk-kubectl-oidc google-cloud-sdk-anthos-auth google-cloud-sdk-app-engine-grpc google-cloud-sdk-pubsub-emulator google-cloud-sdk-datalab google-cloud-sdk-skaffold google-cloud-sdk google-cloud-sdk-terraform-tools google-cloud-sdk-config-connector\n",
    "    ! gcloud components update --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23f3ba8346f4"
   },
   "source": [
    "### 创建一个私有的Docker仓库\n",
    "您的第一步是在Google Artifact Registry中创建自己的Docker仓库。\n",
    "\n",
    "1 - 运行gcloud artifacts repositories create命令，使用您的地区和描述“docker仓库”创建一个新的Docker仓库。\n",
    "\n",
    "2 - 运行gcloud artifacts repositories list命令来验证您的仓库是否已创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64fee26c2dff"
   },
   "outputs": [],
   "source": [
    "! gcloud artifacts repositories create {REPOSITORY} --repository-format=docker --location={REGION} --description=\"Docker repository\"\n",
    "\n",
    "! gcloud artifacts repositories list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22bfd31ec64d"
   },
   "source": [
    "使用Cloud-Build将图像推送到创建的存储库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dd7448f4703"
   },
   "outputs": [],
   "source": [
    "!gcloud builds submit --region={REGION} --tag={REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b438bfa2129f"
   },
   "source": [
    "使用 Python SDK 从 artifact URI 上载并部署您的模型，创建一个 Vertex AI 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2738154345d5"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=f\"{BUCKET_URI}/{MODEL_ARTIFACT_DIR}\",\n",
    "    serving_container_image_uri=f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd1b85afc7df"
   },
   "source": [
    "将模型部署到Vertex AI终端\n",
    "\n",
    "将模型部署到终端。完成此步骤后，模型将被部署并准备好进行在线预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62cf66498a28"
   },
   "outputs": [],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6883e7b07143"
   },
   "source": [
    "## 请求预测\n",
    "\n",
    "向部署到端点的模型发送在线请求并获得预测结果。\n",
    "\n",
    "### 使用Python SDK\n",
    "\n",
    "使用Python SDK从端点获取预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fd5d8ea367ea"
   },
   "outputs": [],
   "source": [
    "# Send an instance for the model without regressor\n",
    "endpoint.predict(\n",
    "    instances=[{\"category\": [\"CANADIAN WHISKIES\"], \"days\": [30], \"regressor\": [\"\"]}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6a0ed7c9917d"
   },
   "outputs": [],
   "source": [
    "# Send an instance for the model with regressor\n",
    "endpoint.predict(\n",
    "    instances=[\n",
    "        {\"category\": [\"CANADIAN WHISKIES\"], \"days\": [30], \"regressor\": [\"_weather\"]}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "370d22f53427"
   },
   "source": [
    "使用REST\n",
    "\n",
    "使用curl请求从端点获取预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ba55bc560d58"
   },
   "outputs": [],
   "source": [
    "ENDPOINT_ID = endpoint.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95c562b4e98b"
   },
   "outputs": [],
   "source": [
    "! curl \\\n",
    "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d @instances.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{REGION}/endpoints/{ENDPOINT_ID}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa71174a7dd0"
   },
   "source": [
    "使用gcloud CLI获得通过终端点的预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23b8e807b02c"
   },
   "outputs": [],
   "source": [
    "!gcloud ai endpoints predict $ENDPOINT_ID \\\n",
    "  --region=$REGION \\\n",
    "  --json-request=instances.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在此教程中创建的各个资源：\n",
    "\n",
    "- 模型\n",
    "- 端点\n",
    "- Artefact Registry镜像\n",
    "- Artefact Repository：将`delete_art_repo`设置为**True**以删除在此教程中创建的存储库。\n",
    "- Cloud Storage存储桶：将`delete_bucket`设置为**True**以删除在此教程中使用的Cloud Storage存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "delete_bucket = False\n",
    "delete_art_repo = False\n",
    "\n",
    "# # Undeploy model and delete endpoint\n",
    "endpoint.undeploy_all()\n",
    "endpoint.delete()\n",
    "\n",
    "# # Delete the model resource\n",
    "model.delete()\n",
    "\n",
    "# Delete the container image from Artifact Registry\n",
    "!gcloud artifacts docker images delete \\\n",
    "    --quiet \\\n",
    "    --delete-tags \\\n",
    "    {REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}\n",
    "\n",
    "# # Delete the artifact registry\n",
    "if delete_art_repo or os.getenv(\"IS_TESTING\"):\n",
    "    ! gcloud artifacts repositories delete {REPOSITORY} --location=$REGION -q\n",
    "\n",
    "# Delete the Cloud Storage bucket\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil -m rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SDK_FBProphet_Forecasting_Online.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
