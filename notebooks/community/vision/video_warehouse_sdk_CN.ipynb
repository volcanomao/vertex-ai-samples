{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FX2wUzd3gjTc"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# 视频仓库 SDK 演示\n",
    "\n",
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/vision/video_warehouse_sdk.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/vision/video_warehouse_sdk.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>                                                                                         \n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/vision/video_warehouse_sdk.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在 Vertex AI Workbench 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI8d5ytBhfuw"
   },
   "source": [
    "**_注意_**：此笔记本在以下环境中进行了测试：\n",
    "\n",
    "* Python版本 = 3.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENEut1m0h3Uo"
   },
   "source": [
    "## 概述\n",
    "\n",
    "通过使用SDK逐步学习如何构建一个[视频仓库](https://cloud.google.com/vision-ai/docs)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMF4pbEIuZS2"
   },
   "source": [
    "### 目标\n",
    "本示例旨在展示如何使用Warehouse SDK处理输入视频，建立索引并进行搜索。\n",
    "\n",
    "执行步骤包括:\n",
    "\n",
    "* 创建语料库。\n",
    "\n",
    "* 使用来自Google Cloud Storage的视频文件创建和上传资产。\n",
    "\n",
    "* 创建索引，创建索引端点，并部署索引。\n",
    "  * 此步骤可能需要一个小时。\n",
    "\n",
    "* 运行转换以分析资产:\n",
    "  * 语音转换\n",
    "    * 使用Video intelligence API运行语音转录并存储到仓库中。默认情况下，语音结果可以通过\"speech\"字段进行搜索。您可以通过在SpeechTransformerInitConfig中设置speech_transcript_search_criteria_key来指定搜索条件字段。\n",
    "  * OCR转换\n",
    "    * 使用Video intelligence API运行文本检测并存储到仓库中。默认情况下，文本检测结果可以通过\"text\"字段进行搜索。通过在OcrTransformerInitConfig中设置ocr_search_criteria_key来指定搜索条件字段。\n",
    "  * 嵌入式分析\n",
    "\n",
    "* 建立索引。\n",
    "\n",
    "* 搜索。\n",
    "\n",
    "* 清理资源（资产、索引、索引端点、语料库）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzdLmFrajntF"
   },
   "source": [
    "### 数据集\n",
    "该数据集将使用存储在Google Cloud Storage桶中的视频集合：[gs://cloud-samples-data/video](https://pantheon.corp.google.com/storage/browser/cloud-samples-data/video)。\n",
    "\n",
    "本教程演示了如何使用Warehouse SDK来运行语音转录、文本检测、嵌入式分析，以及为该数据集中的视频构建搜索索引并提供搜索功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQV4SMLUqchE"
   },
   "source": [
    "### 成本\n",
    "\n",
    "本教程使用了 Google Cloud 的计费组件：\n",
    "\n",
    "Vertex AI Vision（[定价](https://cloud.google.com/vision-ai/pricing)）\n",
    "\n",
    "Video Intelligence（[定价](https://cloud.google.com/video-intelligence/pricing)）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5ZDs2SUq0DN"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装以下所需的软件包以执行这个笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2DWuFFA_wUtL"
   },
   "outputs": [],
   "source": [
    "!gsutil cp gs://visionai-artifacts/visionai-0.0.6-py3-none-any.whl .\n",
    "!pip install visionai-0.0.6-py3-none-any.whl --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58707a750154"
   },
   "source": [
    "只有Colab才能：取消对以下单元格的注释以重新启动内核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f200f10a1da3"
   },
   "outputs": [],
   "source": [
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeRSrNTGZVBJ"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### 设置你的Google云项目\n",
    "\n",
    "**无论你使用什么笔记本环境，以下步骤都是必需的。**\n",
    "\n",
    "1. [选择或创建一个Google云项目](https://console.cloud.google.com/cloud-resource-manager)。当你第一次创建账户时，你会获得$300的免费信用额度用于计算/存储成本。\n",
    "\n",
    "2. [确保你的项目已启用计费](https://cloud.google.com/billing/docs/how-to/modify-project)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3i7BDALZqeQ"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下操作：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面：[找到项目ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOkFz5v6Z5mL"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBCra4QMA2wR"
   },
   "source": [
    "### 验证您的Google Cloud帐户\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动进行身份验证。请按照以下相关说明进行操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74ccc9e52986"
   },
   "source": [
    "1. Vertex AI Workbench\n",
    "* 无需操作，因为您已经验证过了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de775a3773ba"
   },
   "source": [
    "2. 本地 JupyterLab 实例，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "254614fa0c46"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iXNewDH2wkV-"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef21552ccea8"
   },
   "source": [
    "3. Colab，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "603adbbf0532"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user(project_id=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixfp-_Ne09EK"
   },
   "source": [
    "### 设置其他常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBCHXC3uhrQo"
   },
   "outputs": [],
   "source": [
    "PROJECT_NUMBER_STR = !gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\"\n",
    "PROJECT_NUMBER = int(PROJECT_NUMBER_STR[0])\n",
    "\n",
    "# Only us-central1 is supported.\n",
    "# Please note that this region is for VisionAi services. For speech\n",
    "# transcription, we may not respect the region here.\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "CORPUS_DISPLAY_NAME = \"Demo corpus\"  # @param {type: \"string\"}\n",
    "CORPUS_DESCRIPTION = \"Demo corpus to demo warehouse transformations and search\"  # @param {type: \"string\"}\n",
    "\n",
    "# External users can only access PROD environment.\n",
    "ENV = \"PROD\"\n",
    "\n",
    "INDEX_DISPLAY_NAME = \"Demo Index\"  # @param {type: \"string\"}\n",
    "INDEX_ENDPOINT_DISPLAY_NAME = \"Demo Index Endpoint\"  # @param {type: \"string\"}\n",
    "\n",
    "CLEAN_UP_ASSETS = True  # @param {type: \"boolean\"}\n",
    "CLEAN_UP_INDEX = True  # @param {type: \"boolean\"}\n",
    "CLEAN_UP_CORPUS = True  # @param {type: \"boolean\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4aFiWRihds8"
   },
   "source": [
    "无论使用现有语料库和索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOhXWtfjhxuz"
   },
   "outputs": [],
   "source": [
    "# Because it takes ~1h to create and deploy index. A existing index can be\n",
    "# specified to save time.\n",
    "\n",
    "# If CORPUS_ID is specified, skip creating a new corpus.\n",
    "CORPUS_ID = None  # @param {type: \"string\"}\n",
    "# If DEPLOYED_INDEX_ID is specified, use existing index instead of creating and\n",
    "# deploying a new index.\n",
    "DEPLOYED_INDEX_ID = None  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUDxEpztitwN"
   },
   "source": [
    "### 输入视频文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYgf32fogKHa"
   },
   "outputs": [],
   "source": [
    "GCS_FILES = [\n",
    "    \"gs://cloud-samples-data/video/animals.mp4\",\n",
    "    \"gs://cloud-samples-data/video/googlework_short.mp4\",\n",
    "    \"gs://cloud-samples-data/video/chicago.mp4\",\n",
    "    (\n",
    "        \"gs://cloud-samples-data/video/Machine Learning Solving Problems\"\n",
    "        \" Big, Small, and Prickly.mp4\"\n",
    "    ),\n",
    "    \"gs://cloud-samples-data/video/JaneGoodall.mp4\",\n",
    "    \"gs://cloud-samples-data/video/gbikes_dinosaur.mp4\",\n",
    "    \"gs://cloud-samples-data/video/pizza.mp4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxXIz2fhpbe3"
   },
   "source": [
    "### 启用 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PBV1hcV_spkd"
   },
   "outputs": [],
   "source": [
    "!gcloud services enable videointelligence.googleapis.com\n",
    "!gcloud services enable visionai.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAZP-f1LhLpY"
   },
   "source": [
    "### 配置日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tgumkNAeoBGg"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "_logger = logging.getLogger(\"colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtpK3kCfhRQ5"
   },
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b74iOAaMynQT"
   },
   "outputs": [],
   "source": [
    "import concurrent\n",
    "import logging\n",
    "\n",
    "from visionai.python.gapic.visionai import visionai_v1\n",
    "from visionai.python.net import channel\n",
    "from visionai.python.warehouse.transformer import \\\n",
    "    asset_indexing_transformer as ait\n",
    "from visionai.python.warehouse.transformer import (ocr_transformer,\n",
    "                                                   speech_transformer,\n",
    "                                                   transformer_factory)\n",
    "from visionai.python.warehouse.utils import (vod_asset, vod_corpus,\n",
    "                                             vod_index_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D78bPt9wftNS"
   },
   "source": [
    "## 创建仓库客户端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjBTqlAricqz"
   },
   "outputs": [],
   "source": [
    "warehouse_endpoint = channel.get_warehouse_service_endpoint(channel.Environment[ENV])\n",
    "warehouse_client = visionai_v1.WarehouseClient(\n",
    "    client_options={\"api_endpoint\": warehouse_endpoint}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsJVdL9if-cK"
   },
   "source": [
    "创建一个语料库或使用现有的语料库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oEVMGRjuf5oJ"
   },
   "outputs": [],
   "source": [
    "if CORPUS_ID is None:\n",
    "    corpus_name = vod_corpus.create_corpus(\n",
    "        warehouse_client,\n",
    "        PROJECT_NUMBER,\n",
    "        REGION,\n",
    "        CORPUS_DISPLAY_NAME,\n",
    "        CORPUS_DESCRIPTION,\n",
    "    ).name\n",
    "else:\n",
    "    corpus_name = visionai_v1.WarehouseClient.corpus_path(\n",
    "        PROJECT_NUMBER, REGION, CORPUS_ID\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TuwJWZtiAXF"
   },
   "source": [
    "创建一个执行者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXh9TlJv9Ayz"
   },
   "outputs": [],
   "source": [
    "# Creates an executor to upload and transform assets in parallel.\n",
    "executor = concurrent.futures.ThreadPoolExecutor(max_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aifUauuriHMm"
   },
   "source": [
    "创建和上传资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZWKPBR_yHIF"
   },
   "outputs": [],
   "source": [
    "new_asset_futures = []\n",
    "for gcs_file in GCS_FILES:\n",
    "    new_asset_futures.append(\n",
    "        executor.submit(\n",
    "            vod_asset.create_and_upload_asset,\n",
    "            warehouse_client,\n",
    "            gcs_file,\n",
    "            corpus_name,\n",
    "        )\n",
    "    )\n",
    "done_or_error, _ = concurrent.futures.wait(\n",
    "    new_asset_futures, return_when=\"ALL_COMPLETED\"\n",
    ")\n",
    "asset_names = []\n",
    "for done_future in done_or_error:\n",
    "    try:\n",
    "        asset_names.append(done_future.result())\n",
    "        _logger.info(\"Create and upload asset succeeded %s\", done_future.result())\n",
    "    except Exception as e:\n",
    "        _logger.exception(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICZAwBuyiMpM"
   },
   "source": [
    "准备索引或使用现有索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJpefxMzl4FM"
   },
   "outputs": [],
   "source": [
    "# Create index and index endpoint for the corpus, or use existing index\n",
    "# and index endpoint if specified.\n",
    "if DEPLOYED_INDEX_ID is None:\n",
    "    # Creates index for the corpus.\n",
    "    index_name = vod_corpus.index_corpus(\n",
    "        warehouse_client, corpus_name, INDEX_DISPLAY_NAME\n",
    "    )\n",
    "    # Creates index endpoint and deploys the created index above to the index\n",
    "    # endpoint.\n",
    "    index_endpoint_name = vod_index_endpoint.create_index_endpoint(\n",
    "        warehouse_client,\n",
    "        PROJECT_NUMBER,\n",
    "        REGION,\n",
    "        INDEX_ENDPOINT_DISPLAY_NAME,\n",
    "    ).name\n",
    "    deploy_operation = warehouse_client.deploy_index(\n",
    "        visionai_v1.DeployIndexRequest(\n",
    "            index_endpoint=index_endpoint_name,\n",
    "            deployed_index=visionai_v1.DeployedIndex(\n",
    "                index=index_name,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    _logger.info(\"Wait for index to be deployed %s.\", deploy_operation.operation.name)\n",
    "    # Wait for the deploy index operation. Depends on the data size to be\n",
    "    # indexed, the timeout may need to be increased.\n",
    "    deploy_operation.result(timeout=7200)\n",
    "    _logger.info(\"Index is deployed.\")\n",
    "else:\n",
    "    index_name = \"{}/indexes/{}\".format(corpus_name, DEPLOYED_INDEX_ID)\n",
    "    index = warehouse_client.get_index(visionai_v1.GetIndexRequest(name=index_name))\n",
    "    _logger.info(\"Use existing index %s.\", index)\n",
    "    if index.state != visionai_v1.Index.State.CREATED:\n",
    "        _logger.critical(\"Invalid index. The index state must be Created.\")\n",
    "    if not index.deployed_indexes:\n",
    "        _logger.critical(\"Invalid index. The index must be deployed.\")\n",
    "    index_endpoint_name = index.deployed_indexes[0].index_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iw6l8UYiiYy3"
   },
   "source": [
    "## 运行转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPp5LV0-x4ZS"
   },
   "outputs": [],
   "source": [
    "ocr_config = ocr_transformer.OcrTransformerInitConfig(\n",
    "    corpus_name=corpus_name,\n",
    "    env=channel.Environment[ENV],\n",
    ")\n",
    "\n",
    "ml_config = transformer_factory.MlTransformersCreationConfig(\n",
    "    run_embedding=True,\n",
    "    speech_transformer_init_config=speech_transformer.SpeechTransformerInitConfig(\n",
    "        corpus_name=corpus_name, language_code=\"en-US\"\n",
    "    ),\n",
    "    ocr_transformer_init_config=ocr_config,\n",
    ")\n",
    "ml_transformers = transformer_factory.create_ml_transformers(\n",
    "    warehouse_client, ml_config\n",
    ")\n",
    "# Creates indexing transformer to index assets.\n",
    "asset_indexing_transformer = ait.AssetIndexingTransformer(warehouse_client, index_name)\n",
    "# Runs the transformers for the assets.\n",
    "futures = []\n",
    "\n",
    "for asset_name in asset_names:\n",
    "    futures.append(\n",
    "        executor.submit(\n",
    "            vod_asset.transform_single_asset,\n",
    "            asset_name,\n",
    "            ml_transformers,\n",
    "            asset_indexing_transformer,\n",
    "        )\n",
    "    )\n",
    "done_or_error, _ = concurrent.futures.wait(futures, return_when=\"ALL_COMPLETED\")\n",
    "for future in done_or_error:\n",
    "    try:\n",
    "        future.result()\n",
    "    except Exception as e:\n",
    "        _logger.exception(e)\n",
    "\n",
    "all_transformers = ml_transformers + [asset_indexing_transformer]\n",
    "for transformer in all_transformers:\n",
    "    transformer.teardown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BstsgXbnij2I"
   },
   "source": [
    "搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fKlKYnA7hEPT"
   },
   "outputs": [],
   "source": [
    "search_response = warehouse_client.search_index_endpoint(\n",
    "    visionai_v1.SearchIndexEndpointRequest(\n",
    "        index_endpoint=index_endpoint_name,\n",
    "        text_query=\"dinosaur\",\n",
    "        page_size=10,\n",
    "    )\n",
    ")\n",
    "_logger.info(\"Search response: %s\", search_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0znp7rq8PvS"
   },
   "outputs": [],
   "source": [
    "cr = visionai_v1.Criteria(\n",
    "    field=\"speech\", text_array=visionai_v1.StringArray(txt_values=[\"kid\"])\n",
    ")\n",
    "search_response = warehouse_client.search_index_endpoint(\n",
    "    visionai_v1.SearchIndexEndpointRequest(\n",
    "        index_endpoint=index_endpoint_name,\n",
    "        text_query=\"river\",\n",
    "        criteria=[cr],\n",
    "        page_size=100,\n",
    "    )\n",
    ")\n",
    "_logger.info(\"Search response: %s\", search_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ypuAtP0E8y-"
   },
   "outputs": [],
   "source": [
    "cr = visionai_v1.Criteria(\n",
    "    field=\"text\", text_array=visionai_v1.StringArray(txt_values=[\"National Park\"])\n",
    ")\n",
    "search_response = warehouse_client.search_index_endpoint(\n",
    "    visionai_v1.SearchIndexEndpointRequest(\n",
    "        index_endpoint=index_endpoint_name,\n",
    "        text_query=\"trees\",\n",
    "        criteria=[cr],\n",
    "        page_size=100,\n",
    "    )\n",
    ")\n",
    "_logger.info(\"Search response: %s\", search_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NZsfKd2djB4"
   },
   "source": [
    "清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZt1pXWfsaAt"
   },
   "outputs": [],
   "source": [
    "if CLEAN_UP_ASSETS:\n",
    "    for asset_name in asset_names:\n",
    "        warehouse_client.delete_asset(visionai_v1.DeleteAssetRequest(name=asset_name))\n",
    "        _logger.info(\"Deleted asset %s\", asset_name)\n",
    "\n",
    "if CLEAN_UP_INDEX:\n",
    "    undeploy_operation = warehouse_client.undeploy_index(\n",
    "        visionai_v1.UndeployIndexRequest(index_endpoint=index_endpoint_name)\n",
    "    )\n",
    "    _logger.info(\n",
    "        \"Wait for index to be undeployed %s.\",\n",
    "        undeploy_operation.operation.name,\n",
    "    )\n",
    "    # Wait for the undeploy index operation.\n",
    "    undeploy_operation.result(timeout=1800)\n",
    "    _logger.info(\"Index is undeployed.\")\n",
    "    warehouse_client.delete_index(visionai_v1.DeleteIndexRequest(name=index_name))\n",
    "    _logger.info(\"Deleted index %s\", index_name)\n",
    "    warehouse_client.delete_index_endpoint(\n",
    "        visionai_v1.DeleteIndexEndpointRequest(name=index_endpoint_name)\n",
    "    )\n",
    "    _logger.info(\"Deleted index endpoint %s\", index_endpoint_name)\n",
    "\n",
    "if CLEAN_UP_CORPUS:\n",
    "    warehouse_client.delete_corpus(visionai_v1.DeleteCorpusRequest(name=corpus_name))\n",
    "    _logger.info(\"Deleted corpus %s\", corpus_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "video_warehouse_sdk.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
