{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:migration,new"
   },
   "source": [
    "# Vertex SDK：使用TensorFlow提交一个超参数调优训练作业"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip"
   },
   "source": [
    "安装\n",
    "\n",
    "安装最新（预览）版本的Vertex SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXVD8TE-iBAZ"
   },
   "outputs": [],
   "source": [
    "! pip3 install -U google-cloud-aiplatform --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_storage"
   },
   "source": [
    "安装Google的*云存储*库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JOoJeejiBAa"
   },
   "outputs": [],
   "source": [
    "! pip3 install google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### 重新启动内核\n",
    "\n",
    "一旦您已安装了Vertex SDK和Google *cloud-storage*，您需要重新启动笔记本内核以便它可以找到这些包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlJHybHWiBAa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"AUTORUN\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### GPU 运行时\n",
    "\n",
    "*确保在GPU运行时下运行此笔记本（如果有这个选项）。在Colab中，选择* **Runtime > Change Runtime Type > GPU**\n",
    "\n",
    "### 设置您的GCP项目\n",
    "\n",
    "**无论您的笔记本环境如何，都需要执行以下步骤。**\n",
    "\n",
    "1. [选择或创建 GCP 项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建帐户时，您将获得$300的免费信用额度用于计算/存储成本。\n",
    "\n",
    "2. [确保为您的项目启用计费。](https://cloud.google.com/billing/docs/how-to/modify-project)\n",
    "\n",
    "3. [启用 Vertex API 和 Compute Engine API。](https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,compute_component)\n",
    "\n",
    "4. [Google Cloud SDK](https://cloud.google.com/sdk) 已经安装在 Google Cloud笔记本中。\n",
    "\n",
    "5. 在下面的单元格中输入您的项目ID。然后运行该单元格，确保 Cloud SDK 在此笔记本中的所有命令中使用正确的项目。\n",
    "\n",
    "**注意**：Jupyter会运行以`!`为前缀的行作为shell命令，并将以`$`为前缀的Python变量插入这些命令中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_gcloud_project_id"
   },
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "区域\n",
    "\n",
    "您也可以更改“REGION”变量，该变量用于笔记本的其余部分操作。 以下是Vertex AI支持的区域。 我们建议尽可能选择距离您最近的区域。\n",
    "\n",
    "- 美洲：`us-central1`\n",
    "- 欧洲：`europe-west4`\n",
    "- 亚太：`asia-east1`\n",
    "\n",
    "您不能在Vertex上使用多区域存储桶进行培训。 并非所有区域都支持所有Vertex服务。 有关每个区域的最新支持，请参见 [Vertex AI服务的区域支持](https://cloud.google.com/vertex-ai/docs/general/locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkzC9Mn5iBAd"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "时间戳\n",
    "\n",
    "如果您正在进行直播教程会话，您可能正在使用共享的测试帐户或项目。为了避免用户在创建的资源上发生名称冲突，您会为每个实例会话创建一个时间戳，并将其附加到将在本教程中创建的资源的名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jX9n6pVLiBAd"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 认证您的GCP账户\n",
    "\n",
    "**如果您正在使用Google Cloud笔记本**，您的环境已经经过验证。请跳过此步骤。\n",
    "\n",
    "*注意: 如果您在Vertex笔记本上运行单元格，单元格会自动跳过执行身份验证步骤。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BH7LjNZTiBAe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your Google Cloud account. This provides access\n",
    "# to your Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "# If on Vertex, then don't execute this code\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\"):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this tutorial in a notebook locally, replace the string\n",
    "    # below with the path to your service account key and run this cell to\n",
    "    # authenticate your Google Cloud account.\n",
    "    else:\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS your_path_to_credentials.json\n",
    "\n",
    "    # Log in to your account on Google Cloud\n",
    "    ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:batch_prediction"
   },
   "source": [
    "### 创建一个云存储存储桶\n",
    "\n",
    "**无论您使用的是笔记本环境如何，都需要按照以下步骤操作。**\n",
    "\n",
    "本教程旨在使用存储在公共云存储桶中的训练数据以及本地云存储桶用于批量预测。您也可以使用您自己存储在本地云存储桶中的训练数据。\n",
    "\n",
    "请在下方设置您的云存储桶的名称。这个名称必须在所有云存储桶中是唯一的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"[your-bucket-name]\":\n",
    "    BUCKET_NAME = PROJECT_ID + \"aip-\" + TIMESTAMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有当您的存储桶尚不存在时才能执行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdMuD9HViBAf"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validate_bucket"
   },
   "source": [
    "最后，通过检查云存储桶的内容来验证对其的访问权限："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRs6mJDwiBAg"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在本教程中使用的变量。\n",
    "### 导入库并定义常数\n",
    "\n",
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在本教程中使用的变量。\n",
    "### 导入库并定义常数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_aip"
   },
   "source": [
    "#### 导入Vertex SDK\n",
    "\n",
    "将Vertex SDK导入到我们的Python环境中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UCREN4OMiBAg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from google.cloud.aiplatform import gapic as aip\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.json_format import MessageToJson, ParseDict\n",
    "from google.protobuf.struct_pb2 import Struct, Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aip_constants"
   },
   "source": [
    "常量用于Vertex AI设置：\n",
    "\n",
    "- `API_ENDPOINT`：用于数据集、模型、作业、流水线和端点服务的Vertex AI API服务端点。\n",
    "- `API_PREDICT_ENDPOINT`：用于预测的Vertex AI API服务端点。\n",
    "- `PARENT`：数据集、模型和端点资源的Vertex AI位置根路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5-uS7XSiBAh"
   },
   "outputs": [],
   "source": [
    "# API Endpoint\n",
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "\n",
    "# Vertex AI location root path for your dataset, model and endpoint resources\n",
    "PARENT = \"projects/\" + PROJECT_ID + \"/locations/\" + REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clients"
   },
   "source": [
    "客户端\n",
    "\n",
    "Vertex SDK 以客户端/服务器模型工作。在您的一侧（Python 脚本）中，您将创建一个客户端，向服务器（Vertex）发送请求并接收响应。\n",
    "\n",
    "在本教程中，您将使用多个客户端，因此请提前设置它们所有。\n",
    "\n",
    "- 用于受管数据集的数据集服务。\n",
    "- 用于受管模型的模型服务。\n",
    "- 用于训练的管道服务。\n",
    "- 用于部署的端点服务。\n",
    "- 用于批处理作业和自定义训练的作业服务。\n",
    "- 用于提供预测的预测服务。*注意*：预测具有不同的服务端点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DhFs5vNiBAi"
   },
   "outputs": [],
   "source": [
    "# client options same for all services\n",
    "client_options = {\"api_endpoint\": API_ENDPOINT}\n",
    "\n",
    "\n",
    "def create_model_client():\n",
    "    client = aip.ModelServiceClient(client_options=client_options)\n",
    "    return client\n",
    "\n",
    "\n",
    "def create_endpoint_client():\n",
    "    client = aip.EndpointServiceClient(client_options=client_options)\n",
    "    return client\n",
    "\n",
    "\n",
    "def create_prediction_client():\n",
    "    client = aip.PredictionServiceClient(client_options=client_options)\n",
    "    return client\n",
    "\n",
    "\n",
    "def create_job_client():\n",
    "    client = aip.JobServiceClient(client_options=client_options)\n",
    "    return client\n",
    "\n",
    "\n",
    "clients = {}\n",
    "clients[\"model\"] = create_model_client()\n",
    "clients[\"endpoint\"] = create_endpoint_client()\n",
    "clients[\"prediction\"] = create_prediction_client()\n",
    "clients[\"job\"] = create_job_client()\n",
    "\n",
    "for client in clients.items():\n",
    "    print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NnFMX6QiBAi"
   },
   "source": [
    "准备一个训练脚本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrRN2X0DiBAi"
   },
   "source": [
    "### 包裹组装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMP5OyIYiBAj"
   },
   "outputs": [],
   "source": [
    "# Make folder for python training script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\\n",
    "tag_build =\\n\\\n",
    "tag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\\n",
    "# Requires TensorFlow Datasets\\n\\\n",
    "setuptools.setup(\\n\\\n",
    "    install_requires=[\\n\\\n",
    "        'tensorflow_datasets==1.3.0',\\n\\\n",
    "    ],\\n\\\n",
    "    packages=setuptools.find_packages())\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\\n",
    "Name: Hyperparameter Tuning - Boston Housing\\n\\\n",
    "Version: 0.0.0\\n\\\n",
    "Summary: Demonstration hyperparameter tuning script\\n\\\n",
    "Home-page: www.google.com\\n\\\n",
    "Author: Google\\n\\\n",
    "Author-email: aferlitsch@gmail.com\\n\\\n",
    "License: Public\\n\\\n",
    "Description: Demo\\n\\\n",
    "Platform: Vertex AI\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZLqlZ2OiBAj"
   },
   "source": [
    "### Task.py 的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDCJ3DXmiBAj"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "# hyperparameter tuningfor Boston Housing\n",
    "  \n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from hypertune import HyperTune\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model-dir', dest='model_dir',\n",
    "                    default='/tmp/saved_model', type=str, help='Model dir.')\n",
    "parser.add_argument('--lr', dest='lr',\n",
    "                    default=0.001, type=float,\n",
    "                    help='Learning rate.')\n",
    "parser.add_argument('--units', dest='units',\n",
    "                    default=64, type=int,\n",
    "                    help='Number of units.')\n",
    "parser.add_argument('--epochs', dest='epochs',\n",
    "                    default=20, type=int,\n",
    "                    help='Number of epochs.')\n",
    "parser.add_argument('--param-file', dest='param_file',\n",
    "                    default='/tmp/param.txt', type=str,\n",
    "                    help='Output file for parameters')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print('Python Version = {}'.format(sys.version))\n",
    "print('TensorFlow Version = {}'.format(tf.__version__))\n",
    "print('TF_CONFIG = {}'.format(os.environ.get('TF_CONFIG', 'Not found')))\n",
    "\n",
    "def make_dataset():\n",
    "  # Scaling Boston Housing data features\n",
    "  def scale(feature):\n",
    "    max = np.max(feature)\n",
    "    feature = (feature / max).astype(np.float)\n",
    "    return feature, max\n",
    "\n",
    "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
    "  )\n",
    "  params = []\n",
    "  for _ in range(13):\n",
    "    x_train[_], max = scale(x_train[_])\n",
    "    x_test[_], _ = scale(x_test[_])\n",
    "    params.append(max)\n",
    "    \n",
    "  # store the normalization (max) value for each feature\n",
    "  with tf.io.gfile.GFile(args.param_file, 'w') as f:\n",
    "    f.write(str(params))\n",
    "  return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "# Build the Keras model\n",
    "def build_and_compile_dnn_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(args.units, activation='relu', input_shape=(13,)),\n",
    "      tf.keras.layers.Dense(args.units, activation='relu'),\n",
    "      tf.keras.layers.Dense(1, activation='linear')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss='mse',\n",
    "      optimizer=tf.keras.optimizers.RMSprop(learning_rate=args.lr))\n",
    "  return model\n",
    "\n",
    "model = build_and_compile_dnn_model()\n",
    "\n",
    "# Instantiate the HyperTune reporting object\n",
    "hpt = HyperTune()\n",
    "\n",
    "# Reporting callback\n",
    "class HPTCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global hpt\n",
    "        hpt.report_hyperparameter_tuning_metric(\n",
    "        hyperparameter_metric_tag='val_loss',\n",
    "        metric_value=logs['val_loss'],\n",
    "        global_step=epoch)\n",
    "\n",
    "# Train the model\n",
    "BATCH_SIZE = 16\n",
    "(x_train, y_train), (x_test, y_test) = make_dataset()\n",
    "model.fit(x_train, y_train, epochs=args.epochs, batch_size=BATCH_SIZE, validation_split=0.1, callbacks=[HPTCallback()])\n",
    "model.save(args.model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDd81Xt8iBAj"
   },
   "source": [
    "### 将培训脚本存储在您的云存储桶中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8CofVaX6iBAk"
   },
   "outputs": [],
   "source": [
    "! rm -f custom.tar custom.tar.gz\n",
    "! tar cvf custom.tar custom\n",
    "! gzip custom.tar\n",
    "! gsutil cp custom.tar.gz gs://$BUCKET_NAME/hpt_boston_housing.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "text_create_and_deploy_model:migration"
   },
   "source": [
    "训练一个模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oqIBOSnJjkW"
   },
   "source": [
    "### [projects.locations.hyperparameterTuningJob.create](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.hyperparameterTuningJobs/create)\n",
    "\n",
    "### [projects.locations.hyperparameterTuningJob.create](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.hyperparameterTuningJobs/create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EILzZZ4biBAk"
   },
   "source": [
    "#### 请求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2KyGzoYiBAk"
   },
   "outputs": [],
   "source": [
    "JOB_NAME = \"hyperparameter_tuning_\" + TIMESTAMP\n",
    "\n",
    "WORKER_POOL_SPEC = [\n",
    "    {\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": {\"machine_type\": \"n1-standard-4\", \"accelerator_count\": 0},\n",
    "        \"python_package_spec\": {\n",
    "            \"executor_image_uri\": \"gcr.io/cloud-aiplatform/training/tf-cpu.2-1:latest\",\n",
    "            \"package_uris\": [\"gs://\" + BUCKET_NAME + \"/hpt_boston_housing.tar.gz\"],\n",
    "            \"python_module\": \"trainer.task\",\n",
    "            \"args\": [\"--model-dir=\" + \"gs://{}/{}\".format(BUCKET_NAME, JOB_NAME)],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "STUDY_SPEC = {\n",
    "    \"metrics\": [\n",
    "        {\"metric_id\": \"val_loss\", \"goal\": aip.StudySpec.MetricSpec.GoalType.MINIMIZE}\n",
    "    ],\n",
    "    \"parameters\": [\n",
    "        {\n",
    "            \"parameter_id\": \"lr\",\n",
    "            \"discrete_value_spec\": {\"values\": [0.001, 0.01, 0.1]},\n",
    "            \"scale_type\": aip.StudySpec.ParameterSpec.ScaleType.UNIT_LINEAR_SCALE,\n",
    "        },\n",
    "        {\n",
    "            \"parameter_id\": \"units\",\n",
    "            \"integer_value_spec\": {\"min_value\": 32, \"max_value\": 256},\n",
    "            \"scale_type\": aip.StudySpec.ParameterSpec.ScaleType.UNIT_LINEAR_SCALE,\n",
    "        },\n",
    "    ],\n",
    "    \"algorithm\": aip.StudySpec.Algorithm.RANDOM_SEARCH,\n",
    "}\n",
    "\n",
    "hyperparameter_tuning_job = aip.HyperparameterTuningJob(\n",
    "    display_name=JOB_NAME,\n",
    "    trial_job_spec={\"worker_pool_specs\": WORKER_POOL_SPEC},\n",
    "    study_spec=STUDY_SPEC,\n",
    "    max_trial_count=6,\n",
    "    parallel_trial_count=1,\n",
    ")\n",
    "\n",
    "print(\n",
    "    MessageToJson(\n",
    "        aip.CreateHyperparameterTuningJobRequest(\n",
    "            parent=PARENT, hyperparameter_tuning_job=hyperparameter_tuning_job\n",
    "        ).__dict__[\"_pb\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "datasets_import:migration,new,request"
   },
   "source": [
    "{\n",
    "  \"parent\": \"projects/migration-ucaip-training/locations/us-central1\",\n",
    "  \"hyperparameterTuningJob\": {\n",
    "    \"displayName\": \"hyperparameter_tuning_20210226020029\",\n",
    "    \"studySpec\": {\n",
    "      \"metrics\": [\n",
    "        {\n",
    "          \"metricId\": \"val_loss\",\n",
    "          \"goal\": \"MINIMIZE\"\n",
    "        }\n",
    "      ],\n",
    "      \"parameters\": [\n",
    "        {\n",
    "          \"parameterId\": \"lr\",\n",
    "          \"discreteValueSpec\": {\n",
    "            \"values\": [\n",
    "              0.001,\n",
    "              0.01,\n",
    "              0.1\n",
    "            ]\n",
    "          },\n",
    "          \"scaleType\": \"UNIT_LINEAR_SCALE\"\n",
    "        },\n",
    "        {\n",
    "          \"parameterId\": \"units\",\n",
    "          \"integerValueSpec\": {\n",
    "            \"minValue\": \"32\",\n",
    "            \"maxValue\": \"256\"\n",
    "          },\n",
    "          \"scaleType\": \"UNIT_LINEAR_SCALE\"\n",
    "        }\n",
    "      ],\n",
    "      \"algorithm\": \"RANDOM_SEARCH\"\n",
    "    },\n",
    "    \"maxTrialCount\": 6,\n",
    "    \"parallelTrialCount\": 1,\n",
    "    \"trialJobSpec\": {\n",
    "      \"workerPoolSpecs\": [\n",
    "        {\n",
    "          \"machineSpec\": {\n",
    "            \"machineType\": \"n1-standard-4\"\n",
    "          },\n",
    "          \"replicaCount\": \"1\",\n",
    "          \"pythonPackageSpec\": {\n",
    "            \"executorImageUri\": \"gcr.io/cloud-aiplatform/training/tf-cpu.2-1:latest\",\n",
    "            \"packageUris\": [\n",
    "              \"gs://migration-ucaip-trainingaip-20210226020029/hpt_boston_housing.tar.gz\"\n",
    "            ],\n",
    "            \"pythonModule\": \"trainer.task\",\n",
    "            \"args\": [\n",
    "              \"--model-dir=gs://migration-ucaip-trainingaip-20210226020029/hyperparameter_tuning_20210226020029\"\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94Kfzi6UiBAm"
   },
   "source": [
    "#### 呼叫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NeORIoMiBAm"
   },
   "outputs": [],
   "source": [
    "request = clients[\"job\"].create_hyperparameter_tuning_job(\n",
    "    parent=PARENT, hyperparameter_tuning_job=hyperparameter_tuning_job\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baTCgkvoiBAm"
   },
   "source": [
    "回复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLTfBHC2iBAn"
   },
   "outputs": [],
   "source": [
    "print(MessageToJson(request.__dict__[\"_pb\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZY0QyWbiBAn"
   },
   "source": [
    "{\n",
    "  \"名称\": \"projects/116273516712/locations/us-central1/hyperparameterTuningJobs/5264408897233354752\",\n",
    "  \"显示名称\": \"hyperparameter_tuning_20210226020029\",\n",
    "  \"studySpec\": {\n",
    "    \"指标\": [\n",
    "      {\n",
    "        \"指标ID\": \"val_loss\",\n",
    "        \"目标\": \"最小化\"\n",
    "      }\n",
    "    ],\n",
    "    \"参数\": [\n",
    "      {\n",
    "        \"参数ID\": \"lr\",\n",
    "        \"离散值规范\": {\n",
    "          \"值\": [\n",
    "            0.001,\n",
    "            0.01,\n",
    "            0.1\n",
    "          ]\n",
    "        },\n",
    "        \"比例类型\": \"单位线性比例\"\n",
    "      },\n",
    "      {\n",
    "        \"参数ID\": \"units\",\n",
    "        \"整数值规范\": {\n",
    "          \"最小值\": \"32\",\n",
    "          \"最大值\": \"256\"\n",
    "        },\n",
    "        \"比例类型\": \"单位线性比例\"\n",
    "      }\n",
    "    ],\n",
    "    \"算法\": \"随机搜索\"\n",
    "  },\n",
    "  \"最大试验次数\": 6,\n",
    "  \"并行试验次数\": 1,\n",
    "  \"试验作业规范\": {\n",
    "    \"工作池规范\": [\n",
    "      {\n",
    "        \"机器规范\": {\n",
    "          \"机器类型\": \"n1-standard-4\"\n",
    "        },\n",
    "        \"副本数量\": \"1\",\n",
    "        \"磁盘规范\": {\n",
    "          \"启动磁盘类型\": \"pd-ssd\",\n",
    "          \"启动磁盘大小GB\": 100\n",
    "        },\n",
    "        \"Python包规范\": {\n",
    "          \"执行器映像URI\": \"gcr.io/cloud-aiplatform/training/tf-cpu.2-1:latest\",\n",
    "          \"软件包URIs\": [\n",
    "            \"gs://migration-ucaip-trainingaip-20210226020029/hpt_boston_housing.tar.gz\"\n",
    "          ],\n",
    "          \"Python模块\": \"trainer.task\",\n",
    "          \"参数\": [\n",
    "            \"--model-dir=gs://migration-ucaip-trainingaip-20210226020029/hyperparameter_tuning_20210226020029\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"状态\": \"作业状态待定\",\n",
    "  \"创建时间\": \"2021-02-26T02:02:02.787187Z\",\n",
    "  \"更新时间\": \"2021-02-26T02:02:02.787187Z\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_pipeline_id:migration,new,response"
   },
   "outputs": [],
   "source": [
    "# The full unique ID for the hyperparameter tuningjob\n",
    "hyperparameter_tuning_id = request.name\n",
    "# The short numeric ID for the hyperparameter tuningjob\n",
    "hyperparameter_tuning_short_id = hyperparameter_tuning_id.split(\"/\")[-1]\n",
    "\n",
    "print(hyperparameter_tuning_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNbWmXHziBAo"
   },
   "source": [
    "###[projects.locations.hyperparameterTuningJob.get](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.hyperparameterTuningJobs/get)\n",
    "\n",
    "将上述英文文本翻译为中文：[项目.位置.超参数调整作业.获取](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.hyperparameterTuningJobs/get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOP1v7ybiBAo"
   },
   "source": [
    "#### 电话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKH3m0NTiBAo"
   },
   "outputs": [],
   "source": [
    "request = clients[\"job\"].get_hyperparameter_tuning_job(name=hyperparameter_tuning_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVgPQi7MiBAo"
   },
   "source": [
    "回复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0EdlOAeiBAp"
   },
   "outputs": [],
   "source": [
    "print(MessageToJson(request.__dict__[\"_pb\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJ7nxJ2OiBAp"
   },
   "source": [
    "*示例输出*：\n",
    "```\n",
    "{\n",
    "  \"name\": \"projects/116273516712/locations/us-central1/hyperparameterTuningJobs/5264408897233354752\",\n",
    "  \"displayName\": \"hyperparameter_tuning_20210226020029\",\n",
    "  \"studySpec\": {\n",
    "    \"metrics\": [\n",
    "      {\n",
    "        \"metricId\": \"val_loss\",\n",
    "        \"goal\": \"MINIMIZE\"\n",
    "      }\n",
    "    ],\n",
    "    \"parameters\": [\n",
    "      {\n",
    "        \"parameterId\": \"lr\",\n",
    "        \"discreteValueSpec\": {\n",
    "          \"values\": [\n",
    "            0.001,\n",
    "            0.01,\n",
    "            0.1\n",
    "          ]\n",
    "        },\n",
    "        \"scaleType\": \"UNIT_LINEAR_SCALE\"\n",
    "      },\n",
    "      {\n",
    "        \"parameterId\": \"units\",\n",
    "        \"integerValueSpec\": {\n",
    "          \"minValue\": \"32\",\n",
    "          \"maxValue\": \"256\"\n",
    "        },\n",
    "        \"scaleType\": \"UNIT_LINEAR_SCALE\"\n",
    "      }\n",
    "    ],\n",
    "    \"algorithm\": \"RANDOM_SEARCH\"\n",
    "  },\n",
    "  \"maxTrialCount\": 6,\n",
    "  \"parallelTrialCount\": 1,\n",
    "  \"trialJobSpec\": {\n",
    "    \"workerPoolSpecs\": [\n",
    "      {\n",
    "        \"machineSpec\": {\n",
    "          \"machineType\": \"n1-standard-4\"\n",
    "        },\n",
    "        \"replicaCount\": \"1\",\n",
    "        \"diskSpec\": {\n",
    "          \"bootDiskType\": \"pd-ssd\",\n",
    "          \"bootDiskSizeGb\": 100\n",
    "        },\n",
    "        \"pythonPackageSpec\": {\n",
    "          \"executorImageUri\": \"gcr.io/cloud-aiplatform/training/tf-cpu.2-1:latest\",\n",
    "          \"packageUris\": [\n",
    "            \"gs://migration-ucaip-trainingaip-20210226020029/hpt_boston_housing.tar.gz\"\n",
    "          ],\n",
    "          \"pythonModule\": \"trainer.task\",\n",
    "          \"args\": [\n",
    "            \"--model-dir=gs://migration-ucaip-trainingaip-20210226020029/hyperparameter_tuning_20210226020029\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"state\": \"JOB_STATE_PENDING\",\n",
    "  \"createTime\": \"2021-02-26T02:02:02.787187Z\",\n",
    "  \"updateTime\": \"2021-02-26T02:02:02.787187Z\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QflEzRwkiBAp"
   },
   "source": [
    "## 等待研究完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trainingpipelines_get:migration,new,wait"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    response = clients[\"job\"].get_hyperparameter_tuning_job(\n",
    "        name=hyperparameter_tuning_id\n",
    "    )\n",
    "    if response.state != aip.PipelineState.PIPELINE_STATE_SUCCEEDED:\n",
    "        print(\"Study trials have not completed:\", response.state)\n",
    "        if response.state == aip.PipelineState.PIPELINE_STATE_FAILED:\n",
    "            break\n",
    "    else:\n",
    "        print(\"Study trials have completed:\", response.end_time - response.start_time)\n",
    "        break\n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cL8hxrQ6iBAp"
   },
   "source": [
    "## 请审阅研究结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blbKukdkiBAq"
   },
   "outputs": [],
   "source": [
    "best = (None, None, None, 0.0)\n",
    "response = clients[\"job\"].get_hyperparameter_tuning_job(name=hyperparameter_tuning_id)\n",
    "for trial in response.trials:\n",
    "    print(MessageToJson(trial.__dict__[\"_pb\"]))\n",
    "    # Keep track of the best outcome\n",
    "    try:\n",
    "        if float(trial.final_measurement.metrics[0].value) > best[3]:\n",
    "            best = (\n",
    "                trial.id,\n",
    "                float(trial.parameters[0].value),\n",
    "                float(trial.parameters[1].value),\n",
    "                float(trial.final_measurement.metrics[0].value),\n",
    "            )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print()\n",
    "print(\"ID\", best[0])\n",
    "print(\"Decay\", best[1])\n",
    "print(\"Learning Rate\", best[2])\n",
    "print(\"Validation Accuracy\", best[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ONNEM15iBAq"
   },
   "source": [
    "{\n",
    "  \"id\": \"1\",\n",
    "  \"state\": \"成功\",\n",
    "  \"parameters\": [\n",
    "    {\n",
    "      \"parameterId\": \"lr\",\n",
    "      \"value\": 0.1\n",
    "    },\n",
    "    {\n",
    "      \"parameterId\": \"units\",\n",
    "      \"value\": 80.0\n",
    "    }\n",
    "  ],\n",
    "  \"finalMeasurement\": {\n",
    "    \"stepCount\": \"19\",\n",
    "    \"metrics\": [\n",
    "      {\n",
    "        \"metricId\": \"val_loss\",\n",
    "        \"value\": 46.61515110294993\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"startTime\": \"2021-02-26T02:05:16.935353384Z\",\n",
    "  \"endTime\": \"2021-02-26T02:12:44Z\"\n",
    "}\n",
    "{\n",
    "  \"id\": \"2\",\n",
    "  \"state\": \"成功\",\n",
    "  \"parameters\": [\n",
    "    {\n",
    "      \"parameterId\": \"lr\",\n",
    "      \"value\": 0.01\n",
    "    },\n",
    "    {\n",
    "      \"parameterId\": \"units\",\n",
    "      \"value\": 45.0\n",
    "    }\n",
    "  ],\n",
    "  \"finalMeasurement\": {\n",
    "    \"stepCount\": \"19\",\n",
    "    \"metrics\": [\n",
    "      {\n",
    "        \"metricId\": \"val_loss\",\n",
    "        \"value\": 32.55313952376203\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"startTime\": \"2021-02-26T02:15:31.357856840Z\",\n",
    "  \"endTime\": \"2021-02-26T02:24:18Z\"\n",
    "}\n",
    "{\n",
    "  \"id\": \"3\",\n",
    "  \"state\": \"成功\",\n",
    "  \"parameters\": [\n",
    "    {\n",
    "      \"parameterId\": \"lr\",\n",
    "      \"value\": 0.1\n",
    "    },\n",
    "    {\n",
    "      \"parameterId\": \"units\",\n",
    "      \"value\": 70.0\n",
    "    }\n",
    "  ],\n",
    "  \"finalMeasurement\": {\n",
    "    \"stepCount\": \"19\",\n",
    "    \"metrics\": [\n",
    "      {\n",
    "        \"metricId\": \"val_loss\",\n",
    "        \"value\": 42.709188321741614\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"startTime\": \"2021-02-26T02:26:40.704476222Z\",\n",
    "  \"endTime\": \"2021-02-26T02:34:21Z\"\n",
    "}\n",
    "{\n",
    "  \"id\": \"4\",\n",
    "  \"state\": \"成功\",\n",
    "  \"parameters\": [\n",
    "    {\n",
    "      \"parameterId\": \"lr\",\n",
    "      \"value\": 0.01\n",
    "    },\n",
    "    {\n",
    "      \"parameterId\": \"units\",\n",
    "      \"value\": 173.0\n",
    "    }\n",
    "  ],\n",
    "  \"finalMeasurement\": {\n",
    "    \"stepCount\": \"17\",\n",
    "    \"metrics\": [\n",
    "      {\n",
    "        \"metricId\": \"val_loss\",\n",
    "        \"value\": 46.12480219399057\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"startTime\": \"2021-02-26T02:37:45.275581053Z\",\n",
    "  \"endTime\": \"2021-02-26T02:51:07Z\"\n",
    "}\n",
    "{\n",
    "  \"id\": \"5\",\n",
    "  \"state\": \"成功\",\n",
    "  \"parameters\": [\n",
    "    {\n",
    "      \"parameterId\": \"lr\",\n",
    "      \"value\": 0.01\n",
    "    },\n",
    "    {\n",
    "      \"parameterId\": \"units\",\n",
    "      \"value\": 223.0\n",
    "    }\n",
    "  ],\n",
    "  \"finalMeasurement\": {\n",
    "    \"stepCount\": \"19\",\n",
    "    \"metrics\": [\n",
    "      {\n",
    "        \"metricId\": \"val_loss\",\n",
    "        \"value\": 24.875632611716664\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"startTime\": \"2021-02-26T02:53:32.612612421Z\",\n",
    "  \"endTime\": \"2021-02-26T02:54:19Z\"\n",
    "}\n",
    "{\n",
    "  \"id\": \"6\",\n",
    "  \"state\": \"成功\",\n",
    "  \"parameters\": [\n",
    "    {\n",
    "      \"parameterId\": \"lr\",\n",
    "      \"value\": 0.1\n",
    "    },\n",
    "    {\n",
    "      \"parameterId\": \"units\",\n",
    "      \"value\": 123.0\n",
    "    }\n",
    "  ],\n",
    "  \"finalMeasurement\": {\n",
    "    \"stepCount\": \"13\",\n",
    "    \"metrics\": [\n",
    "      {\n",
    "        \"metricId\": \"val_loss\",\n",
    "        \"value\": 43.352300690441595\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"startTime\": \"2021-02-26T02:56:47.323707459Z\",\n",
    "  \"endTime\": \"2021-02-26T03:03:49Z\"\n",
    "}\n",
    "\n",
    "ID 1\n",
    "衰减率 0.1\n",
    "学习率 80.0\n",
    "验证准确度 46.61515110294993\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:migration,new"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有GCP资源，您可以[删除用于本教程的GCP项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QACczMumiBAq"
   },
   "outputs": [],
   "source": [
    "delete_hpt_job = True\n",
    "delete_bucket = True\n",
    "\n",
    "# Delete the hyperparameter tuningusing the Vertex AI fully qualified identifier for the custome training\n",
    "try:\n",
    "    if delete_hpt_job:\n",
    "        clients[\"job\"].delete_hyperparameter_tuning_job(name=hyperparameter_tuning_id)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if delete_bucket and \"BUCKET_NAME\" in globals():\n",
    "    ! gsutil rm -r gs://$BUCKET_NAME"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "UJ11 unified HyperParameter Tuning Training Job with TensorFlow.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
