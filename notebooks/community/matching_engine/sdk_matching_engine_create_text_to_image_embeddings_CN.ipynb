{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "使用Vertex AI矢量搜索进行文本到图像嵌入\n",
    "![ ](https://www.google-analytics.com/collect?v=2&tid=G-L6X3ECH596&cid=1&en=page_view&sid=1&dt=sdk_matching_engine_create_text_to_image_embeddings.ipynb&dl=notebooks%2Fofficial%2Fmatching_engine%2Fsdk_matching_engine_create_text_to_image_embeddings.ipynb)\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_create_text_to_image_embeddings.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_create_text_to_image_embeddings.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      查看GitHub上的代码\n",
    "    </a>\n",
    "  </td>\n",
    "      <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/matching_engine/sdk_matching_engine_create_text_to_image_embeddings.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0a74aaf1481"
   },
   "source": [
    "## 概述\n",
    "\n",
    "此示例演示了如何使用DiffusionDB数据集和CLIP模型创建文本到图像嵌入，并将其上传到Vertex AI向量搜索服务。这是一个高规模、低延迟的解决方案，用于在大型语料库中查找相似的向量。此外，它是一个完全托管的提供，进一步减少了运营开销。它是建立在谷歌研究开发的[近似最近邻（ANN）技术](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html)之上。\n",
    "\n",
    "**先决条件**：此笔记本要求您已经设置了一个VPC网络。请参阅[创建Vertex AI向量搜索索引笔记本](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_for_indexing.ipynb)中的“准备VPC网络”部分。\n",
    "\n",
    "了解更多关于[Vertex AI向量搜索](https://cloud.google.com/vertex-ai/docs/matching-engine/overview)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34a4b245e795"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在这本笔记本中，您将学习如何对自定义文本嵌入进行编码，创建一个近似最近邻（ANN）索引，并针对索引进行查询。\n",
    "\n",
    "本教程使用以下 Google Cloud ML 服务：\n",
    "\n",
    "- `Vertex AI Vector Search`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "* 创建ANN索引\n",
    "* 使用VPC网络创建索引端点\n",
    "* 部署ANN索引\n",
    "* 执行在线查询"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "数据集\n",
    "\n",
    "本教程使用的数据集是[DiffusionDB数据集](https://github.com/poloclub/diffusiondb)。\n",
    "\n",
    "DiffusionDB是第一个大规模的文本到图像提示数据集。它包含由真实用户指定的提示和超参数生成的1400万张图像。这个前所未有的规模和多样性的人为驱动数据集为理解提示和生成模型之间的相互作用、检测深度伪造以及设计人工智能交互工具以帮助用户更容易地使用这些模型提供了令人兴奋的研究机会。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0f1bea346db"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装最新版本的Cloud Storage、BigQuery和Python的Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfbccc635a17"
   },
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                         google-cloud-storage --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4967f0d712e"
   },
   "source": [
    "安装最新版本的transformers和torch库以编码文本和图像嵌入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f455fbba6a33"
   },
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade transformers torch --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97473593f37f"
   },
   "source": [
    "安装最新版本的google-cloud-vision，用于过滤安全图像，同时安装pyrate_limiter，以限制对Google Cloud Vision API的调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5709d1d57927"
   },
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "! pip install google-cloud-vision pyrate_limiter==2.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5b08ba354c6e"
   },
   "source": [
    "只有合作：取消以下单元格的注释以重新启动内核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bea801acf6b5"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd28c9e4f067"
   },
   "source": [
    "## 在开始之前\n",
    "#### 设置您的项目ID\n",
    "\n",
    "如果您不知道您的项目ID，可以尝试以下操作：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 参考支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80c0215f05a0"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f4512bf63b3"
   },
   "source": [
    "#### 区域\n",
    "\n",
    "您还可以更改由Vertex AI使用的`REGION`变量。了解有关[Vertex AI区域](https://cloud.google.com/vertex-ai/docs/general/locations)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "474be5183c27"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "949271bfebe3"
   },
   "source": [
    "### 验证您的 Google Cloud 帐户\n",
    "\n",
    "根据您的 Jupyter 环境，您可能需要手动进行身份验证。请按照以下相关说明操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b65b4ce80d9a"
   },
   "source": [
    "1. 顶点人工智能工作台\n",
    "* 无需操作，因为您已经验证通过。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "985cdbfe7372"
   },
   "source": [
    "2. 本地 JupyterLab 实例，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbc9cd30cc4b"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79efab26ad02"
   },
   "source": [
    "3. Colab，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a336a05c6149"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c0a44fa330f"
   },
   "source": [
    "请参考https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples，了解如何向您的服务帐号授予云存储权限。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3uj8x73nDX_"
   },
   "source": [
    "身份验证：在从 Vertex AI Workbench 笔记本终端注销并且需要凭据时，请重新运行 `gcloud auth login` 命令。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhq5zEbGg0XX"
   },
   "source": [
    "只有协作：取消对以下单元格的注释以重新启动内核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzrelQZ22IZj"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产物，例如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "只有当您还没有这个存储桶时：运行以下单元格来创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lR6Wwv-hCCN-"
   },
   "source": [
    "##准备数据\n",
    "\n",
    "您将使用[DiffusionDB数据集](https://github.com/poloclub/diffusiondb)中的图像提示和图像对。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9e2a05095082"
   },
   "source": [
    "克隆DiffusionDB存储库###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wzS85TeB9dG"
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/poloclub/diffusiondb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49ee8d2c2df7"
   },
   "source": [
    "### 为了下载数据集安装依赖项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ed67efa3c0f3"
   },
   "outputs": [],
   "source": [
    "! pip install -r diffusiondb/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0bc039db70e"
   },
   "source": [
    "下载图像文件###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7d27d986c61f"
   },
   "outputs": [],
   "source": [
    "# Download image files from 1 to 5. Each file is 1000 images.\n",
    "! python diffusiondb/scripts/download.py -i 1 -r 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a514786370e5"
   },
   "source": [
    "提取图像存档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b43937b6065d"
   },
   "outputs": [],
   "source": [
    "# Unzip all image files\n",
    "image_directory = \"extracted\"\n",
    "\n",
    "! unzip -n 'images/*.zip' -d '{image_directory}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09a6602bb745"
   },
   "source": [
    "### 加载图像元数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cacd9869ee5"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "metadatas = {}\n",
    "for file_name in os.listdir(image_directory):\n",
    "    if file_name.endswith(\".json\"):\n",
    "        with open(os.path.join(image_directory, file_name)) as f:\n",
    "            metadata = json.load(f)\n",
    "            metadatas.update(metadata)\n",
    "\n",
    "image_names = list(metadatas.keys())\n",
    "image_paths = [os.path.join(image_directory, image_name) for image_name in image_names]\n",
    "\n",
    "len(metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a593ec69048"
   },
   "source": [
    "### 定义检测显性图像的函数\n",
    "\n",
    "定义一个函数来查询Cloud Vision API以检测潜在的显性图像。\n",
    "\n",
    "了解更多关于[检测显性内容](https://cloud.google.com/vision/docs/detecting-safe-search)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce31cc893826"
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from google.cloud import vision\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "\n",
    "def detect_safe_search(path: str) -> Optional[bool]:\n",
    "    \"\"\"Detects unsafe features in the file.\"\"\"\n",
    "    import io\n",
    "\n",
    "    image_file = io.open(path, \"rb\")\n",
    "    content = image_file.read()\n",
    "    image_file.close()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.safe_search_detection(image=image)\n",
    "\n",
    "    if response.error.message:\n",
    "        print(response.error.message)\n",
    "        return None\n",
    "\n",
    "    return response.safe_search_annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e330a70627ed"
   },
   "source": [
    "定义安全搜索标注转换为布尔值\n",
    "定义一个将安全搜索标注结果转换为布尔值的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fc3c32afb383"
   },
   "outputs": [],
   "source": [
    "from google.cloud.vision_v1.types.image_annotator import (Likelihood,\n",
    "                                                          SafeSearchAnnotation)\n",
    "\n",
    "\n",
    "# Returns true if some annotations have a potential safety issues\n",
    "def convert_annotation_to_safety(safe_search_annotation: SafeSearchAnnotation) -> bool:\n",
    "    return all(\n",
    "        [\n",
    "            (safe_level == Likelihood.VERY_UNLIKELY)\n",
    "            or (safe_level == Likelihood.UNLIKELY)\n",
    "            for safe_level in [\n",
    "                safe_search_annotation.adult,\n",
    "                safe_search_annotation.medical,\n",
    "                safe_search_annotation.violence,\n",
    "                safe_search_annotation.racy,\n",
    "            ]\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aded0a519b0c"
   },
   "source": [
    "### 执行限速显示图像检测\n",
    "\n",
    "Google Cloud Vision 对API请求设置了速率限制。\n",
    "\n",
    "使用速率限制器确保请求在此限制范围内。\n",
    "为了获得更好的性能，请使用线程池进行并行请求。这超出了本笔记本的范围。\n",
    "\n",
    "了解更多关于[配额和限制](https://cloud.google.com/vision/quotas?hl=en)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bc753c9264a9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyrate_limiter import Duration, Limiter, RequestRate\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a rate limiter with a limit of 1800 requests per second\n",
    "limiter = Limiter(RequestRate(1800, Duration.MINUTE))\n",
    "\n",
    "safe_search_annotations = []\n",
    "for image_path in tqdm(image_paths, total=len(image_paths)):\n",
    "    limiter.try_acquire()\n",
    "    safe_search_annotations.append(detect_safe_search(image_path))\n",
    "\n",
    "# Convert annotations to boolean values\n",
    "is_safe_values_cloud_vision = list(\n",
    "    map(convert_annotation_to_safety, safe_search_annotations)\n",
    ")\n",
    "\n",
    "# Print number of safe images found\n",
    "print(\n",
    "    f\"Safe images = {np.array(is_safe_values_cloud_vision).sum()} out of {len(is_safe_values_cloud_vision)} images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00c8234f9828"
   },
   "outputs": [],
   "source": [
    "# Filter images by safety\n",
    "metadatas = [\n",
    "    metadata\n",
    "    for metadata, is_safe in zip(metadatas, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]\n",
    "image_names = [\n",
    "    image_name\n",
    "    for image_name, is_safe in zip(image_names, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]\n",
    "image_paths = [\n",
    "    image_path\n",
    "    for image_path, is_safe in zip(image_paths, is_safe_values_cloud_vision)\n",
    "    if is_safe\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1124422cc200"
   },
   "source": [
    "#### 实例化文本到图像编码模型\n",
    "\n",
    "使用由OpenAI开发的[clip-vit-base-patch32编码器](https://huggingface.co/openai/clip-vit-base-patch32)将文本和图像转换为嵌入向量。\n",
    "\n",
    "> CLIP模型是由OpenAI研究人员开发的，用于了解什么对计算机视觉任务的鲁棒性有贡献。该模型还被开发用于测试模型在零样本方式下对任意图像分类任务进行泛化的能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ed41c7712930"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import CLIPModel, CLIPProcessor, CLIPTokenizerFast\n",
    "\n",
    "MODEL_ID = \"openai/clip-vit-base-patch32\"\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "tokenizer = CLIPTokenizerFast.from_pretrained(MODEL_ID)\n",
    "processor = CLIPProcessor.from_pretrained(MODEL_ID)\n",
    "model = CLIPModel.from_pretrained(MODEL_ID).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43088937e820"
   },
   "source": [
    "#### 定义编码函数\n",
    "\n",
    "定义后续将接受文本和图像并将它们转换为嵌入的函数。\n",
    "\n",
    "在此处查看更多信息: https://huggingface.co/openai/clip-vit-base-patch32#use-with-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0370bd840d2"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def encode_text_to_embedding(model, tokenizer, text: List[str]) -> np.ndarray:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    embeddings = model.get_text_features(**inputs)\n",
    "    return embeddings.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def encode_images_to_embedding(model, device, image_paths: List[str]) -> np.ndarray:\n",
    "    images = [copy.deepcopy(Image.open(path)) for path in image_paths]\n",
    "    image_pixel_values = processor(\n",
    "        text=None, images=images, return_tensors=\"pt\", padding=True\n",
    "    )[\"pixel_values\"].to(device)\n",
    "    embeddings = model.get_image_features(pixel_values=image_pixel_values)\n",
    "    return embeddings.squeeze(0).cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def encode_images_to_embedding_chunked(\n",
    "    model, device, image_paths: List[str], batch_size: int = 16\n",
    ") -> np.ndarray:\n",
    "    embeddings_list = []\n",
    "\n",
    "    # Process images in batches to prevent out-of-memory errors.\n",
    "    for i in tqdm(range(0, len(image_paths), batch_size)):\n",
    "        embeddings_list.append(\n",
    "            encode_images_to_embedding(\n",
    "                model=model, device=device, image_paths=image_paths[i : i + batch_size]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return np.vstack(embeddings_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba45d58bf96e"
   },
   "source": [
    "测试编码功能\n",
    "\n",
    "对一部分数据进行编码，看看嵌入和距离度量是否合理。\n",
    "\n",
    "根据[CLIP研究论文](https://arxiv.org/pdf/2103.00020.pdf)，嵌入的相似性是使用余弦相似度进行计算的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9b01baa906b5"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Encode 1000 images\n",
    "image_paths_filtered = random.sample(image_paths, 1000)\n",
    "image_embeddings = encode_images_to_embedding_chunked(\n",
    "    model=model, device=device, image_paths=image_paths_filtered\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9de878127530"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosine_similarity(\n",
    "    text_embedding: np.ndarray, image_embeddings: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    # compute cosine similarity between text and image embeddings by taking the dot product normalized by the product of the L2 norms\n",
    "    return np.divide(\n",
    "        np.dot(text_embedding, image_embeddings.T),\n",
    "        (\n",
    "            np.linalg.norm(text_embedding)\n",
    "            * np.linalg.norm(image_embeddings, axis=1, keepdims=True)\n",
    "        ).squeeze(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95e408daf219"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_query = \"Birds in flight\"\n",
    "\n",
    "# Calculate text embedding of query\n",
    "text_embedding = encode_text_to_embedding(\n",
    "    model=model, tokenizer=tokenizer, text=[text_query]\n",
    ")[0]\n",
    "\n",
    "# Calculate cosine similarity\n",
    "scores = cosine_similarity(\n",
    "    text_embedding=text_embedding, image_embeddings=image_embeddings\n",
    ")\n",
    "\n",
    "# Set the maximum number of images to display\n",
    "MAX_IMAGES = 20\n",
    "\n",
    "# Sort images and scores by descending order of scores and select the top max_images\n",
    "sorted_data = sorted(\n",
    "    zip(image_paths_filtered, scores), key=lambda x: x[1], reverse=True\n",
    ")[:MAX_IMAGES]\n",
    "\n",
    "# Calculate the number of rows and columns needed to display the images\n",
    "num_cols = 4\n",
    "num_rows = math.ceil(len(sorted_data) / num_cols)\n",
    "\n",
    "\n",
    "# Create a grid of subplots to display the images\n",
    "fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(10, 12))\n",
    "\n",
    "# Loop through the top max_images images and display them in the subplots\n",
    "for i, (image_path, score) in enumerate(sorted_data):\n",
    "    # Calculate the row and column index for the current image\n",
    "    row_idx = i // num_cols\n",
    "    col_idx = i % num_cols\n",
    "\n",
    "    # Display the image in the current subplot\n",
    "    image = copy.deepcopy(Image.open(image_path))\n",
    "    axs[row_idx, col_idx].imshow(image, cmap=\"gray\")\n",
    "\n",
    "    # Set the title of the subplot to the image index and score\n",
    "    axs[row_idx, col_idx].set_title(f\"Rank {i+1}, Score = {score:.2f}\")\n",
    "\n",
    "    # Remove ticks from the subplot\n",
    "    axs[row_idx, col_idx].set_xticks([])\n",
    "    axs[row_idx, col_idx].set_yticks([])\n",
    "\n",
    "# Adjust the spacing between subplots and display the plot\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17f24794c9f0"
   },
   "source": [
    "创建索引时保存维度大小以便将来使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55a128883028"
   },
   "outputs": [],
   "source": [
    "DIMENSIONS = len(text_embedding)\n",
    "\n",
    "DIMENSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQIQSyF9GtSv"
   },
   "source": [
    "保存火车拆分为JSONL格式。\n",
    "\n",
    "数据必须以JSONL格式格式化，这意味着每个嵌入字典都以自己的一行JSON字符串形式写入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43aaff23416e"
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "# Create temporary file to write embeddings to\n",
    "embeddings_file = tempfile.NamedTemporaryFile(suffix=\".json\", delete=False)\n",
    "\n",
    "embeddings_file.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "307f468a3ecd"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "BATCH_SIZE = 1000\n",
    "\n",
    "with open(embeddings_file.name, \"a\") as f:\n",
    "    for i in tqdm(range(0, len(image_names), BATCH_SIZE)):\n",
    "        image_names_chunk = image_names[i : i + BATCH_SIZE]\n",
    "        image_paths_chunk = image_paths[i : i + BATCH_SIZE]\n",
    "\n",
    "        embeddings = encode_images_to_embedding_chunked(\n",
    "            model=model, device=device, image_paths=image_paths_chunk\n",
    "        )\n",
    "\n",
    "        # Append to file\n",
    "        embeddings_formatted = [\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"id\": str(id),\n",
    "                    \"embedding\": [str(value) for value in embedding],\n",
    "                }\n",
    "            )\n",
    "            + \"\\n\"\n",
    "            for id, embedding in zip(image_names_chunk, embeddings)\n",
    "        ]\n",
    "        f.writelines(embeddings_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuVl8DrWG8NS"
   },
   "source": [
    "将训练数据上传到GCS。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PgsA_vbI8Vg"
   },
   "outputs": [],
   "source": [
    "UNIQUE_FOLDER_NAME = \"embeddings_folder_unique\"\n",
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/{UNIQUE_FOLDER_NAME}/\"\n",
    "! gsutil cp {embeddings_file.name} {EMBEDDINGS_INITIAL_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mglUPwHpJH98"
   },
   "source": [
    "创建索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhIBCQ7dDSbW"
   },
   "source": [
    "创建 ANN 索引（用于生产环境）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qiIg9b5zJLi1"
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"text_to_image\"\n",
    "DESCRIPTION = \"CLIP text_to_image embeddings\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svLYiDf0OD2G"
   },
   "source": [
    "创建ANN索引配置：\n",
    "\n",
    "要了解更多关于配置索引的信息，请参阅[输入数据格式和结构](https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup#input-data-format)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4zooldkGoM4"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzY7TpUSJcTV"
   },
   "outputs": [],
   "source": [
    "tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
    "    dimensions=DIMENSIONS,\n",
    "    approximate_neighbors_count=150,\n",
    "    distance_measure_type=\"COSINE_DISTANCE\",\n",
    "    leaf_node_embedding_count=500,\n",
    "    leaf_nodes_to_search_percent=7,\n",
    "    description=DESCRIPTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17jrQi501QyX"
   },
   "outputs": [],
   "source": [
    "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
    "INDEX_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f1a9fbecabb"
   },
   "source": [
    "使用资源名称，您可以检索现有的MatchingEngineIndex。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ddb70647d98"
   },
   "outputs": [],
   "source": [
    "tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qV2xjAnDDObD"
   },
   "source": [
    "## 在VPC网络中创建一个索引终端点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpZQoJyxDlbO"
   },
   "outputs": [],
   "source": [
    "# Retrieve the project number\n",
    "PROJECT_NUMBER = !gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
    "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
    "\n",
    "VPC_NETWORK = \"[YOUR-VPC-NETWORK]\"\n",
    "VPC_NETWORK_FULL = \"projects/{}/global/networks/{}\".format(PROJECT_NUMBER, VPC_NETWORK)\n",
    "VPC_NETWORK_FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuARXzJVGyQX"
   },
   "outputs": [],
   "source": [
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    description=DISPLAY_NAME,\n",
    "    network=VPC_NETWORK_FULL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "np2cgVuuIe9k"
   },
   "source": [
    "部署索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ew1UgcIIiJG"
   },
   "source": [
    "### 部署 ANN 指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLOYTGygIlMK"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_INDEX_ID = \"deployed_index_id_unique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uK4WOgqN1NG"
   },
   "outputs": [],
   "source": [
    "my_index_endpoint = my_index_endpoint.deploy_index(\n",
    "    index=tree_ah_index, deployed_index_id=DEPLOYED_INDEX_ID\n",
    ")\n",
    "\n",
    "my_index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LCGvBNvBd8D"
   },
   "source": [
    "创建在线查询\n",
    "\n",
    "在建立了索引之后，您可以查询部署的索引以找到最近的邻居。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48e4e417a496"
   },
   "outputs": [],
   "source": [
    "# Encode query\n",
    "text_embeddings = encode_text_to_embedding(\n",
    "    model=model, tokenizer=tokenizer, text=[\"New York skyline\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3KYVw5HB-4v"
   },
   "outputs": [],
   "source": [
    "# Define number of neighbors to return\n",
    "NUM_NEIGHBORS = 20\n",
    "\n",
    "response = my_index_endpoint.match(\n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    queries=text_embeddings,\n",
    "    num_neighbors=NUM_NEIGHBORS,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1116c7c0d7d"
   },
   "source": [
    "绘制响应并验证图像是否与文本查询匹配。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f4ddb7c8d54"
   },
   "outputs": [],
   "source": [
    "# Sort images and scores by descending order of scores and select the top max_images\n",
    "sorted_data = sorted(response[0], key=lambda x: x.distance, reverse=True)\n",
    "\n",
    "# Create a grid of subplots to display the images\n",
    "fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(10, 12))\n",
    "\n",
    "# Loop through the top max_images images and display them in the subplots\n",
    "for i, response in enumerate(sorted_data):\n",
    "    image_path = f\"{image_directory}/{response.id}\"\n",
    "    score = response.distance\n",
    "\n",
    "    # Calculate the row and column index for the current image\n",
    "    row_idx = i // num_cols\n",
    "    col_idx = i % num_cols\n",
    "\n",
    "    # Display the image in the current subplot\n",
    "    if os.path.exists(image_path):\n",
    "        image = copy.deepcopy(Image.open(image_path))\n",
    "        axs[row_idx, col_idx].imshow(image, cmap=\"gray\")\n",
    "\n",
    "        # Set the title of the subplot to the image index and score\n",
    "        axs[row_idx, col_idx].set_title(f\"Rank {i+1}, Score = {score:.2f}\")\n",
    "\n",
    "        # Remove ticks from the subplot\n",
    "        axs[row_idx, col_idx].set_xticks([])\n",
    "        axs[row_idx, col_idx].set_yticks([])\n",
    "\n",
    "# Adjust the spacing between subplots and display the plot\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于本教程的[Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "您也可以通过运行以下代码手动删除您创建的资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "delete_bucket = False\n",
    "\n",
    "# Force undeployment of indexes and delete endpoint\n",
    "my_index_endpoint.delete(force=True)\n",
    "\n",
    "# Delete indexes\n",
    "tree_ah_index.delete()\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil -m rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sdk_matching_engine_create_text_to_image_embeddings.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
