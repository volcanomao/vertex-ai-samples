{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06cb539bac9c"
   },
   "source": [
    "开始使用Vertex AI管道机器管理\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/get_started_with_machine_management.ipynb\">\n",
    "  <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "</a>\n",
    "\n",
    "<a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/get_started_with_machine_management.ipynb\">\n",
    "  <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "  在GitHub上查看\n",
    "</a>\n",
    "\n",
    "<a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/pipelines/get_started_with_machine_management.ipynb\">\n",
    "  <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "  在Vertex AI工作台中打开\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c16c6df3c48d"
   },
   "source": [
    "## 概览\n",
    "\n",
    "本教程演示了如何在“Vertex AI Pipelines”中作为组件训练时管理机器资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b10d2fb975d"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在这个教程中，您将学习如何将一个自包含的自定义训练组件转换为`Vertex AI CustomJob`，实现以下功能：\n",
    "\n",
    "    - 可跟踪训练作业和生成的工件。\n",
    "    - 设置机器资源，如机器类型、CPU/GPU、内存、磁盘等。\n",
    "\n",
    "此教程使用以下谷歌云ML服务：\n",
    "\n",
    "- `Vertex AI Pipelines`\n",
    "\n",
    "本教程中执行的步骤包括：\n",
    "\n",
    "- 创建一个具有自包含训练作业的自定义组件。\n",
    "- 使用组件级别设置执行管道以设置机器资源。\n",
    "- 将自包含训练组件转换为`Vertex AI CustomJob`。\n",
    "- 使用CustomJob级别设置执行管道以设置机器资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39c8466c1f07"
   },
   "source": [
    "数据集\n",
    "\n",
    "该数据集是MNIST数据集。该数据集由28x28像素的灰度图像组成，包含数字0至9。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35bee437737d"
   },
   "source": [
    "### 成本\n",
    "\n",
    "本教程使用了 Google Cloud 的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI 定价](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage 定价](https://cloud.google.com/storage/pricing)，并使用[定价计算器](https://cloud.google.com/products/calculator/)根据您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_mlops"
   },
   "source": [
    "安装所需的软件包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_mlops"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                         google-cloud-pipeline-components --quiet\n",
    "! pip3 install --upgrade kfp --quiet\n",
    "! pip3 install --upgrade tensorflow==2.7 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "只有Colab：取消注释下面的单元格以重新启动内核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-ZBOjErv5mM"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin"
   },
   "source": [
    "在你开始之前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "### 设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下操作：\n",
    "* 运行`gcloud config list`。\n",
    "* 运行`gcloud projects list`。\n",
    "* 查看支持页面：[找到项目ID](https://support.google.com/googleapi/answer/7014113)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 地区\n",
    "\n",
    "您还可以更改 Vertex AI 使用的 `REGION` 变量。了解有关 [Vertex AI 地区](https://cloud.google.com/vertex-ai/docs/general/locations)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 验证您的Google Cloud账户\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动进行身份验证。请按照以下相关说明操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvQeFm3Gv5mR"
   },
   "source": [
    "1. 顶点人工智能工作台\n",
    "* 无需操作，因为您已经通过身份验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ad1138a125ea"
   },
   "source": [
    "本地的JupyterLab实例，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce6043da7b33"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0367eac06a10"
   },
   "source": [
    "3. 协作，取消注释并运行:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21ad4dbb4a61"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c13224697bfb"
   },
   "source": [
    "4. 服务帐户或其他\n",
    "* 查看如何在https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples 上授予您的服务帐户云存储权限。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产物，比如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有在您的存储桶尚不存在时才能运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "set_service_account"
   },
   "source": [
    "#### 服务账号\n",
    "\n",
    "**如果您不知道您的服务账号**，请尝试使用`gcloud`命令来获取您的服务账号，执行下面的第二个单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_service_account"
   },
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = \"[your-service-account]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_service_account"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if (\n",
    "    SERVICE_ACCOUNT == \"\"\n",
    "    or SERVICE_ACCOUNT is None\n",
    "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
    "):\n",
    "    # Get your service account from gcloud\n",
    "    if not IS_COLAB:\n",
    "        shell_output = !gcloud auth list 2>/dev/null\n",
    "        SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\n",
    "\n",
    "    if IS_COLAB:\n",
    "        shell_output = ! gcloud projects describe  $PROJECT_ID\n",
    "        # print(\"shell_output=\", shell_output)\n",
    "        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
    "        SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
    "\n",
    "    print(\"Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "set_service_account:pipelines"
   },
   "source": [
    "#### 为Vertex AI Pipelines设置服务账号访问权限\n",
    "\n",
    "运行以下命令来授予您的服务账号权限，在您上一步创建的存储桶中读取和写入管道文件 -- 您只需要在每个服务账号上运行一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_service_account:pipelines"
   },
   "outputs": [],
   "source": [
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n",
    "\n",
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。\n",
    "\n",
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7650fa22e03d"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from google.cloud import aiplatform\n",
    "from google_cloud_pipeline_components.v1.custom_job import \\\n",
    "    create_custom_training_job_from_component\n",
    "from kfp import compiler, dsl\n",
    "from kfp.dsl import component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6183d4018b5b"
   },
   "source": [
    "初始化Python的Vertex AI SDK，为您的项目和相应的存储桶进行初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcf75deec9a4"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,prediction,ngpu,mbsdk"
   },
   "source": [
    "#### 设置硬件加速器\n",
    "\n",
    "您可以为训练和预测设置硬件加速器。\n",
    "\n",
    "设置变量`TRAIN_GPU/TRAIN_NGPU`和`DEPLOY_GPU/DEPLOY_NGPU`，以使用支持 GPU 的容器镜像以及分配给虚拟机实例的 GPU 数量。例如，要使用一个 GPU 容器镜像，并为每个 VM 分配 4 个 Nvidia Telsa K80 GPU，您可以指定：\n",
    "\n",
    "    (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
    "\n",
    "否则指定`(None, None)`以使用在 CPU 上运行的容器镜像。\n",
    "\n",
    "了解更多关于[您地区的硬件加速器支持](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)。\n",
    "\n",
    "*注意*：在 TF 2.3 之前的 GPU 支持版本将无法加载本教程中的自定义模型。这是一个已知问题，在 TF 2.3 中已得到修复。这是由生成在服务函数中的静态图操作引起的。如果在自己的定制模型中遇到此问题，请使用带有 GPU 支持的 TF 2.3 容器镜像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accelerators:training,prediction,ngpu,mbsdk"
   },
   "outputs": [],
   "source": [
    "TRAIN_GPU, TRAIN_NGPU = (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80, 1)\n",
    "\n",
    "DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction"
   },
   "source": [
    "设置预构建的容器\n",
    "\n",
    "设置用于训练和预测的预构建Docker容器映像。\n",
    "\n",
    "有关最新列表，请参阅[用于训练的预构建容器](https://cloud.google.com/ai-platform-unified/docs/training/pre-built-containers)。\n",
    "\n",
    "有关最新列表，请参阅[用于预测的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:training,prediction"
   },
   "outputs": [],
   "source": [
    "TF = \"2.5\".replace(\".\", \"-\")\n",
    "TRAIN_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "DEPLOY_VERSION = \"tf2-gpu.{}\".format(TF)\n",
    "\n",
    "\n",
    "TRAIN_IMAGE = \"{}-docker.pkg.dev/vertex-ai/training/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], TRAIN_VERSION\n",
    ")\n",
    "DEPLOY_IMAGE = \"{}-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], DEPLOY_VERSION\n",
    ")\n",
    "\n",
    "print(\"Training:\", TRAIN_IMAGE, TRAIN_GPU, TRAIN_NGPU)\n",
    "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU, DEPLOY_NGPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training,prediction"
   },
   "source": [
    "### 设置机器类型\n",
    "\n",
    "接下来，设置用于训练和预测的机器类型。\n",
    "\n",
    "- 设置变量`TRAIN_COMPUTE`和`DEPLOY_COMPUTE`来配置用于训练和预测的虚拟机的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`: 每个vCPU的内存为3.75GB。\n",
    "     - `n1-highmem`: 每个vCPU的内存为6.5GB。\n",
    "     - `n1-highcpu`: 每个vCPU的内存为0.9GB。\n",
    " - `vCPU数目`: \\[2, 4, 8, 16, 32, 64, 96 \\]\n",
    "\n",
    "*注意: 以下机型不支持用于训练:*\n",
    "\n",
    " - `standard`: 2个vCPU\n",
    " - `highcpu`: 2、4和8个vCPU\n",
    "\n",
    "*注意: 您也可以使用n2和e2机型进行训练和部署，但它们不支持GPU。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training,prediction"
   },
   "outputs": [],
   "source": [
    "TRAIN_COMPUTE = \"n1-standard-4\"\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)\n",
    "\n",
    "DEPLOY_COMPUTE = \"n1-standard-4\"\n",
    "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9a7b0163bef"
   },
   "source": [
    "## 创建一个自包含的自定义训练组件\n",
    "\n",
    "首先，您可以创建一个包含整个训练步骤的组件。该组件使用 TensorFlow 框架训练一个简单的 MNIST 模型。训练完全包含在组件中：\n",
    "\n",
    "- 获取并预处理数据。\n",
    "- 获取/构建模型。\n",
    "- 训练模型。\n",
    "- 保存模型。\n",
    "\n",
    "该组件接受以下参数：\n",
    "\n",
    "- `model_dir`：保存训练模型构件的 Cloud Storage 位置。\n",
    "- `epochs`：训练模型的时代数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7492cdd9eb6d"
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=TRAIN_IMAGE,\n",
    "    packages_to_install=[\"tensorflow\"],\n",
    ")\n",
    "def self_contained_training_component(\n",
    "    model_dir: str,\n",
    "    epochs: int,\n",
    ") -> str:\n",
    "    import numpy as np\n",
    "\n",
    "    def get_data():\n",
    "        from tensorflow.keras.datasets import mnist\n",
    "\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "        x_train = (x_train / 255.0).astype(np.float32)\n",
    "        x_test = (x_test / 255.0).astype(np.float32)\n",
    "\n",
    "        return (x_train, y_train, x_test, y_test)\n",
    "\n",
    "    def get_model():\n",
    "        from tensorflow.keras import Sequential\n",
    "        from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "        model = Sequential(\n",
    "            [\n",
    "                Flatten(input_shape=(28, 28, 1)),\n",
    "                Dense(128, activation=\"relu\"),\n",
    "                Dense(256, activation=\"relu\"),\n",
    "                Dense(128, activation=\"relu\"),\n",
    "                Dense(10, activation=\"softmax\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"]\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train_model(x_train, y_train, model, epochs):\n",
    "        history = model.fit(x_train, y_train, epochs=epochs)\n",
    "        return history\n",
    "\n",
    "    (x_train, y_train, _, _) = get_data()\n",
    "    model = get_model()\n",
    "    train_model(x_train, y_train, model, epochs)\n",
    "\n",
    "    model.save(model_dir)\n",
    "    return model_dir\n",
    "\n",
    "\n",
    "compiler.Compiler().compile(self_contained_training_component, \"demo_componet.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "408dfb113b5e"
   },
   "source": [
    "## 创建自包含的训练管道\n",
    "\n",
    "接下来，您需要创建用于训练该组件的管道，包括以下步骤：\n",
    "\n",
    "- *训练模型*。对于这个组件，您需要设置以下组件级别的资源：\n",
    "    - `cpu_limit`：容器的虚拟机实例的CPU数量。\n",
    "    - `memory_limit`：容器的虚拟机实例的内存量。\n",
    "    - `node_selector_constraint`：容器的虚拟机实例的GPU类型。\n",
    "    - `gpu_limit`：容器的虚拟机实例的GPU数量。\n",
    "- *将模型工件导入到模型容器工件中*。\n",
    "- *将容器工件上传到`Vertex AI Model`资源中*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5ea18c76110"
   },
   "outputs": [],
   "source": [
    "PIPELINE_ROOT = \"{}/pipeline_root/machine_settings\".format(BUCKET_URI)\n",
    "\n",
    "CPU_LIMIT = \"8\"  # vCPUs\n",
    "MEMORY_LIMIT = \"8G\"\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"component-level-set-resources\",\n",
    "    description=\"A simple pipeline that requests component-level machine resource\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "def pipeline(epochs: int, model_dir: str, project: str = PROJECT_ID):\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    from google_cloud_pipeline_components.v1.model import ModelUploadOp\n",
    "    from kfp.dsl import importer_node\n",
    "\n",
    "    training_job_task = (\n",
    "        self_contained_training_component(epochs=epochs, model_dir=model_dir)\n",
    "        .set_display_name(\"self-contained-training\")\n",
    "        .set_cpu_limit(CPU_LIMIT)\n",
    "        .set_memory_limit(MEMORY_LIMIT)\n",
    "        .add_node_selector_constraint(\"NVIDIA_TESLA_K80\")\n",
    "        .set_gpu_limit(TRAIN_NGPU)\n",
    "    )\n",
    "\n",
    "    import_unmanaged_model_task = importer_node.importer(\n",
    "        artifact_uri=training_job_task.output,\n",
    "        artifact_class=artifact_types.UnmanagedContainerModel,\n",
    "        metadata={\n",
    "            \"containerSpec\": {\n",
    "                \"imageUri\": DEPLOY_IMAGE,\n",
    "            },\n",
    "        },\n",
    "    ).after(training_job_task)\n",
    "\n",
    "    _ = ModelUploadOp(\n",
    "        project=project,\n",
    "        display_name=\"mnist_model\",\n",
    "        unmanaged_container_model=import_unmanaged_model_task.outputs[\"artifact\"],\n",
    "    ).after(import_unmanaged_model_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4da63151e961"
   },
   "source": [
    "### 编译并执行管道\n",
    "\n",
    "接下来，您编译管道然后执行它。管道接受以下参数，这些参数作为字典`parameter_values`传递：\n",
    "\n",
    "- `model_dir`：保存模型工件的 Cloud Storage 位置。\n",
    "- `epochs`：训练模型的时代数量。\n",
    "- `project`：您的项目 ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "371dab32ab03"
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path=\"component_level_settings.yaml\",\n",
    ")\n",
    "\n",
    "pipeline = aiplatform.PipelineJob(\n",
    "    display_name=\"component-level-settings\",\n",
    "    template_path=\"component_level_settings.yaml\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\"model_dir\": BUCKET_URI, \"epochs\": 20, \"project\": PROJECT_ID},\n",
    "    enable_caching=False,\n",
    ")\n",
    "\n",
    "pipeline.run()\n",
    "\n",
    "! rm -rf component_level_settings.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view_pipleline_results:bqml"
   },
   "source": [
    "查看管道结果\n",
    "\n",
    "一旦管道完成，您可以查看每个组件步骤的工件输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "291d81126fef"
   },
   "outputs": [],
   "source": [
    "PROJECT_NUMBER = pipeline.gca_resource.name.split(\"/\")[1]\n",
    "print(PROJECT_NUMBER)\n",
    "\n",
    "\n",
    "def print_pipeline_output(job, output_task_name):\n",
    "    JOB_ID = job.name\n",
    "    print(JOB_ID)\n",
    "    for _ in range(len(job.gca_resource.job_detail.task_details)):\n",
    "        TASK_ID = job.gca_resource.job_detail.task_details[_].task_id\n",
    "        EXECUTE_OUTPUT = (\n",
    "            PIPELINE_ROOT\n",
    "            + \"/\"\n",
    "            + PROJECT_NUMBER\n",
    "            + \"/\"\n",
    "            + JOB_ID\n",
    "            + \"/\"\n",
    "            + output_task_name\n",
    "            + \"_\"\n",
    "            + str(TASK_ID)\n",
    "            + \"/executor_output.json\"\n",
    "        )\n",
    "        GCP_RESOURCES = (\n",
    "            PIPELINE_ROOT\n",
    "            + \"/\"\n",
    "            + PROJECT_NUMBER\n",
    "            + \"/\"\n",
    "            + JOB_ID\n",
    "            + \"/\"\n",
    "            + output_task_name\n",
    "            + \"_\"\n",
    "            + str(TASK_ID)\n",
    "            + \"/gcp_resources\"\n",
    "        )\n",
    "        EVAL_METRICS = (\n",
    "            PIPELINE_ROOT\n",
    "            + \"/\"\n",
    "            + PROJECT_NUMBER\n",
    "            + \"/\"\n",
    "            + JOB_ID\n",
    "            + \"/\"\n",
    "            + output_task_name\n",
    "            + \"_\"\n",
    "            + str(TASK_ID)\n",
    "            + \"/evaluation_metrics\"\n",
    "        )\n",
    "        if tf.io.gfile.exists(EXECUTE_OUTPUT):\n",
    "            ! gsutil cat $EXECUTE_OUTPUT\n",
    "            return EXECUTE_OUTPUT\n",
    "        elif tf.io.gfile.exists(GCP_RESOURCES):\n",
    "            ! gsutil cat $GCP_RESOURCES\n",
    "            return GCP_RESOURCES\n",
    "        elif tf.io.gfile.exists(EVAL_METRICS):\n",
    "            ! gsutil cat $EVAL_METRICS\n",
    "            return EVAL_METRICS\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "print(\"self-contained-training\")\n",
    "artifacts = print_pipeline_output(pipeline, \"self-contained-training\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"importer\")\n",
    "artifacts = print_pipeline_output(pipeline, \"importer\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"model-upload\")\n",
    "artifacts = print_pipeline_output(pipeline, \"model-upload\")\n",
    "output = !gsutil cat $artifacts\n",
    "output = json.loads(output[0])\n",
    "model_id = output[\"artifacts\"][\"model\"][\"artifacts\"][0][\"metadata\"][\"resourceName\"]\n",
    "print(\"\\n\")\n",
    "print(\"MODEL ID\", model_id)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "delete_pipeline"
   },
   "source": [
    "删除管道任务\n",
    "\n",
    "在管道任务完成后，您可以使用`delete（）`方法删除管道任务。在完成之前，可以使用`cancel（）`方法取消管道任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UTEiNi9J39s"
   },
   "outputs": [],
   "source": [
    "pipeline.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2311daeb87ee"
   },
   "source": [
    "### 删除模型\n",
    "\n",
    "您可以使用`delete()`方法删除由管道生成的`Model`资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0806f57602fd"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model(model_id)\n",
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b8f4f5cde8d"
   },
   "source": [
    "将自包含培训组件转换为`Vertex AI CustomJob`。\n",
    "\n",
    "接下来，您可以使用实用程序`create_custom_training_job_from_component()`将其转换为`Vertex AI CustomJob`。 这将带来以下好处：\n",
    "\n",
    "- 将额外的 ML Metadata 跟踪添加为自定义作业。\n",
    "- 可以设置特定于自定义作业的资源控制。\n",
    "    - `machine_type`：`CustomJob`的机器（VM）实例。\n",
    "    - `accelerator_type`：GPU 或 TPU 的类型（如果有）。\n",
    "    - `accelerator_count`：HW 加速器（GPU/TPU）的数量或零。\n",
    "    - `replica_count`：作业的 VM 实例数（默认为 1）。\n",
    "    - `boot_disk_type`：引导磁盘的类型（默认为“pd-ssd”）。\n",
    "    - `boot_disk_size_gb`：引导磁盘的大小（单位为 GB，默认为 100GB）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8268b4ebe07d"
   },
   "outputs": [],
   "source": [
    "custom_job_op = create_custom_training_job_from_component(\n",
    "    self_contained_training_component,\n",
    "    display_name=\"test-component\",\n",
    "    machine_type=TRAIN_COMPUTE,\n",
    "    accelerator_type=TRAIN_GPU.name,\n",
    "    accelerator_count=TRAIN_NGPU,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1903cc4ad80f"
   },
   "source": [
    "### 创建CustomJob流水线\n",
    "\n",
    "接下来，您将创建用于训练此组件的流水线，包括以下步骤：\n",
    "\n",
    "- *训练模型*。对于这个组件，您设置以下自定义作业级别资源：\n",
    "    - `machine_type`：机器（VM）实例。\n",
    "    - `accelerator_type`：容器的VM实例的GPU类型。\n",
    "    - `accelerator_count`：容器的VM实例的GPU数量。\n",
    "    - `replica_count`：机器（VM）实例数量。\n",
    "- *将模型工件导入到Model Container工件中*。\n",
    "- *上传容器工件到`Vertex AI Model`资源中*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vRMAa6YEqAhq"
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"customjob-set-resources\",\n",
    "    description=\"A simple pipeline that requests customjob-level machine resource\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "def pipeline(\n",
    "    epochs: int, model_dir: str, project: str = PROJECT_ID, region: str = REGION\n",
    "):\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    from google_cloud_pipeline_components.v1.model import ModelUploadOp\n",
    "    from kfp.dsl import importer_node\n",
    "\n",
    "    training_job_task = custom_job_op(\n",
    "        epochs=epochs, model_dir=model_dir, project=project, location=region\n",
    "    )\n",
    "\n",
    "    import_unmanaged_model_task = importer_node.importer(\n",
    "        artifact_uri=training_job_task.outputs[\"Output\"],\n",
    "        artifact_class=artifact_types.UnmanagedContainerModel,\n",
    "        metadata={\n",
    "            \"containerSpec\": {\n",
    "                \"imageUri\": DEPLOY_IMAGE,\n",
    "            },\n",
    "        },\n",
    "    ).after(training_job_task)\n",
    "\n",
    "    _ = ModelUploadOp(\n",
    "        project=project,\n",
    "        display_name=\"mnist_model\",\n",
    "        unmanaged_container_model=import_unmanaged_model_task.outputs[\"artifact\"],\n",
    "    ).after(import_unmanaged_model_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf17b10aba45"
   },
   "source": [
    "### 编译和执行管道\n",
    "\n",
    "接下来，您编译管道，然后执行它。管道接受以下参数，这些参数作为字典`parameter_values`传递：\n",
    "\n",
    "- `model_dir`：保存模型文件的云存储位置。\n",
    "- `epochs`：训练模型所需的轮数。\n",
    "- `project`：您的项目ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5af9ac9acf12"
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path=\"customjob_level_settings.yaml\",\n",
    ")\n",
    "\n",
    "pipeline = aiplatform.PipelineJob(\n",
    "    display_name=\"customjob-level-settings\",\n",
    "    template_path=\"customjob_level_settings.yaml\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\"model_dir\": BUCKET_URI, \"epochs\": 20, \"project\": PROJECT_ID},\n",
    "    enable_caching=False,\n",
    ")\n",
    "\n",
    "pipeline.run()\n",
    "\n",
    "! rm -rf customjob_level_settings.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view_pipleline_results:bqml"
   },
   "source": [
    "查看管道结果\n",
    "\n",
    "一旦管道完成，您可以查看每个组件步骤的工件输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fcf1627d99c"
   },
   "outputs": [],
   "source": [
    "print(\"self-contained-training-component\")\n",
    "artifacts = print_pipeline_output(pipeline, \"self-contained-training-component\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"importer\")\n",
    "artifacts = print_pipeline_output(pipeline, \"importer\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"model-upload\")\n",
    "artifacts = print_pipeline_output(pipeline, \"model-upload\")\n",
    "output = !gsutil cat $artifacts\n",
    "output = json.loads(output[0])\n",
    "model_id = output[\"artifacts\"][\"model\"][\"artifacts\"][0][\"metadata\"][\"resourceName\"]\n",
    "print(\"\\n\")\n",
    "print(\"MODEL ID\", model_id)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "delete_pipeline"
   },
   "source": [
    "### 删除管道作业\n",
    "\n",
    "在管道作业完成后，您可以使用`delete()`方法删除管道作业。在完成之前，您可以使用`cancel()`方法取消管道作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UTEiNi9J39s"
   },
   "outputs": [],
   "source": [
    "pipeline.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8199abb1687"
   },
   "source": [
    "### 删除模型\n",
    "\n",
    "您可以使用`delete()`方法删除由管道生成的`Model`资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96056ca9f28c"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model(model_id)\n",
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在此教程中创建的各个资源："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dab6f335219e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set this to true only if you'd like to delete your bucket\n",
    "delete_bucket = False\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "get_started_with_machine_management.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
