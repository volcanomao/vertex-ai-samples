{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic"
   },
   "source": [
    "# Vertex AI管道：使用google-cloud-pipeline-components训练、上传和部署TPU模型\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/master/notebooks/official/pipelines/google_cloud_pipeline_components_TPU_model_train_upload_deploy.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/notebooks/blob/master/official/pipelines/google_cloud_pipeline_components_TPU_model_train_upload_deploy.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/pipelines/google_cloud_pipeline_components_TPU_model_train_upload_deploy.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI工作台中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:pipelines,custom"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本笔记本展示如何使用[`google_cloud_pipeline_components`](https://github.com/kubeflow/pipelines/tree/master/components/google-cloud)中定义的组件结合实验性的`run_as_aiplatform_custom_job`方法，构建一个[Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines)工作流程，用于训练使用TPUs的[自定义模型](https://cloud.google.com/vertex-ai/docs/training/containers-overview)，上传模型作为`Model`资源，创建`Endpoint`资源，并将`Model`资源部署到`Endpoint`资源中。\n",
    "\n",
    "了解更多关于[使用TPU加速器进行训练](https://cloud.google.com/vertex-ai/docs/training/training-with-tpu-vm)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:bikes_weather,lrg"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是来自[TensorFlow数据集](https://www.tensorflow.org/datasets/catalog/overview)的[cifar10数据集](https://www.tensorflow.org/datasets/catalog/cifar10)。您将使用的数据集版本已内置于TensorFlow中。训练的模型可预测图像属于十个类别中的哪一类：飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船或卡车。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:pipelines,custom"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用来自`google_cloud_pipeline_components`的组件和您构建的自定义管道组件来创建自定义模型的流水线。\n",
    "\n",
    "本教程使用以下谷歌云ML服务：\n",
    "\n",
    "- `Vertex AI 训练`\n",
    "- `Vertex AI 管道`\n",
    "- `Google Cloud Pipeline Components`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 为自定义模型构建自定义容器。\n",
    "- 使用TPU训练自定义模型。\n",
    "- 将训练好的模型上传为`Model`资源。\n",
    "- 创建一个`Endpoint`资源。\n",
    "- 将`Model`资源部署到`Endpoint`资源上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "成本\n",
    "\n",
    "本教程使用Google Cloud的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI 的定价](https://cloud.google.com/vertex-ai/pricing) 和 [Cloud Storage 的定价](https://cloud.google.com/storage/pricing)，并使用[Pricing Calculator](https://cloud.google.com/products/calculator/) 根据您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_mlops"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装执行此笔记本所需的软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ac64e73628ff"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
    "                                 google-cloud-storage \\\n",
    "                                 google-cloud-pipeline-components \\\n",
    "                                 kfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### 仅限Colab使用：取消注释以下单元格以重新启动内核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-ZBOjErv5mM"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfEglUHQk9S3"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### 设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下操作:\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 参阅支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID} --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 区域\n",
    "\n",
    "您还可以更改 Vertex AI 使用的 `REGION` 变量。了解有关 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations) 的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 验证您的谷歌云帐户\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动进行身份验证。请按照以下相关指示操作。\n",
    "\n",
    "**1. Vertex AI Workbench**\n",
    "* 不需要做任何操作，因为您已经通过身份验证。\n",
    "\n",
    "**2. 本地JupyterLab实例，请取消注释并运行：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce6043da7b33"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0367eac06a10"
   },
   "source": [
    "3. 合作，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21ad4dbb4a61"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c13224697bfb"
   },
   "source": [
    "查看如何在https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples为您的服务账户授予Cloud Storage权限。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产物，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "autoset_bucket"
   },
   "source": [
    "只有当您的存储桶尚不存在时，才运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91c46850b49b"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "set_service_account"
   },
   "source": [
    "#### 服务账号\n",
    "\n",
    "**如果你不知道你的服务账号**，尝试使用`gcloud`命令通过执行下面的第二个单元格来获取你的服务账号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_service_account"
   },
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = \"[your-service-account]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_service_account"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if (\n",
    "    SERVICE_ACCOUNT == \"\"\n",
    "    or SERVICE_ACCOUNT is None\n",
    "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
    "):\n",
    "    # Get your service account from gcloud\n",
    "    if not IS_COLAB:\n",
    "        shell_output = !gcloud auth list 2>/dev/null\n",
    "        SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\n",
    "\n",
    "    else:  # IS_COLAB:\n",
    "        shell_output = ! gcloud projects describe  $PROJECT_ID\n",
    "        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
    "        SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
    "\n",
    "    print(\"Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "set_service_account:pipelines"
   },
   "source": [
    "为Vertex AI Pipelines设置服务账号访问权限\n",
    "\n",
    "运行以下命令，将您的服务账号授权以读取和写入在上一步中创建的存储桶中的管道工件--每个服务账号只需运行一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_service_account:pipelines"
   },
   "outputs": [],
   "source": [
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n",
    "\n",
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。\n",
    "\n",
    "### 导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import google.cloud.aiplatform as aip\n",
    "import kfp\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "from google_cloud_pipeline_components.v1.custom_job.component import \\\n",
    "    custom_training_job as CustomTrainingJobOp\n",
    "from google_cloud_pipeline_components.v1.endpoint import (EndpointCreateOp,\n",
    "                                                          ModelDeployOp)\n",
    "from google_cloud_pipeline_components.v1.model import ModelUploadOp\n",
    "from kfp import compiler\n",
    "from kfp.dsl import importer_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pipeline_constants"
   },
   "source": [
    "设置以下 Vertex AI Pipelines 的常量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pipeline_constants"
   },
   "outputs": [],
   "source": [
    "PIPELINE_ROOT = \"{}/pipeline_root/tpu_cifar10_pipeline\".format(BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "## 初始化用于Python的Vertex AI SDK\n",
    "\n",
    "为您的项目和相应的存储桶初始化用于Python的Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,prediction"
   },
   "source": [
    "#### 设置硬件加速器\n",
    "\n",
    "您可以为训练和预测都设置硬件加速器。\n",
    "\n",
    "将变量`TRAIN_TPU/TRAIN_NTPU`设置为使用支持TPU的容器训练镜像和分配的TPU数量，将`DEPLOY_GPU/DEPLOY_NGPU`设置为使用支持GPU的容器部署镜像和分配给虚拟机实例的GPU数量。\n",
    "\n",
    "查看[可用加速器的位置](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)。\n",
    "\n",
    "否则，指定`(None, None)`以使用在CPU上运行的容器映像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xd5PLXDTlugv"
   },
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform import gapic\n",
    "\n",
    "TRAIN_TPU, TRAIN_NTPU = (\n",
    "    gapic.AcceleratorType.TPU_V2,\n",
    "    8,\n",
    ")  # Using TPU_V2 with 8 accelerators\n",
    "\n",
    "DEPLOY_GPU, DEPLOY_NGPU = (gapic.AcceleratorType.NVIDIA_TESLA_K80, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction"
   },
   "source": [
    "#### 设置预构建容器\n",
    "\n",
    "Vertex AI提供预构建容器来运行训练和预测。\n",
    "\n",
    "有关最新列表，请参见[用于训练的预构建容器](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers)和[用于预测的预构建容器](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1u1mr18jlugv"
   },
   "outputs": [],
   "source": [
    "DEPLOY_VERSION = \"tf2-gpu.2-9\"\n",
    "\n",
    "DEPLOY_IMAGE = \"us-docker.pkg.dev/cloud-aiplatform/prediction/{}:latest\".format(\n",
    "    DEPLOY_VERSION\n",
    ")\n",
    "\n",
    "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU, DEPLOY_NGPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training,prediction"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于训练和预测的机器类型。\n",
    "\n",
    "- 设置变量`TRAIN_COMPUTE`和`DEPLOY_COMPUTE`来配置您的训练和预测的计算资源。\n",
    "  - `机器类型`\n",
    "     - `cloud-tpu`：用于TPU训练。请查看[TPU架构网站](https://cloud.google.com/tpu/docs/system-architecture-tpu-vm)了解详情\n",
    "     - `n1-standard`：每个vCPU 3.75GB的内存\n",
    "     - `n1-highmem`：每个vCPU 6.5GB的内存\n",
    "     - `n1-highcpu`：每个vCPU 0.9GB的内存\n",
    "  - `vCPUs`：\\[2, 4, 8, 16, 32, 64, 96\\]的数量\n",
    "\n",
    "*注：以下内容不支持用于训练：*\n",
    "\n",
    "   - `standard`：2个vCPUs\n",
    "   - `highcpu`：2、4和8个vCPUs\n",
    "\n",
    "*注：您也可以使用n2和e2机器类型进行训练和部署，但它们不支持GPU*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAXwbqKKlugv"
   },
   "outputs": [],
   "source": [
    "MACHINE_TYPE = \"cloud-tpu\"\n",
    "\n",
    "# TPU VMs do not require VCPU definition\n",
    "TRAIN_COMPUTE = MACHINE_TYPE\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)\n",
    "\n",
    "MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b70e0a15eda9"
   },
   "outputs": [],
   "source": [
    "if not TRAIN_NTPU or TRAIN_NTPU < 2:\n",
    "    TRAIN_STRATEGY = \"single\"\n",
    "else:\n",
    "    TRAIN_STRATEGY = \"tpu\"\n",
    "\n",
    "EPOCHS = 20\n",
    "STEPS = 10000\n",
    "\n",
    "TRAINER_ARGS = [\n",
    "    \"--epochs=\" + str(EPOCHS),\n",
    "    \"--steps=\" + str(STEPS),\n",
    "    \"--distribute=\" + TRAIN_STRATEGY,\n",
    "]\n",
    "\n",
    "# create working dir to pass to job spec\n",
    "WORKING_DIR = f\"{PIPELINE_ROOT}/model\"\n",
    "\n",
    "MODEL_DISPLAY_NAME = \"tpu_train_deploy\"\n",
    "print(TRAINER_ARGS, WORKING_DIR, MODEL_DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_custom_model"
   },
   "source": [
    "创建一个自定义容器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0833ff8115f5"
   },
   "source": [
    "我们将创建一个目录，并将所有容器构建产物写入该文件夹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0189aba78b0"
   },
   "outputs": [],
   "source": [
    "CONTAINER_ARTIFACTS_DIR = \"tpu-container-artifacts\"\n",
    "\n",
    "!mkdir {CONTAINER_ARTIFACTS_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d901a90e455a"
   },
   "source": [
    "写Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88fff423eb02"
   },
   "outputs": [],
   "source": [
    "dockerfile = \"\"\"FROM python:3.8\n",
    "\n",
    "WORKDIR /root\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY train.py /root/train.py\n",
    "\n",
    "RUN pip3 install tensorflow-datasets\n",
    "\n",
    "# Install TPU Tensorflow and dependencies.\n",
    "# libtpu.so must be under the '/lib' directory.\n",
    "RUN wget https://storage.googleapis.com/cloud-tpu-tpuvm-artifacts/libtpu/20210525/libtpu.so -O /lib/libtpu.so\n",
    "RUN chmod 777 /lib/libtpu.so\n",
    "\n",
    "RUN wget https://storage.googleapis.com/cloud-tpu-tpuvm-artifacts/tensorflow/20210525/tf_nightly-2.6.0-cp38-cp38-linux_x86_64.whl\n",
    "RUN pip3 install tf_nightly-2.6.0-cp38-cp38-linux_x86_64.whl\n",
    "RUN rm tf_nightly-2.6.0-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "ENTRYPOINT [\"python3\", \"train.py\"]\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(CONTAINER_ARTIFACTS_DIR, \"Dockerfile\"), \"w\") as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taskpy_contents"
   },
   "source": [
    "#### 训练脚本\n",
    "\n",
    "在下一个单元格中，您可以编写训练脚本 `train.py` 的内容。 总结如下：\n",
    "\n",
    "- 从环境变量 `AIP_MODEL_DIR` 中获取保存模型工件的目录。 这个变量是由训练服务设置的。\n",
    "- 从 TF 数据集（tfds）加载 CIFAR10 数据集。\n",
    "- 使用 TF.Keras 模型 API 构建模型。\n",
    "- 编译模型（`compile()`）。\n",
    "- 根据参数 `args.distribute` 设置训练分布策略。\n",
    "- 使用参数 `args.epochs` 和 `args.steps` 训练模型（`fit()`）。\n",
    "- 将经过训练的模型保存（`save(MODEL_DIR)`）到指定的模型目录中。\n",
    "\n",
    "下面列出了专门针对 TPU 的更改：\n",
    "- 添加了一个部分，用于查找 TPU 集群，连接到它，并将训练策略设置为 TPUStrategy。\n",
    "- 添加了一个部分，将经过训练的 TPU 模型保存到本地设备，以便可以保存到 AIP_MODEL_DIR 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72rUqXNFlugx"
   },
   "outputs": [],
   "source": [
    "%%writefile {CONTAINER_ARTIFACTS_DIR}/train.py\n",
    "# Single, Mirror and Multi-Machine Distributed Training for CIFAR-10\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--lr', dest='lr',\n",
    "                    default=0.01, type=float,\n",
    "                    help='Learning rate.')\n",
    "parser.add_argument('--epochs', dest='epochs',\n",
    "                    default=10, type=int,\n",
    "                    help='Number of epochs.')\n",
    "parser.add_argument('--steps', dest='steps',\n",
    "                    default=200, type=int,\n",
    "                    help='Number of steps per epoch.')\n",
    "parser.add_argument('--distribute', dest='distribute', type=str, default='single',\n",
    "                    help='distributed training strategy')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print('Python Version = {}'.format(sys.version))\n",
    "print('TensorFlow Version = {}'.format(tf.__version__))\n",
    "print('TF_CONFIG = {}'.format(os.environ.get('TF_CONFIG', 'Not found')))\n",
    "print('DEVICES', device_lib.list_local_devices())\n",
    "\n",
    "# Single Machine, single compute device\n",
    "if args.distribute == 'single':\n",
    "    if tf.test.is_gpu_available():\n",
    "        strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    else:\n",
    "        strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
    "# Single Machine, multiple TPU devices\n",
    "elif args.distribute == 'tpu':\n",
    "    cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n",
    "    tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
    "    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "# Single Machine, multiple compute device\n",
    "elif args.distribute == 'mirror':\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "# Multiple Machine, multiple compute device\n",
    "elif args.distribute == 'multi':\n",
    "    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "# Multi-worker configuration\n",
    "print('num_replicas_in_sync = {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Preparing dataset\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def make_datasets_unbatched():\n",
    "  # Scaling CIFAR10 data from (0, 255] to (0., 1.]\n",
    "  def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.0\n",
    "    return image, label\n",
    "\n",
    "  datasets, info = tfds.load(name='cifar10',\n",
    "                            with_info=True,\n",
    "                            as_supervised=True)\n",
    "  return datasets['train'].map(scale).cache().shuffle(BUFFER_SIZE).repeat()\n",
    "\n",
    "\n",
    "# Build the Keras model\n",
    "def build_and_compile_cnn_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(32, 32, 3)),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "      optimizer=tf.keras.optimizers.SGD(learning_rate=args.lr),\n",
    "      metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "# Train the model\n",
    "NUM_WORKERS = strategy.num_replicas_in_sync\n",
    "# Here the batch size scales up by number of workers since\n",
    "# `tf.data.Dataset.batch` expects the global batch size.\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE * NUM_WORKERS\n",
    "MODEL_DIR = os.getenv(\"AIP_MODEL_DIR\")\n",
    "\n",
    "train_dataset = make_datasets_unbatched().batch(GLOBAL_BATCH_SIZE)\n",
    "\n",
    "with strategy.scope():\n",
    "  # Creation of dataset, and model building/compiling need to be within\n",
    "  # `strategy.scope()`.\n",
    "  model = build_and_compile_cnn_model()\n",
    "\n",
    "model.fit(x=train_dataset, epochs=args.epochs, steps_per_epoch=args.steps)\n",
    "if args.distribute==\"tpu\":\n",
    "    save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "    model.save(MODEL_DIR, options=save_locally)\n",
    "else:\n",
    "    model.save(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LYlV4D2ftD0"
   },
   "source": [
    "### 建立容器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2d242773d707"
   },
   "source": [
    "启用Artifact Registry API\n",
    "您必须为您的项目启用Artifact Registry API服务。\n",
    "\n",
    "<a href=\"https://cloud.google.com/artifact-registry/docs/enable-service\">了解更多关于启用服务的信息</a>。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d72f89cabd5"
   },
   "outputs": [],
   "source": [
    "! gcloud services enable artifactregistry.googleapis.com\n",
    "\n",
    "if os.getenv(\"IS_TESTING\"):\n",
    "    ! sudo apt-get update --yes && sudo apt-get --only-upgrade --yes install google-cloud-sdk-cloud-run-proxy google-cloud-sdk-harbourbridge google-cloud-sdk-cbt google-cloud-sdk-gke-gcloud-auth-plugin google-cloud-sdk-kpt google-cloud-sdk-local-extract google-cloud-sdk-minikube google-cloud-sdk-app-engine-java google-cloud-sdk-app-engine-go google-cloud-sdk-app-engine-python google-cloud-sdk-spanner-emulator google-cloud-sdk-bigtable-emulator google-cloud-sdk-nomos google-cloud-sdk-package-go-module google-cloud-sdk-firestore-emulator kubectl google-cloud-sdk-datastore-emulator google-cloud-sdk-app-engine-python-extras google-cloud-sdk-cloud-build-local google-cloud-sdk-kubectl-oidc google-cloud-sdk-anthos-auth google-cloud-sdk-app-engine-grpc google-cloud-sdk-pubsub-emulator google-cloud-sdk-datalab google-cloud-sdk-skaffold google-cloud-sdk google-cloud-sdk-terraform-tools google-cloud-sdk-config-connector\n",
    "    ! gcloud components update --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "797c277266d7"
   },
   "source": [
    "请运行这些Artifact Registry和Docker步骤一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "892542f5315e"
   },
   "outputs": [],
   "source": [
    "!sudo usermod -a -G docker ${USER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3f02b426046"
   },
   "outputs": [],
   "source": [
    "REPOSITORY = \"tpu-training-repository\"\n",
    "IMAGE = \"tpu-train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a04b48b7eaf0"
   },
   "outputs": [],
   "source": [
    "!gcloud auth configure-docker us-central1-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e69e2d5f373a"
   },
   "outputs": [],
   "source": [
    "!gcloud artifacts repositories create $REPOSITORY --repository-format=docker \\\n",
    "--location=us-central1 --description=\"Vertex TPU training repository\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92e7de44b91d"
   },
   "source": [
    "构建训练图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2eb5b2b0468a"
   },
   "outputs": [],
   "source": [
    "TRAIN_IMAGE = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90dedc4dae6e"
   },
   "outputs": [],
   "source": [
    "print(TRAIN_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8d3e23223b12"
   },
   "outputs": [],
   "source": [
    "%cd $CONTAINER_ARTIFACTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17cce4ce9068"
   },
   "outputs": [],
   "source": [
    "# Use quiet flag as the output is fairly large\n",
    "!docker build --quiet \\\n",
    "    --tag={TRAIN_IMAGE} \\\n",
    "    ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3efe0d9b4e75"
   },
   "outputs": [],
   "source": [
    "!docker push {TRAIN_IMAGE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a34bb81b5bbe"
   },
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "define_pipeline:gcpc,bikes_weather,lrg"
   },
   "source": [
    "## 定义自定义模型流水线，使用来自`google_cloud_pipeline_components` 的组件\n",
    "\n",
    "接下来，您可以定义流水线。\n",
    "\n",
    "`experimental.run_as_aiplatform_custom_job` 方法接受之前定义的组件以及`worker_pool_specs`列表（在这种情况下是一个）作为参数。自定义训练作业将使用这个列表进行配置。\n",
    "\n",
    "然后，使用[`google_cloud_pipeline_components`](https://github.com/kubeflow/pipelines/tree/master/components/google-cloud) 组件来定义流水线的其余部分：上传模型，创建端点，以及将模型部署到端点。\n",
    "\n",
    "*注意：* 虽然这个例子中没有展示，但模型部署将会在没有提供端点的情况下创建一个端点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3762e4d0ccdc"
   },
   "outputs": [],
   "source": [
    "WORKER_POOL_SPECS = [\n",
    "    {\n",
    "        \"containerSpec\": {\n",
    "            \"args\": TRAINER_ARGS,\n",
    "            \"env\": [{\"name\": \"AIP_MODEL_DIR\", \"value\": WORKING_DIR}],\n",
    "            \"imageUri\": TRAIN_IMAGE,\n",
    "        },\n",
    "        \"replicaCount\": \"1\",\n",
    "        \"machineSpec\": {\n",
    "            \"machineType\": TRAIN_COMPUTE,\n",
    "            \"accelerator_type\": TRAIN_TPU,\n",
    "            \"accelerator_count\": TRAIN_NTPU,\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "define_component:print_op"
   },
   "source": [
    "定义管道\n",
    "\n",
    "该管道有四个主要步骤：\n",
    "\n",
    "1) run_as_experimental_custom_job 运行将执行训练任务的docker容器\n",
    "\n",
    "2) ModelUploadOp 将训练好的模型上传到 Vertex\n",
    "\n",
    "3) EndpointCreateOp 创建模型端点\n",
    "\n",
    "4) 最后，ModelDeployOp 部署模型到端点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "define_pipeline:gcpc,bikes_weather,lrg"
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name=\"train-endpoint-deploy\")\n",
    "def pipeline(\n",
    "    project: str = PROJECT_ID,\n",
    "    model_display_name: str = MODEL_DISPLAY_NAME,\n",
    "    serving_container_image_uri: str = DEPLOY_IMAGE,\n",
    "):\n",
    "\n",
    "    custom_job_task = CustomTrainingJobOp(\n",
    "        display_name=\"tpu model training\",\n",
    "        worker_pool_specs=WORKER_POOL_SPECS,\n",
    "    )\n",
    "\n",
    "    import_unmanaged_model_task = importer_node.importer(\n",
    "        artifact_uri=WORKING_DIR,\n",
    "        artifact_class=artifact_types.UnmanagedContainerModel,\n",
    "        metadata={\n",
    "            \"containerSpec\": {\n",
    "                \"imageUri\": serving_container_image_uri  # \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-9:latest\",\n",
    "            },\n",
    "        },\n",
    "    ).after(custom_job_task)\n",
    "\n",
    "    model_upload_op = ModelUploadOp(\n",
    "        project=project,\n",
    "        display_name=model_display_name,\n",
    "        unmanaged_container_model=import_unmanaged_model_task.outputs[\"artifact\"],\n",
    "    )\n",
    "\n",
    "    endpoint_create_op = EndpointCreateOp(\n",
    "        project=project,\n",
    "        display_name=\"tpu-pipeline-created-endpoint\",\n",
    "    )\n",
    "\n",
    "    _ = ModelDeployOp(\n",
    "        endpoint=endpoint_create_op.outputs[\"endpoint\"],\n",
    "        model=model_upload_op.outputs[\"model\"],\n",
    "        deployed_model_display_name=model_display_name,\n",
    "        dedicated_resources_machine_type=DEPLOY_COMPUTE,\n",
    "        dedicated_resources_min_replica_count=1,\n",
    "        dedicated_resources_max_replica_count=1,\n",
    "        dedicated_resources_accelerator_type=DEPLOY_GPU.name,\n",
    "        dedicated_resources_accelerator_count=DEPLOY_NGPU,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "compile_pipeline"
   },
   "source": [
    "## 编译管道\n",
    "\n",
    "接下来，编译管道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compile_pipeline"
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path=\"tpu_train_cifar10_pipeline.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_pipeline:custom"
   },
   "source": [
    "运行管道\n",
    "\n",
    "接下来，运行管道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_pipeline:custom"
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"tpu_cifar10_training\"\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    template_path=\"tpu_train_cifar10_pipeline.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "job.run()\n",
    "\n",
    "! rm tpu_train_cifar10_pipeline.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view_pipeline_run:custom"
   },
   "source": [
    "点击生成的链接，以在云控制台中查看你的运行。\n",
    "\n",
    "在用户界面中，当你点击它们时，许多流水线DAG节点会展开或折叠。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:pipelines"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于本教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除您在本教程中创建的各个资源 -- *注意:* 这是自动生成的，不是所有资源可能适用于此教程：\n",
    "### 获取清理的管道资源\n",
    "用于获取任务详情的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50f5f0d96294"
   },
   "outputs": [],
   "source": [
    "def get_task_detail(\n",
    "    task_details: List[Dict[str, Any]], task_name: str\n",
    ") -> List[Dict[str, Any]]:\n",
    "    for task_detail in task_details:\n",
    "        if task_detail.task_name == task_name:\n",
    "            return task_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0966cd56fc3e"
   },
   "outputs": [],
   "source": [
    "pipeline_task_details = (\n",
    "    job.gca_resource.job_detail.task_details\n",
    ")  # fetch pipeline task details\n",
    "\n",
    "\n",
    "# fetch endpoint from pipeline and delete the endpoint\n",
    "endpoint_task = get_task_detail(pipeline_task_details, \"endpoint-create\")\n",
    "endpoint_resourceName = (\n",
    "    endpoint_task.outputs[\"endpoint\"].artifacts[0].metadata[\"resourceName\"]\n",
    ")\n",
    "endpoint = aip.Endpoint(endpoint_resourceName)\n",
    "# undeploy model from endpoint\n",
    "endpoint.undeploy_all()\n",
    "endpoint.delete()\n",
    "\n",
    "# fetch model from pipeline and delete the model\n",
    "model_task = get_task_detail(pipeline_task_details, \"model-upload\")\n",
    "model_resourceName = model_task.outputs[\"model\"].artifacts[0].metadata[\"resourceName\"]\n",
    "model = aip.Model(model_resourceName)\n",
    "model.delete()\n",
    "\n",
    "job.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:pipelines"
   },
   "outputs": [],
   "source": [
    "# Warning: Setting this to true will delete everything in your bucket\n",
    "delete_bucket = False\n",
    "\n",
    "\n",
    "if delete_bucket and \"BUCKET_URI\" in globals():\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "google_cloud_pipeline_components_TPU_model_train_upload_deploy.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
