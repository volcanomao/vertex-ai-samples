{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40399883"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# 在Vertex AI中尝试BQML和AutoML\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/rapid_prototyping_bqml_automl.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>  \n",
    "\n",
    "  <td>\n",
    "<a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/rapid_prototyping_bqml_automl.ipynb\" target='_blank'>\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "<a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/pipelines/rapid_prototyping_bqml_automl.ipynb\" target='_blank'>\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okkqa_U8AcsN"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示如何使用Vertex AI Pipelines来快速原型化模型，同时使用AutoML和BQML进行评估比较，在进行自定义模型之前对基线进行评估。\n",
    "\n",
    "学习更多关于[AutoML组件](https://cloud.google.com/vertex-ai/docs/pipelines/vertex-automl-component)和[BigQuery ML组件](https://cloud.google.com/vertex-ai/docs/pipelines/bigqueryml-component)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-82uiXlTjvw"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用 `Vertex AI Predictions` 快速原型化模型。\n",
    "\n",
    "本教程使用以下谷歌云机器学习服务：\n",
    "\n",
    "- `Vertex AI Pipelines`\n",
    "- `Vertex AI AutoML`\n",
    "- `Vertex AI BigQuery ML`\n",
    "- `Google Cloud Pipeline Components`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 创建一个 BigQuery 和 Vertex AI 训练数据集。\n",
    "- 训练 BigQuery ML 和 AutoML 模型。\n",
    "- 从 BigQuery ML 和 AutoML 模型中提取评估指标。\n",
    "- 选择最佳训练模型。\n",
    "- 部署最佳训练模型。\n",
    "- 测试已部署的模型基础设施。\n",
    "\n",
    "## 数据集\n",
    "\n",
    "#### 鲍鱼数据集\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/rafacarv-public-bucket-do-not-delete/abalone/dataset.png\" />\n",
    "\n",
    "<p>数据集来源</p>\n",
    "<p>Dua, D. and Graff, C. (2019). UCI Machine Learning Repository <a href=\"http://archive.ics.uci.edu/ml\">http://archive.ics.uci.edu/ml</a>. Irvine, CA: University of California, School of Information and Computer Science.</p>\n",
    "\n",
    "<p><a href=\"https://archive.ics.uci.edu/ml/datasets/abalone\">直接链接</a></p>\n",
    "    \n",
    "    \n",
    "#### 属性信息：\n",
    "\n",
    "<p>给出的是属性名称、属性类型、测量单位和简要描述。环数是要预测的值：可以作为连续值或分类问题。</p>\n",
    "\n",
    "<body>\n",
    "\t<table>\n",
    "\t\t<tr>\n",
    "\t\t\t<th>名称</th>\n",
    "\t\t\t<th>数据类型</th>\n",
    "\t\t\t<th>测量单位</th>\n",
    "\t\t\t<th>描述</th>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>性别</td>\n",
    "            <td>名义</td>\n",
    "            <td>--</td>\n",
    "            <td>M、F 和 I（幼崽）</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>长度</td>\n",
    "            <td>连续</td>\n",
    "            <td>毫米</td>\n",
    "            <td>最长的贝壳测量</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>直径</td>\n",
    "            <td>连续</td>\n",
    "            <td>毫米</td>\n",
    "            <td>与长度垂直</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>高度</td>\n",
    "            <td>连续</td>\n",
    "            <td>毫米</td>\n",
    "            <td>含肉壳</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>全重</td>\n",
    "            <td>连续</td>\n",
    "            <td>克</td>\n",
    "            <td>整只鲍鱼</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>去壳重量</td>\n",
    "            <td>连续</td>\n",
    "            <td>克</td>\n",
    "            <td>肉的重量</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>内脏重量</td>\n",
    "            <td>连续</td>\n",
    "            <td>克</td>\n",
    "            <td>内脏重量（出血后）</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>贝壳重量</td>\n",
    "            <td>连续</td>\n",
    "            <td>克</td>\n",
    "            <td>干燥后的重量</td>\n",
    "\t\t</tr>\n",
    "        <tr>\n",
    "\t\t\t<td>环数</td>\n",
    "            <td>整数</td>\n",
    "\t\t\t<td>--</td>\n",
    "            <td>+1.5 表示年龄</td>\n",
    "\t\t</tr>\n",
    "\t</table>\n",
    "</body>\n",
    "\n",
    "\n",
    "## 费用\n",
    "\n",
    "本教程使用谷歌云的收费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* 云存储\n",
    "\n",
    "了解 [Vertex AI 定价](https://cloud.google.com/vertex-ai/pricing) 和 [云存储定价](https://cloud.google.com/storage/pricing)，并使用 [定价计算器](https://cloud.google.com/products/calculator/) 根据您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwLGChAYTjvy"
   },
   "source": [
    "### 设置本地开发环境\n",
    "\n",
    "如果您使用 Colab 或者 Vertex AI Workbench，那么您的环境已经满足运行本笔记本的所有要求。您可以跳过这一步。\n",
    "\n",
    "否则，请确保您的环境满足本笔记本的要求。您需要以下内容：\n",
    "\n",
    "- 云存储 SDK\n",
    "- Git\n",
    "- Python 3\n",
    "- virtualenv\n",
    "- 在虚拟环境中以 Python 3 运行的 Jupyter 笔记本\n",
    "\n",
    "云存储指南中有关[设置 Python 开发环境](https://cloud.google.com/python/setup)和 [Jupyter 安装指南](https://jupyter.org/install) 提供了满足这些要求的详细说明。以下步骤提供了简洁的一套指令：\n",
    "\n",
    "1. [安装并初始化 SDK](https://cloud.google.com/sdk/docs/)。\n",
    "\n",
    "2. [安装 Python 3](https://cloud.google.com/python/setup#installing_python)。\n",
    "\n",
    "3. [安装 virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv) 并创建一个使用 Python 3 的虚拟环境。激活虚拟环境。\n",
    "\n",
    "4. 要安装 Jupyter，请在命令行终端中运行 `pip3 install jupyter`。\n",
    "\n",
    "5. 若要启动 Jupyter，请在命令行终端中运行 `jupyter notebook`。\n",
    "\n",
    "6. 在 Jupyter Notebook 仪表板中打开此笔记本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "安装额外的软件包\n",
    "\n",
    "安装以下软件包以执行此笔记本所需。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7c2da21e"
   },
   "outputs": [],
   "source": [
    "# Install Python package dependencies.\n",
    "! pip3 install --quiet google-cloud-pipeline-components kfp\n",
    "! pip3 install --quiet --upgrade google-cloud-aiplatform google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### 仅用合作者：取消以下单元格的注释以重新启动内核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-ZBOjErv5mM"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "## 准备开始之前\n",
    "\n",
    "### 设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下方法：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 区域\n",
    "\n",
    "您也可以修改 Vertex AI 使用的 `REGION` 变量。了解更多关于 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dw8q9fdQEH5"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57dad372c81b"
   },
   "source": [
    "UUID\n",
    "\n",
    "如果您正在进行现场教程会话，您可能会使用共享的测试账户或项目。为了避免用户在创建的资源之间发生名称冲突，您需要为每个实例会话创建一个UUID，并将其附加到您在本教程中创建的资源的名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e166d927e36"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 验证您的谷歌云账户\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动进行身份验证。请按照以下相关说明进行操作。\n",
    "\n",
    "**1. Vertex AI Workbench**\n",
    "* 由于您已经经过身份验证，无需进行任何操作。\n",
    "\n",
    "**2. 本地JupyterLab实例，请取消注释并运行：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce6043da7b33"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0367eac06a10"
   },
   "source": [
    "3. 合作，取消注释并运行:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21ad4dbb4a61"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c13224697bfb"
   },
   "source": [
    "4. 服务账户或其他\n",
    "* 查看如何在 https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples 上授予您的服务账户云存储权限。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶，用来存储中间产物，如数据集。\n",
    "\n",
    "- *{给笔记本作者的提示：对于任何需要是唯一的用户提供的字符串（例如存储桶名称或模型ID），请在末尾追加“-unique”以便进行适当的测试}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有在您的存储桶尚不存在时：运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zml9wWqtTjwA"
   },
   "source": [
    "服务帐号\n",
    "\n",
    "**如果您不知道您的服务帐号**，请尝试使用`gcloud`命令在下面执行第二个单元格以获取您的服务帐号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KnHtCwvfTjwA"
   },
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = \"[your-service-account]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IAvOQzG6TjwA"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if (\n",
    "    SERVICE_ACCOUNT == \"\"\n",
    "    or SERVICE_ACCOUNT is None\n",
    "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
    "):\n",
    "    # Get your service account from gcloud\n",
    "    if not IS_COLAB:\n",
    "        shell_output = !gcloud auth list 2>/dev/null\n",
    "        SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\n",
    "\n",
    "    if IS_COLAB:\n",
    "        shell_output = ! gcloud projects describe  $PROJECT_ID\n",
    "        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
    "        SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
    "\n",
    "    print(\"Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0D9zuobTjwA"
   },
   "source": [
    "#### 为Vertex AI Pipeline设置服务账户访问权限\n",
    "\n",
    "运行以下命令，为您的服务账户授予访问权限，以读取和写入在上一步创建的存储桶中的管道工件 -- 您只需要为每个服务账户运行一次这些命令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbbhYgtCTjwB"
   },
   "outputs": [],
   "source": [
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n",
    "\n",
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7aBmVRZGr1d"
   },
   "source": [
    "### 要求的进口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3444fe2c"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import NamedTuple\n",
    "\n",
    "from google.cloud import aiplatform as vertex\n",
    "from google_cloud_pipeline_components.v1 import bigquery as bq_components\n",
    "from google_cloud_pipeline_components.v1.automl.training_job import \\\n",
    "    AutoMLTabularTrainingJobRunOp\n",
    "from google_cloud_pipeline_components.v1.dataset import TabularDatasetCreateOp\n",
    "from google_cloud_pipeline_components.v1.endpoint import (EndpointCreateOp,\n",
    "                                                          ModelDeployOp)\n",
    "from google_cloud_pipeline_components.v1.model import ModelUploadOp\n",
    "from kfp import compiler, dsl\n",
    "from kfp.dsl import Artifact, Input, Metrics, Output, component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63_AplznG3J7"
   },
   "source": [
    "确定一些项目和管道变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dy-vIuq2yWjw"
   },
   "source": [
    "指南：\n",
    "- 确保GCS存储桶和BigQuery数据集不存在。这个脚本可能**删除**任何现有内容。\n",
    "- 您的存储桶必须与您的Vertex AI资源位于同一地区。\n",
    "- BQ地区可以是美国或欧盟；\n",
    "- 确保您首选的Vertex AI地区受支持[[链接]](https://cloud.google.com/vertex-ai/docs/general/locations#americas_1)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ef138d54"
   },
   "outputs": [],
   "source": [
    "PIPELINE_YAML_PKG_PATH = \"rapid_prototyping.yaml\"\n",
    "PIPELINE_ROOT = f\"{BUCKET_URI}/pipeline_root\"\n",
    "DATA_FOLDER = f\"{BUCKET_URI[5:]}/data\"\n",
    "\n",
    "RAW_INPUT_DATA = f\"gs://{DATA_FOLDER}/abalone.csv\"\n",
    "BQ_DATASET = \"vertex_ai_dev_dataset_\" + UUID  # @param {type:\"string\"}\n",
    "BQ_LOCATION = \"US\"  # @param {type:\"string\"}\n",
    "BQ_LOCATION = BQ_LOCATION.upper()\n",
    "BQML_EXPORT_LOCATION = f\"{BUCKET_URI}/artifacts/bqml\"\n",
    "\n",
    "DISPLAY_NAME = \"rapid-prototyping\"\n",
    "ENDPOINT_DISPLAY_NAME = f\"{DISPLAY_NAME}_endpoint\"\n",
    "\n",
    "image_prefix = REGION.split(\"-\")[0]\n",
    "BQML_SERVING_CONTAINER_IMAGE_URI = (\n",
    "    f\"{image_prefix}-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-8:latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "333e4035"
   },
   "outputs": [],
   "source": [
    "!gcloud config set project $PROJECT_ID\n",
    "!gcloud config set ai/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3-Bqs7vFU7Y"
   },
   "source": [
    "### 下载数据\n",
    "\n",
    "下面的单元格将把数据集下载到CSV文件中，在GCS中保存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6bd858d"
   },
   "outputs": [],
   "source": [
    "! gsutil cp gs://cloud-samples-data/vertex-ai/community-content/datasets/abalone/abalone.data {RAW_INPUT_DATA}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owlPQF1KF8QO"
   },
   "source": [
    "## 管道组件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79eaa73a"
   },
   "source": [
    "### 导入到BQ\n",
    "\n",
    "该组件会将csv文件导入到BigQuery中的表中。如果数据集不存在，将会被创建。如果已经存在同名的表，它将被删除并重新创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e44af8ac"
   },
   "outputs": [],
   "source": [
    "@component(base_image=\"python:3.9\", packages_to_install=[\"google-cloud-bigquery\"])\n",
    "def import_data_to_bigquery(\n",
    "    project: str,\n",
    "    bq_location: str,\n",
    "    bq_dataset: str,\n",
    "    gcs_data_uri: str,\n",
    "    raw_dataset: Output[Artifact],\n",
    "    table_name_prefix: str = \"abalone\",\n",
    "):\n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    # Construct a BigQuery client object.\n",
    "    client = bigquery.Client(project=project, location=bq_location)\n",
    "\n",
    "    def load_dataset(gcs_uri, table_id):\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            schema=[\n",
    "                bigquery.SchemaField(\"Sex\", \"STRING\"),\n",
    "                bigquery.SchemaField(\"Length\", \"NUMERIC\"),\n",
    "                bigquery.SchemaField(\"Diameter\", \"NUMERIC\"),\n",
    "                bigquery.SchemaField(\"Height\", \"NUMERIC\"),\n",
    "                bigquery.SchemaField(\"Whole_weight\", \"NUMERIC\"),\n",
    "                bigquery.SchemaField(\"Shucked_weight\", \"NUMERIC\"),\n",
    "                bigquery.SchemaField(\"Viscera_weight\", \"NUMERIC\"),\n",
    "                bigquery.SchemaField(\"Shell_weight\", \"NUMERIC\"),\n",
    "                bigquery.SchemaField(\"Rings\", \"NUMERIC\"),\n",
    "            ],\n",
    "            skip_leading_rows=1,\n",
    "            # The source format defaults to CSV, so the line below is optional.\n",
    "            source_format=bigquery.SourceFormat.CSV,\n",
    "        )\n",
    "        print(f\"Loading {gcs_uri} into {table_id}\")\n",
    "        load_job = client.load_table_from_uri(\n",
    "            gcs_uri, table_id, job_config=job_config\n",
    "        )  # Make an API request.\n",
    "\n",
    "        load_job.result()  # Waits for the job to complete.\n",
    "        destination_table = client.get_table(table_id)  # Make an API request.\n",
    "        print(\"Loaded {} rows.\".format(destination_table.num_rows))\n",
    "\n",
    "    def create_dataset_if_not_exist(bq_dataset_id, bq_location):\n",
    "        print(\n",
    "            \"Checking for existence of bq dataset. If it does not exist, it creates one\"\n",
    "        )\n",
    "        dataset = bigquery.Dataset(bq_dataset_id)\n",
    "        dataset.location = bq_location\n",
    "        dataset = client.create_dataset(dataset, exists_ok=True, timeout=300)\n",
    "        print(f\"Created dataset {dataset.full_dataset_id} @ {dataset.location}\")\n",
    "\n",
    "    bq_dataset_id = f\"{project}.{bq_dataset}\"\n",
    "    create_dataset_if_not_exist(bq_dataset_id, bq_location)\n",
    "\n",
    "    raw_table_name = f\"{table_name_prefix}_raw\"\n",
    "    table_id = f\"{project}.{bq_dataset}.{raw_table_name}\"\n",
    "    print(\"Deleting any tables that might have the same name on the dataset\")\n",
    "    client.delete_table(table_id, not_found_ok=True)\n",
    "    print(\"will load data to table\")\n",
    "    load_dataset(gcs_data_uri, table_id)\n",
    "\n",
    "    raw_dataset_uri = f\"bq://{table_id}\"\n",
    "    raw_dataset.uri = raw_dataset_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "637de8be"
   },
   "source": [
    "## 切割数据集\n",
    "\n",
    "将数据集切分为3个部分：\n",
    "- 训练集\n",
    "- 评估集\n",
    "- 测试集\n",
    "\n",
    "AutoML和BigQuery ML在数据切分方面使用不同的术语：\n",
    "\n",
    "#### BQML\n",
    "BQML如何切分数据：[链接](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-hyperparameter-tuning#data_split)\n",
    "\n",
    "#### AutoML\n",
    "AutoML如何切分数据：[链接](https://cloud.google.com/vertex-ai/docs/general/ml-use?hl=da&skip_cache=false)\n",
    "\n",
    "<ul>\n",
    "    <li>模型训练\n",
    "<p>训练集用于训练具有不同的预处理、架构和超参数选项组合的模型。这些模型在验证集上进行质量评估，指导探索其他选项组合。在并行调整阶段确定的最佳参数和架构用于训练下面描述的两个整体模型。</p></li>\n",
    "\n",
    "<li>模型评估\n",
    "<p>\n",
    "Vertex AI使用训练和验证集作为训练数据来训练评估模型。Vertex AI使用测试集在该模型上生成最终模型评估指标。这是该过程中首次使用测试集。这种方法确保最终评估指标是对最终训练模型在生产环境中性能如何的无偏反映。</p></li>\n",
    "\n",
    "<li>服务模型\n",
    "<p>使用训练、验证和测试集来训练一个模型，以最大化训练数据量。这个模型是您用来请求预测的模型。</p></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8cf0a61c"
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\"google-cloud-bigquery\"],\n",
    ")  # pandas, pyarrow and fsspec required to export bq data to csv\n",
    "def split_datasets(\n",
    "    raw_dataset: Input[Artifact],\n",
    "    bq_location: str,\n",
    ") -> NamedTuple(\n",
    "    \"bqml_split\",\n",
    "    [\n",
    "        (\"dataset_uri\", str),\n",
    "        (\"dataset_bq_uri\", str),\n",
    "        (\"test_dataset_uri\", str),\n",
    "    ],\n",
    "):\n",
    "\n",
    "    from collections import namedtuple\n",
    "\n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    raw_dataset_uri = raw_dataset.uri\n",
    "    table_name = raw_dataset_uri.split(\"bq://\")[-1]\n",
    "    print(table_name)\n",
    "    raw_dataset_uri = table_name.split(\".\")\n",
    "    print(raw_dataset_uri)\n",
    "    project = raw_dataset_uri[0]\n",
    "    bq_dataset = raw_dataset_uri[1]\n",
    "    bq_raw_table = raw_dataset_uri[2]\n",
    "\n",
    "    client = bigquery.Client(project=project, location=bq_location)\n",
    "\n",
    "    def split_dataset(table_name_dataset):\n",
    "        training_dataset_table_name = f\"{project}.{bq_dataset}.{table_name_dataset}\"\n",
    "        split_query = f\"\"\"\n",
    "        CREATE OR REPLACE TABLE\n",
    "            `{training_dataset_table_name}`\n",
    "           AS\n",
    "        SELECT\n",
    "          Sex,\n",
    "          Length,\n",
    "          Diameter,\n",
    "          Height,\n",
    "          Whole_weight,\n",
    "          Shucked_weight,\n",
    "          Viscera_weight,\n",
    "          Shell_weight,\n",
    "          Rings,\n",
    "            CASE(ABS(MOD(FARM_FINGERPRINT(TO_JSON_STRING(f)), 10)))\n",
    "              WHEN 9 THEN 'TEST'\n",
    "              WHEN 8 THEN 'VALIDATE'\n",
    "              ELSE 'TRAIN' END AS split_col\n",
    "        FROM\n",
    "          `{project}.{bq_dataset}.abalone_raw` f\n",
    "        \"\"\"\n",
    "        dataset_uri = f\"{project}.{bq_dataset}.{bq_raw_table}\"\n",
    "        print(\"Splitting the dataset\")\n",
    "        query_job = client.query(split_query)  # Make an API request.\n",
    "        query_job.result()\n",
    "        print(dataset_uri)\n",
    "        print(split_query.replace(\"\\n\", \" \"))\n",
    "        return training_dataset_table_name\n",
    "\n",
    "    def create_test_view(training_dataset_table_name, test_view_name=\"dataset_test\"):\n",
    "        view_uri = f\"{project}.{bq_dataset}.{test_view_name}\"\n",
    "        query = f\"\"\"\n",
    "             CREATE OR REPLACE VIEW `{view_uri}` AS SELECT\n",
    "          Sex,\n",
    "          Length,\n",
    "          Diameter,\n",
    "          Height,\n",
    "          Whole_weight,\n",
    "          Shucked_weight,\n",
    "          Viscera_weight,\n",
    "          Shell_weight,\n",
    "          Rings \n",
    "          FROM `{training_dataset_table_name}`  f\n",
    "          WHERE \n",
    "          f.split_col = 'TEST'\n",
    "          \"\"\"\n",
    "        print(f\"Creating view for --> {test_view_name}\")\n",
    "        print(query.replace(\"\\n\", \" \"))\n",
    "        query_job = client.query(query)  # Make an API request.\n",
    "        query_job.result()\n",
    "        return view_uri\n",
    "\n",
    "    table_name_dataset = \"dataset\"\n",
    "\n",
    "    dataset_uri = split_dataset(table_name_dataset)\n",
    "    test_dataset_uri = create_test_view(dataset_uri)\n",
    "    dataset_bq_uri = \"bq://\" + dataset_uri\n",
    "\n",
    "    print(f\"dataset: {dataset_uri}\")\n",
    "\n",
    "    result_tuple = namedtuple(\n",
    "        \"bqml_split\",\n",
    "        [\"dataset_uri\", \"dataset_bq_uri\", \"test_dataset_uri\"],\n",
    "    )\n",
    "    return result_tuple(\n",
    "        dataset_uri=str(dataset_uri),\n",
    "        dataset_bq_uri=str(dataset_bq_uri),\n",
    "        test_dataset_uri=str(test_dataset_uri),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5e5d1785"
   },
   "source": [
    "### 训练BQML模型\n",
    "\n",
    "对于这个演示，我们在BQML上使用简单的线性回归模型。然而，您也可以尝试其他的模型架构，如深度神经网络、XGboost、逻辑回归等。\n",
    "\n",
    "要查看BQML支持的所有模型的完整列表，请看这里：[每个模型的端到端用户旅程](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-e2e-journey)。\n",
    "\n",
    "正如之前指出的，BQML和AutoML使用不同的拆分术语，因此我们在CREATE model查询的SELECT部分直接进行<i>split_col</i>列的调整：\n",
    "\n",
    "> 当DATA_SPLIT_METHOD的值为'CUSTOM'时，相应的列应该是BOOL类型。带有TRUE或NULL值的行将用作评估数据。带有FALSE值的行将用作训练数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "802ee37d"
   },
   "outputs": [],
   "source": [
    "def _query_create_model(\n",
    "    project_id: str,\n",
    "    bq_dataset: str,\n",
    "    training_data_uri: str,\n",
    "    model_name: str = \"linear_regression_model_prototyping\",\n",
    "):\n",
    "    model_uri = f\"{project_id}.{bq_dataset}.{model_name}\"\n",
    "\n",
    "    model_options = \"\"\"OPTIONS\n",
    "      ( MODEL_TYPE='LINEAR_REG',\n",
    "        input_label_cols=['Rings'],\n",
    "         DATA_SPLIT_METHOD='CUSTOM',\n",
    "        DATA_SPLIT_COL='split_col'\n",
    "        )\n",
    "        \"\"\"\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE MODEL\n",
    "      `{model_uri}`\n",
    "      {model_options}\n",
    "     AS\n",
    "    SELECT\n",
    "      Sex,\n",
    "      Length,\n",
    "      Diameter,\n",
    "      Height,\n",
    "      Whole_weight,\n",
    "      Shucked_weight,\n",
    "      Viscera_weight,\n",
    "      Shell_weight,\n",
    "      Rings,\n",
    "      CASE(split_col)\n",
    "        WHEN 'TEST' THEN TRUE\n",
    "      ELSE\n",
    "      FALSE\n",
    "    END\n",
    "      AS split_col\n",
    "    FROM\n",
    "      `{training_data_uri}`;\n",
    "    \"\"\"\n",
    "\n",
    "    print(query.replace(\"\\n\", \" \"))\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3332263db93e"
   },
   "source": [
    "### 解释BQML模型评估\n",
    "\n",
    "当您在模型创建查询上进行超参数调优时，预先构建的组件[BigqueryEvaluateModelJobOp](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-1.0.0/google_cloud_pipeline_components.experimental.bigquery.html#google_cloud_pipeline_components.experimental.bigquery.BigqueryEvaluateModelJobOp)的输出将是一个表格，其中包含BQML在训练模型时获得的指标。在您的BigQuery控制台中，它们看起来像下面的图片。我们需要以编程方式访问它们，以便我们可以将它们与AutoML模型进行比较。\n",
    "\n",
    "下面的单元格显示了如何完成这一操作的示例。BQML不会在指标列表中提供均方根误差，所以我们手动将其添加到指标字典中。有关输出的更多信息，请查看[BQML文档](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate#mlevaluate_output)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae09c98b32dd"
   },
   "outputs": [],
   "source": [
    "@component(base_image=\"python:3.9\")\n",
    "def interpret_bqml_evaluation_metrics(\n",
    "    bqml_evaluation_metrics: Input[Artifact], metrics: Output[Metrics]\n",
    ") -> dict:\n",
    "    import math\n",
    "\n",
    "    metadata = bqml_evaluation_metrics.metadata\n",
    "    for r in metadata[\"rows\"]:\n",
    "\n",
    "        rows = r[\"f\"]\n",
    "        schema = metadata[\"schema\"][\"fields\"]\n",
    "\n",
    "        output = {}\n",
    "        for metric, value in zip(schema, rows):\n",
    "            metric_name = metric[\"name\"]\n",
    "            val = float(value[\"v\"])\n",
    "            output[metric_name] = val\n",
    "            metrics.log_metric(metric_name, val)\n",
    "            if metric_name == \"mean_squared_error\":\n",
    "                rmse = math.sqrt(val)\n",
    "                metrics.log_metric(\"root_mean_squared_error\", rmse)\n",
    "\n",
    "    metrics.log_metric(\"framework\", \"BQML\")\n",
    "\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5bd1715e98a"
   },
   "source": [
    "### 解释 AutoML 模型评估\n",
    "\n",
    "类似于 BQML，AutoML 在模型创建过程中也会生成指标。可以在以下 UI 中查看这些指标：\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/rafacarv-public-bucket-do-not-delete/abalone/automl-evaluate.png\" />\n",
    "\n",
    "由于我们没有预构建组件来以编程方式访问这些指标，我们可以使用 Vertex AI GAPIC（Google API Compiler），这将自动生成服务的低级 gRPC 接口。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0f2927e"
   },
   "outputs": [],
   "source": [
    "# Inspired by Andrew Ferlitsch's work on https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage3/get_started_with_automl_pipeline_components.ipynb\n",
    "\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        \"google-cloud-aiplatform\",\n",
    "    ],\n",
    ")\n",
    "def interpret_automl_evaluation_metrics(\n",
    "    region: str, model: Input[Artifact], metrics: Output[Metrics]\n",
    "):\n",
    "    \"\"\"'\n",
    "    For a list of available regression metrics, go here: gs://google-cloud-aiplatform/schema/modelevaluation/regression_metrics_1.0.0.yaml.\n",
    "\n",
    "    More information on available metrics for different types of models: https://cloud.google.com/vertex-ai/docs/predictions/online-predictions-automl\n",
    "    \"\"\"\n",
    "\n",
    "    import google.cloud.aiplatform.gapic as gapic\n",
    "\n",
    "    # Get a reference to the Model Service client\n",
    "    client_options = {\"api_endpoint\": f\"{region}-aiplatform.googleapis.com\"}\n",
    "\n",
    "    model_service_client = gapic.ModelServiceClient(client_options=client_options)\n",
    "\n",
    "    model_resource_name = model.metadata[\"resourceName\"]\n",
    "\n",
    "    model_evaluations = model_service_client.list_model_evaluations(\n",
    "        parent=model_resource_name\n",
    "    )\n",
    "    model_evaluation = list(model_evaluations)[0]\n",
    "\n",
    "    available_metrics = [\n",
    "        \"meanAbsoluteError\",\n",
    "        \"meanAbsolutePercentageError\",\n",
    "        \"rSquared\",\n",
    "        \"rootMeanSquaredError\",\n",
    "        \"rootMeanSquaredLogError\",\n",
    "    ]\n",
    "    output = dict()\n",
    "    for x in available_metrics:\n",
    "        val = model_evaluation.metrics.get(x)\n",
    "        output[x] = val\n",
    "        metrics.log_metric(str(x), float(val))\n",
    "\n",
    "    metrics.log_metric(\"framework\", \"AutoML\")\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7421c559"
   },
   "source": [
    "模型选择\n",
    "\n",
    "现在我们已经独立评估了模型，我们将只选择其中一个继续前进。此次选举将基于在前几步中收集的模型评估指标来进行。\n",
    "\n",
    "请注意，BigQuery ML和AutoML使用不同的评估指标名称，因此我们需要对这些不同的术语进行映射。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20d363d9"
   },
   "outputs": [],
   "source": [
    "@component(base_image=\"python:3.9\")\n",
    "def select_best_model(\n",
    "    metrics_bqml: Input[Metrics],\n",
    "    metrics_automl: Input[Metrics],\n",
    "    thresholds_dict_str: str,\n",
    "    best_metrics: Output[Metrics],\n",
    "    reference_metric_name: str = \"rmse\",\n",
    ") -> NamedTuple(\n",
    "    \"Outputs\",\n",
    "    [\n",
    "        (\"deploy_decision\", str),\n",
    "        (\"best_model\", str),\n",
    "        (\"metric\", float),\n",
    "        (\"metric_name\", str),\n",
    "    ],\n",
    "):\n",
    "    import json\n",
    "    from collections import namedtuple\n",
    "\n",
    "    best_metric = float(\"inf\")\n",
    "    best_model = None\n",
    "\n",
    "    # BQML and AutoML use different metric names.\n",
    "    metric_possible_names = []\n",
    "\n",
    "    if reference_metric_name == \"mae\":\n",
    "        metric_possible_names = [\"meanAbsoluteError\", \"mean_absolute_error\"]\n",
    "    elif reference_metric_name == \"rmse\":\n",
    "        metric_possible_names = [\"rootMeanSquaredError\", \"root_mean_squared_error\"]\n",
    "\n",
    "    metric_bqml = float(\"inf\")\n",
    "    metric_automl = float(\"inf\")\n",
    "    print(metrics_bqml.metadata)\n",
    "    print(metrics_automl.metadata)\n",
    "    for x in metric_possible_names:\n",
    "\n",
    "        try:\n",
    "            metric_bqml = metrics_bqml.metadata[x]\n",
    "            print(f\"Metric bqml: {metric_bqml}\")\n",
    "        except:\n",
    "            print(f\"{x} does not exist int the BQML dictionary\")\n",
    "\n",
    "        try:\n",
    "            metric_automl = metrics_automl.metadata[x]\n",
    "            print(f\"Metric automl: {metric_automl}\")\n",
    "        except:\n",
    "            print(f\"{x} does not exist on the AutoML dictionary\")\n",
    "\n",
    "    # Change condition if higher is better.\n",
    "    print(f\"Comparing BQML ({metric_bqml}) vs AutoML ({metric_automl})\")\n",
    "    if metric_bqml <= metric_automl:\n",
    "        best_model = \"bqml\"\n",
    "        best_metric = metric_bqml\n",
    "        best_metrics.metadata = metrics_bqml.metadata\n",
    "    else:\n",
    "        best_model = \"automl\"\n",
    "        best_metric = metric_automl\n",
    "        best_metrics.metadata = metrics_automl.metadata\n",
    "\n",
    "    thresholds_dict = json.loads(thresholds_dict_str)\n",
    "    deploy = False\n",
    "\n",
    "    # Change condition if higher is better.\n",
    "    if best_metric < thresholds_dict[reference_metric_name]:\n",
    "        deploy = True\n",
    "\n",
    "    if deploy:\n",
    "        deploy_decision = \"true\"\n",
    "    else:\n",
    "        deploy_decision = \"false\"\n",
    "\n",
    "    print(f\"Which model is best? {best_model}\")\n",
    "    print(f\"What metric is being used? {reference_metric_name}\")\n",
    "    print(f\"What is the best metric? {best_metric}\")\n",
    "    print(f\"What is the threshold to deploy? {thresholds_dict_str}\")\n",
    "    print(f\"Deploy decision: {deploy_decision}\")\n",
    "\n",
    "    Outputs = namedtuple(\n",
    "        \"Outputs\", [\"deploy_decision\", \"best_model\", \"metric\", \"metric_name\"]\n",
    "    )\n",
    "\n",
    "    return Outputs(\n",
    "        deploy_decision=deploy_decision,\n",
    "        best_model=best_model,\n",
    "        metric=best_metric,\n",
    "        metric_name=reference_metric_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f573556"
   },
   "source": [
    "### 验证基础设施\n",
    "\n",
    "一旦部署了最佳模型，您可以通过向其进行简单预测来验证端点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aa1bab55"
   },
   "outputs": [],
   "source": [
    "@component(base_image=\"python:3.9\", packages_to_install=[\"google-cloud-aiplatform\"])\n",
    "def validate_infrastructure(\n",
    "    endpoint: Input[Artifact],\n",
    ") -> NamedTuple(\n",
    "    \"validate_infrastructure_output\", [(\"instance\", str), (\"prediction\", float)]\n",
    "):\n",
    "    import json\n",
    "    from collections import namedtuple\n",
    "\n",
    "    from google.cloud import aiplatform\n",
    "    from google.protobuf import json_format\n",
    "    from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "    def treat_uri(uri):\n",
    "        return uri[uri.find(\"projects/\") :]\n",
    "\n",
    "    def request_prediction(endp, instance):\n",
    "        instance = json_format.ParseDict(instance, Value())\n",
    "        instances = [instance]\n",
    "        parameters_dict = {}\n",
    "        parameters = json_format.ParseDict(parameters_dict, Value())\n",
    "        response = endp.predict(instances=instances, parameters=parameters)\n",
    "        print(\"deployed_model_id:\", response.deployed_model_id)\n",
    "        print(\"predictions: \", response.predictions)\n",
    "        # The predictions are a google.protobuf.Value representation of the model's predictions.\n",
    "        predictions = response.predictions\n",
    "\n",
    "        for pred in predictions:\n",
    "            if type(pred) is dict and \"value\" in pred.keys():\n",
    "                # AutoML predictions\n",
    "                prediction = pred[\"value\"]\n",
    "            elif type(pred) is list:\n",
    "                # BQML Predictions return different format\n",
    "                prediction = pred[0]\n",
    "            return prediction\n",
    "\n",
    "    endpoint_uri = endpoint.uri\n",
    "    treated_uri = treat_uri(endpoint_uri)\n",
    "\n",
    "    instance = {\n",
    "        \"Sex\": \"M\",\n",
    "        \"Length\": 0.33,\n",
    "        \"Diameter\": 0.255,\n",
    "        \"Height\": 0.08,\n",
    "        \"Whole_weight\": 0.205,\n",
    "        \"Shucked_weight\": 0.0895,\n",
    "        \"Viscera_weight\": 0.0395,\n",
    "        \"Shell_weight\": 0.055,\n",
    "    }\n",
    "    instance_json = json.dumps(instance)\n",
    "    print(\"Will use the following instance: \" + instance_json)\n",
    "\n",
    "    endpoint = aiplatform.Endpoint(treated_uri)\n",
    "    prediction = request_prediction(endpoint, instance)\n",
    "    result_tuple = namedtuple(\n",
    "        \"validate_infrastructure_output\", [\"instance\", \"prediction\"]\n",
    "    )\n",
    "\n",
    "    return result_tuple(instance=str(instance_json), prediction=float(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpB_bdDbGGOp"
   },
   "source": [
    "## 管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5PsR31ysGuj"
   },
   "outputs": [],
   "source": [
    "pipeline_params = {\n",
    "    \"project\": PROJECT_ID,\n",
    "    \"region\": REGION,\n",
    "    \"gcs_input_file_uri\": RAW_INPUT_DATA,\n",
    "    \"bq_dataset\": BQ_DATASET,\n",
    "    \"bq_location\": BQ_LOCATION,\n",
    "    \"bqml_model_export_location\": BQML_EXPORT_LOCATION,\n",
    "    \"bqml_serving_container_image_uri\": BQML_SERVING_CONTAINER_IMAGE_URI,\n",
    "    \"endpoint_display_name\": ENDPOINT_DISPLAY_NAME,\n",
    "    \"thresholds_dict_str\": '{\"rmse\": 2.5}',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f64ccb39400b"
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=DISPLAY_NAME, description=\"Rapid Prototyping\")\n",
    "def train_pipeline(\n",
    "    project: str,\n",
    "    gcs_input_file_uri: str,\n",
    "    region: str,\n",
    "    bq_dataset: str,\n",
    "    bq_location: str,\n",
    "    bqml_model_export_location: str,\n",
    "    bqml_serving_container_image_uri: str,\n",
    "    endpoint_display_name: str,\n",
    "    thresholds_dict_str: str,\n",
    "):\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    from kfp.dsl import importer_node\n",
    "\n",
    "    # Imports data to BigQuery using a custom component.\n",
    "    import_data_to_bigquery_op = import_data_to_bigquery(\n",
    "        project=project,\n",
    "        bq_location=bq_location,\n",
    "        bq_dataset=bq_dataset,\n",
    "        gcs_data_uri=gcs_input_file_uri,\n",
    "    )\n",
    "    raw_dataset = import_data_to_bigquery_op.outputs[\"raw_dataset\"]\n",
    "\n",
    "    # Splits the BQ dataset using a custom component.\n",
    "    split_datasets_op = split_datasets(raw_dataset=raw_dataset, bq_location=bq_location)\n",
    "\n",
    "    # Generates the query to create a BQML using a static function.\n",
    "    create_model_query = _query_create_model(\n",
    "        project_id=project,\n",
    "        bq_dataset=bq_dataset,\n",
    "        training_data_uri=split_datasets_op.outputs[\"dataset_uri\"],\n",
    "    )\n",
    "\n",
    "    # Builds BQML model using pre-built-component.\n",
    "    bqml_create_op = bq_components.BigqueryCreateModelJobOp(\n",
    "        project=project, location=bq_location, query=create_model_query\n",
    "    )\n",
    "    bqml_model = bqml_create_op.outputs[\"model\"]\n",
    "\n",
    "    # Gathers BQML evaluation metrics using a pre-built-component.\n",
    "    bqml_evaluate_op = bq_components.BigqueryEvaluateModelJobOp(\n",
    "        project=project, location=bq_location, model=bqml_model\n",
    "    )\n",
    "    bqml_eval_metrics_raw = bqml_evaluate_op.outputs[\"evaluation_metrics\"]\n",
    "\n",
    "    # Analyzes evaluation BQML metrics using a custom component.\n",
    "    interpret_bqml_evaluation_metrics_op = interpret_bqml_evaluation_metrics(\n",
    "        bqml_evaluation_metrics=bqml_eval_metrics_raw\n",
    "    )\n",
    "    bqml_eval_metrics = interpret_bqml_evaluation_metrics_op.outputs[\"metrics\"]\n",
    "\n",
    "    # Exports the BQML model to a GCS bucket using a pre-built-component.\n",
    "    bqml_export_op = bq_components.BigqueryExportModelJobOp(\n",
    "        project=project,\n",
    "        location=bq_location,\n",
    "        model=bqml_model,\n",
    "        model_destination_path=bqml_model_export_location,\n",
    "    ).after(bqml_evaluate_op)\n",
    "    bqml_exported_gcs_path = bqml_export_op.outputs[\"exported_model_path\"]\n",
    "\n",
    "    unmanaged_model_importer = importer_node.importer(\n",
    "        artifact_uri=bqml_exported_gcs_path,\n",
    "        artifact_class=artifact_types.UnmanagedContainerModel,\n",
    "        metadata={\n",
    "            \"containerSpec\": {\n",
    "                \"imageUri\": \"us-docker.pkg.dev/cloud-aiplatform/prediction/tf2-cpu.2-3:latest\"\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Uploads the recently exported the BQML model from GCS into Vertex AI using a pre-built-component.\n",
    "    bqml_model_upload_op = ModelUploadOp(\n",
    "        project=project,\n",
    "        location=region,\n",
    "        display_name=DISPLAY_NAME + \"_bqml\",\n",
    "        unmanaged_container_model=unmanaged_model_importer.outputs[\"artifact\"],\n",
    "    )\n",
    "    bqml_vertex_model = bqml_model_upload_op.outputs[\"model\"]\n",
    "\n",
    "    # Creates a Vertex AI Tabular dataset using a pre-built-component.\n",
    "    dataset_create_op = TabularDatasetCreateOp(\n",
    "        project=project,\n",
    "        location=region,\n",
    "        display_name=DISPLAY_NAME,\n",
    "        bq_source=split_datasets_op.outputs[\"dataset_bq_uri\"],\n",
    "    )\n",
    "\n",
    "    # Trains an AutoML Tables model using a pre-built-component.\n",
    "    automl_training_op = AutoMLTabularTrainingJobRunOp(\n",
    "        project=project,\n",
    "        location=region,\n",
    "        display_name=f\"{DISPLAY_NAME}_automl\",\n",
    "        optimization_prediction_type=\"regression\",\n",
    "        optimization_objective=\"minimize-rmse\",\n",
    "        predefined_split_column_name=\"split_col\",\n",
    "        dataset=dataset_create_op.outputs[\"dataset\"],\n",
    "        target_column=\"Rings\",\n",
    "        column_transformations=[\n",
    "            {\"categorical\": {\"column_name\": \"Sex\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Length\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Diameter\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Height\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Whole_weight\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Shucked_weight\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Viscera_weight\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Shell_weight\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Rings\"}},\n",
    "        ],\n",
    "    )\n",
    "    automl_model = automl_training_op.outputs[\"model\"]\n",
    "\n",
    "    # Analyzes evaluation AutoML metrics using a custom component.\n",
    "    automl_eval_op = interpret_automl_evaluation_metrics(\n",
    "        region=region, model=automl_model\n",
    "    )\n",
    "    automl_eval_metrics = automl_eval_op.outputs[\"metrics\"]\n",
    "\n",
    "    # 1) Decides which model is best (AutoML vs BQML);\n",
    "    # 2) Determines if the best model meets the deployment condition.\n",
    "    best_model_task = select_best_model(\n",
    "        metrics_bqml=bqml_eval_metrics,\n",
    "        metrics_automl=automl_eval_metrics,\n",
    "        thresholds_dict_str=thresholds_dict_str,\n",
    "    )\n",
    "\n",
    "    # If the deploy condition is True, then deploy the best model.\n",
    "    with dsl.Condition(\n",
    "        best_model_task.outputs[\"deploy_decision\"] == \"true\",\n",
    "        name=\"deploy_decision\",\n",
    "    ):\n",
    "        # Creates a Vertex AI endpoint using a pre-built-component.\n",
    "        endpoint_create_op = EndpointCreateOp(\n",
    "            project=project,\n",
    "            location=region,\n",
    "            display_name=endpoint_display_name,\n",
    "        )\n",
    "        endpoint_create_op.after(best_model_task)\n",
    "\n",
    "        # In case the BQML model is the best...\n",
    "        with dsl.Condition(\n",
    "            best_model_task.outputs[\"best_model\"] == \"bqml\",\n",
    "            name=\"deploy_bqml\",\n",
    "        ):\n",
    "            # Deploys the BQML model (now on Vertex AI) to the recently created endpoint using a pre-built component.\n",
    "            model_deploy_bqml_op = ModelDeployOp(  # noqa: F841\n",
    "                endpoint=endpoint_create_op.outputs[\"endpoint\"],\n",
    "                model=bqml_vertex_model,\n",
    "                deployed_model_display_name=DISPLAY_NAME + \"_best_bqml\",\n",
    "                dedicated_resources_machine_type=\"n1-standard-2\",\n",
    "                dedicated_resources_min_replica_count=2,\n",
    "                dedicated_resources_max_replica_count=2,\n",
    "                traffic_split={\n",
    "                    \"0\": 100\n",
    "                },  # newly deployed model gets 100% of the traffic\n",
    "            ).set_caching_options(False)\n",
    "\n",
    "            # Sends an online prediction request to the recently deployed model using a custom component.\n",
    "            validate_infrastructure(\n",
    "                endpoint=endpoint_create_op.outputs[\"endpoint\"]\n",
    "            ).set_caching_options(False).after(model_deploy_bqml_op)\n",
    "\n",
    "        # In case the AutoML model is the best...\n",
    "        with dsl.Condition(\n",
    "            best_model_task.outputs[\"best_model\"] == \"automl\",\n",
    "            name=\"deploy_automl\",\n",
    "        ):\n",
    "            # Deploys the AutoML model to the recently created endpoint using a pre-built component.\n",
    "            model_deploy_automl_op = ModelDeployOp(  # noqa: F841\n",
    "                endpoint=endpoint_create_op.outputs[\"endpoint\"],\n",
    "                model=automl_model,\n",
    "                deployed_model_display_name=DISPLAY_NAME + \"_best_automl\",\n",
    "                dedicated_resources_machine_type=\"n1-standard-2\",\n",
    "                dedicated_resources_min_replica_count=2,\n",
    "                dedicated_resources_max_replica_count=2,\n",
    "                traffic_split={\n",
    "                    \"0\": 100\n",
    "                },  # newly deployed model gets 100% of the traffic\n",
    "            ).set_caching_options(False)\n",
    "\n",
    "            # Sends an online prediction request to the recently deployed model using a custom component.\n",
    "            validate_infrastructure(\n",
    "                endpoint=endpoint_create_op.outputs[\"endpoint\"]\n",
    "            ).set_caching_options(False).after(model_deploy_automl_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxfy-pXXGS3R"
   },
   "source": [
    "### 运行管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLeS1xRpGYPx"
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=train_pipeline,\n",
    "    package_path=PIPELINE_YAML_PKG_PATH,\n",
    ")\n",
    "\n",
    "\n",
    "vertex.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "pipeline_job = vertex.PipelineJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    template_path=PIPELINE_YAML_PKG_PATH,\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values=pipeline_params,\n",
    "    enable_caching=False,\n",
    ")\n",
    "\n",
    "response = pipeline_job.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f49899d5e838"
   },
   "source": [
    "等待管道完成\n",
    "\n",
    "目前，您的管道通过使用`submit()`方法异步运行。要以同步方式运行它，您需要调用`run()`方法。\n",
    "\n",
    "在这最后一步中，您会通过使用`wait()`方法阻塞在异步执行的任务等待完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vo0hPcsraVIt"
   },
   "outputs": [],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGKH0lKwz7Ci"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有 Google Cloud 资源，您可以[删除用于本教程的 Google Cloud 项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41229df87d23"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "vertex.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "delete_bucket = False\n",
    "\n",
    "print(\"Will delete endpoint\")\n",
    "endpoints = vertex.Endpoint.list(\n",
    "    filter=f\"display_name={DISPLAY_NAME}_endpoint\", order_by=\"create_time\"\n",
    ")\n",
    "endpoint = endpoints[0]\n",
    "endpoint.undeploy_all()\n",
    "vertex.Endpoint.delete(endpoint)\n",
    "print(\"Deleted endpoint:\", endpoint)\n",
    "\n",
    "print(\"Will delete models\")\n",
    "suffix_list = [\"bqml\", \"automl\"]\n",
    "for suffix in suffix_list:\n",
    "    try:\n",
    "        model_display_name = f\"{DISPLAY_NAME}_{suffix}\"\n",
    "        print(\"Will delete model with name \" + model_display_name)\n",
    "        models = vertex.Model.list(\n",
    "            filter=f\"display_name={model_display_name}\", order_by=\"create_time\"\n",
    "        )\n",
    "\n",
    "        model = models[0]\n",
    "        vertex.Model.delete(model)\n",
    "        print(\"Deleted model:\", model)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "print(\"Will delete Vertex dataset\")\n",
    "datasets = vertex.TabularDataset.list(\n",
    "    filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    ")\n",
    "\n",
    "dataset = datasets[0]\n",
    "vertex.TabularDataset.delete(dataset)\n",
    "print(\"Deleted Vertex dataset:\", dataset)\n",
    "\n",
    "\n",
    "pipelines = vertex.PipelineJob.list(\n",
    "    filter=f\"pipeline_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    ")\n",
    "pipeline = pipelines[0]\n",
    "vertex.PipelineJob.delete(pipeline)\n",
    "print(\"Deleted pipeline:\", pipeline)\n",
    "\n",
    "delete_dataset = True\n",
    "\n",
    "# delete dataset\n",
    "if delete_dataset or os.getenv(\"IS_TESTING\"):\n",
    "    ! bq rm -r -f -d $PROJECT_ID:$BQ_DATASET\n",
    "\n",
    "dataset_id = f\"{PROJECT_ID}.{BQ_DATASET}\"\n",
    "print(f\"Deleted BQ dataset '{dataset_id}' from location {BQ_LOCATION}.\")\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rapid_prototyping_bqml_automl.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
