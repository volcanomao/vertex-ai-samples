{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# 使用自定义训练容器和模型的自定义训练\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/custom/custom_training_container_and_model_registry.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "        <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/custom/custom_training_container_and_model_registry.ipynb\">\n",
    "        <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "        </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/custom/custom_training_container_and_model_registry.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:custom,training,custom_container"
   },
   "source": [
    "## 概览\n",
    "\n",
    "本教程演示了如何使用Vertex AI SDK使用自定义容器进行训练，并自动注册模型。\n",
    "\n",
    "了解更多关于[自定义训练](https://cloud.google.com/vertex-ai/docs/training/custom-training)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:custom,training,custom_container,online_prediction"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将使用 Vertex AI SDK 在自定义的 Docker 容器中从 Python 脚本创建自定义模型，并自动将该模型注册到 Vertex AI 模型注册表中。您也可以选择使用 `gcloud` 命令行工具或云控制台在线创建自定义模型。\n",
    "\n",
    "本教程使用以下 Google Cloud ML 服务和资源：\n",
    "\n",
    "- Vertex AI 模型注册表\n",
    "- Vertex AI 训练\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 创建一个用于训练模型的 Vertex AI 自定义作业。\n",
    "- 使用自定义容器训练和注册 TensorFlow 模型。\n",
    "- 从 Vertex AI 模型注册表中列出已注册的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:custom,cifar10,icn"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是来自[TensorFlow数据集](https://www.tensorflow.org/datasets/catalog/overview)中的[CIFAR10数据集](https://www.tensorflow.org/datasets/catalog/cifar10)。你将使用的数据集版本已经内置在TensorFlow中。训练好的模型会预测图像属于十种类别中的哪一种：飞机、汽车、鸟、猫、鹿、狗、青蛙、马、轮船、卡车。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "费用\n",
    "\n",
    "本教程使用 Google Cloud 中的可计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解 [Vertex AI\n",
    "定价](https://cloud.google.com/vertex-ai/pricing) 和 [Cloud Storage\n",
    "定价](https://cloud.google.com/storage/pricing)，并使用 [定价计算器](https://cloud.google.com/products/calculator/)\n",
    "根据您的预期使用情况生成费用估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ze4-nDLfK4pw"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装以下必要的软件包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b4ef9b72d43"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade google-cloud-aiplatform --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUw6ibN-n5Za"
   },
   "source": [
    "仅限Colab使用：取消注释以下单元格以重新启动内核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FM12wbWhn7w0"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgFWLeJfoGQu"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### 设置您的谷歌云项目\n",
    "\n",
    "**无论您使用的是笔记本环境，下面的步骤都是必须的。**\n",
    "\n",
    "1. [选择或创建谷歌云项目](https://console.cloud.google.com/cloud-resource-manager)。当您首次创建帐户时，您将获得300美元的免费信用额度，可用于计算/存储成本。\n",
    "\n",
    "2. [确保您的项目已启用计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "3. [启用 Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。\n",
    "\n",
    "4. 如果您在本地运行这个笔记本，您需要安装 [Cloud SDK](https://cloud.google.com/sdk)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ckyxpX_oSzD"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果你不知道你的项目ID**，请尝试以下操作：\n",
    "* 运行`gcloud config list`。\n",
    "* 运行`gcloud projects list`。\n",
    "* 查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zY8DKBoVoVy3"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSQjVQmMosMl"
   },
   "source": [
    "#### 区域\n",
    "\n",
    "您还可以更改 Vertex AI 使用的`REGION`变量。了解有关[Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfJRIMBpo5Pg"
   },
   "source": [
    "### 验证您的谷歌云账号\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动进行身份验证。请按照以下相关说明操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acFN0s3So9-Y"
   },
   "source": [
    "1. 顶点 AI 工作台\n",
    "* 无需操作，因为您已经经过身份验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ_mNwuapE5T"
   },
   "source": [
    "本地JupyterLab实例，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cR_MzpknpGgM"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-MuVI_ypJfw"
   },
   "source": [
    "3. 合作，取消注释并运行:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BeaQlCwMpQUT"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKtKGmr9pfr6"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产物，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "In3aQanwYjFB"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有在您的存储桶不存在时才能运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ankcS-vtp7Wv"
   },
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "初始化用于 Python 的 Vertex AI SDK\n",
    "\n",
    "为您的项目和对应的存储桶初始化 Python 的 Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,prediction,cpu,mbsdk"
   },
   "source": [
    "#### 设置硬件加速器\n",
    "\n",
    "您可以为训练和预测设置硬件加速器。\n",
    "\n",
    "设置变量 `TRAIN_GPU/TRAIN_NGPU` 来使用支持 GPU 的容器映像以及分配给虚拟机实例的 GPU 数量。例如，要使用一个包含 4 个 Nvidia Telsa K80 GPU 的 GPU 容器映像分配到每个 VM，您可以指定：\n",
    "\n",
    "    (aip.gapic.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
    "\n",
    "\n",
    "否则，指定 `(None, None)` 来使用一个在 CPU 上运行的容器映像。\n",
    "\n",
    "在此处了解更多有关您区域的硬件加速器支持信息：[在此处](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accelerators:training,prediction,cpu,mbsdk"
   },
   "outputs": [],
   "source": [
    "TRAIN_GPU, TRAIN_NGPU = (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:prediction"
   },
   "source": [
    "设置预构建的容器\n",
    "\n",
    "为预测设置预构建的Docker容器映像。\n",
    "\n",
    "- 将变量`TF`设置为容器映像的TensorFlow版本。例如，`2-1`表示版本2.1，`1-15`表示版本1.15。下面列出了一些可用的预构建映像：\n",
    "\n",
    "\n",
    "要获取最新列表，请参阅[用于预测的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:prediction"
   },
   "outputs": [],
   "source": [
    "TF = \"2-7\"\n",
    "\n",
    "DEPLOY_VERSION = \"tf2-cpu.{}\".format(TF)\n",
    "DEPLOY_IMAGE = \"gcr.io/cloud-aiplatform/prediction/{}:latest\".format(DEPLOY_VERSION)\n",
    "\n",
    "print(\"Deployment:\", DEPLOY_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training,prediction"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于训练和预测的机器类型。\n",
    "\n",
    "- 设置变量`TRAIN_COMPUTE`和`DEPLOY_COMPUTE`以配置用于训练和预测的虚拟机的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`：每个虚拟CPU的内存为3.75GB。\n",
    "     - `n1-highmem`：每个虚拟CPU的内存为6.5GB。\n",
    "     - `n1-highcpu`：每个虚拟CPU的内存为0.9GB。\n",
    " - `vCPUs`：数量为\\ [2, 4, 8, 16, 32, 64, 96 \\]\n",
    "\n",
    "*注意：以下内容不支持用于训练：*\n",
    "\n",
    " - `标准`：2个虚拟CPU\n",
    " - `高CPU`：2、4和8个虚拟CPU\n",
    "\n",
    "*注意：您也可以使用n2和e2机器类型进行训练和部署，但它们不支持GPU*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training,prediction"
   },
   "outputs": [],
   "source": [
    "TRAIN_COMPUTE = \"n1-standard-4\"\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tutorial_start:custom"
   },
   "source": [
    "# 教程\n",
    "\n",
    "现在你已经准备好开始创建自己的自定义模型并对CIFAR10进行训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_custom_model"
   },
   "source": [
    "## 训练模型\n",
    "\n",
    "您可以使用容器映像的两种方式来训练一个定制模型：\n",
    "\n",
    "- **使用 Google Cloud 预构建容器**。如果您使用预构建容器，您还需要指定要安装到容器映像中的 Python 软件包。这个 Python 软件包包含了您用于训练定制模型的代码。\n",
    "\n",
    "- **使用您自己的自定义容器映像**。如果您使用自己的容器，容器需要包含您用于训练定制模型的代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_docker_container:training"
   },
   "source": [
    "### 创建一个Docker文件\n",
    "\n",
    "在本教程中，您将使用自己的自定义容器训练一个CIFAR10模型。\n",
    "\n",
    "为了使用自己的自定义容器，您需要创建一个Docker文件。首先，您需要为容器组件创建一个目录。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_training_package"
   },
   "source": [
    "### 检查培训包\n",
    "\n",
    "#### 包布局\n",
    "\n",
    "在开始培训之前，您将看看如何为定制培训工作创建Python包。解压缩后，包含以下目录/文件布局。\n",
    "\n",
    "- PKG-INFO\n",
    "- README.md\n",
    "- setup.cfg\n",
    "- setup.py\n",
    "- trainer\n",
    "  - \\_\\_init\\_\\_.py\n",
    "  - task.py\n",
    "\n",
    "文件`setup.cfg`和`setup.py`包含了将包安装到Docker镜像的操作环境中的说明。\n",
    "\n",
    "文件`trainer/task.py`是执行定制培训工作的Python脚本。*注意*，当我们在worker pool规范中提到它时，我们用点(`trainer.task`)替换了目录斜杠，并去掉了文件后缀(`.py`)。\n",
    "\n",
    "#### 包组装\n",
    "\n",
    "在下面的单元格中，您将组装培训包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "examine_training_package"
   },
   "outputs": [],
   "source": [
    "# Make folder for Python training script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\nsetuptools.setup(\\n\\n    install_requires=[\\n\\n        'tensorflow_datasets==1.3.0',\\n\\n    ],\\n\\n    packages=setuptools.find_packages())\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\nName: CIFAR10 image classification\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taskpy_contents:cifar10"
   },
   "source": [
    "#### Task.py 文件内容\n",
    "\n",
    "在下一个单元格中，您可以编写训练脚本 task.py 的内容。我们不会详细说明，只是让您浏览一下。总结如下：\n",
    "\n",
    "- 从命令行获取保存模型工件的目录（`--model_dir`），如果未指定，则从环境变量 `AIP_MODEL_DIR` 中获取。\n",
    "- 从 TF 数据集（tfds）加载 CIFAR10 数据集。\n",
    "- 使用 TF.Keras 模型 API 构建模型。\n",
    "- 编译模型（`compile()`）。\n",
    "- 根据参数 `args.distribute` 设置训练分布策略。\n",
    "- 根据参数 `args.epochs` 和 `args.steps` 训练模型（`fit()`）。\n",
    "- 将训练后的模型保存（`save(args.model_dir)`）到指定的模型目录中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taskpy_contents:cifar10"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "# Single, Mirror and Multi-Machine Distributed Training for CIFAR-10\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model-dir', dest='model_dir',\n",
    "                    default=os.getenv(\"AIP_MODEL_DIR\"), type=str, help='Model dir.')\n",
    "parser.add_argument('--lr', dest='lr',\n",
    "                    default=0.01, type=float,\n",
    "                    help='Learning rate.')\n",
    "parser.add_argument('--epochs', dest='epochs',\n",
    "                    default=10, type=int,\n",
    "                    help='Number of epochs.')\n",
    "parser.add_argument('--steps', dest='steps',\n",
    "                    default=200, type=int,\n",
    "                    help='Number of steps per epoch.')\n",
    "parser.add_argument('--distribute', dest='distribute', type=str, default='single',\n",
    "                    help='distributed training strategy')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print('Python Version = {}'.format(sys.version))\n",
    "print('TensorFlow Version = {}'.format(tf.__version__))\n",
    "print('TF_CONFIG = {}'.format(os.environ.get('TF_CONFIG', 'Not found')))\n",
    "print('DEVICES', device_lib.list_local_devices())\n",
    "\n",
    "# Single Machine, single compute device\n",
    "if args.distribute == 'single':\n",
    "    if tf.test.is_gpu_available():\n",
    "        strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    else:\n",
    "        strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
    "# Single Machine, multiple compute device\n",
    "elif args.distribute == 'mirror':\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "# Multiple Machine, multiple compute device\n",
    "elif args.distribute == 'multi':\n",
    "    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "# Multi-worker configuration\n",
    "print('num_replicas_in_sync = {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Preparing dataset\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "def make_datasets_unbatched():\n",
    "\n",
    "  # Scaling CIFAR10 data from (0, 255] to (0., 1.]\n",
    "  def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.0\n",
    "    return image, label\n",
    "\n",
    "\n",
    "  datasets, info = tfds.load(name='cifar10',\n",
    "                            with_info=True,\n",
    "                            as_supervised=True)\n",
    "  return datasets['train'].map(scale).cache().shuffle(BUFFER_SIZE).repeat()\n",
    "\n",
    "\n",
    "# Build the Keras model\n",
    "def build_and_compile_cnn_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(32, 32, 3)),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "      optimizer=tf.keras.optimizers.SGD(learning_rate=args.lr),\n",
    "      metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "\n",
    "# Train the model\n",
    "NUM_WORKERS = strategy.num_replicas_in_sync\n",
    "# Here the batch size scales up by number of workers since\n",
    "# `tf.data.Dataset.batch` expects the global batch size.\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE * NUM_WORKERS\n",
    "train_dataset = make_datasets_unbatched().batch(GLOBAL_BATCH_SIZE)\n",
    "\n",
    "with strategy.scope():\n",
    "  # Creation of dataset, and model building/compiling need to be within\n",
    "  # `strategy.scope()`.\n",
    "  model = build_and_compile_cnn_model()\n",
    "\n",
    "model.fit(x=train_dataset, epochs=args.epochs, steps_per_epoch=args.steps)\n",
    "model.save(args.model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "write_docker_file:training,tf-dlvm"
   },
   "source": [
    "编写Docker文件内容\n",
    "\n",
    "将您的代码容器化的第一步是创建一个Docker文件。在您的Docker文件中，您将包含运行容器镜像所需的所有命令。它将安装您正在使用的所有库，并设置用于训练代码的入口点。\n",
    "\n",
    "1. 从TensorFlow仓库中安装预定义的深度学习图像容器。\n",
    "2. 复制Python训练代码，稍后将显示。\n",
    "3. 将入口点设置为Python训练脚本的`trainer/task.py`。注意，ENTRYPOINT命令中省略了`.py`，因为它是隐含的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "write_docker_file:training,tf-dlvm"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/Dockerfile\n",
    "\n",
    "FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-3\n",
    "WORKDIR /root\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY trainer /trainer\n",
    "\n",
    "# Sets up the entry point to invoke the trainer.\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "name_container:training"
   },
   "source": [
    "构建本地容器\n",
    "\n",
    "接下来，您将为您的客户容器提供一个名称，用于将其提交到Google容器注册表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "name_container:training"
   },
   "outputs": [],
   "source": [
    "TRAIN_IMAGE = \"gcr.io/\" + PROJECT_ID + \"/cifar10:v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "build_container:training"
   },
   "source": [
    "接下来，建造容器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "build_container:training"
   },
   "outputs": [],
   "source": [
    "! docker build custom -t $TRAIN_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_container:training"
   },
   "source": [
    "在本地测试容器\n",
    "\n",
    "在你的笔记本实例中运行容器，以确保它能正常工作。你将运行5个周期。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_container:training"
   },
   "outputs": [],
   "source": [
    "! docker run $TRAIN_IMAGE --epochs=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "register_container:training"
   },
   "source": [
    "注册自定义容器\n",
    "当您在本地完成运行容器之后，将其推送到Google容器注册表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "register_container:training"
   },
   "outputs": [],
   "source": [
    "! docker push $TRAIN_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tarball_training_script"
   },
   "source": [
    "将培训脚本存储在您的云存储桶中\n",
    "\n",
    "接下来，您将培训文件夹打包成压缩的tar球，然后存储在您的云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tarball_training_script"
   },
   "outputs": [],
   "source": [
    "! rm -f custom.tar custom.tar.gz\n",
    "! tar cvf custom.tar custom\n",
    "! gzip custom.tar\n",
    "! gsutil cp custom.tar.gz $BUCKET_URI/trainer_cifar10.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_training_job:mbsdk,no_model,custom"
   },
   "source": [
    "### 创建并运行自定义训练作业\n",
    "\n",
    "要训练一个自定义模型，您需要执行两个步骤：1) 创建一个自定义训练作业，2) 运行该作业。\n",
    "\n",
    "#### 创建自定义训练作业\n",
    "\n",
    "使用`CustomTrainingJob`类来创建一个自定义训练作业，需要设置以下参数：\n",
    "\n",
    "- `display_name`：自定义训练作业的可读名称。\n",
    "- `container_uri`：训练容器镜像。\n",
    "- `model_serving_container_image_uri`：用于部署模型的容器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_custom_training_job:mbsdk,no_model,custom"
   },
   "outputs": [],
   "source": [
    "job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=\"cifar10\",\n",
    "    container_uri=TRAIN_IMAGE,\n",
    "    model_serving_container_image_uri=DEPLOY_IMAGE,\n",
    ")\n",
    "\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prepare_custom_cmdargs"
   },
   "source": [
    "### 准备你的命令行参数\n",
    "\n",
    "现在为你的自定义训练容器定义命令行参数：\n",
    "\n",
    "- `args`：传递给设置为容器入口点的可执行文件的命令行参数。\n",
    "  - `--model-dir`：为了我们的演示，我们使用这个命令行参数来指定存储模型工件的位置。\n",
    "     - 直接：将Cloud Storage位置作为命令行参数传递给你的训练脚本（设置变量`DIRECT = True`），或者\n",
    "     - 间接：服务将Cloud Storage位置作为环境变量`AIP_MODEL_DIR`传递给你的训练脚本（设置变量`DIRECT = False`）。在这种情况下，你在作业规范中告诉服务模型工件的位置。\n",
    "  - `\"--epochs=\" + EPOCHS`：训练的周期数。\n",
    "  - `\"--steps=\" + STEPS`：每周期的步数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare_custom_cmdargs"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = \"{}/{}\".format(BUCKET_URI, \"model\")\n",
    "\n",
    "EPOCHS = 20\n",
    "STEPS = 100\n",
    "\n",
    "CMDARGS = [\n",
    "    \"--epochs=\" + str(EPOCHS),\n",
    "    \"--steps=\" + str(STEPS),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_custom_job:mbsdk,no_model"
   },
   "source": [
    "运行自定义训练作业\n",
    "\n",
    "接下来，通过调用方法 `run`，使用以下参数运行自定义作业来启动训练作业：\n",
    "\n",
    "- `args`: 要传递给训练脚本的命令行参数。\n",
    "- `replica_count`: 用于训练的计算实例数量（replica_count = 1 表示单节点训练）。\n",
    "- `machine_type`: 用于计算实例的机器类型。\n",
    "- `accelerator_type`: 硬件加速器类型。\n",
    "- `accelerator_count`: 要连接到工作副本的加速器数量。\n",
    "- `base_output_dir`: 用于写入模型工件的 Cloud 存储位置。\n",
    "- `model_display_name`: 注册模型的可读名称。\n",
    "- `sync`: 是否阻塞直到任务完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_custom_job:mbsdk,no_model"
   },
   "outputs": [],
   "source": [
    "if TRAIN_GPU:\n",
    "    model = job.run(\n",
    "        args=CMDARGS,\n",
    "        replica_count=1,\n",
    "        machine_type=TRAIN_COMPUTE,\n",
    "        accelerator_type=TRAIN_GPU.name,\n",
    "        accelerator_count=TRAIN_NGPU,\n",
    "        base_output_dir=MODEL_DIR,\n",
    "        model_display_name=\"cifar10\",\n",
    "        sync=True,\n",
    "    )\n",
    "else:\n",
    "    model = job.run(\n",
    "        args=CMDARGS,\n",
    "        replica_count=1,\n",
    "        machine_type=TRAIN_COMPUTE,\n",
    "        base_output_dir=MODEL_DIR,\n",
    "        model_display_name=\"cifar10\",\n",
    "        sync=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "929696a237fe"
   },
   "source": [
    "### 在模型注册表中查看模型\n",
    "\n",
    "最后，`run()` 方法将返回自动注册在模型注册表中的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33a1644f99f1"
   },
   "outputs": [],
   "source": [
    "print(model.gca_resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "清理工作\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于本教程的[Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "delete_bucket = False\n",
    "\n",
    "job.delete()\n",
    "model.delete()\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil -m rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "custom_training_container_and_model_registry.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
