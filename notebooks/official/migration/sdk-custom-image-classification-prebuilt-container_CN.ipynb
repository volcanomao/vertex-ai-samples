{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:migration,new"
   },
   "source": [
    "# Vertex AI 迁移：使用预构建的训练容器进行自定义图像分类\n",
    "\n",
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/migration/sdk-custom-image-classification-prebuilt-container.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/migration/sdk-custom-image-classification-prebuilt-container.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "<a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/migration/sdk-custom-image-classification-prebuilt-container.ipynb\" target='_blank'>\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在 Vertex AI Workbench 中打开\n",
    "    </a>\n",
    "  </td>                                                                                               \n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a8a13b86a8b"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何使用 Python 版本的 Vertex AI SDK，在使用预构建容器进行训练的同时，部署一个用于在线和批量预测的自定义图像分类模型。\n",
    "\n",
    "了解更多关于[迁移到 Vertex AI](https://cloud.google.com/vertex-ai/docs/start/migrating-to-vertex-ai)和[自定义训练](https://cloud.google.com/vertex-ai/docs/training/custom-training)的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1ae7d54ad29"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用预构建的容器和 Vertex AI 训练来训练一个 tensorflow 图像分类模型。训练完成后，您还将使用预构建的容器将模型部署到 Vertex AI，并对其进行批量和在线预测。\n",
    "\n",
    "本教程使用以下 Google Cloud ML 服务和资源：\n",
    "\n",
    "- Vertex AI 训练\n",
    "- Vertex AI 模型注册表\n",
    "- Vertex AI 预测\n",
    "- Vertex AI 批量预测\n",
    "- Vertex AI 终端\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- *将训练代码打包成 python 应用程序。*\n",
    "- *使用 Cloud Build 和 Artifact Registry 将训练应用程序容器化。*\n",
    "- *在 Vertex AI 中创建一个自定义容器训练作业并运行它。*\n",
    "- *评估从训练作业生成的模型。*\n",
    "- *在 Vertex AI 模型注册表为训练的模型创建一个模型资源。*\n",
    "- *运行 Vertex AI 的批量预测作业。*\n",
    "- *将模型资源部署到 Vertex AI 终端。*\n",
    "- *在模型资源上运行在线预测作业。*\n",
    "- *清理创建的资源。*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:custom,cifar10,icn"
   },
   "source": [
    "数据集\n",
    "\n",
    "本教程使用的数据集是[TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview)中的[CIFAR10数据集](https://www.tensorflow.org/datasets/catalog/cifar10)。您将使用的数据集版本已经集成到TensorFlow中。训练好的模型会预测图像属于十个类别中的哪一类：飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船、卡车。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "费用\n",
    "\n",
    "本教程使用Google Cloud的计费组件：\n",
    "\n",
    "- Vertex AI\n",
    "- Cloud Storage\n",
    "\n",
    "了解[Vertex AI定价](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage定价](https://cloud.google.com/storage/pricing)，并使用[Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "根据您的预期使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装执行此笔记本所需的包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform google-cloud-storage\n",
    "\n",
    "! apt-get update && apt-get install -y python3-opencv-headless\n",
    "! apt-get install -y libgl1-mesa-dev\n",
    "! pip3 install --upgrade opencv-python-headless  \n",
    "! pip3 install --upgrade tensorflow  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### 仅限协作：取消以下单元格的注释以重新启动内核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-ZBOjErv5mM"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "## 在你开始之前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "### 设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下操作：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "区域\n",
    "\n",
    "您还可以更改 Vertex AI 使用的 `REGION` 变量。了解有关 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations) 的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "UUID\n",
    "\n",
    "如果您正在进行现场教程会话，您可能正在使用共享的测试帐户或项目。为了避免用户在创建的资源之间的名称冲突，您为每个实例会话创建一个uuid，并将其附加到您在教程中创建的资源的名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e87d5856317d"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "###验证您的Google Cloud账号\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动进行身份验证。请按照以下相关指示操作。\n",
    "\n",
    "**1. Vertex AI Workbench**\n",
    "* 无需操作，因为您已经过身份验证。\n",
    "\n",
    "**2. 本地JupyterLab实例，请取消注释并运行：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce6043da7b33"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0367eac06a10"
   },
   "source": [
    "3. 合作，取消注释并运行:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21ad4dbb4a61"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c13224697bfb"
   },
   "source": [
    "查看如何在https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples 上为您的服务帐号授予云存储权限。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶以存储中间产物，比如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有在您的存储桶尚不存在时才执行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "1. 设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。\n",
    "2. 导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "初始化Python的顶点SDK\n",
    "\n",
    "为您的项目和相应的存储桶初始化Python的顶点AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "source": [
    "#### 设置硬件加速器\n",
    "\n",
    "您可以为训练和预测设置硬件加速器。\n",
    "\n",
    "设置变量 `TRAIN_GPU/TRAIN_NGPU` 和 `DEPLOY_GPU/DEPLOY_NGPU`，以使用支持 GPU 的容器映像以及分配给虚拟机实例的 GPU 数量。例如，要使用一个带有 4 个 Nvidia Telsa K80 GPU 的 GPU 容器映像分配给每个 VM，您可以指定：\n",
    "\n",
    "    (aip.gapic.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
    "\n",
    "\n",
    "否则，指定 `(None, None)` 来在 CPU 上运行一个容器映像。\n",
    "\n",
    "在此处了解更多关于您地区的[硬件加速器支持](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)\n",
    "\n",
    "*注意*：TF 2.3 之前的 GPU 支持版本将无法加载此教程中的自定义模型。这是一个已知问题，在 TF 2.3 中得到解决 —— 这是由在服务函数中生成的静态图操作引起的。如果您在您自己的自定义模型上遇到此问题，请使用带有 GPU 支持的 TF 2.3 容器映像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "outputs": [],
   "source": [
    "TRAIN_GPU, TRAIN_NGPU = (None, None)\n",
    "\n",
    "DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction"
   },
   "source": [
    "设置预构建的容器\n",
    "\n",
    "设置用于训练和预测的预构建Docker容器镜像。\n",
    "\n",
    "要查看最新列表，请访问[用于训练的预构建容器](https://cloud.google.com/ai-platform-unified/docs/training/pre-built-containers)。\n",
    "\n",
    "要查看最新列表，请访问[用于预测的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:training,prediction"
   },
   "outputs": [],
   "source": [
    "TF = \"2-5\"\n",
    "\n",
    "if TRAIN_GPU:\n",
    "    TRAIN_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "else:\n",
    "    TRAIN_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "if DEPLOY_GPU:\n",
    "    DEPLOY_VERSION = \"tf2-gpu.{}\".format(TF)\n",
    "else:\n",
    "    DEPLOY_VERSION = \"tf2-cpu.{}\".format(TF)\n",
    "\n",
    "TRAIN_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/{}:latest\".format(TRAIN_VERSION)\n",
    "DEPLOY_IMAGE = \"us-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(DEPLOY_VERSION)\n",
    "\n",
    "print(\"Training:\", TRAIN_IMAGE, TRAIN_GPU, TRAIN_NGPU)\n",
    "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU, DEPLOY_NGPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training,prediction"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于训练和预测的机器类型。\n",
    "\n",
    "- 设置变量`TRAIN_COMPUTE`和`DEPLOY_COMPUTE`来配置用于训练和预测的虚拟机的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`：每个vCPU 3.75GB内存。\n",
    "     - `n1-highmem`：每个vCPU 6.5GB内存。\n",
    "     - `n1-highcpu`：每个vCPU 0.9GB内存。\n",
    " - `vCPUs`：数量为\\[2, 4, 8, 16, 32, 64, 96\\]\n",
    "\n",
    "*注意：以下情况不支持训练：*\n",
    "\n",
    " - `standard`：2个vCPUs\n",
    " - `highcpu`：2、4和8个vCPUs\n",
    "\n",
    "*注意：您也可以使用n2和e2机器类型进行训练和部署，但它们不支持GPU*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training,prediction"
   },
   "outputs": [],
   "source": [
    "MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)\n",
    "\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_training_package"
   },
   "source": [
    "### 检查培训包\n",
    "\n",
    "#### 包布局\n",
    "\n",
    "在开始培训之前，您将查看如何为自定义培训作业组装 Python 包。解压缩后，该包包含以下目录/文件布局。\n",
    "\n",
    "- PKG-INFO\n",
    "- README.md\n",
    "- setup.cfg\n",
    "- setup.py\n",
    "- trainer\n",
    "  - \\_\\_init\\_\\_.py\n",
    "  - task.py\n",
    "\n",
    "文件 `setup.cfg` 和 `setup.py` 是安装包到 Docker 镜像的操作环境的说明。\n",
    "\n",
    "文件 `trainer/task.py` 是执行自定义培训作业的 Python 脚本。*注意*，当我们在工作池规范中引用它时，我们用点 (`trainer.task`) 替换目录斜杠，并且去掉文件后缀（`.py`）。\n",
    "\n",
    "#### 包组装\n",
    "\n",
    "在下面的单元格中，您将组装培训包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "examine_training_package"
   },
   "outputs": [],
   "source": [
    "# Make folder for Python training script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\nsetuptools.setup(\\n\\n    install_requires=[\\n\\n        'tensorflow_datasets==1.3.0',\\n\\n    ],\\n\\n    packages=setuptools.find_packages())\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\nName: CIFAR10 image classification\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taskpy_contents:cifar10"
   },
   "source": [
    "#### Task.py 文件内容\n",
    "\n",
    "在下一个单元格中，您可以编写训练脚本 task.py 的内容。我们不会详细展开，只是让您浏览一下。总结如下：\n",
    "\n",
    "- 从命令行获取保存模型结果的目录（`--model_dir`），如果未指定，则从环境变量 `AIP_MODEL_DIR` 中获取。\n",
    "- 从 TF Datasets（tfds）加载 CIFAR10 数据集。\n",
    "- 使用 TF.Keras 模型 API 构建模型。\n",
    "- 编译模型（`compile()`）。\n",
    "- 根据参数 `args.distribute` 设置训练分布策略。\n",
    "- 使用参数 `args.epochs` 和 `args.steps` 训练模型（`fit()`）。\n",
    "- 将训练好的模型保存到指定的模型目录中（`save(args.model_dir)`）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taskpy_contents:cifar10"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "# Single, Mirror and Multi-Machine Distributed Training for CIFAR-10\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model-dir', dest='model_dir',\n",
    "                    default=os.getenv(\"AIP_MODEL_DIR\"), type=str, help='Model dir.')\n",
    "parser.add_argument('--lr', dest='lr',\n",
    "                    default=0.01, type=float,\n",
    "                    help='Learning rate.')\n",
    "parser.add_argument('--epochs', dest='epochs',\n",
    "                    default=10, type=int,\n",
    "                    help='Number of epochs.')\n",
    "parser.add_argument('--steps', dest='steps',\n",
    "                    default=200, type=int,\n",
    "                    help='Number of steps per epoch.')\n",
    "parser.add_argument('--distribute', dest='distribute', type=str, default='single',\n",
    "                    help='distributed training strategy')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print('Python Version = {}'.format(sys.version))\n",
    "print('TensorFlow Version = {}'.format(tf.__version__))\n",
    "print('TF_CONFIG = {}'.format(os.environ.get('TF_CONFIG', 'Not found')))\n",
    "print('DEVICES', device_lib.list_local_devices())\n",
    "\n",
    "# Single Machine, single compute device\n",
    "if args.distribute == 'single':\n",
    "    if tf.test.is_gpu_available():\n",
    "        strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    else:\n",
    "        strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
    "# Single Machine, multiple compute device\n",
    "elif args.distribute == 'mirror':\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "# Multiple Machine, multiple compute device\n",
    "elif args.distribute == 'multi':\n",
    "    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "# Multi-worker configuration\n",
    "print('num_replicas_in_sync = {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Preparing dataset\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "def make_datasets_unbatched():\n",
    "\n",
    "  # Scaling CIFAR10 data from (0, 255] to (0., 1.]\n",
    "  def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.0\n",
    "    return image, label\n",
    "\n",
    "\n",
    "  datasets, info = tfds.load(name='cifar10',\n",
    "                            with_info=True,\n",
    "                            as_supervised=True)\n",
    "  return datasets['train'].map(scale).cache().shuffle(BUFFER_SIZE).repeat()\n",
    "\n",
    "\n",
    "# Build the Keras model\n",
    "def build_and_compile_cnn_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(32, 32, 3)),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "      optimizer=tf.keras.optimizers.SGD(learning_rate=args.lr),\n",
    "      metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "\n",
    "# Train the model\n",
    "NUM_WORKERS = strategy.num_replicas_in_sync\n",
    "# Here the batch size scales up by number of workers since\n",
    "# `tf.data.Dataset.batch` expects the global batch size.\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE * NUM_WORKERS\n",
    "train_dataset = make_datasets_unbatched().batch(GLOBAL_BATCH_SIZE)\n",
    "\n",
    "with strategy.scope():\n",
    "  # Creation of dataset, and model building/compiling need to be within\n",
    "  # `strategy.scope()`.\n",
    "  model = build_and_compile_cnn_model()\n",
    "\n",
    "model.fit(x=train_dataset, epochs=args.epochs, steps_per_epoch=args.steps)\n",
    "model.save(args.model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tarball_training_script"
   },
   "source": [
    "将培训脚本存储在您的云存储桶中\n",
    "\n",
    "接下来，您将培训文件夹打包成一个压缩的.tar文件，然后存储在您的云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tarball_training_script"
   },
   "outputs": [],
   "source": [
    "! rm -f custom.tar custom.tar.gz\n",
    "! tar cvf custom.tar custom\n",
    "! gzip custom.tar\n",
    "! gsutil cp custom.tar.gz $BUCKET_URI/trainer_cifar10.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_a_model:migration"
   },
   "source": [
    "训练一个模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "custom_create:migration,new,mbsdk,prebuilt"
   },
   "source": [
    "### [training.create-python-pre-built-container](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container)\n",
    "\n",
    "### [建立 Python 预构建容器](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_training_job:mbsdk,no_model"
   },
   "source": [
    "### 创建并运行自定义训练任务\n",
    "\n",
    "要训练一个自定义模型，您需要执行两个步骤：1）创建一个自定义训练任务，2）运行这个任务。\n",
    "\n",
    "#### 创建自定义训练任务\n",
    "\n",
    "通过使用`CustomTrainingJob`类创建一个自定义训练任务，该类有以下参数：\n",
    "\n",
    "- `display_name`：自定义训练任务的可读名称。\n",
    "- `container_uri`：训练容器镜像。\n",
    "- `requirements`：用于训练容器镜像的包要求（例如，pandas）。\n",
    "- `script_path`：训练脚本的相对路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_custom_training_job:mbsdk,no_model"
   },
   "outputs": [],
   "source": [
    "job = aip.CustomTrainingJob(\n",
    "    display_name=\"cifar10_\" + UUID,\n",
    "    script_path=\"custom/trainer/task.py\",\n",
    "    container_uri=TRAIN_IMAGE,\n",
    "    requirements=[\"gcsfs==0.7.1\", \"tensorflow-datasets==4.4\"],\n",
    ")\n",
    "\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_training_job:mbsdk,no_model"
   },
   "source": [
    "*示例输出：*\n",
    "\n",
    "<google.cloud.aiplatform.training_jobs.CustomTrainingJob object at 0x7feab1346710> \n",
    "\n",
    "*示例输出：*\n",
    "\n",
    "<google.cloud.aiplatform.training_jobs.CustomTrainingJob object at 0x7feab1346710>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_custom_job:mbsdk,no_model"
   },
   "source": [
    "#### 运行定制训练作业\n",
    "\n",
    "接下来，您可以通过调用`run`方法来运行定制作业，从而开始训练作业，参数如下：\n",
    "\n",
    "- `args`：要传递给训练脚本的命令行参数。\n",
    "- `replica_count`：用于训练的计算实例数量（replica_count = 1 表示单节点训练）。\n",
    "- `machine_type`：计算实例的机器类型。\n",
    "- `accelerator_type`：硬件加速器类型。\n",
    "- `accelerator_count`：要附加到工作器副本的加速器数量。\n",
    "- `base_output_dir`：将模型工件写入的云存储位置。\n",
    "- `sync`：是否阻塞直到作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_custom_job:mbsdk,no_model"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = \"{}/{}\".format(BUCKET_URI, UUID)\n",
    "\n",
    "EPOCHS = 20\n",
    "STEPS = 100\n",
    "\n",
    "DIRECT = True\n",
    "if DIRECT:\n",
    "    CMDARGS = [\n",
    "        \"--model-dir=\" + MODEL_DIR,\n",
    "        \"--epochs=\" + str(EPOCHS),\n",
    "        \"--steps=\" + str(STEPS),\n",
    "    ]\n",
    "else:\n",
    "    CMDARGS = [\n",
    "        \"--epochs=\" + str(EPOCHS),\n",
    "        \"--steps=\" + str(STEPS),\n",
    "    ]\n",
    "\n",
    "if TRAIN_GPU:\n",
    "    job.run(\n",
    "        args=CMDARGS,\n",
    "        replica_count=1,\n",
    "        machine_type=TRAIN_COMPUTE,\n",
    "        accelerator_type=TRAIN_GPU.name,\n",
    "        accelerator_count=TRAIN_NGPU,\n",
    "        base_output_dir=MODEL_DIR,\n",
    "        sync=True,\n",
    "    )\n",
    "else:\n",
    "    job.run(\n",
    "        args=CMDARGS,\n",
    "        replica_count=1,\n",
    "        machine_type=TRAIN_COMPUTE,\n",
    "        base_output_dir=MODEL_DIR,\n",
    "        sync=True,\n",
    "    )\n",
    "\n",
    "model_path_to_deploy = MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_custom_job:mbsdk,no_model"
   },
   "source": [
    "### 等待自定义训练作业完成\n",
    "\n",
    "接下来，等待自定义训练作业完成。或者，可以在`run()`方法中将参数`sync`设置为`True`，以阻塞直到自定义训练作业完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_the_model:migration"
   },
   "source": [
    "评估模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "load_saved_model"
   },
   "source": [
    "加载保存的模型\n",
    "\n",
    "您的模型以TensorFlow SavedModel格式存储在云存储桶中。现在从云存储桶加载它，然后您可以做一些事情，比如评估模型和进行预测。\n",
    "\n",
    "要加载，您可以使用TF.Keras的model.load_model()方法，将保存模型的云存储路径传递给它，该路径由MODEL_DIR指定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_saved_model"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "local_model = tf.keras.models.load_model(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_custom_model:image"
   },
   "source": [
    "## 评估模型\n",
    "\n",
    "现在找出模型的表现如何。\n",
    "\n",
    "### 加载评估数据\n",
    "\n",
    "您将从`tf.keras.datasets`中加载CIFAR10测试（留存）数据，使用方法`load_data()`。这将返回一个包含两个元素的元组数据集。第一个元素是训练数据，第二个是测试数据。每个元素也是包含两个元素的元组：图像数据和相应的标签。\n",
    "\n",
    "您不需要训练数据，因此将其加载为`(_,_)`。\n",
    "\n",
    "在可以进行评估之前，您需要预处理数据：\n",
    "\n",
    "`x_test`：\n",
    "1. 通过将每个像素除以255来对像素数据进行归一化（重新缩放）。这将用介于0和1之间的32位浮点数替换每个单字节整数像素。\n",
    "\n",
    "`y_test`：<br/>\n",
    "2. 标签目前是标量（稀疏）。如果您回顾一下`trainer/task.py`脚本中的`compile()`步骤，您会发现它是为稀疏标签编译的。因此我们不需要做其他处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_custom_model:image,cifar10"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(_, _), (x_test, y_test) = cifar10.load_data()\n",
    "x_test = (x_test / 255.0).astype(np.float32)\n",
    "\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "perform_evaluation_custom"
   },
   "source": [
    "### 进行模型评估\n",
    "\n",
    "现在评估定制作业中的模型表现如何。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "perform_evaluation_custom"
   },
   "outputs": [],
   "source": [
    "local_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_model:migration,new"
   },
   "source": [
    "### [general.import-model](https://cloud.google.com/vertex-ai/docs/general/import-model)\n",
    "### [general.import-model](https://cloud.google.com/vertex-ai/docs/general/import-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "serving_function_image"
   },
   "source": [
    "### 图像数据的服务功能\n",
    "\n",
    "为了将图像传递给预测服务，您需要将压缩（例如 JPEG）的图像字节编码为 base 64，这样可以使内容在通过网络传输二进制数据时安全无法修改。由于部署的模型期望输入数据为原始（未压缩）字节，因此您需要确保将 base 64 编码的数据转换回原始字节，然后将其作为输入传递给部署的模型。\n",
    "\n",
    "为了解决这个问题，定义一个服务函数（`serving_fn`）并将其附加到模型上作为预处理步骤。添加一个 `@tf.function` 装饰器，使服务函数与底层模型融合（而不是上游在 CPU 上）。\n",
    "\n",
    "当您发送预测或解释请求时，请求的内容将被 base 64 解码为一个 Tensorflow 字符串（`tf.string`），然后传递给服务函数（`serving_fn`）。服务函数将 `tf.string` 预处理为原始（未压缩）的 numpy 字节（`preprocess_fn`）以满足模型的输入要求：\n",
    "- `io.decode_jpeg` - 解压缩 JPG 图像，返回一个具有三个通道（RGB）的 Tensorflow 张量。\n",
    "- `image.convert_image_dtype` - 将整数像素值转换为浮点数 32。\n",
    "- `image.resize` - 调整图像大小以匹配模型的输入形状。\n",
    "- `resized / 255.0` - 将像素数据重新缩放（归一化）在 0 到 1 之间。\n",
    "\n",
    "此时，数据可以传递给模型（`m_call`）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "serving_function_image"
   },
   "outputs": [],
   "source": [
    "CONCRETE_INPUT = \"numpy_inputs\"\n",
    "\n",
    "\n",
    "def _preprocess(bytes_input):\n",
    "    decoded = tf.io.decode_jpeg(bytes_input, channels=3)\n",
    "    decoded = tf.image.convert_image_dtype(decoded, tf.float32)\n",
    "    resized = tf.image.resize(decoded, size=(32, 32))\n",
    "    rescale = tf.cast(resized / 255.0, tf.float32)\n",
    "    return rescale\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "def preprocess_fn(bytes_inputs):\n",
    "    decoded_images = tf.map_fn(\n",
    "        _preprocess, bytes_inputs, dtype=tf.float32, back_prop=False\n",
    "    )\n",
    "    return {\n",
    "        CONCRETE_INPUT: decoded_images\n",
    "    }  # User needs to make sure the key matches model's input\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "def serving_fn(bytes_inputs):\n",
    "    images = preprocess_fn(bytes_inputs)\n",
    "    prob = m_call(**images)\n",
    "    return prob\n",
    "\n",
    "\n",
    "m_call = tf.function(local_model.call).get_concrete_function(\n",
    "    [tf.TensorSpec(shape=[None, 32, 32, 3], dtype=tf.float32, name=CONCRETE_INPUT)]\n",
    ")\n",
    "\n",
    "tf.saved_model.save(\n",
    "    local_model, model_path_to_deploy, signatures={\"serving_default\": serving_fn}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "serving_function_signature:image"
   },
   "source": [
    "获取服务功能签名\n",
    "\n",
    "您可以通过重新加载模型到内存，并查询每个层对应的签名来获取模型的输入和输出层的签名。\n",
    "\n",
    "对于您的目的，您需要服务功能的签名。为什么呢？当我们将数据发送用作 HTTP 请求数据包进行预测时，图像数据是 base64 编码的，而我们的 TF.Keras 模型需要 numpy 输入。您的服务功能将会将数据从 base64 转换为 numpy 数组。\n",
    "\n",
    "在进行预测请求时，您需要将请求路由到服务功能而不是模型，因此您需要知道服务功能的输入层名称 - 这将在您进行预测请求时稍后使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "serving_function_signature:image"
   },
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(model_path_to_deploy)\n",
    "\n",
    "serving_input = list(\n",
    "    loaded.signatures[\"serving_default\"].structured_input_signature[1].keys()\n",
    ")[0]\n",
    "print(\"Serving function input:\", serving_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_model:mbsdk"
   },
   "source": [
    "## 上传模型\n",
    "\n",
    "接下来，使用`Model.upload()`方法将您的模型上传到一个`Model`资源，使用以下参数：\n",
    "\n",
    "- `display_name`：`Model`资源的可读名称。\n",
    "- `artifact`：训练模型工件的存储位置。\n",
    "- `serving_container_image_uri`：提供容器图像。\n",
    "- `sync`：是否异步或同步执行上传。\n",
    "\n",
    "如果`upload()`方法是异步运行的，您可以随后使用`wait()`方法阻塞直到完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "model = aip.Model.upload(\n",
    "    display_name=\"cifar10_\" + UUID,\n",
    "    artifact_uri=MODEL_DIR,\n",
    "    serving_container_image_uri=DEPLOY_IMAGE,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_model:mbsdk"
   },
   "source": [
    "示例输出：\n",
    "\n",
    "INFO:google.cloud.aiplatform.models:创建模型\n",
    "INFO:google.cloud.aiplatform.models:创建模型后端LRO：projects/759209241365/locations/us-central1/models/925164267982815232/operations/3458372263047331840\n",
    "INFO:google.cloud.aiplatform.models:模型已创建。资源名称：projects/759209241365/locations/us-central1/models/925164267982815232\n",
    "INFO:google.cloud.aiplatform.models:在另一个会话中使用此模型：\n",
    "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/759209241365/locations/us-central1/models/925164267982815232')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_batch_predictions:migration"
   },
   "source": [
    "进行批量预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batchpredictionjobs_create:migration,new,mbsdk"
   },
   "source": [
    "### [predictions.batch-prediction](https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions) \n",
    "\n",
    "### [predictions.batch-prediction](https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_test_items:test"
   },
   "source": [
    "获取测试项目\n",
    "\n",
    "您将使用数据集的测试（保留）部分中的示例作为测试项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_test_items:test"
   },
   "outputs": [],
   "source": [
    "test_image_1 = x_test[0]\n",
    "test_label_1 = y_test[0]\n",
    "test_image_2 = x_test[1]\n",
    "test_label_2 = y_test[1]\n",
    "print(test_image_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prepare_test_items:test,image"
   },
   "source": [
    "### 准备请求内容\n",
    "您将发送CIFAR10图像作为压缩的JPG图像，而不是原始未压缩的字节： \n",
    "\n",
    "- `cv2.imwrite`：使用openCV将未压缩的图像写入磁盘作为压缩的JPEG图像。\n",
    "- 将图像数据从\\[0,1)范围反归一化到[0,255)。\n",
    "- 将32位浮点值转换为8位无符号整数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare_test_items:test,image"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cv2.imwrite(\"tmp1.jpg\", (test_image_1 * 255).astype(np.uint8))\n",
    "cv2.imwrite(\"tmp2.jpg\", (test_image_2 * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "copy_test_items:test"
   },
   "source": [
    "### 复制测试项目\n",
    "\n",
    "对于批量预测，请将测试项目复制到您的云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copy_test_items:test"
   },
   "outputs": [],
   "source": [
    "! gsutil cp tmp1.jpg $BUCKET_URI/tmp1.jpg\n",
    "! gsutil cp tmp2.jpg $BUCKET_URI/tmp2.jpg\n",
    "\n",
    "test_item_1 = BUCKET_URI + \"/tmp1.jpg\"\n",
    "test_item_2 = BUCKET_URI + \"/tmp2.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_batch_file:custom,image"
   },
   "source": [
    "### 制作批量输入文件\n",
    "\n",
    "现在制作一个批量输入文件，你将把它存储在你的本地云存储桶中。批量输入文件只能是 JSONL 格式。对于 JSONL 文件，你需要为每个数据项（实例）每行制作一个字典条目。字典包含以下键/值对：\n",
    "\n",
    "- `input_name`：底层模型的输入层的名称。\n",
    "- `'b64'`：指示内容为 base64 编码的键。\n",
    "- `content`：压缩的 JPG 图像字节，作为 base64 编码的字符串。\n",
    "\n",
    "预测请求中的每个实例都是以下形式的字典条目：\n",
    "\n",
    "{ serving_input: {'b64': content}}\n",
    "\n",
    "为了将图像数据传递给预测服务，你需要将字节编码为 base64 -- 这样在通过网络传输二进制数据时，可以确保内容不会被修改。\n",
    "\n",
    "- `tf.io.read_file`：将压缩的 JPG 图像按原始字节读入内存。\n",
    "- `base64.b64encode`：将原始字节编码为 base64 编码的字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "make_batch_file:custom,image"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "\n",
    "gcs_input_uri = BUCKET_URI + \"/\" + \"test.jsonl\"\n",
    "with tf.io.gfile.GFile(gcs_input_uri, \"w\") as f:\n",
    "    bytes = tf.io.read_file(test_item_1)\n",
    "    b64str = base64.b64encode(bytes.numpy()).decode(\"utf-8\")\n",
    "    data = {serving_input: {\"b64\": b64str}}\n",
    "    f.write(json.dumps(data) + \"\\n\")\n",
    "    bytes = tf.io.read_file(test_item_2)\n",
    "    b64str = base64.b64encode(bytes.numpy()).decode(\"utf-8\")\n",
    "    data = {serving_input: {\"b64\": b64str}}\n",
    "    f.write(json.dumps(data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request:mbsdk,jsonl,custom"
   },
   "source": [
    "### 进行批量预测请求\n",
    "\n",
    "现在您的模型资源已经训练完成，您可以通过调用batch_predict（）方法来进行批量预测，具有以下参数：\n",
    "\n",
    "- `job_display_name`：批量预测作业的人类可读名称。\n",
    "- `gcs_source`：一个或多个批量请求输入文件的列表。\n",
    "- `gcs_destination_prefix`：用于存储批量预测结果的Cloud Storage位置。\n",
    "- `instances_format`：输入实例的格式，可以是'csv'或'jsonl'。默认为'jsonl'。\n",
    "- `predictions_format`：输出预测的格式，可以是'csv'或'jsonl'。默认为'jsonl'。\n",
    "- `machine_type`：用于训练的机器类型。\n",
    "- `accelerator_type`：硬件加速器类型。\n",
    "- `accelerator_count`：要附加到工作人员副本的加速器数量。\n",
    "- `sync`：如果设置为True，调用将会阻塞，同时等待异步批处理作业的完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request:mbsdk,jsonl,custom"
   },
   "outputs": [],
   "source": [
    "MIN_NODES = 1\n",
    "MAX_NODES = 1\n",
    "\n",
    "batch_predict_job = model.batch_predict(\n",
    "    job_display_name=\"cifar10_\" + UUID,\n",
    "    gcs_source=gcs_input_uri,\n",
    "    gcs_destination_prefix=BUCKET_URI,\n",
    "    instances_format=\"jsonl\",\n",
    "    predictions_format=\"jsonl\",\n",
    "    model_parameters=None,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    accelerator_type=DEPLOY_GPU,\n",
    "    accelerator_count=DEPLOY_NGPU,\n",
    "    starting_replica_count=MIN_NODES,\n",
    "    max_replica_count=MAX_NODES,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "print(batch_predict_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request:mbsdk,jsonl,custom"
   },
   "source": [
    "示例输出：\n",
    "\n",
    "INFO: google.cloud.aiplatform.jobs: 创建 BatchPredictionJob\n",
    "<google.cloud.aiplatform.jobs.BatchPredictionJob 对象在 0x7f806a6112d0 处等待上游依赖完成。\n",
    "INFO: google.cloud.aiplatform.jobs: 创建了 BatchPredictionJob。资源名称：projects/759209241365/locations/us-central1/batchPredictionJobs/5110965452507447296\n",
    "INFO: google.cloud.aiplatform.jobs: 要在另一个会话中使用此 BatchPredictionJob：\n",
    "INFO: google.cloud.aiplatform.jobs: bpj = aiplatform.BatchPredictionJob('projects/759209241365/locations/us-central1/batchPredictionJobs/5110965452507447296')\n",
    "INFO: google.cloud.aiplatform.jobs: 查看批量预测任务：\n",
    "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/5110965452507447296?project=759209241365\n",
    "INFO: google.cloud.aiplatform.jobs: BatchPredictionJob projects/759209241365/locations/us-central1/batchPredictionJobs/5110965452507447296 当前状态：JobState.JOB_STATE_RUNNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "source": [
    "等待批量预测作业完成\n",
    "\n",
    "接下来，等待批处理作业完成。或者，可以在`batch_predict()`方法中将参数`sync`设置为`True`，以阻止直到批量预测作业完成为止。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "outputs": [],
   "source": [
    "batch_predict_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "source": [
    "示例输出：\n",
    "\n",
    "INFO:google.cloud.aiplatform.jobs:已创建批量预测作业。资源名称：projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328\n",
    "INFO:google.cloud.aiplatform.jobs:要在另一个会话中使用此批量预测作业：\n",
    "INFO:google.cloud.aiplatform.jobs:bpj = aiplatform.BatchPredictionJob('projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328')\n",
    "INFO:google.cloud.aiplatform.jobs:查看批量预测作业：\n",
    "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/181835033978339328?project=759209241365\n",
    "INFO:google.cloud.aiplatform.jobs:批量预测作业 projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328 当前状态：\n",
    "JobState.JOB_STATE_RUNNING\n",
    "INFO:google.cloud.aiplatform.jobs:批量预测作业 projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328 当前状态：\n",
    "JobState.JOB_STATE_RUNNING\n",
    "INFO:google.cloud.aiplatform.jobs:批量预测作业 projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328 当前状态：\n",
    "JobState.JOB_STATE_RUNNING\n",
    "INFO:google.cloud.aiplatform.jobs:批量预测作业 projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328 当前状态：\n",
    "JobState.JOB_STATE_RUNNING\n",
    "INFO:google.cloud.aiplatform.jobs:批量预测作业 projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328 当前状态：\n",
    "JobState.JOB_STATE_RUNNING\n",
    "INFO:google.cloud.aiplatform.jobs:批量预测作业 projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328 当前状态：\n",
    "JobState.JOB_STATE_RUNNING\n",
    "INFO:google.cloud.aiplatform.jobs:批量预测作业 projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328 当前状态：\n",
    "JobState.JOB_STATE_RUNNING\n",
    "INFO:google.cloud.aiplatform.jobs:批量预测作业 projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328 当前状态：\n",
    "JobState.JOB_STATE_RUNNING\n",
    "INFO:google.cloud.aiplatform.jobs:已完成批量预测作业运行。资源名称：projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_batch_prediction:mbsdk,custom,icn"
   },
   "source": [
    "获取预测结果\n",
    "\n",
    "接下来，从完成的批量预测作业中获取结果。\n",
    "\n",
    "结果会被写入到你在批量预测请求中指定的云存储输出存储桶中。你可以调用方法iter_outputs()来获取包含结果的每个云存储文件的列表。每个文件都以JSON格式包含一个或多个预测请求：\n",
    "\n",
    "- `instance`：预测请求。\n",
    "- `prediction`：预测响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_batch_prediction:mbsdk,custom,icn"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "bp_iter_outputs = batch_predict_job.iter_outputs()\n",
    "\n",
    "prediction_results = list()\n",
    "for blob in bp_iter_outputs:\n",
    "    if blob.name.split(\"/\")[-1].startswith(\"prediction\"):\n",
    "        prediction_results.append(blob.name)\n",
    "\n",
    "tags = list()\n",
    "for prediction_result in prediction_results:\n",
    "    gfile_name = f\"gs://{bp_iter_outputs.bucket.name}/{prediction_result}\"\n",
    "    with tf.io.gfile.GFile(name=gfile_name, mode=\"r\") as gfile:\n",
    "        for line in gfile.readlines():\n",
    "            line = json.loads(line)\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_batch_prediction:mbsdk,custom,icn"
   },
   "source": [
    "{'instance': {'bytes_inputs': {'b64': '/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYFBgYGBwkIBgcJBwYGCAsICQoKC...'}}, 'prediction': [0.0560616329, 0.122713037, 0.121289924, 0.109751239, 0.121320881, 0.0897410363, 0.145011798, 0.0976110101, 0.0394041203, 0.0970953554]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_online_predictions:migration"
   },
   "source": [
    "进行在线预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:migration,new,mbsdk"
   },
   "source": [
    "### [predictions.deploy-model-api]（https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api） \n",
    "\n",
    "### [预测部署模型 API]（https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:mbsdk,all"
   },
   "source": [
    "## 部署模型\n",
    "\n",
    "接下来，将您的模型部署用于在线预测。要部署模型，您需要调用`deploy`方法，并指定以下参数：\n",
    "\n",
    "- `deployed_model_display_name`：部署模型的可读名称。\n",
    "- `traffic_split`：流量分配在端点上流向该模型的百分比，指定为一个或多个键/值对的字典。\n",
    "如果只有一个模型，那么指定为{ \"0\": 100 }，其中\"0\"指代上传的这个模型，而100表示100%的流量。\n",
    "如果端点上已存在其他模型，需要将流量分配给它们，则使用model_id指定为{ \"0\": 百分比, model_id: 百分比, ... }，其中model_id是已部署到端点的现有模型的模型id。各百分比必须相加为100。\n",
    "- `machine_type`：用于训练的机器类型。\n",
    "- `accelerator_type`：硬件加速器类型。\n",
    "- `accelerator_count`：要附加到工作实例的加速器数量。\n",
    "- `starting_replica_count`：最初规定的计算实例数量。\n",
    "- `max_replica_count`：可扩展到的最大计算实例数量。在本教程中，仅会提供一个实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy_model:mbsdk,all"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_NAME = \"cifar10-\" + UUID\n",
    "\n",
    "TRAFFIC_SPLIT = {\"0\": 100}\n",
    "\n",
    "MIN_NODES = 1\n",
    "MAX_NODES = 1\n",
    "\n",
    "if DEPLOY_GPU:\n",
    "    endpoint = model.deploy(\n",
    "        deployed_model_display_name=DEPLOYED_NAME,\n",
    "        traffic_split=TRAFFIC_SPLIT,\n",
    "        machine_type=DEPLOY_COMPUTE,\n",
    "        accelerator_type=DEPLOY_GPU,\n",
    "        accelerator_count=DEPLOY_NGPU,\n",
    "        min_replica_count=MIN_NODES,\n",
    "        max_replica_count=MAX_NODES,\n",
    "    )\n",
    "else:\n",
    "    endpoint = model.deploy(\n",
    "        deployed_model_display_name=DEPLOYED_NAME,\n",
    "        traffic_split=TRAFFIC_SPLIT,\n",
    "        machine_type=DEPLOY_COMPUTE,\n",
    "        accelerator_type=DEPLOY_GPU,\n",
    "        accelerator_count=0,\n",
    "        min_replica_count=MIN_NODES,\n",
    "        max_replica_count=MAX_NODES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:mbsdk,all"
   },
   "source": [
    "示例输出：\n",
    "\n",
    "    信息：google.cloud.aiplatform.models：创建端点\n",
    "    信息：google.cloud.aiplatform.models：创建端点支持的 LRO：projects/759209241365/locations/us-central1/endpoints/4867177336350441472/operations/4087251132693348352\n",
    "    信息：google.cloud.aiplatform.models：端点已创建。资源名称：projects/759209241365/locations/us-central1/endpoints/4867177336350441472\n",
    "    信息：google.cloud.aiplatform.models：在另一个会话中使用此端点：\n",
    "    信息：google.cloud.aiplatform.models：endpoint = aiplatform.Endpoint('projects/759209241365/locations/us-central1/endpoints/4867177336350441472')\n",
    "    信息：google.cloud.aiplatform.models：将模型部署到端点：projects/759209241365/locations/us-central1/endpoints/4867177336350441472\n",
    "    信息：google.cloud.aiplatform.models：部署端点模型支持的 LRO：projects/759209241365/locations/us-central1/endpoints/4867177336350441472/operations/1691336130932244480\n",
    "    信息：google.cloud.aiplatform.models：端点模型已部署。资源名称：projects/759209241365/locations/us-central1/endpoints/4867177336350441472"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "endpoints_predict:migration,new,mbsdk"
   },
   "source": [
    "### [predictions.online-prediction-automl](https://cloud.google.com/vertex-ai/docs/predictions/online-predictions-automl)\n",
    "\n",
    "### [predictions.online-prediction-automl](https://cloud.google.com/vertex-ai/docs/predictions/online-predictions-automl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_test_item:test"
   },
   "source": [
    "获取测试项目\n",
    "\n",
    "您将使用数据集的测试（保留）部分中的一个示例作为测试项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_test_item:test"
   },
   "outputs": [],
   "source": [
    "test_image = x_test[0]\n",
    "test_label = y_test[0]\n",
    "print(test_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prepare_test_item:test,image"
   },
   "source": [
    "###准备请求内容\n",
    "您将以压缩后的JPG图像的形式发送CIFAR10图像，而不是原始未压缩的字节：\n",
    "\n",
    "- `cv2.imwrite`：使用openCV将未压缩的图像写入磁盘，以压缩后的JPEG图像形式。\n",
    "  - 将图像数据从\\[0,1)范围反归一化为[0,255)。\n",
    "  - 将32位浮点值转换为8位无符号整数。\n",
    "- `tf.io.read_file`：以原始字节的形式将压缩后的JPG图像读入内存。\n",
    "- `base64.b64encode`：将原始字节编码为base64编码的字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare_test_item:test,image"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "import cv2\n",
    "\n",
    "cv2.imwrite(\"tmp.jpg\", (test_image * 255).astype(np.uint8))\n",
    "\n",
    "bytes = tf.io.read_file(\"tmp.jpg\")\n",
    "b64str = base64.b64encode(bytes.numpy()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "predict_request:mbsdk,custom,icn"
   },
   "source": [
    "### 进行预测\n",
    "\n",
    "现在您的 `Model` 资源已部署到一个 `Endpoint` 资源上，您可以通过向 Endpoint 资源发送预测请求来进行在线预测。\n",
    "\n",
    "#### 请求\n",
    "\n",
    "在这个示例中，您的测试项目位于一个 Cloud Storage 存储桶中，您可以使用 `tf.io.gfile.Gfile()` 打开并读取图像的内容。为了将测试数据传递给预测服务，您需要将字节编码为 base64 格式 -- 这样可以在通过网络传输二进制数据时使内容免受修改。\n",
    "\n",
    "每个实例的格式为：\n",
    "\n",
    "    { serving_input: { 'b64': base64编码的字节 } }\n",
    "\n",
    "由于 `predict()` 方法可以接受多个项目（实例），请将您的单个测试项目作为一个测试项目列表发送。\n",
    "\n",
    "#### 响应\n",
    "\n",
    "`predict()` 调用的响应是一个 Python 字典，具有以下条目：\n",
    "\n",
    "- `ids`: 每个预测请求的内部分配的唯一标识符。\n",
    "- `predictions`: 每个类别标签的预测置信度，介于 0 和 1 之间。\n",
    "- `deployed_model_id`: 执行预测的已部署 `Model` 资源的 Vertex AI 标识符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "predict_request:mbsdk,custom,icn"
   },
   "outputs": [],
   "source": [
    "# The format of each instance should conform to the deployed model's prediction input schema.\n",
    "instances = [{serving_input: {\"b64\": b64str}}]\n",
    "\n",
    "prediction = endpoint.predict(instances=instances)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "predict_request:mbsdk,custom,icn"
   },
   "source": [
    "*示例输出：*\n",
    "\n",
    "    预测(predictions=[[0.0560616292, 0.122713044, 0.121289924, 0.109751239, 0.121320873, 0.0897410288, 0.145011798, 0.0976110175, 0.0394041166, 0.0970953479]], 部署模型标识='4087166195420102656', 解释=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "source": [
    "## 卸载模型\n",
    "\n",
    "当您完成预测时，您可以从`Endpoint`资源中卸载模型。这将取消所有计算资源并停止部署模型的计费。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "清理工作\n",
    "\n",
    "要清理本项目中使用的所有 Google Cloud 资源，您可以删除用于本教程的 Google Cloud 项目。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "delete_bucket = False\n",
    "\n",
    "# Delete the model using the Vertex model object\n",
    "model.delete()\n",
    "\n",
    "# Delete the endpoint using the Vertex endpoint object\n",
    "endpoint.delete()\n",
    "\n",
    "# Delete the training job\n",
    "job.delete()\n",
    "\n",
    "# Delete the batch prediction job using the Vertex batch prediction object\n",
    "batch_predict_job.delete()\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sdk-custom-image-classification-prebuilt-container.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
