{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:migration,new"
   },
   "source": [
    "# Vertex AI 迁移：使用预构建的训练容器的自定义 Scikit-Learn 模型\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "<a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/migration/sdk-custom-scikit-learn-prebuilt-container.ipynb\" target='_blank'>\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "<a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/migration/sdk-custom-scikit-learn-prebuilt-container.ipynb\" target='_blank'>\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "     <td>\n",
    "<a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/migration/sdk-custom-scikit-learn-prebuilt-container.ipynb\" target='_blank'>\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在 Vertex AI Workbench 中打开\n",
    "    </a>\n",
    "  </td>         \n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a8a13b86a8b"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何使用Python的Vertex AI SDK来训练和部署自定义的表格分类scikit-learn模型，用于批量预测。\n",
    "\n",
    "了解更多关于[迁移到Vertex AI](https://cloud.google.com/vertex-ai/docs/start/migrating-to-vertex-ai)和[自定义训练](https://cloud.google.com/vertex-ai/docs/training/custom-training)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "618cfedf829a"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用 `Vertex AI Training` 创建一个自定义训练模型，并使用 `Vertex AI Batch Prediction` 对训练模型进行批量预测。\n",
    "\n",
    "您将学习如何使用 Vertex AI SDK for Python 在 Docker 容器中的 Python 脚本中创建一个自定义训练模型，然后通过发送数据对部署的模型进行预测。\n",
    "\n",
    "本教程使用以下 Google Cloud ML 服务：\n",
    "\n",
    "- `Vertex AI Training`\n",
    "- `Vertex AI Batch Prediction`\n",
    "- `Vertex AI Model` 资源\n",
    "- `Vertex AI Endpoint` 资源\n",
    "\n",
    "所执行的步骤包括：\n",
    "\n",
    "- 为训练一个 scikit-learn 模型创建一个 `Vertex AI` 自定义作业。\n",
    "- 将训练好的模型工件上传为 `Model` 资源。\n",
    "- 进行批量预测。\n",
    "- 将模型部署到端点。\n",
    "- 进行在线预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:census,lbn"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是UCI机器学习【美国人口普查数据（1990年）数据集】(https://archive.ics.uci.edu/ml/datasets/US+Census+Data+(1990))。您在本教程中使用的数据集版本存储在公共云存储桶中。\n",
    "\n",
    "该数据集预测一个人的收入是否超过5万美元。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "### 费用\n",
    "\n",
    "本教程使用了 Google Cloud 的可计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解 [Vertex AI 的定价](https://cloud.google.com/vertex-ai/pricing) 和 [Cloud Storage 的定价](https://cloud.google.com/storage/pricing)，并使用 [定价计算器](https://cloud.google.com/products/calculator/) 根据您的预期使用情况生成费用估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装以下所需的包以执行这个笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
    "                                 google-cloud-storage \\\n",
    "                                 tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "只有 Colab：取消注释以下单元格以重新启动内核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-ZBOjErv5mM"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "开始之前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下方法：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 区域\n",
    "\n",
    "您也可以更改 Vertex AI 使用的 `REGION` 变量。了解有关 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations) 的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "UUID\n",
    "\n",
    "如果您在进行实况教程会话中，您可能使用共享的测试账户或项目。为避免用户在创建的资源之间发生名称冲突，您为每个实例会话创建一个uuid，并将其附加到您在本教程中创建的资源名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "timestamp"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 验证您的谷歌云账户\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动验证。请按照以下相关说明进行操作。\n",
    "\n",
    "**1. Vertex AI工作台**\n",
    "* 无需操作，因为您已经验证通过。\n",
    "\n",
    "**2. 本地JupyterLab实例，请取消注释并运行：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce6043da7b33"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0367eac06a10"
   },
   "source": [
    "3. 合作，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21ad4dbb4a61"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c13224697bfb"
   },
   "source": [
    "请查看如何在https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples上为您的服务帐户授予云存储权限。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "创建一个存储桶，用于存储中间产物，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有当您的存储桶尚不存在时，才运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import google.cloud.aiplatform as aip\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "初始化Python的Vertex SDK\n",
    "为您的项目和对应的存储桶初始化Python的Vertex SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction,scilearn"
   },
   "source": [
    "#### 设置预构建容器\n",
    "\n",
    "设置用于训练和预测的预构建Docker容器镜像。\n",
    "\n",
    "有关最新列表，请参阅[用于训练的预构建容器](https://cloud.google.com/ai-platform-unified/docs/training/pre-built-containers)。\n",
    "\n",
    "有关最新列表，请参阅[用于预测的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:training,prediction,scilearn"
   },
   "outputs": [],
   "source": [
    "TRAIN_VERSION = \"scikit-learn-cpu.0-23\"\n",
    "DEPLOY_VERSION = \"sklearn-cpu.1-0\"\n",
    "\n",
    "TRAIN_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/{}:latest\".format(TRAIN_VERSION)\n",
    "DEPLOY_IMAGE = \"us-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(DEPLOY_VERSION)\n",
    "\n",
    "print(\"Training:\", TRAIN_IMAGE)\n",
    "print(\"Deployment:\", DEPLOY_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training,prediction"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于训练和预测的机器类型。\n",
    "\n",
    "- 设置变量`TRAIN_COMPUTE`和`DEPLOY_COMPUTE`来配置用于训练和预测的虚拟机的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`：每个vCPU 3.75GB的内存。\n",
    "     - `n1-highmem`：每个vCPU 6.5GB的内存。\n",
    "     - `n1-highcpu`：每个vCPU 0.9GB的内存。\n",
    " - `vCPUs`：\\[2、4、8、16、32、64、96\\]个\n",
    "\n",
    "*注：以下类型不支持用于训练：*\n",
    "\n",
    " - `standard`：2个vCPUs\n",
    " - `highcpu`：2、4和8个vCPUs\n",
    "\n",
    "*注：您也可以使用n2和e2机器类型来进行训练和部署，但它们不支持GPU。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training,prediction"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TRAIN_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_TRAIN_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)\n",
    "\n",
    "if os.getenv(\"IS_TESTING_DEPLOY_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_DEPLOY_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_training_package"
   },
   "source": [
    "### 检查培训包\n",
    "\n",
    "#### 包布局\n",
    "\n",
    "在开始培训之前，您可以查看 Python 包是如何为自定义训练任务组装的。解压后，该包包含以下目录/文件布局。\n",
    "\n",
    "- PKG-INFO\n",
    "- README.md\n",
    "- setup.cfg\n",
    "- setup.py\n",
    "- trainer\n",
    "  - \\_\\_init\\_\\_.py\n",
    "  - task.py\n",
    "\n",
    "文件 `setup.cfg` 和 `setup.py` 是用于将包安装到 Docker 镜像的操作环境中的说明。\n",
    "\n",
    "文件 `trainer/task.py` 是执行自定义训练任务的 Python 脚本。*注意*，在工作池规范中引用时，我们将目录斜杠替换为点 (`trainer.task`) 并删除文件后缀 (`.py`)。\n",
    "\n",
    "#### 包装配\n",
    "\n",
    "在接下来的单元格中，您将组装培训包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "examine_training_package"
   },
   "outputs": [],
   "source": [
    "# Make folder for Python training script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\nsetuptools.setup(\\n\\n    install_requires=[\\n\\n        'tensorflow_datasets',\\n\\n    ],\\n\\n    packages=setuptools.find_packages())\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\nName: US Census Data (1990) tabular binary classification\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taskpy_contents:scilearn,census"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "# Single Instance Training for Census Income\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model-dir', dest='model_dir',\n",
    "                    default=os.getenv('AIP_MODEL_DIR'), type=str, help='Model dir.')\n",
    "args = parser.parse_args()\n",
    "print('Python Version = {}'.format(sys.version))\n",
    "\n",
    "# Public bucket holding the census data\n",
    "bucket = storage.Client().bucket('cloud-samples-data')\n",
    "\n",
    "# Path to the data inside the public bucket\n",
    "blob = bucket.blob('ai-platform/sklearn/census_data/adult.data')\n",
    "# Download the data\n",
    "blob.download_to_filename('adult.data')\n",
    "\n",
    "# Define the format of your input data including unused columns (These are the columns from the census data files)\n",
    "COLUMNS = (\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',\n",
    "    'education',\n",
    "    'education-num',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'native-country',\n",
    "    'income-level'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Categorical columns are columns that need to be turned into a numerical value to be used by scikit-learn\n",
    "CATEGORICAL_COLUMNS = (\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country'\n",
    ")\n",
    "\n",
    "# Load the training census dataset\n",
    "with open('./adult.data', 'r') as train_data:\n",
    "    raw_training_data = pd.read_csv(train_data, header=None, names=COLUMNS)\n",
    "\n",
    "# Remove the column we are trying to predict ('income-level') from our features list\n",
    "# Convert the Dataframe to a lists of lists\n",
    "train_features = raw_training_data.drop('income-level', axis=1).values.tolist()\n",
    "# Create our training labels list, convert the Dataframe to a lists of lists\n",
    "train_labels = (raw_training_data['income-level'] == ' >50K').values.tolist()\n",
    "\n",
    "# Since the census data set has categorical features, we need to convert\n",
    "# them to numerical values. We'll use a list of pipelines to convert each\n",
    "# categorical column and then use FeatureUnion to combine them before calling\n",
    "# the RandomForestClassifier.\n",
    "categorical_pipelines = []\n",
    "\n",
    "# Each categorical column needs to be extracted individually and converted to a numerical value.\n",
    "# To do this, each categorical column will use a pipeline that extracts one feature column via\n",
    "# SelectKBest(k=1) and a LabelBinarizer() to convert the categorical value to a numerical one.\n",
    "# A scores array (created below) will select and extract the feature column. The scores array is\n",
    "# created by iterating over the COLUMNS and checking if it is a CATEGORICAL_COLUMN.\n",
    "for i, col in enumerate(COLUMNS[:-1]):\n",
    "    if col in CATEGORICAL_COLUMNS:\n",
    "        # Create a scores array to get the individual categorical column.\n",
    "        # Example:\n",
    "        #  data = [39, 'State-gov', 77516, 'Bachelors', 13, 'Never-married', 'Adm-clerical',\n",
    "        #         'Not-in-family', 'White', 'Male', 2174, 0, 40, 'United-States']\n",
    "        #  scores = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        #\n",
    "        # Returns: [['State-gov']]\n",
    "        # Build the scores array.\n",
    "        scores = [0] * len(COLUMNS[:-1])\n",
    "        # This column is the categorical column we want to extract.\n",
    "        scores[i] = 1\n",
    "        skb = SelectKBest(k=1)\n",
    "        skb.scores_ = scores\n",
    "        # Convert the categorical column to a numerical value\n",
    "        lbn = LabelBinarizer()\n",
    "        r = skb.transform(train_features)\n",
    "        lbn.fit(r)\n",
    "        # Create the pipeline to extract the categorical feature\n",
    "        categorical_pipelines.append(\n",
    "            ('categorical-{}'.format(i), Pipeline([\n",
    "                ('SKB-{}'.format(i), skb),\n",
    "                ('LBN-{}'.format(i), lbn)])))\n",
    "\n",
    "# Create pipeline to extract the numerical features\n",
    "skb = SelectKBest(k=6)\n",
    "# From COLUMNS use the features that are numerical\n",
    "skb.scores_ = [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
    "categorical_pipelines.append(('numerical', skb))\n",
    "\n",
    "# Combine all the features using FeatureUnion\n",
    "preprocess = FeatureUnion(categorical_pipelines)\n",
    "\n",
    "# Create the classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Transform the features and fit them to the classifier\n",
    "classifier.fit(preprocess.transform(train_features), train_labels)\n",
    "\n",
    "# Create the overall model as a single pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('union', preprocess),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "# Split path into bucket and subdirectory\n",
    "bucket = args.model_dir.split('/')[2]\n",
    "subdirs = args.model_dir.split('/')[3:]\n",
    "subdir = subdirs[0]\n",
    "subdirs.pop(0)\n",
    "\n",
    "\n",
    "\n",
    "for comp in subdirs:\n",
    "    subdir = os.path.join(subdir, comp)\n",
    "\n",
    "# Write model to a local file\n",
    "joblib.dump(pipeline, 'model.joblib')\n",
    "\n",
    "# Upload the model to GCS\n",
    "bucket = storage.Client().bucket(bucket)\n",
    "blob = bucket.blob(subdir + 'model.joblib')\n",
    "blob.upload_from_filename('model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tarball_training_script"
   },
   "source": [
    "#### 将培训脚本存储在您的云存储桶中\n",
    "\n",
    "接下来，您将培训文件夹打包成一个压缩的tar文件，然后将其存储在您的云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tarball_training_script"
   },
   "outputs": [],
   "source": [
    "! rm -f custom.tar custom.tar.gz\n",
    "! tar cvf custom.tar custom\n",
    "! gzip custom.tar\n",
    "! gsutil cp custom.tar.gz $BUCKET_URI/trainer_census.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_a_model:migration"
   },
   "source": [
    "训练一个模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "custom_create:migration,new,mbsdk,prebuilt"
   },
   "source": [
    "### [training.create-python-pre-built-container](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container) \n",
    "\n",
    "### [training.create-python-pre-built-container](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_training_job:mbsdk,no_model"
   },
   "source": [
    "### 创建并运行自定义训练任务\n",
    "\n",
    "要训练一个自定义模型，您需要执行两个步骤：1) 创建一个自定义训练任务，2) 运行这个任务。\n",
    "\n",
    "#### 创建自定义训练任务\n",
    "\n",
    "使用`CustomTrainingJob`类创建一个自定义训练任务，具有以下参数：\n",
    "\n",
    "- `display_name`: 自定义训练任务的可读名称。\n",
    "- `container_uri`: 训练容器镜像。\n",
    "- `requirements`: 训练容器镜像的包要求（例如，pandas）。\n",
    "- `script_path`: 训练脚本的相对路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_custom_training_job:mbsdk,no_model"
   },
   "outputs": [],
   "source": [
    "job = aip.CustomTrainingJob(\n",
    "    display_name=\"census_\" + UUID,\n",
    "    script_path=\"custom/trainer/task.py\",\n",
    "    container_uri=TRAIN_IMAGE,\n",
    "    requirements=[\"gcsfs\", \"tensorflow-datasets\"],\n",
    ")\n",
    "\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_training_job:mbsdk,no_model"
   },
   "source": [
    "示例输出：\n",
    "\n",
    "<google.cloud.aiplatform.training_jobs.CustomTrainingJob object at 0x7feab1346710>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_custom_job:mbsdk,no_model,cpu"
   },
   "source": [
    "运行定制的训练作业\n",
    "\n",
    "接下来，通过调用`run`方法并使用以下参数来运行自定义作业以启动训练作业：\n",
    "\n",
    "- `replica_count`：用于训练的计算实例数量（replica_count = 1表示单节点训练）。\n",
    "- `machine_type`：计算实例的机器类型。\n",
    "- `base_output_dir`：将模型工件写入的Cloud Storage位置。\n",
    "- `sync`：是否阻塞直到作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_custom_job:mbsdk,no_model,cpu"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = \"{}/{}\".format(BUCKET_URI, UUID)\n",
    "\n",
    "\n",
    "job.run(\n",
    "    replica_count=1, machine_type=TRAIN_COMPUTE, base_output_dir=MODEL_DIR, sync=True\n",
    ")\n",
    "\n",
    "MODEL_DIR = MODEL_DIR + \"/model\"\n",
    "model_path_to_deploy = MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_model:migration,new"
   },
   "source": [
    "### [general.import-model]（https://cloud.google.com/vertex-ai/docs/general/import-model）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_model:mbsdk"
   },
   "source": [
    "## 上传模型\n",
    "\n",
    "接下来，使用`Model.upload()`方法将您的模型上传到`Model`资源，使用以下参数：\n",
    "\n",
    "- `display_name`: `Model`资源的可读名称。\n",
    "- `artifact`: 训练模型工件的云存储位置。\n",
    "- `serving_container_image_uri`: 用于服务的容器映像。\n",
    "- `sync`: 是否异步或同步执行上传。\n",
    "\n",
    "如果`upload()`方法以异步方式运行，您可以随后使用`wait()`方法阻塞直至完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "model = aip.Model.upload(\n",
    "    display_name=\"census_\" + UUID,\n",
    "    artifact_uri=MODEL_DIR,\n",
    "    serving_container_image_uri=DEPLOY_IMAGE,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_model:mbsdk"
   },
   "source": [
    "示例输出：\n",
    "\n",
    "    信息：google.cloud.aiplatform.models：创建模型\n",
    "    信息：google.cloud.aiplatform.models：创建模型的LRO：projects/759209241365/locations/us-central1/models/925164267982815232/operations/3458372263047331840\n",
    "    信息：google.cloud.aiplatform.models：模型已创建。资源名称：projects/759209241365/locations/us-central1/models/925164267982815232\n",
    "    信息：google.cloud.aiplatform.models：要在另一个会话中使用此模型：\n",
    "    信息：google.cloud.aiplatform.models：model = aiplatform.Model('projects/759209241365/locations/us-central1/models/925164267982815232')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_batch_predictions:migration"
   },
   "source": [
    "进行批量预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batchpredictionjobs_create:migration,new,mbsdk"
   },
   "source": [
    "### [predictions.batch-prediction](https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions)\n",
    "\n",
    "### [预测.批量预测](https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_test_items:scilearn,tabular,census"
   },
   "source": [
    "制作测试项目\n",
    "\n",
    "您可以使用合成数据作为测试数据项目。不要担心我们使用合成数据 - 我们只是想展示如何进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "make_test_items:scilearn,tabular,census"
   },
   "outputs": [],
   "source": [
    "INSTANCES = [\n",
    "    [\n",
    "        25,\n",
    "        \"Private\",\n",
    "        226802,\n",
    "        \"11th\",\n",
    "        7,\n",
    "        \"Never-married\",\n",
    "        \"Machine-op-inspct\",\n",
    "        \"Own-child\",\n",
    "        \"Black\",\n",
    "        \"Male\",\n",
    "        0,\n",
    "        0,\n",
    "        40,\n",
    "        \"United-States\",\n",
    "    ],\n",
    "    [\n",
    "        38,\n",
    "        \"Private\",\n",
    "        89814,\n",
    "        \"HS-grad\",\n",
    "        9,\n",
    "        \"Married-civ-spouse\",\n",
    "        \"Farming-fishing\",\n",
    "        \"Husband\",\n",
    "        \"White\",\n",
    "        \"Male\",\n",
    "        0,\n",
    "        0,\n",
    "        50,\n",
    "        \"United-States\",\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_batch_file:custom,tabular,list,jsonl"
   },
   "source": [
    "### 生成批量输入文件\n",
    "\n",
    "现在生成一个批量输入文件，将其存储在您的本地云存储桶中。预测请求中的每个实例都是一个列表，如下所示：\n",
    "\n",
    "[ [内容_1], [内容_2] ]\n",
    "\n",
    "- `内容`：测试项的特征值列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "make_batch_file:custom,tabular,list,jsonl"
   },
   "outputs": [],
   "source": [
    "gcs_input_uri = BUCKET_URI + \"/\" + \"test.jsonl\"\n",
    "with tf.io.gfile.GFile(gcs_input_uri, \"w\") as f:\n",
    "    for i in INSTANCES:\n",
    "        f.write(json.dumps(i) + \"\\n\")\n",
    "\n",
    "! gsutil cat $gcs_input_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request:mbsdk,jsonl,custom,cpu"
   },
   "source": [
    "### 发送批量预测请求\n",
    "\n",
    "现在，您的模型资源经过训练，您可以通过调用`batch_predict()`方法来进行批量预测，使用以下参数：\n",
    "\n",
    "- `job_display_name`：批量预测作业的可读名称。\n",
    "- `gcs_source`：一个或多个批量请求输入文件的列表。\n",
    "- `gcs_destination_prefix`：用于存储批量预测结果的云存储位置。\n",
    "- `instances_format`：输入实例的格式，可以是'csv'或'jsonl'。默认为'jsonl'。\n",
    "- `predictions_format`：输出预测的格式，可以是'csv'或'jsonl'。默认为'jsonl'。\n",
    "- `machine_type`：用于训练的机器类型。\n",
    "- `sync`：如果设置为True，则调用将在等待异步批处理作业完成时阻塞。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request:mbsdk,jsonl,custom,cpu"
   },
   "outputs": [],
   "source": [
    "MIN_NODES = 1\n",
    "MAX_NODES = 1\n",
    "\n",
    "batch_predict_job = model.batch_predict(\n",
    "    job_display_name=\"census_\" + UUID,\n",
    "    gcs_source=gcs_input_uri,\n",
    "    gcs_destination_prefix=BUCKET_URI,\n",
    "    instances_format=\"jsonl\",\n",
    "    predictions_format=\"jsonl\",\n",
    "    model_parameters=None,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    starting_replica_count=MIN_NODES,\n",
    "    max_replica_count=MAX_NODES,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "print(batch_predict_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request:mbsdk,jsonl,custom,cpu"
   },
   "source": [
    "示例输出：\n",
    "\n",
    "    信息：google.cloud.aiplatform.jobs:正在创建BatchPredictionJob\n",
    "    <google.cloud.aiplatform.jobs.BatchPredictionJob object at 0x7f806a6112d0>正在等待上游依赖项完成。\n",
    "    信息：google.cloud.aiplatform.jobs：已创建BatchPredictionJob。资源名称：projects/759209241365/locations/us-central1/batchPredictionJobs/5110965452507447296\n",
    "    信息：google.cloud.aiplatform.jobs：要在另一个会话中使用此BatchPredictionJob：\n",
    "    信息：google.cloud.aiplatform.jobs：bpj = aiplatform.BatchPredictionJob('projects/759209241365/locations/us-central1/batchPredictionJobs/5110965452507447296')\n",
    "    信息：google.cloud.aiplatform.jobs：查看Batch Prediction Job：\n",
    "    https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/5110965452507447296?project=759209241365\n",
    "    信息：google.cloud.aiplatform.jobs：BatchPredictionJob projects/759209241365/locations/us-central1/batchPredictionJobs/5110965452507447296当前状态：\n",
    "    JobState.JOB_STATE_RUNNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "source": [
    "等待批量预测作业完成\n",
    "\n",
    "接下来，等待批处理作业完成。或者，可以在`batch_predict()`方法中将参数`sync`设置为`True`，以阻塞直到批处理预测作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "outputs": [],
   "source": [
    "batch_predict_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "source": [
    "*示例输出：*\n",
    "\n",
    "    INFO：google.cloud.aiplatform.jobs：BatchPredictionJob已创建。 资源名称：projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328\n",
    "    INFO：google.cloud.aiplatform.jobs：在另一个会话中使用此BatchPredictionJob：\n",
    "    INFO：google.cloud.aiplatform.jobs：bpj = aiplatform.BatchPredictionJob（'projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328'）\n",
    "    INFO：google.cloud.aiplatform.jobs：查看批量预测作业：\n",
    "    https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/181835033978339328?project=759209241365\n",
    "    INFO：google.cloud.aiplatform.jobs：BatchPredictionJob projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328 当前状态：\n",
    "    JobState.JOB_STATE_RUNNING\n",
    "    INFO：google.cloud.aiplatform.jobs：BatchPredictionJob projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328 当前状态：\n",
    "    JobState.JOB_STATE_RUNNING\n",
    "    ……（重复多次）\n",
    "    INFO：google.cloud.aiplatform.jobs：BatchPredictionJob projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328 当前状态：\n",
    "    JobState.JOB_STATE_SUCCEEDED\n",
    "    INFO：google.cloud.aiplatform.jobs：批量预测作业已完成运行。 资源名称：projects/759209241365/locations/us-central1/batchPredictionJobs/181835033978339328"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_batch_prediction:mbsdk,custom,lbn"
   },
   "source": [
    "获得预测\n",
    "\n",
    "接下来，从已完成的批量预测作业中获取结果。\n",
    "\n",
    "结果被写入到您在批量预测请求中指定的Cloud Storage输出存储桶中。您可以调用iter_outputs()方法获取生成结果的每个Cloud Storage文件的列表。每个文件都以JSON格式包含一个或多个预测请求：\n",
    "\n",
    "- `instance`：预测请求。\n",
    "- `prediction`：预测响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_batch_prediction:mbsdk,custom,lbn"
   },
   "outputs": [],
   "source": [
    "bp_iter_outputs = batch_predict_job.iter_outputs()\n",
    "\n",
    "prediction_results = list()\n",
    "for blob in bp_iter_outputs:\n",
    "    if blob.name.split(\"/\")[-1].startswith(\"prediction\"):\n",
    "        prediction_results.append(blob.name)\n",
    "\n",
    "tags = list()\n",
    "for prediction_result in prediction_results:\n",
    "    gfile_name = f\"gs://{bp_iter_outputs.bucket.name}/{prediction_result}\"\n",
    "    with tf.io.gfile.GFile(name=gfile_name, mode=\"r\") as gfile:\n",
    "        for line in gfile.readlines():\n",
    "            line = json.loads(line)\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_batch_prediction:mbsdk,custom,lbn"
   },
   "source": [
    "{'instance': [25, 'Private', 226802, '11th', 7, 'Never-married', 'Machine-op-inspct', 'Own-child', 'Black', 'Male', 0, 0, 40, 'United-States'], 'prediction': False}\n",
    "\n",
    "示例输出: \n",
    "\n",
    "{'实例': [25, '私人', 226802, '11th', 7, '未婚', '机器操作检查员', '自己的孩子', '黑色', '男性', 0, 0, 40, '美国'], '预测': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_online_predictions:migration"
   },
   "source": [
    "## 进行在线预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:migration,new,mbsdk"
   },
   "source": [
    "### [predictions.deploy-model-api](https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api)\n",
    "\n",
    "### [predictions.deploy-model-api](https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:mbsdk,cpu"
   },
   "source": [
    "## 部署模型\n",
    "\n",
    "接下来，为在线预测部署您的模型。要部署模型，您需要调用`deploy`方法，并提供以下参数：\n",
    "\n",
    "- `deployed_model_display_name`：部署模型的人类可读名称。\n",
    "- `traffic_split`：在端点上流量的百分比，流向该模型，以字典形式指定一个或多个键值对。\n",
    "如果只有一个模型，则指定为{ \"0\": 100 }，其中 \"0\" 指的是上传的这个模型，100 表示100%的流量。\n",
    "如果端点上存在其他模型，需要对流量进行分配，则使用model_id指定为{ \"0\": percent, model_id: percent, ... }，其中model_id是已部署在端点的现有模型的模型ID。各比例之和必须为100。\n",
    "- `machine_type`：用于训练的机器类型。\n",
    "- `starting_replica_count`：最初预留的计算实例数。\n",
    "- `max_replica_count`：扩展至的最大计算实例数。在本教程中，只预留了一个实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy_model:mbsdk,cpu"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_NAME = \"census-\" + UUID\n",
    "\n",
    "TRAFFIC_SPLIT = {\"0\": 100}\n",
    "\n",
    "MIN_NODES = 1\n",
    "MAX_NODES = 1\n",
    "\n",
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name=DEPLOYED_NAME,\n",
    "    traffic_split=TRAFFIC_SPLIT,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    min_replica_count=MIN_NODES,\n",
    "    max_replica_count=MAX_NODES,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:mbsdk,cpu"
   },
   "source": [
    "INFO：google.cloud.aiplatform.models：创建端点\n",
    "INFO：google.cloud.aiplatform.models：创建端点后台LRO：projects/759209241365/locations/us-central1/endpoints/4867177336350441472/operations/4087251132693348352\n",
    "INFO：google.cloud.aiplatform.models：端点已创建。资源名称：projects/759209241365/locations/us-central1/endpoints/4867177336350441472\n",
    "INFO：google.cloud.aiplatform.models：要在另一个会话中使用此端点：\n",
    "INFO：google.cloud.aiplatform.models：endpoint = aiplatform.Endpoint('projects/759209241365/locations/us-central1/endpoints/4867177336350441472')\n",
    "INFO：google.cloud.aiplatform.models：部署模型到端点：projects/759209241365/locations/us-central1/endpoints/4867177336350441472\n",
    "INFO：google.cloud.aiplatform.models：部署端点模型后台LRO：projects/759209241365/locations/us-central1/endpoints/4867177336350441472/operations/1691336130932244480\n",
    "INFO：google.cloud.aiplatform.models：端点模型已部署。资源名称：projects/759209241365/locations/us-central1/endpoints/4867177336350441472"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_test_item:scilearn,tabular,census"
   },
   "source": [
    "制作测试项目\n",
    "\n",
    "您可以使用合成数据作为测试数据项目。请不要担心我们使用合成数据 - 我们只是想展示如何进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "make_test_item:scilearn,tabular,census"
   },
   "outputs": [],
   "source": [
    "INSTANCE = [\n",
    "    25,\n",
    "    \"Private\",\n",
    "    226802,\n",
    "    \"11th\",\n",
    "    7,\n",
    "    \"Never-married\",\n",
    "    \"Machine-op-inspct\",\n",
    "    \"Own-child\",\n",
    "    \"Black\",\n",
    "    \"Male\",\n",
    "    0,\n",
    "    0,\n",
    "    40,\n",
    "    \"United-States\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "predict_request:mbsdk,custom,lbn"
   },
   "source": [
    "### 进行预测\n",
    "\n",
    "现在您的 `Model` 资源已部署到一个 `Endpoint` 资源上，您可以通过向 `Endpoint` 资源发送预测请求来进行在线预测。\n",
    "\n",
    "#### 请求\n",
    "\n",
    "每个实例的格式是：\n",
    "\n",
    "    [feature_list]\n",
    "\n",
    "由于 predict() 方法可以接受多个项（实例），请将您的单个测试项作为一个测试项列表发送。\n",
    "\n",
    "#### 响应\n",
    "\n",
    "从 predict() 调用的响应是一个包含以下条目的 Python 字典：\n",
    "\n",
    "- `ids`: 每个预测请求的内部分配的唯一标识符。\n",
    "- `predictions`: 每个类别标签的预测置信度，介于 0 和 1 之间。\n",
    "- `deployed_model_id`: 执行预测的 Vertex AI `Model` 资源的标识符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "predict_request:mbsdk,custom,lbn"
   },
   "outputs": [],
   "source": [
    "instances_list = [INSTANCE]\n",
    "\n",
    "prediction = endpoint.predict(instances_list)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "predict_request:mbsdk,custom,lbn"
   },
   "source": [
    "示例输出：\n",
    "\n",
    "    预测（predictions=[False]，deployed_model_id='7220545636163125248'，explanations=None）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "source": [
    "## 撤销模型\n",
    "\n",
    "当您完成预测时，您需要从“端点”资源中撤销模型。这将取消所有计算资源，并结束部署模型的计费。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "清理工作\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于本教程的[Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源：\n",
    "\n",
    "- 数据集\n",
    "- 模型\n",
    "- 终端\n",
    "- AutoML训练作业\n",
    "- 批处理作业\n",
    "- 云存储桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74ddbf65df4c"
   },
   "outputs": [],
   "source": [
    "# delete endpoint\n",
    "endpoint.delete()\n",
    "\n",
    "# Delete the model using the Vertex model object\n",
    "model.delete()\n",
    "\n",
    "# Delete the AutoML or Pipeline training job\n",
    "job.delete()\n",
    "\n",
    "# Delete the batch prediction job using the Vertex batch prediction object\n",
    "batch_predict_job.delete()\n",
    "\n",
    "delete_bucket = False\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil -m rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sdk-custom-scikit-learn-prebuilt-container.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
