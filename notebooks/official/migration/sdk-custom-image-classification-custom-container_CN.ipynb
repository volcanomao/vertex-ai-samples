{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:migration,new"
   },
   "source": [
    "# Vertex AI迁移：使用自定义训练容器进行自定义图像分类\n",
    "\n",
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "<a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/migration/sdk-custom-image-classification-custom-container.ipynb\" target='_blank'>\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "<a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/migration/sdk-custom-image-classification-custom-container.ipynb\" target='_blank'>\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "<a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/migration/sdk-custom-image-classification-custom-container.ipynb\" target='_blank'>\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>                                                                                               \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62b666b5ce2b"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本笔记本演示了如何使用TensorFlow和Vertex AI SDK创建自定义训练容器来训练自定义图像分类模型。该笔记本还演示了如何将训练好的模型部署到Vertex AI并从中生成预测。\n",
    "\n",
    "了解更多关于[Migrate to Vertex AI](https://cloud.google.com/vertex-ai/docs/start/migrating-to-vertex-ai)和[Custom training](https://cloud.google.com/vertex-ai/docs/training/custom-training)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1ae7d54ad29"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用自定义容器和Vertex AI训练来训练一个tensorflow图像分类模型。训练完成后，您还将使用预构建的容器将模型部署到Vertex AI，并对其进行批处理和在线预测。\n",
    "\n",
    "本教程使用以下谷歌云ML服务和资源：\n",
    "\n",
    "- *Vertex AI训练*\n",
    "- *Vertex AI模型注册*\n",
    "- *Vertex AI批处理预测*\n",
    "- *Vertex AI终点*\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- *将训练代码打包成python应用程序。*\n",
    "- *使用Cloud Build和Artifact Registry对训练应用程序进行容器化。*\n",
    "- *在Vertex AI中创建自定义容器训练作业并运行。*\n",
    "- *评估从训练作业生成的模型。*\n",
    "- *在Vertex AI模型注册中为训练模型创建模型资源。*\n",
    "- *运行Vertex AI批处理预测作业。*\n",
    "- *将模型资源部署到Vertex AI终点。*\n",
    "- *在模型资源上运行在线预测作业。*\n",
    "- *清理创建的资源。*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:custom,cifar10,icn"
   },
   "source": [
    "数据集\n",
    "\n",
    "本教程使用的数据集是[TensorFlow数据集](https://www.tensorflow.org/datasets/catalog/cifar10)中的[CIFAR10数据集](https://www.tensorflow.org/datasets/catalog/overview)。您使用的数据集版本已内置于TensorFlow中。训练模型预测图像属于十个类别中的哪一个：*飞机*、*汽车*、*鸟*、*猫*、*鹿*、*狗*、*青蛙*、*马*、*船*和*卡车*。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "### 成本\n",
    "\n",
    "该教程使用 Google Cloud 的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud 存储\n",
    "* Cloud 构建\n",
    "* 存储库\n",
    "\n",
    "了解[Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing)，[Cloud 存储价格](https://cloud.google.com/storage/pricing)，[Cloud 构建价格](https://cloud.google.com/build/pricing)，[存储库价格](https://cloud.google.com/artifact-registry/pricing) 并使用[定价计算器](https://cloud.google.com/products/calculator/)基于您的预估使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMHz63rPbq6P"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装执行此笔记本所需的包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                         google-cloud-storage -q\n",
    "\n",
    "import os\n",
    "if os.getenv(\"IS_TESTING\"):\n",
    "    ! apt-get update && apt-get install -y python3-opencv-headless\n",
    "    ! apt-get install -y libgl1-mesa-dev\n",
    "    ! pip3 install --upgrade opencv-python-headless -q\n",
    "    ! pip3 install tensorflow==2.9 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58707a750154"
   },
   "source": [
    "### 仅限Colab使用：取消注释以下单元格以重新启动内核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f200f10a1da3"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下操作：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 参考支持页面：[找出项目ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 设置地区\n",
    "\n",
    "**可选**：更新'REGION'变量以指定您想要使用的地区。了解更多关于[Vertex AI地区](https://cloud.google.com/vertex-ai/docs/general/locations)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsN5NJKSu-GU"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "UUID\n",
    "\n",
    "如果您正在进行实时教程会话，可能正在使用共享的测试帐户或项目。为了避免用户在创建的资源上的名称冲突，您可以为每个实例会话创建一个uuid，并将其附加到您在本教程中创建的资源名称上。Bitte geben Sie den Text ein oder verwenden Sie die Spracherkennung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "timestamp"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBCra4QMA2wR"
   },
   "source": [
    "### 验证您的Google Cloud账户\n",
    "\n",
    "要验证您的Google Cloud账户，请按照您的Jupyter环境的说明操作：\n",
    "\n",
    "**1. Vertex AI Workbench**\n",
    "<br>您已经通过验证。\n",
    "\n",
    "**2. 本地JupyterLab实例**\n",
    "<br>取消注释并运行以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "254614fa0c46"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef21552ccea8"
   },
   "source": [
    "取消注释并运行以下代码:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "603adbbf0532"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c13224697bfb"
   },
   "source": [
    "请参阅如何将Cloud Storage权限授予您的服务账户的方法，网址为 https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶，用于存储中间产物，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有当您的存储桶不存在时，请运行以下单元格以创建您的云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 导入库\n",
    "\n",
    "加载在这个笔记本中使用的Vertex AI SDK和其他Python库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from google.cloud import aiplatform\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "### 初始化 Python 的 Vertex AI SDK\n",
    "\n",
    "为您的项目和对应的存储桶初始化 Python 的 Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "source": [
    "## 为培训和预测配置容器\n",
    "\n",
    "在这一步中，您设置用于创建培训和服务容器的配置参数，如所需的GPU数量和类型（默认情况下使用CPU）以及服务所需的机器类型。\n",
    "\n",
    "\n",
    "### 设置硬件加速器\n",
    "\n",
    "您可以为培训和预测设置硬件加速器。\n",
    "\n",
    "设置变量 `TRAIN_GPU/TRAIN_NGPU` 和 `DEPLOY_GPU/DEPLOY_NGPU` 来使用支持GPU的容器映像以及分配给虚拟机实例的GPU数量。例如，要使用一个GPU容器映像，并且为每个VM分配了4个 Nvidia Telsa K80 GPU，您可以指定：\n",
    "\n",
    "    (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
    "\n",
    "\n",
    "否则，请指定 `(None, None)` 来使用一个在CPU上运行的容器映像。\n",
    "\n",
    "在[这里](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)了解更多有关您地区的硬件加速器支持的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "outputs": [],
   "source": [
    "TRAIN_GPU, TRAIN_NGPU = (None, None)\n",
    "DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:prediction"
   },
   "source": [
    "### 为预测设置预构建容器\n",
    "\n",
    "设置预构建的Docker容器镜像用于预测。\n",
    "\n",
    "- 将变量`TF`设置为容器镜像的TensorFlow版本。例如，`2-1`表示版本2.1，`1-15`表示版本1.15。以下列表显示了一些可用的预构建镜像：\n",
    "\n",
    "- 要查看可用的预构建镜像列表，请参阅[用于预测的预构建容器文档](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。下面的单元格默认将版本设置为2.9。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:prediction"
   },
   "outputs": [],
   "source": [
    "TF = \"2-9\"\n",
    "\n",
    "if TF[0] == \"2\":\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf2-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf2-cpu.{}\".format(TF)\n",
    "else:\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "\n",
    "DEPLOY_IMAGE = \"gcr.io/cloud-aiplatform/prediction/{}:latest\".format(DEPLOY_VERSION)\n",
    "\n",
    "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training,prediction"
   },
   "source": [
    "### 设置机器类型\n",
    "\n",
    "接下来，设置用于训练和预测的机器类型。\n",
    "\n",
    "- 设置变量 `TRAIN_COMPUTE` 和 `DEPLOY_COMPUTE` 来配置用于训练和预测的虚拟机的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`: 每个 vCPU 3.75GB 的内存。\n",
    "     - `n1-highmem`: 每个 vCPU 6.5GB 的内存。\n",
    "     - `n1-highcpu`: 每个 vCPU 0.9GB 的内存。\n",
    " - `vCPUs`: 数量为 \\[2, 4, 8, 16, 32, 64, 96 \\]\n",
    "\n",
    "*注意：以下内容不支持用于训练：*\n",
    "\n",
    " - `standard`: 2 个 vCPUs\n",
    " - `highcpu`: 2, 4 和 8 个 vCPUs\n",
    "\n",
    "*注意：您也可以使用 n2 和 e2 机器类型进行训练和部署，但它们不支持GPU。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training,prediction"
   },
   "outputs": [],
   "source": [
    "MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)\n",
    "\n",
    "if os.getenv(\"IS_TESTING_DEPLOY_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_DEPLOY_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_training_package"
   },
   "source": [
    "## 包培训应用\n",
    "\n",
    "在这一步中，您将打包用于在CIFAR10数据集上训练tensorflow图像分类模型的代码，使用您自己创建的自定义容器。\n",
    "\n",
    "为了使用您自己创建的自定义容器，您需要构建一个Docker文件。首先，您需要为容器组件创建一个目录。\n",
    "\n",
    "### 包布局\n",
    "\n",
    "在开始培训之前，您需要查看一个如何为自定义培训工作创建Python包。当解压缩后，包含以下目录/文件布局。\n",
    "\n",
    "- PKG-INFO\n",
    "- README.md\n",
    "- setup.cfg\n",
    "- setup.py\n",
    "- trainer\n",
    "  - \\_\\_init\\_\\_.py\n",
    "  - task.py\n",
    "\n",
    "文件 `setup.cfg` 和 `setup.py` 是将包安装到Docker镜像的操作环境中的指南。\n",
    "\n",
    "文件 `trainer/task.py` 是执行自定义培训工作的Python脚本。\n",
    "\n",
    "*注意：当引用worker池规范中的文件时，目录斜杠会被替换为点(`trainer.task`)，并且会删除文件后缀(`.py`)。*\n",
    "\n",
    "### 包装配\n",
    "\n",
    "在下面的单元格中，您将组装训练包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "examine_training_package"
   },
   "outputs": [],
   "source": [
    "# Make folder for Python training script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\nsetuptools.setup(\\n\\n    install_requires=[\\n\\n        'tensorflow_datasets==1.3.0',\\n\\n    ],\\n\\n    packages=setuptools.find_packages())\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\nName: CIFAR10 image classification\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taskpy_contents:cifar10"
   },
   "source": [
    "### 训练器任务内容\n",
    "\n",
    "在下一个单元格中，您将编写训练脚本 `task.py` 的内容。这里不会深入讨论脚本的细节。\n",
    "\n",
    "总结起来，它会：\n",
    "\n",
    "- 从命令行中获取保存模型数据的目录（`--model_dir`），如果未指定，则从环境变量 `AIP_MODEL_DIR` 中获取。\n",
    "- 从 TF Datasets（tfds）加载 CIFAR10 数据集。\n",
    "- 使用 TF.Keras 模型 API 构建模型。\n",
    "- 编译模型（`compile()`）。\n",
    "- 根据参数 `args.distribute` 设置训练分布策略。\n",
    "- 根据参数 `args.epochs` 和 `args.steps` 训练模型（`fit()`）。\n",
    "- 将训练好的模型保存到指定的模型目录中（`save(args.model_dir)`）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taskpy_contents:cifar10"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "# Single, Mirror and Multi-Machine Distributed Training for CIFAR-10\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model-dir', dest='model_dir',\n",
    "                    default=os.getenv(\"AIP_MODEL_DIR\"), type=str, help='Model dir.')\n",
    "parser.add_argument('--lr', dest='lr',\n",
    "                    default=0.01, type=float,\n",
    "                    help='Learning rate.')\n",
    "parser.add_argument('--epochs', dest='epochs',\n",
    "                    default=10, type=int,\n",
    "                    help='Number of epochs.')\n",
    "parser.add_argument('--steps', dest='steps',\n",
    "                    default=200, type=int,\n",
    "                    help='Number of steps per epoch.')\n",
    "parser.add_argument('--distribute', dest='distribute', type=str, default='single',\n",
    "                    help='distributed training strategy')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print('Python Version = {}'.format(sys.version))\n",
    "print('TensorFlow Version = {}'.format(tf.__version__))\n",
    "print('TF_CONFIG = {}'.format(os.environ.get('TF_CONFIG', 'Not found')))\n",
    "print('DEVICES', device_lib.list_local_devices())\n",
    "\n",
    "# Single Machine, single compute device\n",
    "if args.distribute == 'single':\n",
    "    if tf.test.is_gpu_available():\n",
    "        strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    else:\n",
    "        strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
    "# Single Machine, multiple compute device\n",
    "elif args.distribute == 'mirror':\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "# Multiple Machine, multiple compute device\n",
    "elif args.distribute == 'multi':\n",
    "    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "# Multi-worker configuration\n",
    "print('num_replicas_in_sync = {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Preparing dataset\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "def make_datasets_unbatched():\n",
    "\n",
    "  # Scaling CIFAR10 data from (0, 255] to (0., 1.]\n",
    "  def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.0\n",
    "    return image, label\n",
    "\n",
    "\n",
    "  datasets, info = tfds.load(name='cifar10',\n",
    "                            with_info=True,\n",
    "                            as_supervised=True)\n",
    "  return datasets['train'].map(scale).cache().shuffle(BUFFER_SIZE).repeat()\n",
    "\n",
    "\n",
    "# Build the Keras model\n",
    "def build_and_compile_cnn_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(32, 32, 3)),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "      optimizer=tf.keras.optimizers.SGD(learning_rate=args.lr),\n",
    "      metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "\n",
    "# Train the model\n",
    "NUM_WORKERS = strategy.num_replicas_in_sync\n",
    "# Here the batch size scales up by number of workers since\n",
    "# `tf.data.Dataset.batch` expects the global batch size.\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE * NUM_WORKERS\n",
    "train_dataset = make_datasets_unbatched().batch(GLOBAL_BATCH_SIZE)\n",
    "\n",
    "with strategy.scope():\n",
    "  # Creation of dataset, and model building/compiling need to be within\n",
    "  # `strategy.scope()`.\n",
    "  model = build_and_compile_cnn_model()\n",
    "\n",
    "model.fit(x=train_dataset, epochs=args.epochs, steps_per_epoch=args.steps)\n",
    "model.save(args.model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "write_docker_file:training,tf-dlvm"
   },
   "source": [
    "编写Dockerfile内容\n",
    "\n",
    "容器化您的代码的第一步是创建一个Dockerfile。在Dockerfile中，您包含了运行容器镜像所需的所有命令。在构建过程中，将安装所有软件包并设置一个入口点用于您的训练代码。\n",
    "\n",
    "在此步骤中，您的Dockerfile将执行以下操作：\n",
    "1. 从TensorFlow存储库中安装预定义的容器镜像用于深度学习图像。\n",
    "2. 复制Python训练代码，稍后将显示。\n",
    "3. 将入口设置为Python训练脚本为`trainer/task.py`。请注意，在ENTRYPOINT命令中省略了`.py`，因为其被隐含。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "write_docker_file:training,tf-dlvm"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/Dockerfile\n",
    "\n",
    "FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-9\n",
    "WORKDIR /root\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY trainer /trainer\n",
    "\n",
    "# Sets up the entry point to invoke the trainer.\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gar_enable_api"
   },
   "source": [
    "### 启用 Artifact Registry API\n",
    "\n",
    "您必须为您的项目启用Artifact Registry API服务。\n",
    "\n",
    "了解有关[启用服务](https://cloud.google.com/artifact-registry/docs/enable-service)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gar_enable_api"
   },
   "outputs": [],
   "source": [
    "! gcloud services enable artifactregistry.googleapis.com\n",
    "\n",
    "if os.getenv(\"IS_TESTING\"):\n",
    "    ! sudo apt-get update --yes && sudo apt-get --only-upgrade --yes install google-cloud-sdk-cloud-run-proxy google-cloud-sdk-harbourbridge google-cloud-sdk-cbt google-cloud-sdk-gke-gcloud-auth-plugin google-cloud-sdk-kpt google-cloud-sdk-local-extract google-cloud-sdk-minikube google-cloud-sdk-app-engine-java google-cloud-sdk-app-engine-go google-cloud-sdk-app-engine-python google-cloud-sdk-spanner-emulator google-cloud-sdk-bigtable-emulator google-cloud-sdk-nomos google-cloud-sdk-package-go-module google-cloud-sdk-firestore-emulator kubectl google-cloud-sdk-datastore-emulator google-cloud-sdk-app-engine-python-extras google-cloud-sdk-cloud-build-local google-cloud-sdk-kubectl-oidc google-cloud-sdk-anthos-auth google-cloud-sdk-app-engine-grpc google-cloud-sdk-pubsub-emulator google-cloud-sdk-datalab google-cloud-sdk-skaffold google-cloud-sdk google-cloud-sdk-terraform-tools google-cloud-sdk-config-connector\n",
    "    ! gcloud components update --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gar_create_repo"
   },
   "source": [
    "## 创建一个私有的Docker仓库\n",
    "\n",
    "您的第一步是在Google Artifact Registry中创建自己的Docker仓库。\n",
    "\n",
    "1. 运行`gcloud artifacts repositories create`命令，在您的区域创建一个新的Docker仓库，描述为“docker仓库”。\n",
    "\n",
    "2. 运行`gcloud artifacts repositories list`命令来验证您的仓库是否已经创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gar_create_repo"
   },
   "outputs": [],
   "source": [
    "REPOSITORY = \"my-docker-repo\"\n",
    "\n",
    "! gcloud artifacts repositories create {REPOSITORY} --repository-format=docker --location={REGION} --description=\"Docker repository\"\n",
    "\n",
    "! gcloud artifacts repositories list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "name_container:training"
   },
   "source": [
    "## 构建训练容器\n",
    "\n",
    "### 创建一个存储库\n",
    "\n",
    "接下来，在Artifact Registry中创建一个存储库，用于存储您的训练图像。\n",
    "\n",
    "在下面为您的存储库和自定义容器设置名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "name_container:training"
   },
   "outputs": [],
   "source": [
    "CONTAINER_NAME = \"cifar10\"\n",
    "\n",
    "TAG = \"latest\"\n",
    "TRAIN_IMAGE = (\n",
    "    f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{CONTAINER_NAME}:{TAG}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "build_container:training"
   },
   "source": [
    "在Artifact Registry中创建存储库。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "register_container:training"
   },
   "source": [
    "### 为培训构建自定义容器\n",
    "\n",
    "接下来，您使用Cloud Build构建并推送一个docker镜像到创建的存储库。\n",
    "\n",
    "了解更多关于使用Cloud Build构建和推送Docker镜像的过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2e7b3bcc53df"
   },
   "outputs": [],
   "source": [
    "%cd custom\n",
    "!gcloud builds submit --region={REGION} --tag=$TRAIN_IMAGE\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tarball_training_script"
   },
   "source": [
    "### 将培训脚本存储在您的云存储桶中（可选）\n",
    "\n",
    "接下来，您将培训文件夹打包成一个压缩的tar球，然后将其存储在您的云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tarball_training_script"
   },
   "outputs": [],
   "source": [
    "! rm -f custom.tar custom.tar.gz\n",
    "! tar cvf custom.tar custom\n",
    "! gzip custom.tar\n",
    "! gsutil cp custom.tar.gz $BUCKET_URI/trainer_cifar10.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_training_job:mbsdk,no_model,custom"
   },
   "source": [
    "## 创建和运行自定义训练作业\n",
    "\n",
    "要训练一个自定义模型，您需要执行两个步骤：1) 创建一个自定义训练作业，2) 运行这个作业。\n",
    "\n",
    "有关更多详细信息，请参阅[自定义容器概述]（https://cloud.google.com/vertex-ai/docs/training/containers-overview）。\n",
    "\n",
    "### 创建自定义训练作业\n",
    "\n",
    "使用`CustomTrainingJob`类创建一个自定义训练作业，以下是参数：\n",
    "\n",
    "- `display_name`：自定义训练作业的可读名称。\n",
    "- `container_uri`：训练容器镜像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_custom_training_job:mbsdk,no_model,custom"
   },
   "outputs": [],
   "source": [
    "job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=\"cifar10_\" + UUID, container_uri=TRAIN_IMAGE\n",
    ")\n",
    "\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_custom_job:mbsdk,no_model"
   },
   "source": [
    "运行自定义训练作业\n",
    "\n",
    "接下来，您可以通过调用`run`方法来运行自定义作业以启动训练作业，传入以下参数：\n",
    "\n",
    "- `args`：传递给训练脚本的命令行参数。\n",
    "- `replica_count`：用于训练的计算实例数量（replica_count = 1 表示单节点训练）。\n",
    "- `machine_type`：计算实例的机器类型。\n",
    "- `accelerator_type`：硬件加速器类型。\n",
    "- `accelerator_count`：要附加到工作节点的加速器数量。\n",
    "- `base_output_dir`：Cloud Storage 位置，用于写入模型构件。\n",
    "- `sync`：是否阻塞直到作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_custom_job:mbsdk,no_model"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = \"{}/{}\".format(BUCKET_URI, UUID)\n",
    "\n",
    "EPOCHS = 10\n",
    "STEPS = 100\n",
    "\n",
    "DIRECT = True\n",
    "if DIRECT:\n",
    "    CMDARGS = [\n",
    "        \"--model-dir=\" + MODEL_DIR,\n",
    "        \"--epochs=\" + str(EPOCHS),\n",
    "        \"--steps=\" + str(STEPS),\n",
    "    ]\n",
    "else:\n",
    "    CMDARGS = [\n",
    "        \"--epochs=\" + str(EPOCHS),\n",
    "        \"--steps=\" + str(STEPS),\n",
    "    ]\n",
    "\n",
    "if TRAIN_GPU:\n",
    "    job.run(\n",
    "        args=CMDARGS,\n",
    "        replica_count=1,\n",
    "        machine_type=TRAIN_COMPUTE,\n",
    "        accelerator_type=TRAIN_GPU.name,\n",
    "        accelerator_count=TRAIN_NGPU,\n",
    "        base_output_dir=MODEL_DIR,\n",
    "        sync=True,\n",
    "    )\n",
    "else:\n",
    "    job.run(\n",
    "        args=CMDARGS,\n",
    "        replica_count=1,\n",
    "        machine_type=TRAIN_COMPUTE,\n",
    "        base_output_dir=MODEL_DIR,\n",
    "        sync=True,\n",
    "    )\n",
    "\n",
    "model_path_to_deploy = MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_custom_job:mbsdk,no_model"
   },
   "source": [
    "### 等待自定义训练作业完成\n",
    "\n",
    "接下来，等待自定义训练作业完成。或者，可以在`run()`方法中将参数`sync`设置为`True`，以阻塞直到自定义训练作业完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "load_saved_model"
   },
   "source": [
    "加载保存的模型\n",
    "\n",
    "您的模型以 TensorFlow SavedModel 格式存储在 Cloud Storage 存储桶中。现在，从 Cloud Storage 存储桶中加载它，然后您可以执行诸如评估模型和做预测之类的任务。\n",
    "\n",
    "要加载模型，您可以使用 TF.Keras 的 `model.load_model()` 方法，将保存模型的 Cloud Storage 路径（即 `MODEL_DIR` 指定的路径）作为参数传递给它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_saved_model"
   },
   "outputs": [],
   "source": [
    "local_model = tf.keras.models.load_model(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_custom_model:image"
   },
   "source": [
    "## 评估模型\n",
    "\n",
    "现在，您可以通过在测试数据上评估模型来了解模型的表现如何。\n",
    "\n",
    "### 加载测试数据\n",
    "\n",
    "为了进行模型评估，您需要使用`tf.keras.datasets`中的`load_data()`方法加载CIFAR10测试（保留）数据。该方法返回一个包含两个元素的元组。第一个元素是训练数据，第二个是测试数据。每个元素也是一个包含两个元素的元组：图像数据和对应的标签。\n",
    "\n",
    "您不需要训练数据，所以加载时使用`(_, _)`。\n",
    "\n",
    "在对数据进行评估之前，您需要对其进行预处理：\n",
    "\n",
    "`x_test`：通过将每个像素除以255来对像素数据进行归一化（重新缩放）。这将使用32位浮点数字代替每个单字节整数像素，范围在0到1之间。\n",
    "\n",
    "`y_test`：标签目前是标量（稀疏）形式。如果您回顾`trainer/task.py`脚本中的`compile()`步骤，您会发现它是为稀疏标签而编译的。因此我们不需要再做其他处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_custom_model:image,cifar10"
   },
   "outputs": [],
   "source": [
    "(_, _), (x_test, y_test) = cifar10.load_data()\n",
    "x_test = (x_test / 255.0).astype(np.float32)\n",
    "\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "perform_evaluation_custom"
   },
   "source": [
    "### 进行模型评估\n",
    "\n",
    "评估由自定义作业创建的模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "perform_evaluation_custom"
   },
   "outputs": [],
   "source": [
    "local_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "serving_function_image"
   },
   "source": [
    "## 图像数据的处理功能\n",
    "\n",
    "为了将图像传递给预测服务，您需要将压缩（例如JPEG）的图像字节编码为base 64，这样可以使内容在通过网络传输二进制数据时安全免受修改。由于这个部署的模型期望输入数据为原始（未压缩）字节，您需要确保将base 64编码的数据在传递给部署的模型之前转换回原始字节。\n",
    "\n",
    "为了解决这个问题，您需要定义一个服务功能(`serving_fn`)并将其附加到模型作为预处理步骤。添加`@tf.function`装饰器，以便服务功能与底层模型融合在一起（而不是在CPU上游）。\n",
    "\n",
    "当您发送预测或解释请求时，请求的内容将被base 64解码为Tensorflow字符串（`tf.string`），然后传递给服务功能(`serving_fn`)。服务功能将`tf.string`预处理为原始（未压缩）的numpy字节（`preprocess_fn`），以满足模型的输入要求：\n",
    "- `io.decode_jpeg`- 解压JPG图像，返回带有三个通道（RGB）的Tensorflow张量。\n",
    "- `image.convert_image_dtype` - 将整数像素值改为float 32。\n",
    "- `image.resize` - 调整图像大小以匹配模型的输入形状。\n",
    "- `resized / 255.0` - 将像素数据重新缩放（归一化），使其在0到1之间。\n",
    "\n",
    "此时，数据可以传递给模型（`m_call`）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "serving_function_image"
   },
   "outputs": [],
   "source": [
    "CONCRETE_INPUT = \"numpy_inputs\"\n",
    "\n",
    "\n",
    "def _preprocess(bytes_input):\n",
    "    decoded = tf.io.decode_jpeg(bytes_input, channels=3)\n",
    "    decoded = tf.image.convert_image_dtype(decoded, tf.float32)\n",
    "    resized = tf.image.resize(decoded, size=(32, 32))\n",
    "    rescale = tf.cast(resized / 255.0, tf.float32)\n",
    "    return rescale\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "def preprocess_fn(bytes_inputs):\n",
    "    decoded_images = tf.map_fn(\n",
    "        _preprocess, bytes_inputs, dtype=tf.float32, back_prop=False\n",
    "    )\n",
    "    return {\n",
    "        CONCRETE_INPUT: decoded_images\n",
    "    }  # User needs to make sure the key matches model's input\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "def serving_fn(bytes_inputs):\n",
    "    images = preprocess_fn(bytes_inputs)\n",
    "    prob = m_call(**images)\n",
    "    return prob\n",
    "\n",
    "\n",
    "m_call = tf.function(local_model.call).get_concrete_function(\n",
    "    [tf.TensorSpec(shape=[None, 32, 32, 3], dtype=tf.float32, name=CONCRETE_INPUT)]\n",
    ")\n",
    "\n",
    "tf.saved_model.save(\n",
    "    local_model, model_path_to_deploy, signatures={\"serving_default\": serving_fn}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "serving_function_signature:image"
   },
   "source": [
    "## 获取serving函数签名\n",
    "\n",
    "您可以通过重新加载模型到内存，并查询每个图层对应的签名来获取模型的输入和输出图层的签名。\n",
    "\n",
    "当您将数据发送到HTTP请求包进行预测时，图像数据会以base64编码形式发送，而TF Keras模型只接受numpy输入。您的serving函数会将base64转换为numpy数组。\n",
    "\n",
    "在进行预测请求时，您需要将请求路由到serving函数而不是模型。因此，在您进行预测请求时，您需要知道serving函数的输入图层名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "serving_function_signature:image"
   },
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(model_path_to_deploy)\n",
    "\n",
    "serving_input = list(\n",
    "    loaded.signatures[\"serving_default\"].structured_input_signature[1].keys()\n",
    ")[0]\n",
    "print(\"Serving function input:\", serving_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_model:mbsdk"
   },
   "source": [
    "## 上传模型\n",
    "\n",
    "接下来，使用`Model.upload()`方法将您的模型上传到`Model`资源，包括以下参数：\n",
    "\n",
    "- `display_name`：`Model`资源的可读名称。\n",
    "- `artifact`：训练模型工件的Cloud Storage位置。\n",
    "- `serving_container_image_uri`：服务容器镜像。\n",
    "- `sync`：是否异步或同步执行上传。\n",
    "\n",
    "如果使用异步方式运行`upload()`方法，您可以随后使用`wait()`方法阻塞直至完成。\n",
    "\n",
    "了解更多关于[向 Vertex AI 导入模型](https://cloud.google.com/vertex-ai/docs/general/import-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=\"cifar10_\" + UUID,\n",
    "    artifact_uri=MODEL_DIR,\n",
    "    serving_container_image_uri=DEPLOY_IMAGE,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_test_items:test"
   },
   "source": [
    "## 进行批量预测\n",
    "\n",
    "### 获取测试项目\n",
    "\n",
    "您将使用数据集中保留的测试（留置）部分中的示例作为测试项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_test_items:test"
   },
   "outputs": [],
   "source": [
    "test_image_1 = x_test[0]\n",
    "test_label_1 = y_test[0]\n",
    "test_image_2 = x_test[1]\n",
    "test_label_2 = y_test[1]\n",
    "print(test_image_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prepare_test_items:test,image"
   },
   "source": [
    "### 准备请求内容\n",
    "您将发送CIFAR10图像作为压缩的JPG图像，而不是原始未压缩的字节：\n",
    "\n",
    "- `cv2.imwrite`：使用OpenCV将未压缩的图像写入磁盘，保存为压缩的JPEG图像。\n",
    "- 将图像数据从 \\[0,1) 范围反归一化到 [0,255)。\n",
    "- 将32位浮点数值转换为8位无符号整数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare_test_items:test,image"
   },
   "outputs": [],
   "source": [
    "cv2.imwrite(\"tmp1.jpg\", (test_image_1 * 255).astype(np.uint8))\n",
    "cv2.imwrite(\"tmp2.jpg\", (test_image_2 * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "copy_test_items:test"
   },
   "source": [
    "### 复制测试项目。\n",
    "\n",
    "为了进行批量预测，请将测试项目复制到您的云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copy_test_items:test"
   },
   "outputs": [],
   "source": [
    "! gsutil cp tmp1.jpg $BUCKET_URI/tmp1.jpg\n",
    "! gsutil cp tmp2.jpg $BUCKET_URI/tmp2.jpg\n",
    "\n",
    "test_item_1 = BUCKET_URI + \"/tmp1.jpg\"\n",
    "test_item_2 = BUCKET_URI + \"/tmp2.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_batch_file:custom,image"
   },
   "source": [
    "生成批量输入文件\n",
    "\n",
    "现在创建一个批量输入文件，将其存储在您的本地Cloud存储桶中。批量输入文件只能是JSONL格式。对于JSONL文件，您为每个数据项（实例）的每行创建一个字典条目。字典包含键/值对：\n",
    "\n",
    "- `input_name`：基础模型的输入层的名称。\n",
    "- `'b64'`：指示内容为base64编码的键。\n",
    "- `content`：压缩的JPG图像字节作为base64编码的字符串。\n",
    "\n",
    "预测请求中的每个实例是形式为的字典条目：\n",
    "\n",
    "                        {serving_input: {'b64': content}}\n",
    "\n",
    "为将图像数据传递给预测服务，您将字节编码为base64。这使内容在通过网络传输二进制数据时免受修改。\n",
    "\n",
    "- `tf.io.read_file`：将压缩的JPG图像作为原始字节读入内存。\n",
    "- `base64.b64encode`：将原始字节编码为base64编码的字符串。\n",
    "\n",
    "了解更多关于[Vertex AI批量预测](https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions)的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "make_batch_file:custom,image"
   },
   "outputs": [],
   "source": [
    "gcs_input_uri = BUCKET_URI + \"/\" + \"test.jsonl\"\n",
    "with tf.io.gfile.GFile(gcs_input_uri, \"w\") as f:\n",
    "    bytes = tf.io.read_file(test_item_1)\n",
    "    b64str = base64.b64encode(bytes.numpy()).decode(\"utf-8\")\n",
    "    data = {serving_input: {\"b64\": b64str}}\n",
    "    f.write(json.dumps(data) + \"\\n\")\n",
    "    bytes = tf.io.read_file(test_item_2)\n",
    "    b64str = base64.b64encode(bytes.numpy()).decode(\"utf-8\")\n",
    "    data = {serving_input: {\"b64\": b64str}}\n",
    "    f.write(json.dumps(data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request:mbsdk,jsonl,custom"
   },
   "source": [
    "### 发起批量预测请求\n",
    "\n",
    "现在您的模型资源已经训练完成，您可以通过调用batch_predict()方法发起批量预测，使用以下参数：\n",
    "\n",
    "- `job_display_name`：批量预测作业的可读名称。\n",
    "- `gcs_source`：一个或多个批请求输入文件的列表。\n",
    "- `gcs_destination_prefix`：用于存储批量预测结果的Cloud Storage位置。\n",
    "- `instances_format`：输入实例的格式，可以是'csv'或'jsonl'。默认为'jsonl'。\n",
    "- `predictions_format`：输出预测的格式，可以是'csv'或'jsonl'。默认为'jsonl'。\n",
    "- `machine_type`：用于训练的机器类型。\n",
    "- `accelerator_type`：硬件加速器类型。\n",
    "- `accelerator_count`：要附加到工作副本的加速器数量。\n",
    "- `sync`：如果设置为True，调用将在等待异步批处理作业完成期间阻塞。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request:mbsdk,jsonl,custom"
   },
   "outputs": [],
   "source": [
    "MIN_NODES = 1\n",
    "MAX_NODES = 1\n",
    "\n",
    "batch_predict_job = model.batch_predict(\n",
    "    job_display_name=\"cifar10_\" + UUID,\n",
    "    gcs_source=gcs_input_uri,\n",
    "    gcs_destination_prefix=BUCKET_URI,\n",
    "    instances_format=\"jsonl\",\n",
    "    predictions_format=\"jsonl\",\n",
    "    model_parameters=None,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    accelerator_type=DEPLOY_GPU,\n",
    "    accelerator_count=DEPLOY_NGPU,\n",
    "    starting_replica_count=MIN_NODES,\n",
    "    max_replica_count=MAX_NODES,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "print(batch_predict_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "source": [
    "### 等待批量预测任务完成\n",
    "\n",
    "接下来，等待批处理作业完成。或者，可以在`batch_predict()`方法中将参数`sync`设置为`True`，以阻塞直到批处理预测作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "outputs": [],
   "source": [
    "batch_predict_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_batch_prediction:mbsdk,custom,icn"
   },
   "source": [
    "### 获取预测结果\n",
    "\n",
    "接下来，从已完成的批量预测作业中获取结果。\n",
    "\n",
    "结果将写入您在批量预测请求中指定的云存储输出桶。您可以调用iter_outputs()方法获取生成结果的每个云存储文件的列表。每个文件以JSON格式包含一个或多个预测请求：\n",
    "\n",
    "- `instance`：预测请求。\n",
    "- `prediction`：预测响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_batch_prediction:mbsdk,custom,icn"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "bp_iter_outputs = batch_predict_job.iter_outputs()\n",
    "\n",
    "prediction_results = list()\n",
    "for blob in bp_iter_outputs:\n",
    "    if blob.name.split(\"/\")[-1].startswith(\"prediction\"):\n",
    "        prediction_results.append(blob.name)\n",
    "\n",
    "tags = list()\n",
    "for prediction_result in prediction_results:\n",
    "    gfile_name = f\"gs://{bp_iter_outputs.bucket.name}/{prediction_result}\"\n",
    "    with tf.io.gfile.GFile(name=gfile_name, mode=\"r\") as gfile:\n",
    "        for line in gfile.readlines():\n",
    "            line = json.loads(line)\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:mbsdk,all"
   },
   "source": [
    "进行在线预测\n",
    "\n",
    "在可以用于提供在线预测之前，您必须将模型部署到一个端点。部署模型会将物理资源与模型关联起来，以便可以使用低延迟提供在线预测。\n",
    "\n",
    "有关更多详细信息，请参阅[在Vertex AI上获取预测概述](https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api)。\n",
    "\n",
    "部署模型\n",
    "\n",
    "接下来，部署您的模型以进行在线预测。要部署模型，您需要调用`deploy`方法，并提供以下参数：\n",
    "\n",
    "- `deployed_model_display_name`：部署模型的易读名称。\n",
    "- `traffic_split`：在端点上流入此模型的流量百分比，指定为一个或多个键/值对的字典。\n",
    "如果只有一个模型，则指定为{ \"0\": 100 }，其中\"0\"指的是上传的这个模型，100表示100%的流量流向此模型。\n",
    "如果端点上有现有模型，其流量被分割，则使用`model_id`来指定为{ \"0\": 百分比，model_id: 百分比，... }，其中`model_id`是部署端点的现有模型的模型ID。这些百分比必须总和为100。\n",
    "- `machine_type`：用于训练的计算机类型。\n",
    "- `accelerator_type`：硬件加速器类型。\n",
    "- `accelerator_count`：要附加到工作人员副本的加速器数量。\n",
    "- `starting_replica_count`：初始预置的计算实例数量。\n",
    "- `max_replica_count`：要扩展到的最大计算实例数量。在此教程中，仅预留了一个实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy_model:mbsdk,all"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_NAME = \"cifar10-\" + UUID\n",
    "\n",
    "TRAFFIC_SPLIT = {\"0\": 100}\n",
    "\n",
    "MIN_NODES = 1\n",
    "MAX_NODES = 1\n",
    "\n",
    "if DEPLOY_GPU:\n",
    "    endpoint = model.deploy(\n",
    "        deployed_model_display_name=DEPLOYED_NAME,\n",
    "        traffic_split=TRAFFIC_SPLIT,\n",
    "        machine_type=DEPLOY_COMPUTE,\n",
    "        accelerator_type=DEPLOY_GPU,\n",
    "        accelerator_count=DEPLOY_NGPU,\n",
    "        min_replica_count=MIN_NODES,\n",
    "        max_replica_count=MAX_NODES,\n",
    "    )\n",
    "else:\n",
    "    endpoint = model.deploy(\n",
    "        deployed_model_display_name=DEPLOYED_NAME,\n",
    "        traffic_split=TRAFFIC_SPLIT,\n",
    "        machine_type=DEPLOY_COMPUTE,\n",
    "        accelerator_type=DEPLOY_GPU,\n",
    "        accelerator_count=0,\n",
    "        min_replica_count=MIN_NODES,\n",
    "        max_replica_count=MAX_NODES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_test_item:test"
   },
   "source": [
    "获取测试项目\n",
    "\n",
    "您可以从数据集的测试（保留）部分中取一个示例作为测试项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_test_item:test"
   },
   "outputs": [],
   "source": [
    "test_image = x_test[0]\n",
    "test_label = y_test[0]\n",
    "print(test_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prepare_test_item:test,image"
   },
   "source": [
    "### 准备请求内容\n",
    "您发送CIFAR10图像作为压缩的JPG图像，而不是原始的未压缩字节：\n",
    "\n",
    "- `cv2.imwrite`：使用openCV将未压缩的图像写入磁盘作为压缩的JPEG图像。\n",
    " - 将图像数据从\\[0,1)范围反归一化为\\[0,255)。\n",
    " - 将32位浮点值转换为8位无符号整数。\n",
    "- `tf.io.read_file`：将压缩的JPG图像读取回内存为原始字节。\n",
    "- `base64.b64encode`：将原始字节编码为base 64编码的字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare_test_item:test,image"
   },
   "outputs": [],
   "source": [
    "cv2.imwrite(\"tmp.jpg\", (test_image * 255).astype(np.uint8))\n",
    "\n",
    "bytes_data = tf.io.read_file(\"tmp.jpg\")\n",
    "b64str = base64.b64encode(bytes_data.numpy()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "predict_request:mbsdk,custom,icn"
   },
   "source": [
    "### 进行预测\n",
    "\n",
    "现在您的 `Model` 资源已部署到一个 `Endpoint` 资源，您可以通过向 Endpoint 资源发送预测请求来进行在线预测。\n",
    "\n",
    "#### 请求\n",
    "\n",
    "在这个示例中，由于您的测试项目位于一个 Cloud Storage 存储桶中，您需要使用 `tf.io.gfile.Gfile()` 来打开并读取图像的内容。为了将测试数据传递给预测服务，您需要将字节编码为 base64，这样可以确保在网络上传输二进制数据时内容不会被修改。\n",
    "\n",
    "每个实例的格式为：\n",
    "\n",
    "    { serving_input: { 'b64': base64编码的字节 } }\n",
    "\n",
    "由于 `predict()` 方法可以接受多个项目（实例），请将您的单个测试项目作为一个测试项目列表发送。\n",
    "\n",
    "#### 响应\n",
    "\n",
    "从 `predict()` 调用返回的是一个Python字典，其中包含以下条目：\n",
    "\n",
    "- `ids`：每个预测请求的内部分配的唯一标识符。\n",
    "- `predictions`：每个类别标签的预测置信度，介于0和1之间。\n",
    "- `deployed_model_id`：执行预测的已部署 `Model` 资源的 Vertex AI 标识符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "predict_request:mbsdk,custom,icn"
   },
   "outputs": [],
   "source": [
    "# The format of each instance should conform to the deployed model's prediction input schema.\n",
    "instances = [{serving_input: {\"b64\": b64str}}]\n",
    "\n",
    "prediction = endpoint.predict(instances=instances)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "source": [
    "## 下线模型\n",
    "\n",
    "当你完成预测后，你可以从`Endpoint`资源中下线模型。这将取消所有计算资源，并停止部署模型的计费。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除您用于本教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源：\n",
    "\n",
    "将`delete_bucket`设置为**True**以删除Cloud Storage存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "outputs": [],
   "source": [
    "delete_bucket = False\n",
    "\n",
    "# Delete the model using the Vertex model object\n",
    "model.delete()\n",
    "\n",
    "# Delete the endpoint using the Vertex endpoint object\n",
    "endpoint.delete()\n",
    "\n",
    "# Delete the custom trainig job\n",
    "job.delete()\n",
    "\n",
    "# Delete the batch prediction job using the Vertex batch prediction object\n",
    "batch_predict_job.delete()\n",
    "\n",
    "# Delete artifact repository\n",
    "! gcloud artifacts repositories delete $REPOSITORY --location=$REGION --quiet\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sdk-custom-image-classification-custom-container.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
