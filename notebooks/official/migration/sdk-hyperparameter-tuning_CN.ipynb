{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:migration,new"
   },
   "source": [
    "# Vertex AI 迁移：超参数调整\n",
    "\n",
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/migration/sdk-hyperparameter-tuning.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/migration/sdk-hyperparameter-tuning.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "<a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/migration/sdk-hyperparameter-tuning.ipynb\" target='_blank'>\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在 Vertex AI Workbench 中打开\n",
    "    </a>\n",
    "  </td>                                                                                               \n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a8a13b86a8b"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何使用Python的Vertex AI SDK来调整自定义表格分类TensorFlow模型中的超参数。\n",
    "\n",
    "了解更多关于[Migrate to Vertex AI](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview)和[Custom training](https://cloud.google.com/vertex-ai/docs/training/custom-training)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "618cfedf829a"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用`Vertex AI Hyperparameter`来创建和调整自定义训练模型。\n",
    "\n",
    "您将学习如何使用Vertex AI SDK for Python在Docker容器中从Python脚本创建和调整自定义训练模型。\n",
    "\n",
    "本教程使用以下Google Cloud ML服务：\n",
    "\n",
    "- `Vertex AI Training`\n",
    "- `Vertex AI Hyperparameter Tuning`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 为训练TensorFlow模型创建一个`Vertex AI`超参数调整作业。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:custom,boston,lrg"
   },
   "source": [
    "数据集\n",
    "\n",
    "本教程使用的数据集是波士顿房价数据集。本教程中使用的数据集版本已经集成在TensorFlow中。训练模型预测房屋的中位价格，单位为1K美元。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "### 费用\n",
    "\n",
    "本教程使用 Google Cloud 的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* 云存储\n",
    "\n",
    "了解 [Vertex AI 的定价](https://cloud.google.com/vertex-ai/pricing) 和 [云存储的定价](https://cloud.google.com/storage/pricing)，以及使用 [定价计算器](https://cloud.google.com/products/calculator/) 根据您预期的使用量生成费用估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装执行此笔记本所需的包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
    "                                 google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "只有Colab：取消注释以下单元格以重新启动内核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-ZBOjErv5mM"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "## 在开始之前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "### 设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下操作:\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面: [查找项目ID](https://support.google.com/googleapi/answer/7014113)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "区域\n",
    "\n",
    "您也可以更改 Vertex AI 使用的 `REGION` 变量。 了解有关 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations) 的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "UUID\n",
    "\n",
    "如果您正在进行实时教程会话，您可能正在使用共享的测试帐户或项目。为了避免在创建的资源上发生名称冲突，您为每个实例会话创建一个UUID，并将其附加到您在本教程中创建的资源名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "timestamp"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 验证您的Google Cloud账户\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动进行身份验证。请按照以下相关说明进行操作。\n",
    "\n",
    "**1. Vertex AI Workbench**\n",
    "* 无需操作，因为您已经通过身份验证。\n",
    "\n",
    "**2. 本地JupyterLab实例，请取消注释并运行：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce6043da7b33"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0367eac06a10"
   },
   "source": [
    "3. 合作，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21ad4dbb4a61"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c13224697bfb"
   },
   "source": [
    "查看如何在https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples上为您的服务账户授予云存储权限。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶，用于存储中间产物，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有在您的存储桶不存在时：运行下面的单元格来创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在本教程中使用的变量。\n",
    "### 导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "初始化 Python 的 Vertex SDK，用于您的项目和相应的存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "source": [
    "设置硬件加速器\n",
    "\n",
    "您可以为训练和预测设置硬件加速器。\n",
    "\n",
    "设置变量`TRAIN_GPU/TRAIN_NGPU`和`DEPLOY_GPU/DEPLOY_NGPU`以使用支持GPU的容器映像以及分配给虚拟机（VM）实例的GPU数量。例如，要使用一个GPU容器映像，每个VM分配4个Nvidia Telsa K80 GPU，您可以指定：\n",
    "\n",
    "（aip.gapic.AcceleratorType.NVIDIA_TESLA_K80, 4）\n",
    "\n",
    "否则，指定`(None, None)`以使用一个容器映像在CPU上运行。\n",
    "\n",
    "了解更多信息，请访问[这里](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators) 有关您所在地区的硬件加速器支持。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "outputs": [],
   "source": [
    "TRAIN_GPU, TRAIN_NGPU = (None, None)\n",
    "\n",
    "DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction"
   },
   "source": [
    "#### 设置预构建容器\n",
    "\n",
    "设置用于训练和预测的预构建Docker容器镜像。\n",
    "\n",
    "\n",
    "有关最新列表，请参阅[用于训练的预构建容器](https://cloud.google.com/ai-platform-unified/docs/training/pre-built-containers)。\n",
    "\n",
    "\n",
    "有关最新列表，请参阅[用于预测的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:training,prediction"
   },
   "outputs": [],
   "source": [
    "TF = \"2-5\"\n",
    "\n",
    "if TRAIN_GPU:\n",
    "    TRAIN_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "else:\n",
    "    TRAIN_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "if DEPLOY_GPU:\n",
    "    DEPLOY_VERSION = \"tf2-gpu.{}\".format(TF)\n",
    "else:\n",
    "    DEPLOY_VERSION = \"tf2-cpu.{}\".format(TF)\n",
    "\n",
    "TRAIN_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/{}:latest\".format(TRAIN_VERSION)\n",
    "DEPLOY_IMAGE = \"us-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(DEPLOY_VERSION)\n",
    "\n",
    "print(\"Training:\", TRAIN_IMAGE, TRAIN_GPU, TRAIN_NGPU)\n",
    "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU, DEPLOY_NGPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training,prediction"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于训练和预测的机器类型。\n",
    "\n",
    "- 设置变量`TRAIN_COMPUTE`和`DEPLOY_COMPUTE`来配置用于训练和预测的虚拟机的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`：每个vCPU 3.75GB的内存。\n",
    "     - `n1-highmem`：每个vCPU 6.5GB的内存。\n",
    "     - `n1-highcpu`：每个vCPU 0.9GB的内存。\n",
    " - `vCPUs`：\\[2, 4, 8, 16, 32, 64, 96\\]个\n",
    "\n",
    "*注意：以下内容不支持用于训练：*\n",
    "\n",
    " - `standard`：2个vCPUs\n",
    " - `highcpu`：2、4和8个vCPUs\n",
    "\n",
    "*注意：您也可以使用n2和e2机器类型进行训练和部署，但它们不支持GPU。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training,prediction"
   },
   "outputs": [],
   "source": [
    "MACHINE_TYPE = \"n1-standard-4\"\n",
    "\n",
    "TRAIN_COMPUTE = MACHINE_TYPE\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)\n",
    "\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE\n",
    "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_training_package"
   },
   "source": [
    "### 检查培训包\n",
    "\n",
    "#### 包布局\n",
    "\n",
    "在开始培训之前，您先看一下如何为自定义培训工作组装 Python 包。当解压缩后，该包包含以下目录/文件布局。\n",
    "\n",
    "- PKG-INFO\n",
    "- README.md\n",
    "- setup.cfg\n",
    "- setup.py\n",
    "- trainer\n",
    "  - \\_\\_init\\_\\_.py\n",
    "  - task.py\n",
    "\n",
    "文件 `setup.cfg` 和 `setup.py` 是将该包安装到 Docker 镜像的操作环境中的指南。\n",
    "\n",
    "文件 `trainer/task.py` 是用于执行自定义培训工作的 Python 脚本。*注意*，当我们在工作组规范中提到它时，我们会将目录斜杠替换为点号 (`trainer.task`) 并丢弃文件后缀 (`.py`)。\n",
    "\n",
    "#### 包组装\n",
    "\n",
    "在下面的单元格中，您会组装培训包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "examine_training_package"
   },
   "outputs": [],
   "source": [
    "# Make folder for Python training script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\nsetuptools.setup(\\n\\n    install_requires=[\\n\\n        'tensorflow_datasets==1.3.0',\\n\\n    ],\\n\\n    packages=setuptools.find_packages())\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\nName: Boston Housing tabular regression\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taskpy_contents:hpt,boston"
   },
   "source": [
    "#### Task.py 文件内容\n",
    "\n",
    "在下一个单元格中，您可以编写超参数调优脚本 task.py 的内容。我不会详细解释，只是供您参考。总结如下：\n",
    "\n",
    "- 解析命令行参数，用于当前试验的超参数设置。\n",
    "- 从命令行获取保存模型 artifact 的目录（`--model_dir`），如果未指定，则从环境变量 `AIP_MODEL_DIR` 中获取。\n",
    "- 下载并预处理波士顿房价数据集。\n",
    "- 构建一个深度神经网络模型。\n",
    "- 在构建和编译模型时使用每个密集层的单元数和学习率超参数值。\n",
    "- 定义一个名为 `HPTCallback` 的回调，该回调在每个 epoch 结束时获取验证损失，并通过 `hpt.report_hyperparameter_tuning_metric()` 报告给超参数调优服务。\n",
    "- 使用 `fit()` 方法训练模型，并指定一个回调函数，将验证损失报告给超参数调优服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taskpy_contents:hpt,boston"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "# Custom Training for Boston Housing\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from hypertune import HyperTune\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model-dir', dest='model_dir',\n",
    "                    default=os.getenv('AIP_MODEL_DIR'), type=str, help='Model dir.')\n",
    "parser.add_argument('--lr', dest='lr',\n",
    "                    default=0.001, type=float,\n",
    "                    help='Learning rate.')\n",
    "parser.add_argument('--decay', dest='decay',\n",
    "                    default=0.98, type=float,\n",
    "                    help='Decay rate')\n",
    "parser.add_argument('--units', dest='units',\n",
    "                    default=64, type=int,\n",
    "                    help='Number of units.')\n",
    "parser.add_argument('--epochs', dest='epochs',\n",
    "                    default=20, type=int,\n",
    "                    help='Number of epochs.')\n",
    "parser.add_argument('--steps', dest='steps',\n",
    "                    default=200, type=int,\n",
    "                    help='Number of steps per epoch.')\n",
    "parser.add_argument('--param-file', dest='param_file',\n",
    "                    default='/tmp/param.txt', type=str,\n",
    "                    help='Output file for parameters')\n",
    "parser.add_argument('--distribute', dest='distribute', type=str, default='single',\n",
    "                    help='distributed training strategy')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print('Python Version = {}'.format(sys.version))\n",
    "print('TensorFlow Version = {}'.format(tf.__version__))\n",
    "print('TF_CONFIG = {}'.format(os.environ.get('TF_CONFIG', 'Not found')))\n",
    "\n",
    "\n",
    "def make_dataset():\n",
    "\n",
    "  # Scaling Boston Housing data features\n",
    "  def scale(feature):\n",
    "    max = np.max(feature)\n",
    "    feature = (feature / max).astype(np.float)\n",
    "    return feature, max\n",
    "\n",
    "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
    "  )\n",
    "  params = []\n",
    "  for _ in range(13):\n",
    "    x_train[_], max = scale(x_train[_])\n",
    "    x_test[_], _ = scale(x_test[_])\n",
    "    params.append(max)\n",
    "\n",
    "  # store the normalization (max) value for each feature\n",
    "  with tf.io.gfile.GFile(args.param_file, 'w') as f:\n",
    "    f.write(str(params))\n",
    "  return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "# Build the Keras model\n",
    "def build_and_compile_dnn_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(args.units, activation='relu', input_shape=(13,)),\n",
    "      tf.keras.layers.Dense(args.units, activation='relu'),\n",
    "      tf.keras.layers.Dense(1, activation='linear')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss='mse',\n",
    "      optimizer=tf.keras.optimizers.RMSprop(learning_rate=args.lr, decay=args.decay))\n",
    "  return model\n",
    "\n",
    "\n",
    "model = build_and_compile_dnn_model()\n",
    "\n",
    "# Instantiate the HyperTune reporting object\n",
    "hpt = HyperTune()\n",
    "\n",
    "# Reporting callback\n",
    "class HPTCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global hpt\n",
    "        hpt.report_hyperparameter_tuning_metric(\n",
    "        hyperparameter_metric_tag='val_loss',\n",
    "        metric_value=logs['val_loss'],\n",
    "        global_step=epoch)\n",
    "\n",
    "# Train the model\n",
    "BATCH_SIZE = 16\n",
    "(x_train, y_train), (x_test, y_test) = make_dataset()\n",
    "model.fit(x_train, y_train, epochs=args.epochs, batch_size=BATCH_SIZE, validation_split=0.1, callbacks=[HPTCallback()])\n",
    "model.save(args.model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tarball_training_script"
   },
   "source": [
    "将培训脚本存储在您的云存储桶中\n",
    "\n",
    "接下来，您将培训文件夹打包成压缩的tar球，然后存储在您的云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tarball_training_script"
   },
   "outputs": [],
   "source": [
    "! rm -f custom.tar custom.tar.gz\n",
    "! tar cvf custom.tar custom\n",
    "! gzip custom.tar\n",
    "! gsutil cp custom.tar.gz $BUCKET_URI/trainer_boston.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_a_model:migration"
   },
   "source": [
    "训练一个模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyperparameter_tuning:migration,new,mbsdk"
   },
   "source": [
    "### [training.using-hyperparamter-tuning](https://cloud.google.com/vertex-ai/docs/training/using-hyperparameter-tuning)\n",
    "\n",
    "### [使用超参数调整进行训练](https://cloud.google.com/vertex-ai/docs/training/using-hyperparameter-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_custom_job_machine_specification"
   },
   "source": [
    "### 准备您的机器规格\n",
    "\n",
    "现在为您的自定义训练作业定义机器规格。这告诉Vertex需要为训练提供什么类型的机器实例。\n",
    "- `machine_type`：要提供的GCP实例的类型--例如，n1-standard-8。\n",
    "- `accelerator_type`：硬件加速器的类型，如果有的话。在本教程中，如果您之前设置了变量`TRAIN_GPU != None`，则表示您正在使用GPU；否则表示您使用CPU。\n",
    "- `accelerator_count`：加速器的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_custom_job_machine_specification"
   },
   "outputs": [],
   "source": [
    "if TRAIN_GPU:\n",
    "    machine_spec = {\n",
    "        \"machine_type\": TRAIN_COMPUTE,\n",
    "        \"accelerator_type\": TRAIN_GPU,\n",
    "        \"accelerator_count\": TRAIN_NGPU,\n",
    "    }\n",
    "else:\n",
    "    machine_spec = {\"machine_type\": TRAIN_COMPUTE, \"accelerator_count\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_custom_job_disk_specification"
   },
   "source": [
    "###准备您的磁盘规格\n",
    "\n",
    "（可选）现在为您的自定义训练作业定义磁盘规格。这将告诉Vertex在每个训练机器实例中为训练提供什么类型和大小的磁盘。\n",
    "\n",
    "- `boot_disk_type`：SSD或标准。SSD更快，标准更便宜。默认为SSD。\n",
    "- `boot_disk_size_gb`：磁盘大小（以GB为单位）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_custom_job_disk_specification"
   },
   "outputs": [],
   "source": [
    "DISK_TYPE = \"pd-ssd\"  # [ pd-ssd, pd-standard]\n",
    "DISK_SIZE = 200  # GB\n",
    "\n",
    "disk_spec = {\"boot_disk_type\": DISK_TYPE, \"boot_disk_size_gb\": DISK_SIZE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_custom_job_worker_pool_specification:prebuilt_container"
   },
   "source": [
    "### 定义工作池规范\n",
    "\n",
    "接下来，您需要为自定义训练任务定义工作池规范。工作池规范包括以下内容：\n",
    "\n",
    "- `replica_count`：要提供的此机器类型的实例数量。\n",
    "- `machine_spec`：硬件规范。\n",
    "- `disk_spec`：（可选）磁盘存储规范。\n",
    "\n",
    "- `python_package`：要安装在VM实例上的Python训练包，以及要调用的Python模块，以及用于Python模块的命令行参数。\n",
    "\n",
    "现在让我们更深入地了解Python包规范：\n",
    "\n",
    "- `executor_image_spec`：这是为您的自定义训练任务配置的docker镜像。\n",
    "\n",
    "- `package_uris`：这是要在已提供实例上安装的Python训练包的位置（URIs）列表。这些位置需要在Cloud Storage存储桶中。这些可以是单个python文件或整个包的zip（存档）。在后一种情况下，作业服务将解压（解档）内容到docker镜像中。\n",
    "\n",
    "- `python_module`：要调用以运行自定义训练任务的Python模块（脚本）。在本例中，您将调用`trainer.task.py` -- 注意，不需要添加`.py`后缀。\n",
    "\n",
    "- `args`：要传递给相应Python模块的命令行参数。在这个例子中，您将设置：\n",
    " - `\"--model-dir=\" + MODEL_DIR`：存储模型工件的Cloud Storage位置。有两种方法告诉训练脚本保存模型工件的位置：\n",
    "     - 直接：将Cloud Storage位置作为命令行参数传递给您的训练脚本（设置变量`DIRECT = True`），\n",
    "     - 间接：服务将Cloud Storage位置作为环境变量`AIP_MODEL_DIR`传递给您的训练脚本（设置变量`DIRECT = False`）。在这种情况下，您需要在作业规范中告知服务模型工件的位置。\n",
    " - `\"--epochs=\" + EPOCHS`：训练的epoch数。\n",
    " - `\"--steps=\" + STEPS`：每个epoch的步骤（批次）数。\n",
    " - `\"--distribute=\" + TRAIN_STRATEGY\"`：用于单个或分布式训练的训练分发策略。\n",
    "     - `\"single\"`：单个设备。\n",
    "     - `\"mirror\"`：单台计算实例上的所有GPU设备。\n",
    "     - `\"multi\"`：所有计算实例上的所有GPU设备。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_custom_job_worker_pool_specification:prebuilt_container"
   },
   "outputs": [],
   "source": [
    "JOB_NAME = \"custom_job_\" + UUID\n",
    "MODEL_DIR = \"{}/{}\".format(BUCKET_URI, JOB_NAME)\n",
    "\n",
    "if not TRAIN_NGPU or TRAIN_NGPU < 2:\n",
    "    TRAIN_STRATEGY = \"single\"\n",
    "else:\n",
    "    TRAIN_STRATEGY = \"mirror\"\n",
    "\n",
    "EPOCHS = 20\n",
    "STEPS = 100\n",
    "\n",
    "DIRECT = True\n",
    "if DIRECT:\n",
    "    CMDARGS = [\n",
    "        \"--model-dir=\" + MODEL_DIR,\n",
    "        \"--epochs=\" + str(EPOCHS),\n",
    "        \"--steps=\" + str(STEPS),\n",
    "        \"--distribute=\" + TRAIN_STRATEGY,\n",
    "    ]\n",
    "else:\n",
    "    CMDARGS = [\n",
    "        \"--epochs=\" + str(EPOCHS),\n",
    "        \"--steps=\" + str(STEPS),\n",
    "        \"--distribute=\" + TRAIN_STRATEGY,\n",
    "    ]\n",
    "\n",
    "worker_pool_spec = [\n",
    "    {\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": machine_spec,\n",
    "        \"disk_spec\": disk_spec,\n",
    "        \"python_package_spec\": {\n",
    "            \"executor_image_uri\": TRAIN_IMAGE,\n",
    "            \"package_uris\": [BUCKET_URI + \"/trainer_boston.tar.gz\"],\n",
    "            \"python_module\": \"trainer.task\",\n",
    "            \"args\": CMDARGS,\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_job:migration,new,mbsdk"
   },
   "source": [
    "创建自定义作业"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_job:mbsdk"
   },
   "source": [
    "## 创建自定义作业\n",
    "\n",
    "使用`CustomJob`类来创建自定义作业，比如用于超参数调优，具有以下参数：\n",
    "\n",
    "- `display_name`：自定义作业的人类可读名称。\n",
    "- `worker_pool_specs`：相应虚拟机实例的规格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_custom_job:mbsdk"
   },
   "outputs": [],
   "source": [
    "job = aip.CustomJob(display_name=\"boston_\" + UUID, worker_pool_specs=worker_pool_spec)\n",
    "\n",
    "# print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_hpt_job:mbsdk"
   },
   "source": [
    "## 创建一个超参数调整作业\n",
    "\n",
    "使用`HyperparameterTuningJob`类创建一个超参数调整作业，具有以下参数：\n",
    "\n",
    "- `display_name`：自定义作业的可阅读名称。\n",
    "- `custom_job`：该自定义作业的工作池规范适用于所有试验中创建的CustomJobs。\n",
    "- `metrics_spec`：要优化的指标。字典键是指标ID，由您的训练作业报告，字典值是指标的优化目标（'最小化'或'最大化'）。\n",
    "- `parameter_spec`：要优化的参数。字典键是指标ID，作为命令行关键字参数传递给您的训练作业，字典值是指标的参数规范。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_hpt_job:mbsdk"
   },
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "\n",
    "hpt_job = aip.HyperparameterTuningJob(\n",
    "    display_name=\"boston_\" + UUID,\n",
    "    custom_job=job,\n",
    "    metric_spec={\n",
    "        \"val_loss\": \"minimize\",\n",
    "    },\n",
    "    parameter_spec={\n",
    "        \"lr\": hpt.DoubleParameterSpec(min=0.001, max=0.1, scale=\"log\"),\n",
    "        \"units\": hpt.IntegerParameterSpec(min=4, max=128, scale=\"linear\"),\n",
    "    },\n",
    "    max_trial_count=6,\n",
    "    parallel_trial_count=1,\n",
    ")\n",
    "\n",
    "# print(hpt_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_hpt_job:mbsdk"
   },
   "source": [
    "## 运行超参数调整任务\n",
    "\n",
    "使用`run()`方法来执行超参数调整任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_hpt_job:mbsdk"
   },
   "outputs": [],
   "source": [
    "hpt_job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_hpt_job:mbsdk"
   },
   "source": [
    "*示例输出:*\n",
    "\n",
    "    INFO:google.cloud.aiplatform.jobs:创建超参数调整作业\n",
    "    INFO:google.cloud.aiplatform.jobs:已创建超参数调整作业。资源名称: projects/759209241365/locations/us-central1/hyperparameterTuningJobs/760969798560514048\n",
    "    INFO:google.cloud.aiplatform.jobs:要在另一个会话中使用此超参数调整作业:\n",
    "    INFO:google.cloud.aiplatform.jobs:hpt_job = aiplatform.HyperparameterTuningJob.get('projects/759209241365/locations/us-central1/hyperparameterTuningJobs/760969798560514048')\n",
    "    INFO:google.cloud.aiplatform.jobs:查看超参数调整作业:\n",
    "    https://console.cloud.google.com/ai/platform/locations/us-central1/training/760969798560514048?project=759209241365\n",
    "    INFO:google.cloud.aiplatform.jobs:超参数调整作业 projects/759209241365/locations/us-central1/hyperparameterTuningJobs/760969798560514048 当前状态:\n",
    "    JobState.JOB_STATE_RUNNING\n",
    "    INFO:google.cloud.aiplatform.jobs:超参数调整作业 projects/759209241365/locations/us-central1/hyperparameterTuningJobs/760969798560514048 当前状态:\n",
    "    JobState.JOB_STATE_RUNNING\n",
    "    ...\n",
    "    INFO:google.cloud.aiplatform.jobs:超参数调整作业 projects/759209241365/locations/us-central1/hyperparameterTuningJobs/760969798560514048 当前状态:\n",
    "    JobState.JOB_STATE_SUCCEEDED\n",
    "    INFO:google.cloud.aiplatform.jobs:超参数调整作业运行完成。资源名称: projects/759209241365/locations/us-central1/hyperparameterTuningJobs/760969798560514048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpt_trial_results:mbsdk"
   },
   "source": [
    "显示超参数调整作业的试验结果\n",
    "\n",
    "在超参数调整作业完成后，属性`trials`会返回每个试验的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpt_trial_results:mbsdk"
   },
   "outputs": [],
   "source": [
    "print(hpt_job.trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpt_trial_results:mbsdk"
   },
   "source": [
    "*示例输出：*\n",
    "\n",
    "    [id: \"1\"\n",
    "    state: SUCCEEDED\n",
    "    parameters {\n",
    "      parameter_id: \"lr\"\n",
    "      value {\n",
    "        number_value: 0.010000000000000002\n",
    "      }\n",
    "    }\n",
    "    parameters {\n",
    "      parameter_id: \"units\"\n",
    "      value {\n",
    "        number_value: 66.0\n",
    "      }\n",
    "    }\n",
    "    final_measurement {\n",
    "      step_count: 19\n",
    "      metrics {\n",
    "        metric_id: \"val_loss\"\n",
    "        value: 24.61802691948123\n",
    "      }\n",
    "    }\n",
    "    start_time {\n",
    "      seconds: 1629414344\n",
    "      nanos: 232151761\n",
    "    }\n",
    "    end_time {\n",
    "      seconds: 1629414825\n",
    "    }\n",
    "    , id: \"2\"\n",
    "    state: SUCCEEDED\n",
    "    parameters {\n",
    "      parameter_id: \"lr\"\n",
    "      value {\n",
    "        number_value: 0.0036327633937958217\n",
    "      }\n",
    "    }\n",
    "    parameters {\n",
    "      parameter_id: \"units\"\n",
    "      value {\n",
    "        number_value: 94.0\n",
    "      }\n",
    "    }\n",
    "    final_measurement {\n",
    "      step_count: 19\n",
    "      metrics {\n",
    "        metric_id: \"val_loss\"\n",
    "        value: 25.499705989186356\n",
    "      }\n",
    "    }\n",
    "    start_time {\n",
    "      seconds: 1629414960\n",
    "      nanos: 618333580\n",
    "    }\n",
    "    end_time {\n",
    "      seconds: 1629415021\n",
    "    }\n",
    "    ...\n",
    "    , id: \"6\"\n",
    "    state: SUCCEEDED\n",
    "    parameters {\n",
    "      parameter_id: \"lr\"\n",
    "      value {\n",
    "        number_value: 0.002775175422799751\n",
    "      }\n",
    "    }\n",
    "    parameters {\n",
    "      parameter_id: \"units\"\n",
    "      value {\n",
    "        number_value: 104.0\n",
    "      }\n",
    "    }\n",
    "    final_measurement {\n",
    "      step_count: 7\n",
    "      metrics {\n",
    "        metric_id: \"val_loss\"\n",
    "        value: 24.655450123112377\n",
    "      }\n",
    "    }\n",
    "    start_time {\n",
    "      seconds: 1629415735\n",
    "      nanos: 998711852\n",
    "    }\n",
    "    end_time {\n",
    "      seconds: 1629415766\n",
    "    }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "# 清理工作\n",
    "\n",
    "为了清理此项目中使用的所有Google Cloud资源，您可以删除用于教程的[Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在此教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "delete_bucket = False\n",
    "\n",
    "# Delete the training job\n",
    "try:\n",
    "    job.delete()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Delete the HPT job using the Vertex batch prediction object\n",
    "hpt_job.delete()\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sdk-hyperparameter-tuning.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
