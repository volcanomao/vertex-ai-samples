{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "148c71404373"
   },
   "source": [
    "从2024年9月15日开始，您只能通过迁移至Vertex AI Gemini提示和调整来定制分类、实体提取和情感分析模型。不再提供为Vertex AI AutoML的文本分类、实体提取和情感分析目标训练或更新模型。您可以继续使用现有的Vertex AI AutoML文本目标直到2025年6月15日。有关Gemini如何通过改进的提示功能提供增强用户体验的更多信息，请参阅[调整简介](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-gemini-overview)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic"
   },
   "source": [
    "# Vertex AI管道：使用google-cloud-pipeline-components的AutoML文本分类管道\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_evaluation/automl_text_classification_model_evaluation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_evaluation/automl_text_classification_model_evaluation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/model_evaluation/automl_text_classification_model_evaluation.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "     </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "962e636b5cee"
   },
   "source": [
    "注意**: 该笔记本已在以下环境中进行了测试：\n",
    "\n",
    "* Python 版本 = 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:pipelines,automl"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本笔记本演示了如何使用Vertex AI分类模型评估组件来评估自动ML文本分类模型。模型评估帮助您根据评估指标确定模型性能，并在必要时改进模型。\n",
    "\n",
    "了解更多关于[Vertex AI模型评估](https://cloud.google.com/vertex-ai/docs/evaluation/introduction)和[文本数据分类](https://cloud.google.com/vertex-ai/docs/training-overview#classification_for_text)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:pipelines,automl"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用`Vertex AI Pipelines`和`Google Cloud Pipeline Components`来构建和评估一个`AutoML`文本分类模型。\n",
    "\n",
    "本教程使用以下 Google Cloud ML 服务和资源：\n",
    "\n",
    "- Vertex AI `Datasets`\n",
    "- Vertex AI `Training`(AutoML 文本分类) \n",
    "- Vertex AI `Model Registry`\n",
    "- Vertex AI `Pipelines`\n",
    "- Vertex AI `Batch Predictions`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 创建一个 Vertex AI `Dataset`。\n",
    "- 在`Dataset`资源上训练一个 Automl 文本分类模型。\n",
    "- 将训练好的`AutoML 模型资源`导入到管道中。\n",
    "- 运行一个`Batch Prediction`作业。\n",
    "- 使用`分类评估组件`评估 AutoML 模型。\n",
    "- 将评估指标导入到 AutoML 模型资源中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd81fd5c3454"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是来自[Kaggle Datasets](https://www.kaggle.com/ritresearch/happydb)的[Happy Moments dataset](https://www.kaggle.com/ritresearch/happydb)。在本教程中使用的数据集版本存储在一个公共云存储桶中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "### 费用\n",
    "\n",
    "本教程使用 Google Cloud 的可计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解 [Vertex AI\n",
    "价格](https://cloud.google.com/vertex-ai/pricing) 和 [Cloud Storage\n",
    "价格](https://cloud.google.com/storage/pricing)，并使用 [定价计算器](https://cloud.google.com/products/calculator/)\n",
    "根据您的预期使用量生成费用估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "source": [
    "安装\n",
    "\n",
    "安装执行此笔记本所需的软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                         google-cloud-storage \\\n",
    "                         kfp google-cloud-pipeline-components==1.0.25 \\\n",
    "                         ndjson --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### 仅限Colab：取消下面单元格的注释以重新启动内核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-ZBOjErv5mM"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a19566219b28"
   },
   "source": [
    "## 在开始之前\n",
    "\n",
    "### 设置您的谷歌云项目\n",
    "\n",
    "**无论您的笔记本环境如何，以下步骤都是必需的。**\n",
    "\n",
    "1. [选择或创建谷歌云项目](https://console.cloud.google.com/cloud-resource-manager)。首次创建帐户时，您将获得$300免费信用额用于支付计算/存储费用。\n",
    "\n",
    "2. [确保您的项目已启用计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "3. [启用 Vertex AI 和 Dataflow API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,dataflow.googleapis.com)。\n",
    "\n",
    "4. 如果您在本地运行此笔记本，则需要安装 [Cloud SDK](https://cloud.google.com/sdk)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下操作：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "区域\n",
    "\n",
    "您还可以更改 Vertex AI 使用的 `REGION` 变量。了解有关 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations) 的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dw8q9fdQEH5"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 认证您的 Google Cloud 账户\n",
    "\n",
    "根据您的 Jupyter 环境，您可能需要手动进行身份验证。请按照以下相关说明进行操作。\n",
    "\n",
    "**1. Vertex AI Workbench**\n",
    "* 不需要做任何操作，因为您已经过身份验证。\n",
    "\n",
    "**2. 本地 JupyterLab 实例，请取消注释并运行：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce6043da7b33"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0367eac06a10"
   },
   "source": [
    "3. 合作，取消注释并运行:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21ad4dbb4a61"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c13224697bfb"
   },
   "source": [
    "请查看如何向您的服务帐户授予云存储权限的方法，网址为 https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间构件，比如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "autoset_bucket"
   },
   "source": [
    "只有在您的存储桶不存在时：运行以下单元格来创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91c46850b49b"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "set_service_account"
   },
   "source": [
    "#### 服务账户\n",
    "\n",
    "**如果您不知道您的服务账户**，请尝试使用`gcloud`命令在下面执行第二个单元格来获取您的服务账户。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_service_account"
   },
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = \"[your-service-account]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autoset_service_account"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if (\n",
    "    SERVICE_ACCOUNT == \"\"\n",
    "    or SERVICE_ACCOUNT is None\n",
    "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
    "):\n",
    "    # Get your service account from gcloud\n",
    "    if not IS_COLAB:\n",
    "        shell_output = !gcloud auth list 2>/dev/null\n",
    "        SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\n",
    "\n",
    "    if IS_COLAB:\n",
    "        shell_output = ! gcloud projects describe  $PROJECT_ID\n",
    "        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
    "        SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
    "\n",
    "    print(\"Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "set_service_account:pipelines"
   },
   "source": [
    "设置 Vertex AI Pipelines 的服务账号访问权限\n",
    "\n",
    "运行以下命令来授予您的服务账号对您在上一步创建的存储桶中读取和写入管道工件的访问权限。您只需要对每个服务账号运行此步骤一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_service_account:pipelines"
   },
   "outputs": [],
   "source": [
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n",
    "\n",
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import kfp\n",
    "import matplotlib.pyplot as plt\n",
    "import ndjson\n",
    "from google.cloud import aiplatform, aiplatform_v1, storage\n",
    "from kfp.v2 import compiler  # noqa: F811"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "### 初始化用于 Python 的 Vertex AI SDK\n",
    "\n",
    "为您的项目和相应的存储桶初始化 Python 的 Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "define_pipeline:gcpc,automl,happydb,tcn"
   },
   "source": [
    "## 训练和部署AutoML文本分类模型\n",
    "\n",
    "在这个笔记本中，您将执行从数据集构建到模型部署和评估的所有步骤，使用Vertex AI pipelines。\n",
    "\n",
    "作为第一步，您将构建训练和部署管道。该管道包括以下任务：\n",
    "1. 创建一个Vertex AI文本数据集。\n",
    "2. 训练一个AutoML文本分类模型。\n",
    "3. 创建一个Vertex AI端点。\n",
    "4. 将AutoML模型部署到Vertex AI端点。\n",
    "\n",
    "该管道使用`Google Cloud Pipeline Components`软件包中的预构建组件来执行每个任务。\n",
    "\n",
    "了解更多关于[Google Cloud Pipeline Components](https://cloud.google.com/vertex-ai/docs/pipelines/components-introduction)。 \n",
    "\n",
    "设置所需的训练和部署管道参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90e2a99bdcf8"
   },
   "outputs": [],
   "source": [
    "# Specify the GCS path for the text dataset\n",
    "IMPORT_FILE = \"gs://cloud-ml-data/NL-classification/happiness.csv\"\n",
    "\n",
    "# provide dataset display name\n",
    "DATASET_DISPLAY_NAME = \"happydb-dataset-unique\"\n",
    "\n",
    "# provide training job display name\n",
    "TRAINING_JOB_DISPLAY_NAME = \"happydb-automl-job-unique\"\n",
    "\n",
    "# provide model display name\n",
    "MODEL_DISPLAY_NAME = \"happydb-automl-model-unique\"\n",
    "\n",
    "# provide endpoint display name\n",
    "ENDPOINT_DISPLAY_NAME = \"happydb-classification-endpoint-unique\"\n",
    "\n",
    "# provide pipeline job display name\n",
    "TRAINING_PIPELINE_DISPLAY_NAME = \"happydb-training-pipeline-unique\"\n",
    "\n",
    "# provide Cloud Storage root folder path for saving the artifacts\n",
    "PIPELINE_ROOT = f\"{BUCKET_URI}/pipeline_root/happydb\"\n",
    "\n",
    "# provide path to store the compiled pipeline package\n",
    "TRAINING_PIPELINE_PATH = \"automl_text_classification_pipeline.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02efd309b96b"
   },
   "source": [
    "定义Vertex AI管道。\n",
    "\n",
    "了解如何构建[Vertex AI管道](https://cloud.google.com/vertex-ai/docs/pipelines/build-pipeline)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "define_pipeline:gcpc,automl,happydb,tcn"
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name=TRAINING_PIPELINE_DISPLAY_NAME)\n",
    "def pipeline(\n",
    "    import_file: str,\n",
    "    dataset_display_name: str,\n",
    "    training_job_display_name: str,\n",
    "    model_display_name: str,\n",
    "    endpoint_display_name: str,\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION,\n",
    "    training_split: float = 0.4,\n",
    "    validation_split: float = 0.3,\n",
    "    test_split: float = 0.3,\n",
    "):\n",
    "    from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "    from google_cloud_pipeline_components.v1.endpoint import (EndpointCreateOp,\n",
    "                                                              ModelDeployOp)\n",
    "\n",
    "    # component to create the dataset\n",
    "    dataset_create_task = gcc_aip.TextDatasetCreateOp(\n",
    "        display_name=dataset_display_name,\n",
    "        gcs_source=import_file,\n",
    "        import_schema_uri=aiplatform.schema.dataset.ioformat.text.multi_label_classification,\n",
    "        project=project,\n",
    "    )\n",
    "    # component to run AutoML training job\n",
    "    training_run_task = gcc_aip.AutoMLTextTrainingJobRunOp(\n",
    "        dataset=dataset_create_task.outputs[\"dataset\"],\n",
    "        display_name=training_job_display_name,\n",
    "        prediction_type=\"classification\",\n",
    "        multi_label=True,\n",
    "        training_fraction_split=training_split,\n",
    "        validation_fraction_split=validation_split,\n",
    "        test_fraction_split=test_split,\n",
    "        model_display_name=model_display_name,\n",
    "        project=project,\n",
    "    )\n",
    "    # component to create an endpoint\n",
    "    endpoint_op = EndpointCreateOp(\n",
    "        project=project,\n",
    "        location=region,\n",
    "        display_name=endpoint_display_name,\n",
    "    )\n",
    "    # component to deploy the model the endpoint\n",
    "    _ = ModelDeployOp(\n",
    "        model=training_run_task.outputs[\"model\"],\n",
    "        endpoint=endpoint_op.outputs[\"endpoint\"],\n",
    "        automatic_resources_min_replica_count=1,\n",
    "        automatic_resources_max_replica_count=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "compile_pipeline"
   },
   "source": [
    "### 编译管道\n",
    "\n",
    "接下来，将管道编译成一个json包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compile_pipeline"
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path=TRAINING_PIPELINE_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_pipeline:automl,text"
   },
   "source": [
    "### 运行培训和部署管道\n",
    "\n",
    "现在，创建一个Vertex AI管道作业来运行管道。请注意，在管道定义过程中，默认将训练、验证和测试分割比例设置为0.4、0.3和0.3。根据需要进行更改。\n",
    "\n",
    "为了创建管道作业，您需要指定以下参数：\n",
    "\n",
    "- `display_name`：管道的名称，在Google Cloud控制台中显示。\n",
    "- `template_path`：PipelineJob或PipelineSpec JSON或YAML文件的路径。可以是本地路径、Google Cloud Storage URI或Artifact Registry URI。\n",
    "- `parameter_values`：运行时参数名称与控制管道运行的值之间的映射。\n",
    "- `enable_caching`：设置为True以开启运行时的缓存。\n",
    "\n",
    "了解更多关于[PipelineJob](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PipelineJob)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_pipeline:automl,text"
   },
   "outputs": [],
   "source": [
    "# set the values to be passed as input parameters to the pipeline\n",
    "training_parameters = {\n",
    "    \"import_file\": IMPORT_FILE,\n",
    "    \"dataset_display_name\": DATASET_DISPLAY_NAME,\n",
    "    \"training_job_display_name\": TRAINING_JOB_DISPLAY_NAME,\n",
    "    \"model_display_name\": MODEL_DISPLAY_NAME,\n",
    "    \"endpoint_display_name\": ENDPOINT_DISPLAY_NAME,\n",
    "}\n",
    "\n",
    "# create a pipeline job\n",
    "training_job = aiplatform.PipelineJob(\n",
    "    display_name=TRAINING_PIPELINE_DISPLAY_NAME,\n",
    "    template_path=TRAINING_PIPELINE_PATH,\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values=training_parameters,\n",
    "    enable_caching=False,\n",
    ")\n",
    "\n",
    "# run the job\n",
    "training_job.run(sync=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view_pipeline_run:automl,text"
   },
   "source": [
    "点击生成的链接以在云控制台中查看您的运行。\n",
    "\n",
    "在用户界面中，当您点击它们时，许多流水线DAG节点会展开或折叠。这里是DAG的部分展开视图（点击图像查看更大的版本）。\n",
    "\n",
    "<a href=\"https://storage.googleapis.com/amy-jo/images/mp/automl_text_classif.png\" target=\"_blank\"><img src=\"https://storage.googleapis.com/amy-jo/images/mp/automl_text_classif.png\" width=\"40%\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b875cffc34c4"
   },
   "source": [
    "通过过滤显示名称获取创建的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9af2a70fc560"
   },
   "outputs": [],
   "source": [
    "models = aiplatform.Model.list(\n",
    "    filter=f\"display_name={MODEL_DISPLAY_NAME}\", order_by=\"create_time\"\n",
    ")\n",
    "if models:\n",
    "    model = models[0]\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6efda0ed8c17"
   },
   "source": [
    "为模型获取可用的评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "679ded8b6097"
   },
   "outputs": [],
   "source": [
    "# Get evaluations\n",
    "model_evaluations = model.list_model_evaluations()\n",
    "\n",
    "model_evaluation = list(model_evaluations)[0]\n",
    "\n",
    "# Print the evaluation metrics\n",
    "for evaluation in model_evaluations:\n",
    "    evaluation = evaluation.to_dict()\n",
    "    print(\"Model's evaluation metrics from Training:\\n\")\n",
    "    metrics = evaluation[\"metrics\"]\n",
    "    for metric in metrics.keys():\n",
    "        print(f\"metric: {metric}, value: {metrics[metric]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f54ab89a020c"
   },
   "source": [
    "运行模型的批量预测\n",
    "\n",
    "为了评估模型，需要一批测试数据以及基准真相。在评估模型之前，您会为模型生成一个批处理预测任务，以查看模型是否能够批量生成预测。在Vertex AI中，您无需部署模型即可在其上运行批处理预测任务。\n",
    "\n",
    "要创建批处理预测任务，您必须首先格式化输入实例（以JSONL格式）并存储在Google Cloud Storage桶中。您还需要提供一个Google Cloud Storage桶来保存结果。\n",
    "\n",
    "#### 格式化输入实例\n",
    "在此步骤中，实例以JSONL格式进行格式化。JSONL文档中的每一行都需要格式化如下所示。\n",
    "\n",
    "```\n",
    "{ \"content\": \"gs://sourcebucket/datasets/texts/source_text.txt\", \"mimeType\": \"text/plain\"}\n",
    "```\n",
    "\n",
    "JSON结构中的`content`字段必须是指向包含模型文本输入的文档的Google Cloud Storage URI。\n",
    "\n",
    "了解有关[批量预测](https://cloud.google.com/ai-platform-unified/docs/predictions/batch-predictions#text)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f23865fbab9a"
   },
   "outputs": [],
   "source": [
    "# define a set of test samples\n",
    "instances = [\n",
    "    {\n",
    "        \"Text\": \"I went on a successful date with someone I felt sympathy and connection with.\",\n",
    "        \"Labels\": \"affection\",\n",
    "    },\n",
    "    {\n",
    "        \"Text\": \"I was happy when my son got 90% marks in his examination\",\n",
    "        \"Labels\": \"affection\",\n",
    "    },\n",
    "    {\"Text\": \"I went to the gym this morning and did yoga.\", \"Labels\": \"exercise\"},\n",
    "    {\n",
    "        \"Text\": \"We had a serious talk with some friends of ours who have been flaky lately. They understood and we had a good evening hanging out.\",\n",
    "        \"Labels\": \"bonding\",\n",
    "    },\n",
    "    {\n",
    "        \"Text\": \"I went with grandchildren to butterfly display at Crohn Conservatory\",\n",
    "        \"Labels\": \"affection\",\n",
    "    },\n",
    "    {\"Text\": \"I meditated last night.\", \"Labels\": \"leisure\"},\n",
    "    {\n",
    "        \"Text\": \"I made a new recipe for peasant bread, and it came out spectacular!\",\n",
    "        \"Labels\": \"achievement\",\n",
    "    },\n",
    "    {\n",
    "        \"Text\": \"I got gift from my elder brother which was really surprising me\",\n",
    "        \"Labels\": \"affection\",\n",
    "    },\n",
    "    {\"Text\": \"YESTERDAY MY MOMS BIRTHDAY SO I ENJOYED\", \"Labels\": \"enjoy_the_moment\"},\n",
    "    {\n",
    "        \"Text\": \"Watching cupcake wars with my three teen children\",\n",
    "        \"Labels\": \"affection\",\n",
    "    },\n",
    "    {\"Text\": \"I came in 3rd place in my Call of Duty video game.\", \"Labels\": \"leisure\"},\n",
    "    {\n",
    "        \"Text\": \"I completed my 5 miles run without break. It makes me feel strong.\",\n",
    "        \"Labels\": \"exercise\",\n",
    "    },\n",
    "    {\"Text\": \"went to movies with my friends it was fun\", \"Labels\": \"bonding\"},\n",
    "    {\n",
    "        \"Text\": \"I was shorting Gold and made $200 from the trade.\",\n",
    "        \"Labels\": \"achievement\",\n",
    "    },\n",
    "    {\n",
    "        \"Text\": \"Hearing Songs It can be nearly impossible to go from angry to happy, so you're just looking for the thought that eases you out of your angry feeling and moves you in the direction of happiness. It may take a while, but as long as you're headed in a more positive direction youall be doing yourself a world of good.\",\n",
    "        \"Labels\": \"enjoy_the_moment\",\n",
    "    },\n",
    "    {\n",
    "        \"Text\": \"My son performed very well for a test preparation.\",\n",
    "        \"Labels\": \"affection\",\n",
    "    },\n",
    "    {\"Text\": \"I helped my neighbour to fix their car damages.\", \"Labels\": \"bonding\"},\n",
    "    {\n",
    "        \"Text\": \"Managed to get the final trophy in a game I was playing.\",\n",
    "        \"Labels\": \"achievement\",\n",
    "    },\n",
    "    {\n",
    "        \"Text\": \"A hot kiss with my girl friend last night made my day\",\n",
    "        \"Labels\": \"bonding\",\n",
    "    },\n",
    "    {\n",
    "        \"Text\": \"My new BCAAs came in the mail. Yay! Strawberry Lemonade flavored aminos make my heart happy.\",\n",
    "        \"Labels\": \"affection\",\n",
    "    },\n",
    "    {\"Text\": \"Got A in class.\", \"Labels\": \"achievement\"},\n",
    "    {\n",
    "        \"Text\": \"My sister called me from abroad this morning after some long years. Such a happy occassion for all family members.\",\n",
    "        \"Labels\": \"affection\",\n",
    "    },\n",
    "    {\n",
    "        \"Text\": \"The cake I made today came out amazing. It tasted amazing as well.\",\n",
    "        \"Labels\": \"achievement\",\n",
    "    },\n",
    "    {\n",
    "        \"Text\": \"There are two types of people in the world: those who choose to be happy, and those who choose to be unhappy. Contrary to popular belief, happiness doesn't come from fame, fortune, other people, or material possessions\",\n",
    "        \"Labels\": \"enjoy_the_moment\",\n",
    "    },\n",
    "    {\n",
    "        \"Text\": \"My grandmother start to walk from the bed after a long time.\",\n",
    "        \"Labels\": \"affection\",\n",
    "    },\n",
    "    {\"Text\": \"i was able to hit a top spin serve in tennis\", \"Labels\": \"achievement\"},\n",
    "    {\n",
    "        \"Text\": \"I napped with my husband on the bed this afternoon and it was sweet to cuddle so close to him.\",\n",
    "        \"Labels\": \"affection\",\n",
    "    },\n",
    "    {\n",
    "        \"Text\": \"My co-woker started playing a Carley Rae Jepsen song from her phone while ringing out customers.\",\n",
    "        \"Labels\": \"leisure\",\n",
    "    },\n",
    "    {\n",
    "        \"Text\": \"My son woke me up to a fantastic breakfast of eggs, his special hamburger patty and pancakes.\",\n",
    "        \"Labels\": \"affection\",\n",
    "    },\n",
    "    {\n",
    "        \"Text\": \"After a long time my brother gave a suprise visit to my house yesterday.\",\n",
    "        \"Labels\": \"affection\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# define the input file name\n",
    "BATCH_JOB_INPUT_FILE = \"happiness-batch-prediction-input.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d0156222582"
   },
   "source": [
    "将数据保存到云存储桶\n",
    "\n",
    "创建一个新的云存储 blob，将单个实例作为文本文件上传到桶中，然后创建包含实例 URI 的 JSONL 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aa27e20fc2ec"
   },
   "outputs": [],
   "source": [
    "# Instantiate the Storage client and create the new bucket\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(BUCKET_URI[5:])\n",
    "# Iterate over the prediction instances and create a new text file\n",
    "input_file_data = []\n",
    "for count, instance in enumerate(instances):\n",
    "    instance_name = f\"input_{count}.txt\"\n",
    "    instance_file_uri = f\"{BUCKET_URI}/batch-prediction-input/{instance_name}\"\n",
    "    # Add the data to store in the JSONL input file.\n",
    "    tmp_data = {\"content\": instance_file_uri, \"mimeType\": \"text/plain\"}\n",
    "    input_file_data.append(tmp_data)\n",
    "\n",
    "    # Create the new instance file\n",
    "    blob = bucket.blob(\"batch-prediction-input/\" + instance_name)\n",
    "    blob.upload_from_string(instance[\"Text\"])\n",
    "\n",
    "\n",
    "input_str = \"\\n\".join([str(d) for d in input_file_data])\n",
    "file_blob = bucket.blob(f\"{BATCH_JOB_INPUT_FILE}\")\n",
    "file_blob.upload_from_string(input_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90fe8584fe74"
   },
   "source": [
    "创建并运行批量预测作业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d330cc0a3582"
   },
   "outputs": [],
   "source": [
    "# provide display name for the batch prediction job\n",
    "BATCH_JOB_DISPLAY_NAME = \"happydb-batch-prediction-job-unique\"\n",
    "\n",
    "# create the batch prediction job\n",
    "batch_prediction_job = model.batch_predict(\n",
    "    job_display_name=BATCH_JOB_DISPLAY_NAME,\n",
    "    gcs_source=f\"{BUCKET_URI}/{BATCH_JOB_INPUT_FILE}\",\n",
    "    gcs_destination_prefix=f\"{BUCKET_URI}/output\",\n",
    "    sync=True,\n",
    ")\n",
    "batch_prediction_job_name = batch_prediction_job.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3ca5b6c88ef"
   },
   "outputs": [],
   "source": [
    "# fetch the job details\n",
    "batch_job = aiplatform.jobs.BatchPredictionJob(batch_prediction_job_name)\n",
    "print(f\"Batch prediction job state: {str(batch_job.state)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ec70df091f1"
   },
   "source": [
    "从批量预测作业获取预测结果\n",
    "\n",
    "加载保存在指定输出 Cloud Storage 路径的批量预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82c88319987e"
   },
   "outputs": [],
   "source": [
    "bp_iter_outputs = batch_job.iter_outputs()\n",
    "\n",
    "prediction_results = list()\n",
    "for blob in bp_iter_outputs:\n",
    "    if blob.name.split(\"/\")[-1].startswith(\"prediction\"):\n",
    "        prediction_results.append(blob.name)\n",
    "\n",
    "for prediction_result in prediction_results:\n",
    "    gfile_name = f\"gs://{bp_iter_outputs.bucket.name}/{prediction_result}\".replace(\n",
    "        BUCKET_URI + \"/\", \"\"\n",
    "    )\n",
    "    data = bucket.get_blob(gfile_name).download_as_string()\n",
    "    data = ndjson.loads(data)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10aefe12628a"
   },
   "source": [
    "创建包含真实数据的输入文件用于评估\n",
    "\n",
    "评估组件需要将真实数据作为输入文件的一部分，以便将预测结果与其进行比较和评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8f51edb0d581"
   },
   "outputs": [],
   "source": [
    "# set the file name for saving the input with ground truth data\n",
    "BATCH_JOB_INPUT_EVAL_FILE = \"happydb-input-with-groundtruth.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6b057194bb4"
   },
   "outputs": [],
   "source": [
    "# Instantiate the Storage client and create the new bucket\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(BUCKET_URI[5:])\n",
    "# Iterate over the prediction instances, creating a new TXT file\n",
    "# for each.\n",
    "input_file_data = []\n",
    "for count, instance in enumerate(instances):\n",
    "    instance_name = f\"input_{count}.txt\"\n",
    "    instance_file_uri = (\n",
    "        f\"{BUCKET_URI}/evaluation-batch-prediction-input/{instance_name}\"\n",
    "    )\n",
    "    # Add the data to store in the JSONL input file.\n",
    "    # ground_truth variable in each json instance is needed to act as ground_truth for the evaluation task\n",
    "    tmp_data = {\n",
    "        \"content\": instance_file_uri,\n",
    "        \"mimeType\": \"text/plain\",\n",
    "        \"ground_truth\": instance[\"Labels\"],\n",
    "    }\n",
    "    input_file_data.append(tmp_data)\n",
    "\n",
    "    # Create the new instance file\n",
    "    blob = bucket.blob(\"evaluation-batch-prediction-input/\" + instance_name)\n",
    "    blob.upload_from_string(instance[\"Text\"])\n",
    "\n",
    "input_str = json.dumps(input_file_data[0])\n",
    "for i in input_file_data[1:]:\n",
    "    input_str = input_str + \"\\n\" + json.dumps(i)\n",
    "file_blob = bucket.blob(f\"{BATCH_JOB_INPUT_EVAL_FILE}\")\n",
    "file_blob.upload_from_string(input_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da26980e4892"
   },
   "source": [
    "创建一个模型评估的流水线\n",
    "\n",
    "在这一部分，您可以通过调用`evaluate`函数运行一个批量预测作业，并评估从Vertex AI流水线得到的结果。了解更多关于[evaluate函数](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/models.py#L5127)的信息。\n",
    "\n",
    "设置评估流水线的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba99dc63345d"
   },
   "source": [
    "### 定义参数来运行评估函数\n",
    "\n",
    "指定运行`evaluate`函数所需的参数。\n",
    "\n",
    "以下是`evaluate`函数参数的说明：\n",
    "\n",
    "- `prediction_type`: 评估运行所涉及的问题类型。目前支持的问题类型为“分类”和“回归”。\n",
    "- `target_field_name`: 用作分类目标的列的名称。\n",
    "- `gcs_source_uris`: 批量预测输入实例的Cloud Storage存储桶URI列表。\n",
    "- `class_labels`: 数据集中目标字段的所有类别名称列表。\n",
    "- `generate_feature_attributions`: 可选项。模型评估作业是否应该生成特征归因。如果未指定，默认为False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8db9156f3050"
   },
   "outputs": [],
   "source": [
    "DATA_SOURCE = f\"{BUCKET_URI}/{BATCH_JOB_INPUT_EVAL_FILE}\"\n",
    "CLASS_LABELS = [\n",
    "    \"affection\",\n",
    "    \"exercise\",\n",
    "    \"bonding\",\n",
    "    \"leisure\",\n",
    "    \"achievement\",\n",
    "    \"enjoy_the_moment\",\n",
    "    \"nature\",\n",
    "]\n",
    "\n",
    "evaluation_job = model.evaluate(\n",
    "    prediction_type=\"classification\",\n",
    "    target_field_name=\"ground_truth\",\n",
    "    gcs_source_uris=[DATA_SOURCE],\n",
    "    class_labels=CLASS_LABELS,\n",
    "    generate_feature_attributions=False,\n",
    ")\n",
    "\n",
    "print(\"Waiting model evaluation is in process\")\n",
    "evaluation_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40944be9d8e7"
   },
   "source": [
    "检查评估结果\n",
    "\n",
    "要查看管道是否成功运行，请单击上面生成的链接，以在Cloud控制台中查看管道图。\n",
    "\n",
    "在显示的管道中，点击节点时会展开或折叠。 下面可以看到管道的部分展开视图的示例（单击图像查看更大版本）。\n",
    "\n",
    "<img src=\"images/automl-text-classification-evaluation-image.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9b563bdc3d5"
   },
   "source": [
    "获取模型评估结果\n",
    "\n",
    "在评估管道完成后，运行下面的单元格以打印评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81f66e4bd162"
   },
   "outputs": [],
   "source": [
    "model_evaluation = evaluation_job.get_model_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f05de1ad1e67"
   },
   "outputs": [],
   "source": [
    "# Iterate over the pipeline tasks\n",
    "for (\n",
    "    task\n",
    ") in model_evaluation._backing_pipeline_job._gca_resource.job_detail.task_details:\n",
    "    # Obtain the artifacts from the evaluation task\n",
    "    if (\n",
    "        (\"model-evaluation\" in task.task_name)\n",
    "        and (\"model-evaluation-import\" not in task.task_name)\n",
    "        and (\n",
    "            task.state == aiplatform_v1.types.PipelineTaskDetail.State.SUCCEEDED\n",
    "            or task.state == aiplatform_v1.types.PipelineTaskDetail.State.SKIPPED\n",
    "        )\n",
    "    ):\n",
    "        evaluation_metrics = task.outputs.get(\"evaluation_metrics\").artifacts[\n",
    "            0\n",
    "        ]  # ['artifacts']\n",
    "        evaluation_metrics_gcs_uri = evaluation_metrics.uri\n",
    "\n",
    "print(evaluation_metrics)\n",
    "print(evaluation_metrics_gcs_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34c1905f54e3"
   },
   "source": [
    "### 可视化指标\n",
    "\n",
    "使用条形图来可视化可用的指标，如`auRoc`和`logLoss`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "274de9ff8dc5"
   },
   "outputs": [],
   "source": [
    "metrics = []\n",
    "values = []\n",
    "for i in evaluation_metrics.metadata.items():\n",
    "    metrics.append(i[0])\n",
    "    values.append(i[1])\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(x=metrics, height=values)\n",
    "plt.title(\"Evaluation Metrics\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91082815d1b3"
   },
   "source": [
    "### 检查模型注册表中的模型评估\n",
    "\n",
    "为确保模型评估成功导入到模型资源中，列出评估并打印它们。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8a35f4f09cc2"
   },
   "outputs": [],
   "source": [
    "# get the model evaluation configuration from the pipeline job\n",
    "for (\n",
    "    task\n",
    ") in model_evaluation._backing_pipeline_job._gca_resource.job_detail.task_details:\n",
    "    if \"model-evaluation-import\" in task.task_name:\n",
    "        val = json.loads(task.execution.metadata.get(\"output:gcp_resources\"))\n",
    "        model_evaluation = val[\"resources\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70aaaca32f36"
   },
   "outputs": [],
   "source": [
    "# Print the evaluation metrics\n",
    "model_evaluation_id = model_evaluation[\"resourceUri\"].split(\"/\")[-1]\n",
    "print(model_evaluation_id)\n",
    "\n",
    "# get evaluations from the model\n",
    "evaluation = model.get_model_evaluation()\n",
    "evaluation = evaluation.to_dict()\n",
    "print(\"Model's evaluation metrics:\\n\")\n",
    "metrics = evaluation[\"metrics\"]\n",
    "for metric in metrics.keys():\n",
    "    print(f\"metric: {metric}, value: {metrics[metric]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:pipelines"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于本教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在本教程中创建的各个资源：\n",
    "\n",
    "- 评估作业\n",
    "- 批处理预测作业\n",
    "- 训练和部署作业\n",
    "- 终端\n",
    "- 模型\n",
    "- 数据集\n",
    "- 云存储桶（设置 `delete_bucket` 为True以进行删除）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92e77f0a7931"
   },
   "outputs": [],
   "source": [
    "delete_bucket = False\n",
    "\n",
    "# # delete the evaluation job\n",
    "evaluation_job.delete()\n",
    "\n",
    "# # delete the batch prediction job\n",
    "batch_prediction_job.delete()\n",
    "\n",
    "# delete the training job\n",
    "training_job.delete()\n",
    "\n",
    "# list the endpoints filtering the display name\n",
    "endpoints = aiplatform.Endpoint.list(\n",
    "    filter=f\"display_name={ENDPOINT_DISPLAY_NAME}\", order_by=\"create_time\"\n",
    ")\n",
    "\n",
    "# delete the endpoint\n",
    "if endpoints:\n",
    "    endpoint = endpoints[0]\n",
    "    endpoint.undeploy_all()\n",
    "    endpoint.delete()\n",
    "    print(\"Deleted endpoint:\", endpoint)\n",
    "\n",
    "# list the models filtering the display name\n",
    "models = aiplatform.Model.list(\n",
    "    filter=f\"display_name={MODEL_DISPLAY_NAME}\", order_by=\"create_time\"\n",
    ")\n",
    "# delete the model\n",
    "if models:\n",
    "    model = models[0]\n",
    "    model.delete()\n",
    "    print(\"Deleted model:\", model)\n",
    "\n",
    "# list the datasets filtering the display name\n",
    "datasets = aiplatform.TextDataset.list(\n",
    "    filter=f\"display_name={DATASET_DISPLAY_NAME}\", order_by=\"create_time\"\n",
    ")\n",
    "# delete the dataset\n",
    "if datasets:\n",
    "    dataset = datasets[0]\n",
    "    dataset.delete()\n",
    "    print(\"Deleted dataset:\", dataset)\n",
    "\n",
    "# delete the Cloud Storage bucket\n",
    "if delete_bucket and os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "automl_text_classification_model_evaluation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
