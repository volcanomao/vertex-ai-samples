{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Vertex AI 实验：自动记录\n",
    "\n",
    "<table align=\"left\">\n",
    "\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/experiments/get_started_with_vertex_experiments_autologging.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"><br> 在 Colab 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fexperiments%2Fget_started_with_vertex_experiments_autologging.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> 在 Colab Enterprise 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/experiments/get_started_with_vertex_experiments_autologging.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br>\n",
    "      在 Vertex AI Workbench 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/experiments/get_started_with_vertex_experiments_autologging.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br>\n",
    "      在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24743cf4a1e1"
   },
   "source": [
    "注意：此笔记本已在以下环境中进行测试：\n",
    "\n",
    "- Python版本= 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "作为数据科学团队的一部分，您希望在实验阶段尝试不同的建模方法。为了保证可重复性，每种方法都有不同的参数，您需要手动跟踪。这是一项耗时的任务。为了解决这个挑战，Vertex AI SDK引入了自动记录功能，它是一种一行代码的SDK功能，利用MLflow来提供与您的 Vertex AI实验和实验运行相关的自动指标和参数跟踪（请参阅[将数据自动记录到实验运行](https://cloud.google.com/vertex-ai/docs/experiments/autolog-data)）。了解更多关于[Vertex AI实验](https://cloud.google.com/vertex-ai/docs/experiments/intro-vertex-ai-experiments)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用Vertex AI自动记录功能。\n",
    "\n",
    "本教程使用以下谷歌云ML服务和资源：\n",
    "\n",
    "- Vertex AI实验\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 在Vertex AI SDK中启用自动记录功能。\n",
    "- 训练scikit-learn模型，并查看结果实验运行的度量和参数，自动记录到Vertex AI实验中，而无需设置实验运行。\n",
    "- 训练Tensorflow模型，通过手动设置实验运行，并使用`aiplatform.start_run()`和`aiplatform.end_run()`来检查自动记录的度量和参数到Vertex AI实验。\n",
    "- 在Vertex AI SDK中禁用自动记录功能，训练PyTorch模型，并检查未记录任何参数或度量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08d289fa873f"
   },
   "source": [
    "数据集\n",
    "\n",
    "该数据集是[UCI汽车评估数据集](https://archive-beta.ics.uci.edu/dataset/19/car+evaluation)，它源自简单的分层决策模型，包含属性以预测汽车评估类别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aed92deeb4a0"
   },
   "source": [
    "### 成本\n",
    "\n",
    "本教程使用 Google Cloud 的可计费组件：\n",
    "\n",
    "* Vertex AI 实验\n",
    "* 云存储\n",
    "\n",
    "了解 [Vertex AI 定价](https://cloud.google.com/vertex-ai/pricing),\n",
    "以及 [云存储定价](https://cloud.google.com/storage/pricing),\n",
    "并使用 [定价计算器](https://cloud.google.com/products/calculator/)\n",
    "根据您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "开始吧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5d353aa47ac"
   },
   "source": [
    "### 为Python安装Vertex AI SDK和其他必需的包\n",
    "\n",
    "### 安装顶点AI SDK for Python和其他所需的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b4ef9b72d43"
   },
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "USER = \"\"\n",
    "! pip3 install {USER} --upgrade google-cloud-aiplatform tensorflow\n",
    "! pip3 install {USER} --upgrade pandas==2.0.* scikit-learn category_encoders torch torchdata torchmetrics mlflow\n",
    "! pip3 install {USER} --upgrade protobuf==3.20.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58707a750154"
   },
   "source": [
    "### 重新启动运行时（仅适用于Colab）\n",
    "\n",
    "为了使用新安装的软件包，您必须重新启动Google Colab上的运行时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f200f10a1da3"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c87a2a5d7e35"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ 内核即将重新启动。在继续下一步之前等待它完成。⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dccb1c8feb6"
   },
   "source": [
    "### 认证您的笔记本环境（仅适用于Colab）\n",
    "\n",
    "在Google Colab上认证您的环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cc7251520a07"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2fc3d7b6bfa"
   },
   "source": [
    "### 设置Google Cloud项目信息并初始化Python的Vertex AI SDK\n",
    "\n",
    "要开始使用Vertex AI，您必须拥有一个现有的Google Cloud项目并[启用Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。了解更多关于[设置项目和开发环境](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f02130bff721"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产物，例如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "如果您的存储桶尚不存在：运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $LOCATION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d5191a94246"
   },
   "source": [
    "### 初始化Python顶点AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d61513af29a4"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06571eb4063b"
   },
   "source": [
    "#### UUID\n",
    "\n",
    "如果您在进行实时教程会话，您可能会使用共享的测试账户或项目。为避免在创建的资源之间发生名称冲突，您可以为每个实例会话创建一个UUID，并将其附加到您在本教程中创建的资源的名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "697568e92bd6"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of length 8\n",
    "def generate_uuid():\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=8))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmXN14--y9xU"
   },
   "source": [
    "### 设置项目模板\n",
    "\n",
    "设置您在本教程中使用的文件夹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ohz3wHe4zFNb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "tutorial_path = os.path.join(os.getcwd(), \"sdk_autologging_tutorial\")\n",
    "data_path = os.path.join(tutorial_path, \"data\")\n",
    "\n",
    "for path in tutorial_path, data_path:\n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dAKzp-i1UJX"
   },
   "source": [
    "### 下载数据集\n",
    "\n",
    "从公共云存储桶下载汽车评估数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ukztj7v1XZw"
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "DATA_URL = \"http://cloud-samples-data.storage.googleapis.com/vertex-ai/dataset-management/datasets/uci_car_eval/car_evaluation_preprocessed.csv\"\n",
    "data_filepath = os.path.join(data_path, \"car_evaluation_data.csv\")\n",
    "request.urlretrieve(DATA_URL, data_filepath)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "COLUMN_NAMES = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]\n",
    "df = pd.read_csv(data_filepath)\n",
    "df[\"class\"] = df[\"class\"].replace({\"unacc\": 0, \"acc\": 0, \"good\": 1, \"vgood\": 1})\n",
    "\n",
    "processed_data_filepath = os.path.join(data_path, \"car_evaluation_preprocessed.csv\")\n",
    "df.to_csv(processed_data_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFjBFK5a3f4b"
   },
   "outputs": [],
   "source": [
    "!head {processed_data_filepath} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mwQMym-Rteu"
   },
   "source": [
    "### 辅助函数\n",
    "\n",
    "运行实验时，通常会定义实验助手函数，每个模型方法都会评估一个。以下是定义的实验助手函数：\n",
    "\n",
    "* `train_sklearn_model`：一个使用Sklearn训练决策树模型的辅助函数。\n",
    "* `train_tensorflow_model`：一个使用Tensorflow训练简单模型的辅助函数。\n",
    "* `train_pytorch_model`：一个使用PyTorch训练简单神经网络的辅助函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5tWyGgeRvXC"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    A function to set the seed for reproducibility.\n",
    "    Args:\n",
    "        seed: Seed to be set\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    import random\n",
    "\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    import torch\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "def train_sklearn_model(data_path: str, test_size: int, max_depth: int):\n",
    "    \"\"\"\n",
    "    A function to train a Decision Tree model using sklearn.\n",
    "    Args:\n",
    "        data_path: Path to the data\n",
    "        test_size: Size of the test set\n",
    "        max_depth: Maximum depth of the Decision Tree\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Libraries\n",
    "    import pandas as pd\n",
    "    from category_encoders import OrdinalEncoder\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "    # Read data\n",
    "    print(\"Reading data...\")\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    # Train, test split\n",
    "    print(\"Generating train and test data...\")\n",
    "    x = df[[\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\"]]\n",
    "    y = df[[\"class\"]]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=test_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Build pipeline\n",
    "    print(\"Building pipeline...\")\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\"encoder\", OrdinalEncoder()),\n",
    "            (\"model\", DecisionTreeClassifier(criterion=\"gini\", max_depth=max_depth)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    print(\"Training model...\")\n",
    "    pipe.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    print(\"Evaluating model...\")\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"accurancy\", round(accuracy, 3))\n",
    "\n",
    "\n",
    "def train_tensorflow_model(\n",
    "    data_path: str, test_size: float, batch_size: int, epochs: int\n",
    "):\n",
    "    \"\"\"\n",
    "    A function to train a TF model.\n",
    "    Args:\n",
    "        data_path: Path to the data\n",
    "        test_size: Size of the test set\n",
    "        batch_size: Batch size\n",
    "        epochs: Number of epochs\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Libraries\n",
    "    import tensorflow as tf\n",
    "\n",
    "    # Variables\n",
    "    dataset_size = 1729\n",
    "    features_values = {\n",
    "        \"buying\": [\"vhigh\", \"high\", \"med\", \"low\"],\n",
    "        \"maint\": [\"vhigh\", \"high\", \"med\", \"low\"],\n",
    "        \"doors\": [\"2\", \"3\", \"4\", \"5more\"],\n",
    "        \"persons\": [\"2\", \"4\", \"more\"],\n",
    "        \"lug_boot\": [\"small\", \"med\", \"big\"],\n",
    "        \"safety\": [\"low\", \"med\", \"high\"],\n",
    "    }\n",
    "\n",
    "    # Helpers\n",
    "    def get_input_layer(features_vocabulary):\n",
    "        input_map = {}\n",
    "        for cat_name, cat_values in features_vocabulary.items():\n",
    "            input_map[cat_name] = tf.keras.Input(\n",
    "                shape=(1,), name=cat_name, dtype=\"string\"\n",
    "            )\n",
    "        return input_map\n",
    "\n",
    "    def get_features_layer(inputs_map, features_vocabulary):\n",
    "        features_map = {}\n",
    "        for cat_name, cat_values in features_vocabulary.items():\n",
    "            # Calculate categories\n",
    "            cat_index = tf.keras.layers.StringLookup(\n",
    "                vocabulary=cat_values, max_tokens=5\n",
    "            )(inputs_map[cat_name])\n",
    "            # Create encoding layer\n",
    "            cat_layer = tf.keras.layers.CategoryEncoding(num_tokens=5)(cat_index)\n",
    "            features_map[cat_name] = cat_layer\n",
    "        return features_map\n",
    "\n",
    "    # Read data\n",
    "    print(\"Reading data...\")\n",
    "    car_dataset = tf.data.experimental.make_csv_dataset(\n",
    "        data_path,\n",
    "        column_names=[\n",
    "            \"buying\",\n",
    "            \"maint\",\n",
    "            \"doors\",\n",
    "            \"persons\",\n",
    "            \"lug_boot\",\n",
    "            \"safety\",\n",
    "            \"class\",\n",
    "        ],\n",
    "        label_name=\"class\",\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    # Generating Train, test split\n",
    "    print(\"Generating train and test data...\")\n",
    "    train_size = int(0.8 * dataset_size)\n",
    "    test_size = int(test_size * dataset_size)\n",
    "    train_dataset = car_dataset.take(train_size)\n",
    "    test_dataset = car_dataset.skip(train_size).take(test_size)\n",
    "\n",
    "    # Build model\n",
    "    print(\"Building model...\")\n",
    "    inputs_layer = get_input_layer(features_values)\n",
    "    features_layer = get_features_layer(inputs_layer, features_values)\n",
    "    print(\"FEATURE LAYER TYPE: \", type(features_layer.values()))\n",
    "    print(\"FEATURE LAYER TYPE Mod: \", type(features_layer))\n",
    "    print(\"FEATURE LAYER: \", features_layer)\n",
    "    x = tf.keras.layers.Concatenate()(list(features_layer.values()))\n",
    "    x = tf.keras.layers.Dense(10, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(5, activation=\"relu\")(x)\n",
    "    output_layer = tf.keras.layers.Dense(1)(x)\n",
    "    model = tf.keras.Model(inputs=list(inputs_layer.values()), outputs=output_layer)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    print(\"Training model...\")\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=test_dataset,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_pytorch_model(\n",
    "    data_path: str, test_size: float, batch_size: int, lr: float, epochs: int, seed: int\n",
    "):\n",
    "\n",
    "    # Libraries\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torchmetrics\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torchdata import datapipes\n",
    "\n",
    "    # Variables\n",
    "    seed = 8\n",
    "    features_map = {\n",
    "        0: {\"low\": 0, \"med\": 1, \"high\": 2, \"vhigh\": 3},\n",
    "        1: {\"low\": 0, \"med\": 1, \"high\": 2, \"vhigh\": 3},\n",
    "        2: {\"2\": 0, \"3\": 1, \"4\": 2, \"5more\": 3},\n",
    "        3: {\"2\": 0, \"4\": 1, \"more\": 2},\n",
    "        4: {\"small\": 0, \"med\": 1, \"big\": 2},\n",
    "        5: {\"low\": 0, \"med\": 1, \"high\": 2},\n",
    "    }\n",
    "    dataset_length = 1729\n",
    "\n",
    "    # Helpers\n",
    "    def row_processor(r):\n",
    "        for i, value in enumerate(r[:-1]):\n",
    "            r[i] = features_map[i][value]\n",
    "        return {\n",
    "            \"data\": np.array(r[:-1], dtype=np.float64),\n",
    "            \"labels\": np.array(r[-1], dtype=np.float64),\n",
    "        }\n",
    "\n",
    "    # Model definition\n",
    "    class SimpleNetwork(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.linear_relu = nn.Sequential(\n",
    "                nn.Linear(6, 12, dtype=torch.float64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(12, 6, dtype=torch.float64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(6, 3, dtype=torch.float64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(3, 1, dtype=torch.float64),\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            logits = self.linear_relu(x)\n",
    "            return logits\n",
    "\n",
    "    # Read data\n",
    "    print(\"Reading and preparing data...\")\n",
    "    read_dp = datapipes.iter.FileLister(data_path)\n",
    "    open_dp = datapipes.iter.FileOpener(read_dp)\n",
    "    parse_dp = datapipes.iter.CSVParser(open_dp, delimiter=\",\", skip_lines=1)\n",
    "    train_dp, test_dp = datapipes.iter.RandomSplitter(\n",
    "        parse_dp,\n",
    "        weights={\"train\": 1 - test_size, \"test\": test_size},\n",
    "        total_length=dataset_length,\n",
    "        seed=seed,\n",
    "    )\n",
    "    map_train_dp = datapipes.iter.Mapper(train_dp, row_processor)\n",
    "    map_test_dp = datapipes.iter.Mapper(test_dp, row_processor)\n",
    "    train_dataloader = DataLoader(map_train_dp, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(map_test_dp, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Build model\n",
    "    print(\"Building model...\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = SimpleNetwork().to(device)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    # Train model\n",
    "    print(\"Training model...\")\n",
    "    model.train()\n",
    "    for t in range(epochs):\n",
    "        batch = 0\n",
    "        for row in iter(train_dataloader):\n",
    "            features, labels = row[\"data\"].to(device), row[\"labels\"].to(device)\n",
    "            train_predictions = model(features)\n",
    "            train_prediction, _ = torch.max(train_predictions, 1)\n",
    "            train_loss = loss_fn(train_prediction, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch += 1\n",
    "            print(f\"Epoch {t + 1} - Batch {batch} - Loss {train_loss.item():.4f}\")\n",
    "\n",
    "    # Test model\n",
    "    print(\"Evaluating model...\")\n",
    "    metric = torchmetrics.classification.BinaryAccuracy()\n",
    "    metric_values = []\n",
    "    model.eval()\n",
    "    for t in range(epochs):\n",
    "        batch = 0\n",
    "        with torch.no_grad():\n",
    "            for row in iter(test_dataloader):\n",
    "                features, labels = row[\"data\"].to(device), row[\"labels\"].to(device)\n",
    "                val_predictions = model(features)\n",
    "                val_prediction, _ = torch.max(val_predictions, 1)\n",
    "                metric.update(val_prediction, labels)\n",
    "        accuracy = metric.compute()\n",
    "        metric_values.append(accuracy)\n",
    "        metric.reset()\n",
    "\n",
    "        batch += 1\n",
    "        print(f\"Epoch {t + 1} - Batch {batch} - Accuracy {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk,all"
   },
   "source": [
    "设置种子以确保可复制性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1l-7Wft3jb6"
   },
   "outputs": [],
   "source": [
    "set_seed(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "004aGQ1BSLFm"
   },
   "source": [
    "## 使用 Vertex AI 实验中的自动记录进行模型实验\n",
    "\n",
    "Vertex AI Experiments 自动记录功能允许您运行实验并自动记录不同 ML 框架的参数和指标。\n",
    "\n",
    "在启动 Vertex AI 实验后，使用 `vertex_ai.autolog()` 启用自动记录功能。\n",
    "\n",
    "有两种使用自动记录的方式：\n",
    "\n",
    "1. *使用自动实验运行创建*\n",
    "2. *使用用户实验运行创建*\n",
    "\n",
    "使用*自动实验运行创建*，您运行一个实验。Vertex AI SDK 会自动创建一个实验运行，记录在 Vertex AI 实验中的所有参数和指标。\n",
    "\n",
    "使用*用户实验运行创建*，您可以使用 `vertex_ai.start_run(您的实验运行名称)` 创建一个实验并运行。然后，在结束实验运行时使用 `vertex_ai.end_run()` 可以访问到生成的参数和指标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjJVARe5V-MG"
   },
   "source": [
    "创建一个用于跟踪训练参数和指标的实验。\n",
    "\n",
    "首先，使用`init()`方法初始化一个实验。\n",
    "\n",
    "由于一些模型类型，如TensorFlow，会自动记录时间序列指标，所以你需要创建一个TensorBoard实例。\n",
    "\n",
    "要创建一个TensorBoard实例，你可以使用`vertex_ai.Tensorboard.create()`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2z-VaIVTtI5"
   },
   "outputs": [],
   "source": [
    "autologged_experiment_name = f\"autologging-experiment-{UUID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqM2pIO8_4Y7"
   },
   "outputs": [],
   "source": [
    "experiment_tensorboard = vertex_ai.Tensorboard.create()\n",
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    staging_bucket=BUCKET_URI,\n",
    "    experiment=autologged_experiment_name,\n",
    "    experiment_tensorboard=experiment_tensorboard,\n",
    "    experiment_description=\"autolog-experiment-with-automatic-run\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCoYnaY594V7"
   },
   "source": [
    "在这个部分，Vertex AI SDK会自动创建一个实验运行，通过在Vertex AI实验中记录所有参数、训练和后训练指标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VGUnqk6Zvb6"
   },
   "source": [
    "启用自动记录\n",
    "\n",
    "首先，使用`vertex_ai.autolog()`方法启用自动记录。\n",
    "\n",
    "调用`vertex_ai.autolog()`后，来自支持的ML框架的模型训练调用的任何指标和参数将自动记录到Vertex Experiments。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0H9kw74-5ob"
   },
   "outputs": [],
   "source": [
    "vertex_ai.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWWr08gZZzMb"
   },
   "source": [
    "运行基准实验\n",
    "\n",
    "接下来，通过运行Sklearn模型实验来定义您的基准模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCM9wLvRSaKc"
   },
   "outputs": [],
   "source": [
    "sklearn_config = dict(data_path=processed_data_filepath, test_size=0.2, max_depth=5)\n",
    "train_sklearn_model(**sklearn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQh3v_85aGWP"
   },
   "source": [
    "获取实验结果\n",
    "\n",
    "然后，使用方法 `get_experiment_df()` 将实验结果作为 pandas 数据框获取。\n",
    "\n",
    "请注意所有参数和指标都已记录在 Vertex AI 实验中。\n",
    "\n",
    "特别是，`run_name` 已经自动分配，您定义的 `accuracy_score` 指标也已记录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuAl1etkLwAe"
   },
   "outputs": [],
   "source": [
    "experiment_df = vertex_ai.get_experiment_df()\n",
    "experiment_df = experiment_df.T\n",
    "experiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQlwVV_VMjGZ"
   },
   "source": [
    "自动记录用户实验运行创建\n",
    "\n",
    "如上所述，自动记录会自动将运行的实验分配给一个实验运行。\n",
    "\n",
    "但是你可以随时在实验中初始化一个运行，并使用`start_run()`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXU_UY5kcPdR"
   },
   "source": [
    "初始化一个新的实验运行\n",
    "\n",
    "在实验中跟踪特定的运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IxWrkgUQ7KL"
   },
   "outputs": [],
   "source": [
    "autologged_manual_run_experiment_name = f\"autologging-tf-experiment-{UUID}\"\n",
    "vertex_ai.start_run(autologged_manual_run_experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFDLCAlqfYW7"
   },
   "source": [
    "接下来，用TensorFlow模型运行一个新实验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOu7DxpVVMMY"
   },
   "outputs": [],
   "source": [
    "tf_config = dict(\n",
    "    data_path=processed_data_filepath, test_size=0.2, batch_size=5, epochs=3\n",
    ")\n",
    "train_tensorflow_model(**tf_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAQUlys2j0UN"
   },
   "source": [
    "比较实验结果\n",
    "\n",
    "实验运行完成后，调用`end_run()`方法来完成该运行的日志记录，然后您可以再次使用`get_experiment_df()`来获取实验的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rp5rNvZeePwk"
   },
   "outputs": [],
   "source": [
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XcCQUCgdTmG"
   },
   "outputs": [],
   "source": [
    "experiment_df = vertex_ai.get_experiment_df()\n",
    "experiment_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEt-8xvk9czW"
   },
   "source": [
    "不自动记录的运行实验\n",
    "\n",
    "启用自动记录是可选的。您可以随时使用 `vertex_ai.autolog(disable=True)`来禁用自动记录。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SeTs1Oavn2j"
   },
   "source": [
    "禁用自动登录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHp-6wcN9jOq"
   },
   "outputs": [],
   "source": [
    "vertex_ai.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c--rC7i3wFWM"
   },
   "source": [
    "使用Pytorch运行最终实验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3QKpkXc-N5o"
   },
   "outputs": [],
   "source": [
    "pt_config = dict(\n",
    "    data_path=processed_data_filepath,\n",
    "    test_size=0.2,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    lr=0.01,\n",
    "    seed=8,\n",
    ")\n",
    "train_pytorch_model(**pt_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygTmq9Tawfc-"
   },
   "source": [
    "检查实验结果\n",
    "\n",
    "使用`vertex_ai.get_experiment_df()`来检查PyTorch实验运行是否已被记录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTOltQJbacLn"
   },
   "outputs": [],
   "source": [
    "experiment_df = vertex_ai.get_experiment_df()\n",
    "experiment_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9I1hPpV63yyQ"
   },
   "source": [
    "请注意，Vertex AI SDK 自动记录使用了MLFlow的自动记录功能，在实现中只支持PyTorch Lightning。因此，您需要手动记录指标和模型来追踪这个PyTorch实验。查看[Vertex AI实验文档](https://cloud.google.com/vertex-ai/docs/experiments/intro-vertex-ai-experiments)以了解更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理这个项目中使用的所有Google Cloud资源，您可以删除用于教程的[Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Delete experiment\n",
    "experiment_list = vertex_ai.Experiment.list()\n",
    "for experiment in experiment_list:\n",
    "    try:\n",
    "        experiment.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# Delete Cloud Storage objects that were created\n",
    "delete_bucket = False\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil -m rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_with_vertex_experiments_autologging.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
