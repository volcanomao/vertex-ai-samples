{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Vertex AI SDK：AutoML 表格二进制分类模型的批量解释\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/explainable_ai/sdk_automl_tabular_binary_classification_batch_explain.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> 在 Colab 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fexplainable_ai%2Fsdk_automl_tabular_binary_classification_batch_explain.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> 在 Colab Enterprise 中打开\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/explainable_ai/sdk_automl_tabular_binary_classification_batch_explain.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> 在 Workbench 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/explainable_ai/sdk_automl_tabular_binary_classification_batch_explain.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> 在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:automl,xai"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何使用Vertex AI SDK创建一个表格二分类模型，并使用Google Cloud进行批量预测并提供解释。了解更多关于[自动化机器学习(AutoML)](https://cloud.google.com/vertex-ai/docs/start/automl-users)的内容。\n",
    "\n",
    "了解更多关于[表格数据分类](https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/overview)。了解更多关于[Vertex可解释性人工智能](https://cloud.google.com/vertex-ai/docs/explainable-ai/overview)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:automl,training,batch_prediction,xai"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用`AutoML`从Python脚本创建一个表格二元分类模型，然后学习如何使用`Vertex AI批量预测`进行带有解释的预测。您还可以选择使用`gcloud`命令行工具或在线使用Cloud Console来创建和部署模型。\n",
    "\n",
    "本教程使用以下Vertex AI服务：\n",
    "\n",
    "- Vertex AI AutoML\n",
    "- Vertex AI Batch Prediction\n",
    "- Vertex可解释 AI\n",
    "- Vertex AI模型资源\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 创建一个Vertex AI托管的数据集资源。\n",
    "- 训练一个AutoML表格二元分类模型。\n",
    "- 查看训练模型的模型评估指标。\n",
    "- 进行带有解释的批量预测请求。\n",
    "\n",
    "使用批量预测和在线预测之间有一个关键区别：\n",
    "\n",
    "* **预测服务**：为整个实例集（即一个或多个数据项）执行按需预测，并实时返回结果。\n",
    "\n",
    "* **批量预测服务**：对整个实例集进行排队（批量）预测，后台存储结果，并在准备就绪时将结果存储在Cloud存储桶中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a4881cf39a4"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用了一个银行营销数据集。这个数据集不需要任何特征工程。在本教程中使用的数据集版本存储在一个公共云存储桶中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "### 成本\n",
    "\n",
    "本教程使用Google Cloud的计费组件：\n",
    "\n",
    "- Vertex AI\n",
    "- Cloud Storage\n",
    "\n",
    "了解[Vertex AI价格](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage价格](https://cloud.google.com/storage/pricing)，并使用[Pricing 计算器](https://cloud.google.com/products/calculator/)基于您的预期使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0316df526f8"
   },
   "source": [
    "开始吧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "source": [
    "### 为 Python 安装 Vertex AI SDK 和其他所需的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform\n",
    "! pip3 install --upgrade --quiet google-cloud-storage\n",
    "! pip3 install --upgrade --quiet tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### 重新启动运行时（仅适用于Colab）\n",
    "\n",
    "为了使用新安装的包，您必须在Google Colab上重新启动运行时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-ZBOjErv5mM"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ee775571c2b5"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ 内核将重新启动。请等待直到完成再继续下一步。⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92e68cfc3a90"
   },
   "source": [
    "### 在谷歌Colab上验证您的笔记本环境\n",
    "\n",
    "在谷歌Colab上验证您的环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46604f70e831"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c708f022953d"
   },
   "source": [
    "### 设置Google Cloud项目信息\n",
    "\n",
    "了解更多关于[设置项目和开发环境](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产物，比如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "如果您的存储桶尚不存在：运行以下单元格以创建您的云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $LOCATION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "### 初始化用于 Python 的 Vertex AI SDK\n",
    "\n",
    "要开始使用 Vertex AI，您必须[启用 Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。\n",
    "\n",
    "使用位置和暂存桶初始化 Python 的 Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tutorial_start:automl"
   },
   "source": [
    "快速查看数据集\n",
    "\n",
    "您使用存储在公共云存储桶中的银行营销数据集的版本，使用CSV索引文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_file:u_dataset,csv"
   },
   "source": [
    "将变量`IMPORT_FILE`设置为CSV索引文件在云存储中的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:bank,csv,lbn"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = \"gs://cloud-ml-tables-data/bank-marketing.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a5007bb4010"
   },
   "source": [
    "通过计算CSV索引文件中的行数来统计示例数量（`wc -l`），然后查看前几行。\n",
    "\n",
    "在使用AutoML进行训练时，您需要知道标签列的名称，它将被保存为`label_column`。在这个数据集中，标签列被保存在最后一列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quick_peek:tabular"
   },
   "outputs": [],
   "source": [
    "count = ! gsutil cat $IMPORT_FILE | wc -l\n",
    "print(\"Number of Examples\", int(count[0]))\n",
    "\n",
    "print(\"First 10 rows\")\n",
    "! gsutil cat $IMPORT_FILE | head\n",
    "\n",
    "heading = ! gsutil cat $IMPORT_FILE | head -n1\n",
    "label_column = str(heading).split(\",\")[-1].split(\"'\")[0]\n",
    "print(\"Label Column Name\", label_column)\n",
    "if label_column is None:\n",
    "    raise Exception(\"label column missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_dataset:tabular,lbn"
   },
   "source": [
    "### 创建数据集\n",
    "\n",
    "接下来，使用`TabularDataset`类的`create`方法创建Vertex AI托管的数据集资源，该方法接受以下参数：\n",
    "\n",
    "- `display_name`：资源的可读名称。\n",
    "- `gcs_source`：一个或多个数据集索引文件的列表，用于将数据项导入资源。\n",
    "- `bq_source`：或者，从BigQuery表中导入数据项到资源中。\n",
    "\n",
    "此操作可能需要几分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataset:tabular,lbn"
   },
   "outputs": [],
   "source": [
    "dataset = aiplatform.TabularDataset.create(\n",
    "    display_name=\"Bank Marketing\", gcs_source=[IMPORT_FILE]\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_automl_pipeline:tabular,lbn"
   },
   "source": [
    "### 创建并运行训练流水线\n",
    "\n",
    "要在您的数据集上训练AutoML模型，您需要执行以下步骤：\n",
    "1）创建一个训练流水线。\n",
    "2）运行该流水线。\n",
    "\n",
    "#### 创建训练流水线\n",
    "\n",
    "使用`AutoMLTabularTrainingJob`类创建一个AutoML训练流水线，具有以下参数：\n",
    "\n",
    "- `display_name`：`TrainingJob`资源的人类可读名称。\n",
    "- `optimization_prediction_type`：训练模型的任务类型。\n",
    "  - `classification`：一个表格分类模型。\n",
    "  - `regression`：一个表格回归模型。\n",
    "- `column_transformations`：（可选）要应用于输入列的转换。\n",
    "- `optimization_objective`：要最小化或最大化的优化目标。\n",
    "  - 对于二元分类：\n",
    "    - `minimize-log-loss`\n",
    "    - `maximize-au-roc`\n",
    "    - `maximize-au-prc`\n",
    "    - `maximize-precision-at-recall`\n",
    "    - `maximize-recall-at-precision`\n",
    "  - 对于多类分类：\n",
    "    - `minimize-log-loss`\n",
    "  - 对于回归：\n",
    "    - `minimize-rmse`\n",
    "    - `minimize-mae`\n",
    "    - `minimize-rmsle`\n",
    "\n",
    "实例化的对象是一个用于训练流水线的有向无环图（DAG）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_automl_pipeline:tabular,lbn"
   },
   "outputs": [],
   "source": [
    "dag = aiplatform.AutoMLTabularTrainingJob(\n",
    "    display_name=\"bank\",\n",
    "    optimization_prediction_type=\"classification\",\n",
    "    optimization_objective=\"minimize-log-loss\",\n",
    ")\n",
    "\n",
    "print(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_automl_pipeline:tabular"
   },
   "source": [
    "#### 运行训练流水线\n",
    "\n",
    "接下来，通过调用`run`方法并传入以下参数来运行DAG以启动训练作业：\n",
    "\n",
    "- `dataset`：用于训练模型的托管数据集资源。\n",
    "- `model_display_name`：训练模型的可读名称。\n",
    "- `training_fraction_split`：用于训练的数据集百分比。\n",
    "- `test_fraction_split`：用于测试（留出数据）的数据集百分比。\n",
    "- `validation_fraction_split`：用于验证的数据集百分比。\n",
    "- `target_column`：作为标签进行训练的列名。\n",
    "- `budget_milli_node_hours`：（可选）指定的最大训练时间，以毫小时为单位（1000 = 1小时）。模型的训练成本不会超出此预算。\n",
    "- `disable_early_stopping`：如果设置为`True`，则训练可能会在服务认为无法进一步改进模型目标测量时提前完成，而不用完整预算。\n",
    "\n",
    "`run`方法完成后将返回Vertex AI模型资源。\n",
    "\n",
    "训练流水线的执行最长需时20分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_automl_pipeline:tabular"
   },
   "outputs": [],
   "source": [
    "model = dag.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"bank\",\n",
    "    training_fraction_split=0.6,\n",
    "    validation_fraction_split=0.2,\n",
    "    test_fraction_split=0.2,\n",
    "    budget_milli_node_hours=1000,\n",
    "    disable_early_stopping=False,\n",
    "    target_column=label_column,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "source": [
    "## 查看模型评估分数\n",
    "\n",
    "在模型训练完成后，您可以使用 `list_model_evaluations()` 方法查看评估分数。该方法返回每个评估切片的迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "model_evaluations = model.list_model_evaluations()\n",
    "\n",
    "for model_evaluation in model_evaluations:\n",
    "    print(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_prediction"
   },
   "source": [
    "发送一个批量预测请求\n",
    "\n",
    "向您注册的模型发送一个批量预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_batch_file:automl,tabular,alt"
   },
   "source": [
    "### 准备测试数据\n",
    "\n",
    "您可以使用合成数据作为测试数据项。不要担心我们使用合成数据。\n",
    "\n",
    "制作一个批量输入文件，之后将其存储在您的云存储桶中。与图像、视频和文本不同，表格模型的批量输入文件仅支持CSV格式。为了准备CSV文件，您需要确保：\n",
    "\n",
    "- 第一行是带有特征（字段）名称的标题。\n",
    "- 每个剩余行都是一个单独的预测请求，其对应特征值。\n",
    "\n",
    "例如：\n",
    "\n",
    "    \"feature_1\", \"feature_2\". ...\n",
    "    value_1, value_2, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "make_batch_file:automl,tabular,alt"
   },
   "outputs": [],
   "source": [
    "! gsutil cat $IMPORT_FILE | head -n 1 > tmp.csv\n",
    "! gsutil cat $IMPORT_FILE | tail -n 10 >> tmp.csv\n",
    "\n",
    "! cut -d, -f1-16 tmp.csv > batch.csv\n",
    "\n",
    "gcs_input_uri = BUCKET_URI + \"/test.csv\"\n",
    "\n",
    "! gsutil cp batch.csv $gcs_input_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_explain_request:mbsdk,csv"
   },
   "source": [
    "### 发送批量解释请求\n",
    "\n",
    "在创建模型资源后，您可以通过调用`batch_predict()`方法并使用以下参数来进行批量预测：\n",
    "\n",
    "- `job_display_name`：批量预测任务的可读名称。\n",
    "- `gcs_source`：一个或多个批量请求输入文件的列表。\n",
    "- `gcs_destination_prefix`：用于存储批量预测结果的云存储位置。\n",
    "- `instances_format`：输入实例的格式，可以是'csv'或'jsonl'。默认为'jsonl'。\n",
    "- `predictions_format`：输出预测的格式，可以是'csv'或'jsonl'。默认为'jsonl'。\n",
    "- `generate_explanations`：设置为`True`以生成解释。\n",
    "- `sync`：如果设置为True，则调用将等待批处理作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_explain_request:mbsdk,csv"
   },
   "outputs": [],
   "source": [
    "batch_predict_job = model.batch_predict(\n",
    "    job_display_name=\"bank\",\n",
    "    gcs_source=gcs_input_uri,\n",
    "    gcs_destination_prefix=BUCKET_URI,\n",
    "    instances_format=\"csv\",\n",
    "    predictions_format=\"jsonl\",\n",
    "    generate_explanation=True,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "print(batch_predict_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "source": [
    "###等待批量预测作业完成\n",
    "\n",
    "接下来，等待批量作业完成。\n",
    "\n",
    "或者，您可以在`batch_predict()`方法中将`sync`设置为`True`，以执行等待操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "outputs": [],
   "source": [
    "batch_predict_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_batch_explanation:mbsdk,lbn"
   },
   "source": [
    "获取解释\n",
    "\n",
    "接着，从已完成的批量预测作业中获取解释结果。\n",
    "\n",
    "结果被写入到您在批量预测请求中指定的输出 Cloud 存储位置。\n",
    "\n",
    "调用 `iter_outputs()` 方法来获取结果中生成的每个 Cloud 存储文件的列表。每个文件都包含一个或多个解释回应，格式为指定的预测格式，即 JSONL 格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_batch_explanation:mbsdk,lbn"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "bp_iter_outputs = batch_predict_job.iter_outputs()\n",
    "\n",
    "explanation_results = list()\n",
    "for blob in bp_iter_outputs:\n",
    "    if blob.name.split(\"/\")[-1].startswith(\"explanation\"):\n",
    "        explanation_results.append(blob.name)\n",
    "\n",
    "tags = list()\n",
    "for explanation_result in explanation_results:\n",
    "    gfile_name = f\"gs://{bp_iter_outputs.bucket.name}/{explanation_result}\"\n",
    "    with tf.io.gfile.GFile(name=gfile_name, mode=\"r\") as gfile:\n",
    "        for line in gfile.readlines():\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "整理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于此教程的[Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在此教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "outputs": [],
   "source": [
    "# Delete the training job\n",
    "dag.delete()\n",
    "# Delete the tabular dataset\n",
    "dataset.delete()\n",
    "# Delete the model resource\n",
    "model.delete()\n",
    "# Delete the batch prediction job\n",
    "batch_predict_job.delete()\n",
    "\n",
    "# Set this to true only if you'd like to delete your bucket\n",
    "delete_bucket = False\n",
    "\n",
    "if delete_bucket:\n",
    "    ! gsutil rm -r $BUCKET_URI\n",
    "\n",
    "# Delete the locally generated files\n",
    "! rm batch.csv tmp.csv"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sdk_automl_tabular_binary_classification_batch_explain.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
