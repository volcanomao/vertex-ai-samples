{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "使用Vertex可解释人工智能解释图像分类\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/explainable_ai/xai_image_classification_feature_attributions.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> 在Colab中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fofficial%2Fexplainable_ai%2fxai_image_classification_feature_attributions.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> 在Colab Enterprise中打开\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/explainable_ai/xai_image_classification_feature_attributions.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> 在Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/explainable_ai/xai_image_classification_feature_attributions.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> 在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "Vertex Explainable AI提供基于特征和基于示例的解释，以提供更好地理解模型决策过程。对于基于特征的解释，Vertex Explainable AI将特征归因整合到Vertex AI中。特征归因表示模型中每个特征对于每个给定实例的预测贡献了多少。对于图像分类模型，当您请求解释时，您将获得预测的类别以及对于该图像的叠加，显示图像中哪些区域对于最终预测的贡献最大。\n",
    "\n",
    "要在预训练或自定义训练的模型上使用Vertex Explainable AI，您必须在创建您计划从中请求解释的模型资源时配置某些选项，部署模型时，或提交批量解释作业时。本教程演示了如何配置这些选项，并获取和可视化在线和批量预测的解释。\n",
    "\n",
    "了解更多关于[Vertex Explainable AI](https://cloud.google.com/vertex-ai/docs/explainable-ai/overview) 和 [Vertex AI Prediction](https://cloud.google.com/vertex-ai/docs/predictions/get-predictions)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何在预训练的图像分类模型上配置基于特征的解释，并进行带解释的在线和批量预测。\n",
    "\n",
    "本教程使用以下 Google Cloud ML 服务和资源：\n",
    "\n",
    "- Vertex Explainable AI\n",
    "- Vertex AI Prediction\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 从 TensorFlow Hub 下载预训练模型\n",
    "- 上传模型进行部署\n",
    "- 部署模型进行在线预测\n",
    "- 进行带解释的在线预测\n",
    "- 进行带解释的批量预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08d289fa873f"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "在本示例中，您将使用 TensorFlow [flowers](http://download.tensorflow.org/example_images/flower_photos.tgz) 数据集。该数据集包含约3,700张花朵照片，分别保存在五个子目录中，每个目录代表一类花。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aed92deeb4a0"
   },
   "source": [
    "成本\n",
    "\n",
    "本教程使用Google Cloud的可计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* 云存储\n",
    "\n",
    "了解[Vertex AI价格](https://cloud.google.com/vertex-ai/pricing),\n",
    "以及[云存储价格](https://cloud.google.com/storage/pricing),\n",
    "并使用[定价计算器](https://cloud.google.com/products/calculator/)\n",
    "根据您的预计使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "开始吧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### 为Python安装Vertex AI SDK和其他必需的软件包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b4ef9b72d43"
   },
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade -q google-cloud-aiplatform \\\n",
    "                            tensorflow==2.15.1 \\\n",
    "                            tensorflow-hub \\\n",
    "                            matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "重启运行时（仅适用于Colab）\n",
    "\n",
    "要使用新安装的包，您必须重新启动Google Colab上的运行时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRvKdaPDTznN"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️内核将重新启动。在继续下一步之前，请等待直到完成。⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### 在协作笔记本环境中进行身份验证（仅限Colab）\n",
    "\n",
    "在谷歌Colab上验证您的环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyKGtVQjgx13"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### 设置 Google Cloud 项目信息\n",
    "\n",
    "了解更多关于[设置项目和开发环境](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nqwi-5ufWp_B"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产品，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "如果您的桶尚不存在：运行以下单元格以创建您的云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $LOCATION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk,all"
   },
   "source": [
    "### 初始化用于 Python 的 Vertex AI SDK\n",
    "\n",
    "要开始使用 Vertex AI，您必须[启用 Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utUNuq2aARaE"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqI_MEPvWVI5"
   },
   "source": [
    "## 从TensorFlow Hub下载预训练模型\n",
    "\n",
    "特征归因支持所有类型的模型（包括AutoML和自定义训练）、框架（TensorFlow、scikit、XGBoost）和模态（图像、文本、表格、视频）。\n",
    "\n",
    "为了演示目的，本教程使用了来自TensorFlow Hub的图像模型[Inception_v3](https://tfhub.dev/google/imagenet/inception_v3/classification/5)。该模型是在ImageNet基准数据集上进行预训练的。\n",
    "首先，您可以从TensorFlow Hub下载模型，将其包装为一个Keras层，并将模型工件保存到您的Cloud Storage存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_JDDMUjFfXO"
   },
   "outputs": [],
   "source": [
    "classifier_model = \"https://tfhub.dev/google/imagenet/inception_v3/classification/5\"\n",
    "\n",
    "classifier = tf.keras.Sequential([hub.KerasLayer(classifier_model)])\n",
    "\n",
    "classifier.build([None, 224, 224, 3])\n",
    "\n",
    "MODEL_DIR = f\"{BUCKET_URI}/model\"\n",
    "classifier.save(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySldGR7eKdY0"
   },
   "source": [
    "上传模型以进行部署\n",
    "\n",
    "接下来，您需要将模型上传到Vertex AI模型注册表，这将为您的模型创建一个Vertex AI模型资源。在上传之前，您需要定义一个服务函数，将数据转换成模型所期望的格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6wXBlaeZs3j"
   },
   "source": [
    "### 为图像数据定义一个serving函数\n",
    "\n",
    "您可以定义一个serving函数，将图像数据转换为您的模型所期望的格式。当您将编码后的数据发送到Vertex AI时，您的serving函数会确保数据在传递到模型之前在模型服务器上被解码。\n",
    "\n",
    "要在您的自定义模型中启用Vertex可解释AI，您需要从serving函数中设置两个额外的签名：\n",
    "\n",
    "- `xai_preprocess`：在serving函数中的预处理函数。\n",
    "- `xai_model`：用于调用模型的具体函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzA0aHeLFfeq"
   },
   "outputs": [],
   "source": [
    "CONCRETE_INPUT = \"numpy_inputs\"\n",
    "\n",
    "\n",
    "def _preprocess(bytes_input):\n",
    "    decoded = tf.io.decode_jpeg(bytes_input, channels=3)\n",
    "    decoded = tf.image.convert_image_dtype(decoded, tf.float32)\n",
    "    resized = tf.image.resize(decoded, size=(224, 224))\n",
    "    return resized\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "def preprocess_fn(bytes_inputs):\n",
    "    decoded_images = tf.map_fn(\n",
    "        _preprocess, bytes_inputs, dtype=tf.float32, back_prop=False\n",
    "    )\n",
    "    return {\n",
    "        CONCRETE_INPUT: decoded_images\n",
    "    }  # User needs to make sure the key matches model's input\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "def serving_fn(bytes_inputs):\n",
    "    images = preprocess_fn(bytes_inputs)\n",
    "    prob = m_call(**images)\n",
    "    return prob\n",
    "\n",
    "\n",
    "m_call = tf.function(classifier.call).get_concrete_function(\n",
    "    [tf.TensorSpec(shape=[None, 224, 224, 3], dtype=tf.float32, name=CONCRETE_INPUT)]\n",
    ")\n",
    "\n",
    "tf.saved_model.save(\n",
    "    classifier,\n",
    "    MODEL_DIR,\n",
    "    signatures={\n",
    "        \"serving_default\": serving_fn,\n",
    "        \"xai_preprocess\": preprocess_fn,  # Required for XAI\n",
    "        \"xai_model\": m_call,  # Required for XAI\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOOXywwNZBN1"
   },
   "source": [
    "获取服务函数签名\n",
    "\n",
    "通过重新加载模型到内存，并查询每个层对应的签名，您可以得到模型输入和输出层的签名。在进行预测请求时，服务函数的输入层名称将会被使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vVdSjoBSQaEA"
   },
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(MODEL_DIR)\n",
    "\n",
    "serving_input = list(\n",
    "    loaded.signatures[\"serving_default\"].structured_input_signature[1].keys()\n",
    ")[0]\n",
    "print(\"Serving function input:\", serving_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnefcZK1ba4b"
   },
   "source": [
    "## 配置解释设置\n",
    "\n",
    "要使用Vertex Explainable AI与自定义训练的模型，您必须在上传模型时配置解释设置。这些设置包括：\n",
    "\n",
    "- `parameters`：特征归因方法。可用方法包括`shapley`，`ig`，`xrai`。\n",
    "- `metadata`：用于解释的模型输入和输出。**对于TensorFlow 2模型，此字段是可选的。如果省略，Vertex AI会自动推断模型的输入和输出**。您不需要在本教程中配置此字段。\n",
    "\n",
    "了解更多关于[配置基于特征的解释](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-feature-based)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wDTAJoJHx5p"
   },
   "outputs": [],
   "source": [
    "XAI = \"ig\"  # [ shapley, ig, xrai ]\n",
    "\n",
    "if XAI == \"shapley\":\n",
    "    PARAMETERS = {\"sampled_shapley_attribution\": {\"path_count\": 10}}\n",
    "elif XAI == \"ig\":\n",
    "    PARAMETERS = {\"integrated_gradients_attribution\": {\"step_count\": 50}}\n",
    "elif XAI == \"xrai\":\n",
    "    PARAMETERS = {\"xrai_attribution\": {\"step_count\": 50}}\n",
    "\n",
    "parameters = aiplatform.explain.ExplanationParameters(PARAMETERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLslkKlneNyX"
   },
   "source": [
    "将模型上传到Vertex AI模型资源\n",
    "\n",
    "接下来，将您的模型上传到一个带有解释配置的Vertex AI模型资源中。 Vertex AI提供[Docker容器映像](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)，您可以将其作为预先构建的容器来运行，以便从训练模型工件中提供预测和解释。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQ_oIG11ID1o"
   },
   "outputs": [],
   "source": [
    "MODEL_DISPLAY_NAME = \"inception-v3-model-unique\"\n",
    "DEPLOY_IMAGE = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest\"\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=MODEL_DIR,\n",
    "    serving_container_image_uri=DEPLOY_IMAGE,\n",
    "    explanation_parameters=parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfL8qvYlLOo6"
   },
   "source": [
    "将模型部署用于在线预测。\n",
    "\n",
    "接下来，部署您的模型用于在线预测。您可以设置变量 `DEPLOY_COMPUTE` 来配置用于预测的[计算资源](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute)的机器类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOkThfvqJlk6"
   },
   "outputs": [],
   "source": [
    "DEPLOY_DISPLAY_NAME = \"inception-v3-deploy-unique\"\n",
    "DEPLOY_COMPUTE = \"n1-standard-4\"\n",
    "\n",
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name=DEPLOY_DISPLAY_NAME,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    accelerator_type=None,\n",
    "    accelerator_count=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHCXBWAYNx3h"
   },
   "source": [
    "## 用解释进行在线预测\n",
    "\n",
    "### 下载图像数据集和标签\n",
    "在这个例子中，您将使用TensorFlow花朵数据集作为预测的输入数据。该数据集包含大约3700张花朵照片，分为五个子目录，每个目录对应一类。您还会获取ImageNet数据集的标签来解码预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3caSDUXReNo"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "data_dir = tf.keras.utils.get_file(\n",
    "    \"flower_photos\",\n",
    "    origin=\"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\",\n",
    "    untar=True,\n",
    ")\n",
    "\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "images_files = list(data_dir.glob(\"daisy/*\"))\n",
    "\n",
    "labels_path = tf.keras.utils.get_file(\n",
    "    \"ImageNetLabels.txt\",\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\",\n",
    ")\n",
    "\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OcVOWLuv6TQ"
   },
   "source": [
    "### 准备图像处理函数\n",
    "\n",
    "您可以为图像处理和可视化定义一些可重用的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQz4T3h8iU2M"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def encode_image_in_b64(image_file):\n",
    "    bytes = tf.io.read_file(image_file)\n",
    "    b64str = base64.b64encode(bytes.numpy()).decode(\"utf-8\")\n",
    "    return b64str\n",
    "\n",
    "\n",
    "def decode_b64_image(b64_image_str):\n",
    "    image = base64.b64decode(b64_image_str)\n",
    "    image = io.BytesIO(image)\n",
    "    image = mpimg.imread(image, format=\"JPG\")\n",
    "    return image\n",
    "\n",
    "\n",
    "def decode_numpy_image(numpy_inputs):\n",
    "    numpy_inputs_json = json.loads(str(numpy_inputs))\n",
    "    image = np.array(numpy_inputs_json)\n",
    "    return image\n",
    "\n",
    "\n",
    "def show_explanation(encoded_image, prediction, feature_attributions):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(16, 4))\n",
    "\n",
    "    label_index = np.argmax(prediction)\n",
    "    class_name = imagenet_labels[label_index]\n",
    "    confidence_score = prediction[label_index]\n",
    "    axs[0].set_title(\n",
    "        \"Prediction:[\" + class_name + \"] (\" + str(round(confidence_score, 1)) + \"%)\"\n",
    "    )\n",
    "    original_image = decode_b64_image(encoded_image)\n",
    "    axs[0].imshow(original_image, interpolation=\"nearest\", aspect=\"auto\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    numpy_inputs = feature_attributions[\"numpy_inputs\"]\n",
    "    attribution_image = decode_numpy_image(numpy_inputs)\n",
    "    axs[1].set_title(\"Feature attributions\")\n",
    "    axs[1].imshow(attribution_image, interpolation=\"nearest\", aspect=\"auto\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    processed_image = attribution_image.max(axis=2)\n",
    "    axs[2].imshow(processed_image, cmap=\"coolwarm\", aspect=\"auto\")\n",
    "    axs[2].set_title(\"Feature attribution heatmap\")\n",
    "    axs[2].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaO8nWWQxuKw"
   },
   "source": [
    "获取在线解释\n",
    "\n",
    "您向`endpoint`发送一个带有编码输入图像数据的`explain`请求，并获取带有解释的预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_BeaaCy5M1H"
   },
   "outputs": [],
   "source": [
    "TEST_IMAGE_SIZE = 2\n",
    "\n",
    "test_image_list = []\n",
    "for i in range(TEST_IMAGE_SIZE):\n",
    "    test_image_list.append(str(images_files[i]))\n",
    "\n",
    "instances_list = []\n",
    "for test_image in test_image_list:\n",
    "    b64str = encode_image_in_b64(test_image)\n",
    "    instances_list.append({serving_input: {\"b64\": b64str}})\n",
    "\n",
    "response = endpoint.explain(instances_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTegf0H-1M3M"
   },
   "source": [
    "### 可视化在线解释\n",
    "\n",
    "当您请求对图像分类模型的解释时，您将获得预测类别以及一个图像叠加显示哪些像素（集成梯度）或区域（集成梯度或XRAI）有助于预测的解释。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A69Sxd3D0On0"
   },
   "outputs": [],
   "source": [
    "for i, test_image in enumerate(test_image_list):\n",
    "    encoded_image = encode_image_in_b64(test_image)\n",
    "    prediction = response.predictions[i]\n",
    "    explanation = response.explanations[i]\n",
    "    feature_attributions = dict(explanation.attributions[0].feature_attributions)\n",
    "\n",
    "    show_explanation(encoded_image, prediction, feature_attributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoJiAyLOM2tr"
   },
   "source": [
    "## 使用解释进行批量预测\n",
    "\n",
    "### 创建批量输入文件\n",
    "\n",
    "您可以创建一个以JSONL格式的批量输入文件，并将输入文件存储在您的云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LgFY93u0PVf"
   },
   "outputs": [],
   "source": [
    "gcs_input_uri = f\"{BUCKET_URI}/test_images.json\"\n",
    "\n",
    "with tf.io.gfile.GFile(gcs_input_uri, \"w\") as f:\n",
    "    for test_image in test_image_list:\n",
    "        b64str = encode_image_in_b64(test_image)\n",
    "        data = {serving_input: {\"b64\": b64str}}\n",
    "        f.write(json.dumps(data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgxVGYmX2Onc"
   },
   "source": [
    "提交一个批量预测作业\n",
    "\n",
    "通过将`generate_explanation`参数设置为`True`来提交一个批量预测作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaB_dz3h0PYe"
   },
   "outputs": [],
   "source": [
    "JOB_DISPLAY_NAME = \"inception-v3-job-unique\"\n",
    "\n",
    "batch_predict_job = model.batch_predict(\n",
    "    job_display_name=JOB_DISPLAY_NAME,\n",
    "    gcs_source=gcs_input_uri,\n",
    "    gcs_destination_prefix=BUCKET_URI,\n",
    "    instances_format=\"jsonl\",\n",
    "    model_parameters=None,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    generate_explanation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVxOqx-P4nma"
   },
   "source": [
    "### 获取批量解释\n",
    "\n",
    "接下来，您将从完成的批量预测作业中获取解释。结果将被写入您在批量预测请求中指定的Cloud Storage输出桶中。您可以调用方法`iter_outputs()`来获取生成的结果中每个Cloud Storage文件的列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pD7kCit00Pbg"
   },
   "outputs": [],
   "source": [
    "bp_iter_outputs = batch_predict_job.iter_outputs()\n",
    "\n",
    "explanation_results = list()\n",
    "for blob in bp_iter_outputs:\n",
    "    if blob.name.split(\"/\")[-1].startswith(\"explanation.results\"):\n",
    "        explanation_results.append(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSdO0Dx444Ir"
   },
   "source": [
    "### 可视化解释\n",
    "\n",
    "您可以将一个解释结果作为例子，然后可视化解释。对于一种图像分类模型，您可以获得预测类别以及一个图像叠加层，显示哪些像素（整合梯度）或区域（整合梯度或XRAI）对预测做出了贡献。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJpLkjc7Fb9T"
   },
   "outputs": [],
   "source": [
    "explanation_result = explanation_results[0]\n",
    "\n",
    "gfile_name = f\"{BUCKET_URI}/{explanation_result}\"\n",
    "with tf.io.gfile.GFile(name=gfile_name, mode=\"r\") as gfile:\n",
    "    result = json.loads(gfile.read())\n",
    "\n",
    "encoded_image = result[\"instance\"][\"bytes_inputs\"][\"b64\"]\n",
    "prediction = result[\"prediction\"]\n",
    "attributions = result[\"explanation\"][\"attributions\"][0]\n",
    "feature_attributions = attributions[\"featureAttributions\"]\n",
    "\n",
    "show_explanation(encoded_image, prediction, feature_attributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于本教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "# Deploy the model from endpoint\n",
    "endpoint.undeploy_all()\n",
    "# Delete the endpoint\n",
    "endpoint.delete()\n",
    "# Delete the model\n",
    "model.delete()\n",
    "# Delete the batch prediction job\n",
    "batch_predict_job.delete()\n",
    "\n",
    "# Delete Cloud Storage bucket\n",
    "delete_bucket = False  # Set True to delete your bucket\n",
    "if delete_bucket:\n",
    "    ! gsutil -m rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "xai_image_classification_feature_attributions.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
