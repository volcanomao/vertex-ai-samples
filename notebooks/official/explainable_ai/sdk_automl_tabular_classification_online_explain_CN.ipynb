{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Vertex SDK：在线解释自动机器学习训练表格分类模型\n",
    "\n",
    "<table align=\"left\"> \n",
    "  <td style=\"text-align: center\"> \n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/explainable_ai/sdk_automl_tabular_classification_online_explain.ipynb\"> \n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> 在Colab中打开 \n",
    "    </a> \n",
    "  </td> \n",
    "  <td style=\"text-align: center\"> \n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fexplainable_ai%2Fsdk_automl_tabular_classification_online_explain.ipynb\"> \n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> 在Colab Enterprise中打开 \n",
    "    </a> \n",
    "  </td> \n",
    "  <td style=\"text-align: center\"> \n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/explainable_ai/sdk_automl_tabular_classification_online_explain.ipynb\"> \n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> 在工作台中打开 \n",
    "    </a> \n",
    "  </td> \n",
    "  <td style=\"text-align: center\"> \n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/explainable_ai/sdk_automl_tabular_classification_online_explain.ipynb\"> \n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> 在GitHub上查看 \n",
    "    </a> \n",
    "  </td> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:automl,xai"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何使用Vertex AI SDK创建表格式分类模型，并使用Google Cloud [AutoML](https://cloud.google.com/vertex-ai/docs/start/automl-users)模型进行在线预测及解释。\n",
    "\n",
    "了解更多有关[表格数据分类](https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/overview)和[Vertex可解释AI](https://cloud.google.com/vertex-ai/docs/explainable-ai/overview)的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:automl,training,online_prediction,xai"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用 AutoML 从Python脚本创建一个表格二元分类模型。然后，您将学习如何使用 Vertex AI 预测服务来进行带解释的在线预测请求。您也可以选择使用 `gcloud` 命令行工具或在 Cloud Console 上在线创建和部署模型。\n",
    "\n",
    "本教程使用以下谷歌云 ML 服务：\n",
    "\n",
    "- Vertex AI AutoML\n",
    "- Vertex AI 预测\n",
    "- Vertex 可解释AI\n",
    "- Vertex AI 模型资源\n",
    "- Vertex AI 端点资源\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 创建一个 Vertex AI 数据集资源。\n",
    "- 训练一个 AutoML 表格二元分类模型。\n",
    "- 查看训练模型的模型评估指标。\n",
    "- 创建一个服务端点资源。\n",
    "- 部署模型资源到服务端点资源。\n",
    "- 进行带解释的在线预测请求。\n",
    "- 取消部署模型资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:iris,lcn"
   },
   "source": [
    "数据集\n",
    "\n",
    "本教程使用的数据集是来自[TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview)的[Iris数据集](https://www.tensorflow.org/datasets/catalog/iris)。该数据集不需要任何特征工程。本教程中使用的数据集版本存储在公共Cloud Storage桶中。训练好的模型可以预测三种不同Iris花的品种：山鸢尾、维吉尼亚鸢尾或变色鸢尾。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "### 费用\n",
    "\n",
    "本教程使用 Google Cloud 的计费组件：\n",
    "\n",
    "- Vertex AI\n",
    "- Cloud Storage\n",
    "\n",
    "了解[Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage 价格](https://cloud.google.com/storage/pricing)，并使用[Pricing 计算器](https://cloud.google.com/products/calculator/)根据您的预期使用量生成费用估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "开始吧!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### 为Python安装Vertex AI SDK和其他必需的软件包\n",
    "\n",
    "### 安装Vertex AI SDK for Python和其他必需的软件包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
    "                                 google-cloud-storage \n",
    "! pip3 install --upgrade --quiet tensorflow  \n",
    "! pip3 install -U --quiet tabulate  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### 重新启动运行时（仅适用于Colab）\n",
    "\n",
    "为了使用新安装的包，您必须在Google Colab上重新启动运行时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRvKdaPDTznN"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ 内核将要重新启动。在继续到下一步之前，请等待它完成。⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### 在谷歌 Colab 上验证您的笔记本环境\n",
    "\n",
    "在谷歌 Colab 上验证您的环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyKGtVQjgx13"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### 设置 Google Cloud 项目信息\n",
    "\n",
    "要开始使用 Vertex AI，您必须拥有一个现有的 Google Cloud 项目。了解如何[设置项目和开发环境](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nqwi-5ufWp_B"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产物，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有当您的存储桶不存在时才运行以下单元格创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53c6c71ac857"
   },
   "source": [
    "### 初始化 Python 环境下的 Vertex AI SDK\n",
    "\n",
    "为您的项目和对应的存储桶初始化 Python 环境下的 Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "673ef17c3cff"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tutorial_start:automl"
   },
   "source": [
    "# 教程\n",
    "\n",
    "现在您已经准备好创建自己的AutoML表格分类模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_file:u_dataset,csv"
   },
   "source": [
    "将云存储培训数据的位置设置为`IMPORT_FILE`变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:iris,csv,lcn"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = \"gs://cloud-samples-data/tables/iris_1000.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick_peek:tabular"
   },
   "source": [
    "快速查看您的数据\n",
    "\n",
    "您可以通过数CSV索引文件中的行数 (`wc -l`) 来计算示例的数量，然后查看前几行。\n",
    "\n",
    "标签列的标题名称是`label_column`，它是CSV文件中的最后一列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quick_peek:tabular"
   },
   "outputs": [],
   "source": [
    "count = ! gsutil cat $IMPORT_FILE | wc -l\n",
    "print(\"Number of Examples\", int(count[0]))\n",
    "\n",
    "print(\"First 10 rows\")\n",
    "! gsutil cat $IMPORT_FILE | head\n",
    "\n",
    "heading = ! gsutil cat $IMPORT_FILE | head -n1\n",
    "label_column = str(heading).split(\",\")[-1].split(\"'\")[0]\n",
    "print(\"Label Column Name\", label_column)\n",
    "if label_column is None:\n",
    "    raise Exception(\"label column missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_dataset:tabular,lcn"
   },
   "source": [
    "### 创建数据集\n",
    "\n",
    "接下来，使用`TabularDataset`类的`create`方法创建数据集，该方法接受以下参数：\n",
    "\n",
    "- `display_name`：数据集的人类可读名称。\n",
    "- `gcs_source`：一个或多个数据集索引文件的列表，用于将数据项导入数据集。\n",
    "- `bq_source`：另外，您可以将数据项从BigQuery表导入数据集。\n",
    "\n",
    "此操作可能需要几分钟时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataset:tabular,lcn"
   },
   "outputs": [],
   "source": [
    "dataset = aiplatform.TabularDataset.create(\n",
    "    display_name=\"Iris\", gcs_source=[IMPORT_FILE]\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_automl_pipeline:tabular,lcn"
   },
   "source": [
    "### 创建和运行训练管道\n",
    "\n",
    "要训练一个AutoML模型，您需要执行两个步骤：\n",
    "1）创建一个训练管道。\n",
    "2）指定您的训练参数并运行作业。\n",
    "\n",
    "#### 创建训练管道\n",
    "\n",
    "使用`AutoMLTabularTrainingJob`类创建一个AutoML训练管道，具有以下参数：\n",
    "\n",
    "- `display_name`：训练作业的可读名称。\n",
    "- `optimization_prediction_type`：模型要产生的预测类型。\n",
    "  - `classification`：一个表格分类模型。\n",
    "  - `regression`：一个表格回归模型。\n",
    "- `column_transformations`：（可选）要应用于输入列的转换。\n",
    "- `optimization_objective`：要最小化或最大化的优化目标。\n",
    "  - 二元分类：\n",
    "    - `minimize-log-loss`\n",
    "    - `maximize-au-roc`\n",
    "    - `maximize-au-prc`\n",
    "    - `maximize-precision-at-recall`\n",
    "    - `maximize-recall-at-precision`\n",
    "  - 多类分类：\n",
    "    - `minimize-log-loss`\n",
    "  - 回归：\n",
    "    - `minimize-rmse`\n",
    "    - `minimize-mae`\n",
    "    - `minimize-rmsle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_automl_pipeline:tabular,lcn"
   },
   "outputs": [],
   "source": [
    "job = aiplatform.AutoMLTabularTrainingJob(\n",
    "    display_name=\"iris\",\n",
    "    optimization_prediction_type=\"classification\",\n",
    "    optimization_objective=\"minimize-log-loss\",\n",
    ")\n",
    "\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_automl_pipeline:tabular"
   },
   "source": [
    "#### 运行训练流程\n",
    "\n",
    "通过调用`run`方法来启动训练作业，使用以下参数：\n",
    "\n",
    "- `dataset`：用于训练模型的数据集。\n",
    "- `model_display_name`：训练模型的人类可读名称。\n",
    "- `training_fraction_split`：用于训练的数据集的百分比。\n",
    "- `test_fraction_split`：用于测试（留出数据）的数据集的百分比。\n",
    "- `validation_fraction_split`：用于验证的数据集的百分比。\n",
    "- `target_column`：要训练为标签的列名。\n",
    "- `budget_milli_node_hours`：（可选）以千小时为单位指定的最大训练时间。\n",
    "- `disable_early_stopping`： 如果为`True`，服务可能认为无法进一步改进模型目标测量，训练可能会在使用完整预算之前完成。\n",
    "\n",
    "完成`run`方法后，将返回模型资源。\n",
    "\n",
    "训练流程的执行可能需要最多20分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_automl_pipeline:tabular"
   },
   "outputs": [],
   "source": [
    "model = job.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"iris\",\n",
    "    training_fraction_split=0.6,\n",
    "    validation_fraction_split=0.2,\n",
    "    test_fraction_split=0.2,\n",
    "    budget_milli_node_hours=8000,\n",
    "    disable_early_stopping=False,\n",
    "    target_column=label_column,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "source": [
    "## 回顾模型评估分数\n",
    "\n",
    "在模型训练完成后，您可以使用`list_model_evaluations()`方法来查看评估分数。该方法会为每个评估切片返回一个迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "model_evaluations = model.list_model_evaluations()\n",
    "\n",
    "for model_evaluation in model_evaluations:\n",
    "    print(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:mbsdk,dedicated"
   },
   "source": [
    "部署模型\n",
    "\n",
    "接下来，将您的模型部署到在线预测中。要部署模型，请调用`deploy`方法，使用以下参数：\n",
    "\n",
    "- `machine_type`：计算机类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy_model:mbsdk,dedicated"
   },
   "outputs": [],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_prediction:xai"
   },
   "source": [
    "发送一个带有可解释性的在线预测请求，向部署的模型发送。在这种方法中，预测的响应包括一个解释，说明特征是如何对解释有所贡献的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_test_item:automl,online_prediction"
   },
   "source": [
    "创建测试项目\n",
    "\n",
    "为了演示目的，使用合成数据生成预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "make_test_item:automl,tabular,iris"
   },
   "outputs": [],
   "source": [
    "INSTANCE = {\n",
    "    \"petal_length\": \"1.4\",\n",
    "    \"petal_width\": \"1.3\",\n",
    "    \"sepal_length\": \"5.1\",\n",
    "    \"sepal_width\": \"2.8\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "explain_request:mbsdk,lcn"
   },
   "source": [
    "### 通过解释生成预测\n",
    "\n",
    "现在您的模型已部署到一个端点，您可以通过向端点发送预测请求来获得在线解释。\n",
    "\n",
    "#### 请求\n",
    "\n",
    "每个实例的格式为：\n",
    "\n",
    "    [特征列表]\n",
    "\n",
    "由于`explain()`方法可以接受多个项目（实例），请将您的单个测试项目作为一个测试项目列表发送。\n",
    "\n",
    "#### 响应\n",
    "\n",
    "从`explain()`调用的响应是一个包含以下条目的Python字典：\n",
    "\n",
    "- `ids`：每个预测请求的内部分配的唯一标识符。\n",
    "- `displayNames`：每个类别标签的类别名称。\n",
    "- `confidences`：对于分类，每个类别标签的预测置信度值，介于0和1之间。\n",
    "- `values`：对于回归，预测的值。\n",
    "- `deployed_model_id`：生成预测的Vertex AI部署模型资源的标识符。\n",
    "- `explanations`：Explainable AI返回的特征归因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "explain_request:mbsdk,lcn"
   },
   "outputs": [],
   "source": [
    "instances_list = [INSTANCE]\n",
    "\n",
    "prediction = endpoint.explain(instances_list)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "understand_explanations"
   },
   "source": [
    "### 理解解释回应\n",
    "\n",
    "看一下模型预测并将其与实际值进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "understand_explanations:mbsdk,lcn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    label = np.argmax(prediction[0][0][\"scores\"])\n",
    "    cls = prediction[0][0][\"classes\"][label]\n",
    "    print(\"Predicted Value:\", cls, prediction[0][0][\"scores\"][label])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_feature_attributions"
   },
   "source": [
    "### 检查特征归因\n",
    "\n",
    "接下来看看这个特定示例的特征归因。正面归因值意味着特定特征将您的模型预测值上升了该量，负面归因值则相反。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "examine_feature_attributions:mbsdk,iris"
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "feature_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "attributions = prediction.explanations[0].attributions[0].feature_attributions\n",
    "\n",
    "rows = []\n",
    "for i, val in enumerate(feature_names):\n",
    "    rows.append([val, INSTANCE[val], attributions[val]])\n",
    "print(tabulate(rows, headers=[\"Feature name\", \"Feature value\", \"Attribution value\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check_explanations_baselines"
   },
   "source": [
    "检查您的解释和基线\n",
    "\n",
    "为了更好地理解您得到的特征归因，您应该将它们与您模型的基线进行比较。在大多数情况下，您的归因值加上基线应该非常接近于每个输入的模型预测值。还要注意，对于回归模型，解释返回的`baseline_score`对于发送到您模型的每个示例都是相同的。对于分类模型，每个类别都有自己的基线。\n",
    "\n",
    "在本节中，发送10个测试示例给您的模型进行预测，以便将特征归因与基线进行比较。然后，通过`sanity_check_explanations` 方法运行每个测试示例的归因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_explanations_baselines:mbsdk,iris"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Prepare 10 test examples to your model for prediction using a random distribution to generate\n",
    "# test instances\n",
    "instances = []\n",
    "for i in range(10):\n",
    "    pl = str(random.uniform(1.0, 2.0))\n",
    "    pw = str(random.uniform(1.0, 2.0))\n",
    "    sl = str(random.uniform(4.0, 6.0))\n",
    "    sw = str(random.uniform(2.0, 4.0))\n",
    "    instances.append(\n",
    "        {\"petal_length\": pl, \"petal_width\": pw, \"sepal_length\": sl, \"sepal_width\": sw}\n",
    "    )\n",
    "\n",
    "response = endpoint.explain(instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sanity_check_explanations"
   },
   "source": [
    "#### 健全性检查\n",
    "\n",
    "在下面的函数中，您对解释进行了健全性检查。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sanity_check_explanations"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sanity_check_explanations(\n",
    "    explanation, prediction, mean_tgt_value=None, variance_tgt_value=None\n",
    "):\n",
    "    passed_test = 0\n",
    "    total_test = 1\n",
    "    # `attributions` is a dict where keys are the feature names\n",
    "    # and values are the feature attributions for each feature\n",
    "    baseline_score = explanation.attributions[0].baseline_output_value\n",
    "    print(\"baseline:\", baseline_score)\n",
    "\n",
    "    # Sanity check 1\n",
    "    # The prediction at the input is equal to that at the baseline.\n",
    "    #  Please use a different baseline. Some suggestions are: random input, training\n",
    "    #  set mean.\n",
    "    if abs(prediction - baseline_score) <= 0.05:\n",
    "        print(\"Warning: example score and baseline score are too close.\")\n",
    "        print(\"You might not get attributions.\")\n",
    "    else:\n",
    "        passed_test += 1\n",
    "        print(\"Sanity Check 1: Passed\")\n",
    "\n",
    "    print(passed_test, \" out of \", total_test, \" sanity checks passed.\")\n",
    "\n",
    "\n",
    "i = 0\n",
    "for explanation in response.explanations:\n",
    "    try:\n",
    "        prediction = np.max(response.predictions[i][\"scores\"])\n",
    "    except TypeError:\n",
    "        prediction = np.max(response.predictions[i])\n",
    "    sanity_check_explanations(explanation, prediction)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于本教程的[Google Cloud 项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "outputs": [],
   "source": [
    "# Undeploy the model from the endpoint\n",
    "endpoint.undeploy_all()\n",
    "\n",
    "# Delete the model\n",
    "model.delete()\n",
    "\n",
    "# Delete the endpoint\n",
    "endpoint.delete()\n",
    "\n",
    "# Delete the dataset\n",
    "dataset.delete()\n",
    "\n",
    "# Delete the automl training job\n",
    "job.delete()\n",
    "\n",
    "# Delete the Cloud Storage bucket\n",
    "delete_bucket = False  # set True for deletion\n",
    "if delete_bucket:\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sdk_automl_tabular_classification_online_explain.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
