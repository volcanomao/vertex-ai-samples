{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# 使用Vertex AI Reduction服务器的PyTorch分布式训练\n",
    "\n",
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/reduction_server/pytorch_distributed_training_reduction_server.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/reduction_server/pytorch_distributed_training_reduction_server.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/reduction_server/pytorch_distributed_training_reduction_server.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>                                                                                               \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:custom"
   },
   "source": [
    "## 概述\n",
    "\n",
    "当您在使用GPU跨多个节点运行分布式训练作业时，节点之间的梯度通信可能会导致显着的延迟。Reduction Server是一种全局约简算法，可以提高分布式训练的吞吐量并减少延迟。本笔记本演示了如何在Vertex AI上运行带有Reduction Server的PyTorch分布式训练作业。训练作业旨在对来自Hugging Face Transformers库的预训练模型`bert-large-cased`在`imdb`数据集上进行情感分类进行微调。\n",
    "\n",
    "了解有关[Vertex AI训练](https://cloud.google.com/vertex-ai/docs/training/custom-training)和[Vertex AI Reduction Server](https://cloud.google.com/blog/topics/developers-practitioners/optimize-training-performance-reduction-server-vertex-ai)的更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:custom,training,online_prediction"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在这个笔记本中，您将学习如何创建一个使用PyTorch分布式训练框架和工具的PyTorch分布式训练作业，并在Vertex AI训练服务上使用Reduction Server运行训练作业。\n",
    "\n",
    "本教程使用以下Google Cloud ML服务和资源：\n",
    "\n",
    "* Vertex AI训练\n",
    "* Cloud Storage\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "* 创建一个PyTorch分布式训练应用程序\n",
    "* 将训练应用程序打包到预构建的容器中\n",
    "* 在Vertex AI上创建一个带有Reduction Server的自定义作业\n",
    "* 提交并监控作业."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:custom,cifar10,icn"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "在本教程中，我们使用了来自Hugging Face的[`imdb`](https://huggingface.co/datasets/imdb)数据集。`imdb`是一个用于二元情感分类的大型电影评论数据集，包含了用于训练的25000条极性强烈的电影评论和25000条用于测试的评论。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "成本\n",
    "\n",
    "本教程使用Google Cloud的可计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI收费](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage收费](https://cloud.google.com/storage/pricing)，并使用[Pricing Calculator](https://cloud.google.com/products/calculator/)根据您的预计使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装以下所需的软件包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fd00fa70a2a"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### 仅限Colab使用：取消下面的单元格注释以重新启动内核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzPxhxS5lugp"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2qpIurSjmpT"
   },
   "source": [
    "## 在开始之前\n",
    "\n",
    "### 设置您的谷歌云项目\n",
    "\n",
    "**无论您使用哪种笔记本环境，都需要执行以下步骤。**\n",
    "\n",
    "1. [选择或创建一个谷歌云项目](https://console.cloud.google.com/cloud-resource-manager)。当您第一次创建帐户时，您可获得 $300 的免费信用用于计算/存储成本。\n",
    "\n",
    "2. [确保为您的项目启用了计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "3. [启用以下 API：Vertex AI API，Cloud Resource Manager API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,cloudresourcemanager.googleapis.com)。\n",
    "\n",
    "4. 如果您在本地运行此笔记本，您需要安装 [Cloud SDK](https://cloud.google.com/sdk)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_id"
   },
   "source": [
    "#### 设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下操作：\n",
    "- 运行 `gcloud config list`。\n",
    "- 运行 `gcloud projects list`。\n",
    "- 查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsePm9c4jmpT"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a54f9d7c1876"
   },
   "source": [
    "#### 区域\n",
    "\n",
    "您还可以更改Vertex AI使用的“REGION”变量。了解有关[Vertex AI区域](https://cloud.google.com/vertex-ai/docs/general/locations)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3aaadaaf9b30"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7eelnCv6EWn"
   },
   "source": [
    "UUID\n",
    "\n",
    "如果您正在进行现场教程会话，则可能正在使用共享的测试帐户或项目。为了避免在创建的资源上出现用户之间的名称冲突，您可以为每个实例会话创建一个uuid，并将其附加到您在本教程中创建的资源名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHsjsyb76HaN"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specified length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5c0404984792"
   },
   "source": [
    "### 认证您的谷歌云账户\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动进行认证。请按照以下相关说明进行操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2n5SeAAjmpU"
   },
   "source": [
    "**1. Vertex AI 工作台**\n",
    "* 无需操作，因为您已经通过身份验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FDh38swjmpU"
   },
   "source": [
    "2. 本地JupyterLab实例，取消注释并运行:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nt8cEM2GjmpU"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUSL_JcpjmpU"
   },
   "source": [
    "3. 合作，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2zemfGvjmpU"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCPJ38n7jmpU"
   },
   "source": [
    "4. 服务账户或其他\n",
    "* 请查看如何在 https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples 上为您的服务账户授予云存储权限。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:custom"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间工件，如数据集。\n",
    "\n",
    "当您使用 Cloud SDK 提交一个训练作业时，您会将包含训练代码的 Python 包上传到一个云存储桶。Vertex AI 会从这个包中运行代码。在本教程中，Vertex AI 还会将作业产生的经过训练的模型保存在同一个存储桶中。使用这个模型工件，然后您可以创建 Vertex AI 模型资源并用于预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有当您的存储桶尚不存在时：运行以下单元格创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oz8J0vmSlugt"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3sbyPBU75CR"
   },
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8qQuI1377Jr"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_aip"
   },
   "source": [
    "### 初始化用于 Python 的 Vertex AI SDK\n",
    "\n",
    "为您的项目和对应的存储桶初始化 Python 版本的 Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNEiwLd0lugu"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tutorial_start:custom"
   },
   "source": [
    "# 教程\n",
    "\n",
    "现在您已经准备好开始创建PyTorch分布式训练作业。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_custom_model"
   },
   "source": [
    "### 打包训练应用程序\n",
    "\n",
    "在在 Vertex AI 上运行训练作业之前，必须将训练应用程序代码和任何依赖项打包并上传到您的谷歌云项目可以访问的云存储桶或容器注册表或 Artifact Registry 中。本节将展示如何在云中打包和部署您的应用程序。\n",
    "\n",
    "有两种方式可以打包您的应用程序和依赖项，并在 Vertex AI 上进行训练：\n",
    "\n",
    "1. 使用训练代码和依赖项创建 [Python 源分发](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container)，然后与 Vertex AI 上的[预构建容器](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers)一起使用\n",
    "2. 使用 [自定义容器](https://cloud.google.com/ai-platform/training/docs/custom-containers-training) 使用 Docker 容器打包依赖项\n",
    "\n",
    "**本笔记展示了使用 Python 源分发选项在 Vertex AI 上运行自定义训练作业。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBP_kLymhnYP"
   },
   "source": [
    "推荐的培训应用程序结构\n",
    "\n",
    "您可以按照自己喜欢的方式构建培训应用程序。然而，[以下结构](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container#structure)通常在 Vertex AI 示例中使用，并且使您的项目组织类似于示例可以让您更容易跟随示例。\n",
    "\n",
    "```\n",
    ".\n",
    "├── python_package\n",
    "│   ├── README.md\n",
    "│   ├── setup.py\n",
    "│   └── trainer\n",
    "│       ├── __init__.py\n",
    "│       └── task.py\n",
    "└── pytorch-distributed-training-reduction-server.ipynb    --> 这个笔记本\n",
    "```\n",
    "\n",
    "1. 主项目目录包含 `setup.py` 文件与依赖关系。\n",
    "2. 使用名为 `trainer` 的子目录存储您的主应用程序模块和 `scripts` 以在本地或云中提交培训作业。\n",
    "3. 在 `trainer` 目录内：\n",
    "    - `task.py` - 主应用程序模块 1) 初始化 PyTorch 分布式培训环境，以及 2) 运行模型培训和评估实验，并导出最终模型。\n",
    "    - `__init__.py` 是必需的，使Python将包含该文件的目录视为包。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4387867f83f2"
   },
   "source": [
    "为训练应用程序定义变量\n",
    "\n",
    "初始化变量以定义预构建容器映像、训练应用程序的位置和训练模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKPS5aGjaKRy"
   },
   "outputs": [],
   "source": [
    "APP_NAME = \"pytorch-bert\"\n",
    "\n",
    "PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.1-9:latest\"\n",
    ")\n",
    "\n",
    "PYTHON_PACKAGE_APPLICATION_DIR = \"python_package\"\n",
    "\n",
    "source_package_file_name = f\"{PYTHON_PACKAGE_APPLICATION_DIR}/dist/trainer-0.1.tar.gz\"\n",
    "python_package_gcs_uri = (\n",
    "    f\"{BUCKET_URI}/pytorch-on-gcp/{APP_NAME}/train/python_package/trainer-0.1.tar.gz\"\n",
    ")\n",
    "\n",
    "python_module_name = \"trainer.task\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NqTnsxaAdRp"
   },
   "source": [
    "创建培训应用程序的文件结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9zLCELGbOjS"
   },
   "outputs": [],
   "source": [
    "! mkdir {PYTHON_PACKAGE_APPLICATION_DIR}\n",
    "! touch {PYTHON_PACKAGE_APPLICATION_DIR}/README.md\n",
    "\n",
    "! mkdir {PYTHON_PACKAGE_APPLICATION_DIR}/trainer\n",
    "! touch {PYTHON_PACKAGE_APPLICATION_DIR}/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rpehVa0iFjY"
   },
   "source": [
    "创建用于训练应用程序的 `setup.py` 文件\n",
    "\n",
    "以下是用于训练应用程序的 `setup.py` 文件。`setup.py` 中的 `find_packages()` 函数包含了 `trainer` 目录，因为该目录包含了 `__init__.py` 文件，它告诉 [Python Setuptools](https://setuptools.readthedocs.io/en/latest/) 将父目录的所有子目录作为依赖项包含进来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QNjlhx7cBnj"
   },
   "outputs": [],
   "source": [
    "%%writefile ./{PYTHON_PACKAGE_APPLICATION_DIR}/setup.py\n",
    "\n",
    "import os\n",
    "from setuptools import find_packages\n",
    "from setuptools import setup\n",
    "import setuptools\n",
    "\n",
    "from distutils.command.build import build as _build\n",
    "import subprocess\n",
    "\n",
    "\n",
    "REQUIRED_PACKAGES = [\n",
    "    'transformers==4.28.0',\n",
    "    'datasets',\n",
    "    'evaluate',\n",
    "]\n",
    "\n",
    "setup(\n",
    "    name='trainer',\n",
    "    version='0.1',\n",
    "    install_requires=REQUIRED_PACKAGES,\n",
    "    packages=find_packages(),\n",
    "    include_package_data=True,\n",
    "    description='Vertex AI | Training | PyTorch | Text Classification | Python Package'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXlifmTtiTzy"
   },
   "source": [
    "创建训练应用程序代码\n",
    "\n",
    "`task.py` 是主要的应用程序模块。它初始化 PyTorch 分布式训练环境，并运行模型训练和评估实验，并导出最终模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wruDyrEPsLbH"
   },
   "outputs": [],
   "source": [
    "%%writefile ./{PYTHON_PACKAGE_APPLICATION_DIR}/trainer/task.py\n",
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\n",
    "# you may not use this file except in compliance with the License.\\n\",\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import datasets\n",
    "from datasets import ClassLabel, Sequence, load_dataset\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoTokenizer,\n",
    "    EvalPrediction, \n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    default_data_collator)\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "  parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "  parser.add_argument(\"--epochs\", type=int, help=\"Number of training epochs.\", default=2)\n",
    "  parser.add_argument(\"--batch_size\", type=int, help=\"Training batch size for one process.\", default=32)\n",
    "  parser.add_argument(\"--model_dir\", type=str, help=\"Directory for saving models.\", default=os.environ['AIP_MODEL_DIR'] if 'AIP_MODEL_DIR' in os.environ else \"\")\n",
    "  argv = parser.parse_args()\n",
    "\n",
    "  model_name_or_path = \"bert-large-uncased\"\n",
    "  padding = \"max_length\"\n",
    "  max_seq_length = 128\n",
    "\n",
    "  datasets = load_dataset(\"imdb\")\n",
    "  label_list = datasets[\"train\"].unique(\"label\")\n",
    "  label_to_id = {1: 1, 0: 0, -1: 0}\n",
    "\n",
    "  tokenizer = AutoTokenizer.from_pretrained(\n",
    "      model_name_or_path,\n",
    "      use_fast=True,\n",
    "  )\n",
    "\n",
    "  def preprocess_function(examples):\n",
    "      \"\"\"\n",
    "      Tokenize the input example texts\n",
    "      \"\"\"\n",
    "      args = (examples[\"text\"],)\n",
    "      result = tokenizer(\n",
    "          *args, padding=padding, max_length=max_seq_length, truncation=True\n",
    "      )\n",
    "\n",
    "      # Map labels to IDs (not necessary for GLUE tasks)\n",
    "      if label_to_id is not None and \"label\" in examples:\n",
    "          result[\"label\"] = [label_to_id[example] for example in examples[\"label\"]]\n",
    "\n",
    "      return result\n",
    "\n",
    "  # apply preprocessing function to input examples\n",
    "  datasets = datasets.map(preprocess_function, batched=True, load_from_cache_file=True)\n",
    "\n",
    "  model = AutoModelForSequenceClassification.from_pretrained(\n",
    "      model_name_or_path, \n",
    "      num_labels=len(label_list)\n",
    "  )\n",
    "\n",
    "  ngpus_per_node = torch.cuda.device_count()\n",
    "  world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "  \n",
    "  # Since we have ngpus_per_node processes per node, the total world_size\n",
    "  # needs to be adjusted accordingly\n",
    "  world_size =  world_size * ngpus_per_node\n",
    "\n",
    "  start = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "  print(f'Starting distributed training: {start}') \n",
    "  \n",
    "  # Use torch.multiprocessing.spawn to launch distributed processes\n",
    "  torch.multiprocessing.spawn(main_worker,\n",
    "    args = (ngpus_per_node, world_size, datasets, model, tokenizer, argv),\n",
    "    nprocs = ngpus_per_node,\n",
    "    join = True)\n",
    "  \n",
    "  end = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "  print(f'Distributed training complete: {end}')\n",
    "\n",
    "def main_worker(local_rank, ngpus_per_node, world_size, datasets, model, tokenizer, argv):\n",
    "\n",
    "  # This is the (global) rank of the current process\n",
    "  rank = int(os.environ[\"RANK\"])\n",
    "  \n",
    "  # For multiprocessing distributed training, rank needs to be the\n",
    "  # global rank among all the processes\n",
    "  rank = rank * ngpus_per_node + local_rank\n",
    "  print (f\"Distributed and Multi-processing. Setting rank for each worker. rank={rank}\")\n",
    "\n",
    "  dist.init_process_group(\n",
    "      backend=\"nccl\", \n",
    "      init_method=\"env://\",\n",
    "      world_size=world_size, \n",
    "      rank=rank)\n",
    "  \n",
    "  per_device_batch_size = int(argv.batch_size / ngpus_per_node)\n",
    "\n",
    "  training_args = TrainingArguments(\n",
    "      output_dir=\"/tmp/output/\",\n",
    "      num_train_epochs=argv.epochs, \n",
    "      per_device_train_batch_size=per_device_batch_size,\n",
    "      per_device_eval_batch_size=per_device_batch_size,\n",
    "      local_rank=local_rank,\n",
    "  )\n",
    "\n",
    "  def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}\n",
    "  \n",
    "  trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets[\"train\"],\n",
    "    eval_dataset=datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator,\n",
    "  )\n",
    "\n",
    "  trainer.train()\n",
    "\n",
    "  # Save the trained model locally\n",
    "  model_filename = \"pytorch-birt-model\"\n",
    "  local_path = os.path.join(\"/tmp\", model_filename)\n",
    "  trainer.save_model(local_path)\n",
    "\n",
    "  if (os.path.exists(local_path)):\n",
    "    # Upload the trained model to Cloud storage\n",
    "    model_directory = argv.model_dir\n",
    "    storage_path = os.path.join(model_directory, model_filename)\n",
    "    blob = storage.blob.Blob.from_string(storage_path, client=storage.Client())\n",
    "\n",
    "    files = [f for f in os.listdir(local_path) if os.path.isfile(os.path.join(local_path, f))]\n",
    "    for file in files:\n",
    "      local_file = os.path.join(local_path, file)\n",
    "      blob.upload_from_filename(local_file)\n",
    "  \n",
    "    print(f\"Saved model files in {model_directory}/{model_filename}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzmJxNOnix9O"
   },
   "source": [
    "创建一个源分发`dist/trainer-0.1.tar.gz`，并将带有训练应用程序的源分发上传到云存储桶，然后验证源分发是否存在于云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGgRZ4N-bbW0"
   },
   "outputs": [],
   "source": [
    "! cd {PYTHON_PACKAGE_APPLICATION_DIR} && python3 setup.py sdist --formats=gztar\n",
    "\n",
    "! gsutil cp {source_package_file_name} {python_package_gcs_uri}\n",
    "\n",
    "! gsutil ls -l {python_package_gcs_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gv0PB6WhjKsA"
   },
   "source": [
    "在Vertex AI上使用Reduction Server运行自定义训练作业\n",
    "\n",
    "配置一个自定义作业，使用预先构建的PyTorch容器映像和打包为Python源代码分发的训练代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPWYVIEwcQWX"
   },
   "outputs": [],
   "source": [
    "print(f\"APP_NAME={APP_NAME}\")\n",
    "print(\n",
    "    f\"PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI={PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI}\"\n",
    ")\n",
    "print(f\"python_package_gcs_uri={python_package_gcs_uri}\")\n",
    "print(f\"python_module_name={python_module_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iy_OwOByjW1W"
   },
   "source": [
    "创建一个训练作业\n",
    "\n",
    "您可以使用[Python的Vertex AI SDK](https://cloud.google.com/vertex-ai/docs/start/client-libraries#client_libraries)来创建一个自定义训练作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ups1PMXCcjDB"
   },
   "outputs": [],
   "source": [
    "JOB_NAME = f\"pytorch-birt-reduction-server-{UUID}\"\n",
    "print(f\"JOB_NAME={JOB_NAME}\")\n",
    "\n",
    "job = aiplatform.CustomPythonPackageTrainingJob(\n",
    "    display_name=f\"{JOB_NAME}\",\n",
    "    python_package_gcs_uri=python_package_gcs_uri,\n",
    "    python_module_name=python_module_name,\n",
    "    container_uri=PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YimBZzZmAUwP"
   },
   "source": [
    "#### 定义训练集群工作人员池和实验配置参数\n",
    "\n",
    "Reduction Server可以与使用NVIDIA NCCL库进行全局归约集合运算的任何分布式训练框架一起使用。您无需更改或重新编译您的训练应用程序。\n",
    "\n",
    "Google Cloud指南[分布式训练](https://cloud.google.com/vertex-ai/docs/training/distributed-training)提供了有关如何在Vertex AI上运行分布式训练作业的详细说明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIjTAfqvcnJu"
   },
   "outputs": [],
   "source": [
    "# Training cluster worker pool configuration\n",
    "REPLICA_COUNT = 3\n",
    "MACHINE_TYPE = \"n1-standard-16\"\n",
    "ACCELERATOR_TYPE = \"NVIDIA_TESLA_V100\"\n",
    "ACCELERATOR_COUNT = 2\n",
    "\n",
    "# Reduction Server configuration\n",
    "REDUCTION_SERVER_COUNT = 4\n",
    "REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "REDUCTION_SERVER_IMAGE_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai-restricted/training/reductionserver:latest\"\n",
    ")\n",
    "ENVIRONMENT_VARIABLES = {\"NCCL_DEBUG\": \"INFO\"}\n",
    "\n",
    "# Training experiment parameters\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 32\n",
    "MODEL_DIR = f\"{BUCKET_URI}/{JOB_NAME}\"\n",
    "\n",
    "training_args = [\n",
    "    \"--epochs\",\n",
    "    str(EPOCHS),\n",
    "    \"--batch_size\",\n",
    "    str(BATCH_SIZE),\n",
    "    \"--model_dir\",\n",
    "    MODEL_DIR,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xErX0T7LHYjX"
   },
   "source": [
    "提交培训任务\n",
    "\n",
    "在定义了培训集群配置参数之后，使用Python的Vertex AI SDK提交和监控一个训练任务。\n",
    "\n",
    "*注意：使用Python的Vertex AI SDK提交培训任务时，会创建一个训练管道，该管道会在Vertex AI训练服务上启动自定义任务。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XtBA-NTIcr7T"
   },
   "outputs": [],
   "source": [
    "model = job.run(\n",
    "    replica_count=REPLICA_COUNT,\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_type=ACCELERATOR_TYPE,\n",
    "    accelerator_count=ACCELERATOR_COUNT,\n",
    "    reduction_server_replica_count=REDUCTION_SERVER_COUNT,\n",
    "    reduction_server_machine_type=REDUCTION_SERVER_MACHINE_TYPE,\n",
    "    reduction_server_container_uri=REDUCTION_SERVER_IMAGE_URI,\n",
    "    environment_variables=ENVIRONMENT_VARIABLES,\n",
    "    args=training_args,\n",
    "    sync=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CA38ygH_jeJe"
   },
   "source": [
    "#### 监控培训工作（可选）\n",
    "\n",
    "您可以通过以下链接监视从Cloud Console启动的自定义作业[这里](https://console.cloud.google.com/vertex-ai/training/training-pipelines/)，或使用gcloud CLI命令 [`gcloud beta ai custom-jobs stream-logs`](https://cloud.google.com/sdk/gcloud/reference/beta/ai/custom-jobs/stream-logs)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6LpsQI1WpPz"
   },
   "source": [
    "验证模型工件（可选）\n",
    "\n",
    "您可以在训练应用程序成功完成作业后，通过验证写入云存储桶的模型工件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_138iEP3HD0L"
   },
   "outputs": [],
   "source": [
    "print(f\"Model artifacts are available at {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:custom"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于本教程的[Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNmebHf7lug0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "delete_custom_job = True\n",
    "delete_bucket = False\n",
    "\n",
    "if delete_custom_job:\n",
    "    try:\n",
    "        job.delete()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pytorch_distributed_training_reduction_server.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
