{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# 使用TabNet内置算法开始训练表格模型\n",
    "\n",
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/tabnet/get_started_with_tabnet.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/tabnet/get_started_with_tabnet.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/tabnet/get_started_with_tabnet.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>                                                                                               \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概览\n",
    "\n",
    "本教程演示了如何在Vertex AI平台上使用TabNet内置算法服务训练自定义表格模型。\n",
    "\n",
    "TabNet结合了两个世界的优点：它具有可解释性（类似于简单的基于树的模型），同时又具有高性能（类似于深度神经网络）。这使其非常适用于零售商、金融和保险行业应用，如信用评分预测、欺诈检测和预测。\n",
    "\n",
    "TabNet使用一种名为序列关注的机器学习技术，在模型的每个步骤中选择要从中推理的模型特征。这种机制使得可以解释模型如何得出预测，并帮助它学习更准确的模型。TabNet不仅胜过其他神经网络和决策树，还提供可解释的特征归因。\n",
    "\n",
    "研究论文：[TabNet：关注可解释的表格学习](https://arxiv.org/pdf/1908.07442.pdf)\n",
    "\n",
    "了解更多关于[Tabular Workflow for TabNet](https://cloud.google.com/vertex-ai/docs/tabular-data/tabular-workflows/tabnet)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5040751873a"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在这个笔记本中，您将学习如何运行构建的 `Vertex AI TabNet` 算法来训练自定义表格模型。\n",
    "\n",
    "本教程使用以下 Google Cloud 机器学习服务和资源：\n",
    "\n",
    "- `Vertex AI TabNet`\n",
    "- `Vertex AI Prediction`\n",
    "- `Vertex AI Training`\n",
    "- `Vertex AI Models`\n",
    "- `Vertex AI Endpoints`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 获取训练数据。\n",
    "- 配置 `Vertex AI TabNet` 容器的训练参数。\n",
    "- 使用 CSV 数据使用 `Vertex AI Training` 训练模型。\n",
    "- 将模型上传为 `Vertex AI Model` 资源。\n",
    "- 部署 `Vertex AI Model` 资源到 `Vertex AI Endpoint` 资源。\n",
    "- 使用部署的模型进行预测。\n",
    "- 调整 `Vertex AI TabNet` 模型的超参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ac8c8586ab03"
   },
   "source": [
    "数据集\n",
    "\n",
    "本教程使用公共云存储桶`gs://cloud-samples-data/ai-platform-unified/datasets/tabular/`中的`petfinder`数据集，该数据集来自[PetFinder.my Adoption Prediction](https://www.kaggle.com/c/petfinder-adoption-prediction)。该数据集用于预测动物被领养的速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fc0ad661ebb"
   },
   "source": [
    "### 费用\n",
    "\n",
    "本教程使用谷歌云的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* 云存储\n",
    "\n",
    "了解 [Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing) 和 [云存储价格](https://cloud.google.com/storage/pricing)，并使用 [定价计算器](https://cloud.google.com/products/calculator/) 根据您预计的使用情况生成费用估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "安装以下软件包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b4ef9b72d43"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade tensorflow --quiet\n",
    "! pip3 install --upgrade google-cloud-aiplatform\n",
    "! gcloud components update --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "仅限Colab：取消注释以下单元格以重新启动内核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-ZBOjErv5mM"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "在你开始之前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "### 设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下方法：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "区域\n",
    "\n",
    "您还可以更改 Vertex AI 中使用的 `REGION` 变量。了解有关 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations) 的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 认证您的Google Cloud帐户\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动进行认证。请按照以下相关说明进行操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvQeFm3Gv5mR"
   },
   "source": [
    "1. 顶点人工智能工作台\n",
    "* 无需操作，因为您已经通过身份验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ad1138a125ea"
   },
   "source": [
    "2. 本地JupyterLab实例，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce6043da7b33"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0367eac06a10"
   },
   "source": [
    "3. 合作，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21ad4dbb4a61"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c13224697bfb"
   },
   "source": [
    "4. 服务账户或其他\n",
    "* 请参阅如何在 https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples 上为您的服务账户授予云存储权限。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产物，比如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "只有在您的存储桶不存在时才能运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf"
   },
   "source": [
    "导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRUOFELefqf1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "###初始化Vertex AI SDK用于Python\n",
    "\n",
    "初始化Vertex AI SDK用于您的项目和相应的存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "source": [
    "设置硬件加速器\n",
    "\n",
    "您可以为训练和预测设置硬件加速器。\n",
    "\n",
    "设置变量`DEPLOY_GPU/DEPLOY_NGPU`以使用支持GPU和分配给虚拟机实例的GPU数量的容器映像。例如，要使用一个具有4个Nvidia Telsa K80 GPU分配给每个VM的GPU容器映像，您可以指定：\n",
    "\n",
    "    (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
    "\n",
    "\n",
    "否则，请指定 `(None, None)` 以使用一个在CPU上运行的容器映像。\n",
    "\n",
    "了解更多关于[您区域的硬件加速器支持](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)。\n",
    "\n",
    "*注意*：TF 2.3之前的GPU支持版本将无法加载本教程中的自定义模型。这是一个已知问题，在TF 2.3中已修复。这是由生成在服务功能中的静态图操作所引起的。如果在您自己的自定义模型上遇到此问题，请使用支持GPU的TF 2.3的容器映像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "outputs": [],
   "source": [
    "TRAIN_GPU, TRAIN_NGPU = (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80, 1)\n",
    "\n",
    "DEPLOY_GPU, DEPLOY_NGPU = (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于训练和预测的机器类型。\n",
    "\n",
    "- 设置变量`TRAIN_COMPUTE`和`DEPLOY_COMPUTE`来配置用于训练和预测的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`：每个vCPU 3.75GB内存\n",
    "     - `n1-highmem`：每个vCPU 6.5GB内存\n",
    "     - `n1-highcpu`：每个vCPU 0.9GB内存\n",
    " - `vCPUs`：\\[2, 4, 8, 16, 32, 64, 96 \\]个\n",
    "\n",
    "*注意：以下内容不支持用于训练：*\n",
    "\n",
    " - `standard`：2个vCPUs\n",
    " - `highcpu`：2、4和8个vCPUs\n",
    "\n",
    "*注意：您也可以使用n2和e2机器类型进行训练和部署，但它们不支持GPU*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training"
   },
   "outputs": [],
   "source": [
    "TRAIN_COMPUTE = \"n1-standard-4\"\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)\n",
    "\n",
    "DEPLOY_COMPUTE = \"n1-standard-4\"\n",
    "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bffd1dbc8a8c"
   },
   "source": [
    "设置训练容器\n",
    "\n",
    "接下来，您使用预构建的“Vertex AI TabNet”容器来训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f29b4eab8132"
   },
   "outputs": [],
   "source": [
    "TRAIN_IMAGE = \"us-docker.pkg.dev/vertex-ai-restricted/builtin-algorithm/tab_net_v2\"\n",
    "\n",
    "print(\"Training:\", TRAIN_IMAGE, TRAIN_GPU, TRAIN_NGPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction"
   },
   "source": [
    "设置预先构建的容器以进行部署\n",
    "\n",
    "设置预先构建的Docker容器镜像进行预测。\n",
    "\n",
    "获取最新列表，请查看[用于预测的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:training,prediction"
   },
   "outputs": [],
   "source": [
    "TF = \"2.5\".replace(\".\", \"-\")\n",
    "\n",
    "if DEPLOY_GPU:\n",
    "    DEPLOY_VERSION = \"tf2-gpu.{}\".format(TF)\n",
    "else:\n",
    "    DEPLOY_VERSION = \"tf2-cpu.{}\".format(TF)\n",
    "\n",
    "DEPLOY_IMAGE = \"{}-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], DEPLOY_VERSION\n",
    ")\n",
    "\n",
    "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU, DEPLOY_NGPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dd2b940d35d"
   },
   "source": [
    "获取训练数据\n",
    "\n",
    "首先，您需要从一个公共云存储桶中获取训练数据的副本——以CSV文件的形式，并将训练数据复制到您自己的云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BoVqAMOuedPe"
   },
   "outputs": [],
   "source": [
    "# Please note that if you use csv input, the first column is the label column.\n",
    "\n",
    "IMPORT_FILE = \"petfinder-tabular-classification-tabnet-with-header.csv\"\n",
    "TRAINING_DATA_PATH = f\"{BUCKET_URI}/data/petfinder/train.csv\"\n",
    "\n",
    "! gsutil cp gs://cloud-samples-data/ai-platform-unified/datasets/tabular/{IMPORT_FILE} {TRAINING_DATA_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_container_training_job:mbsdk,no_model"
   },
   "source": [
    "### 创建并运行 `Vertex AI TabNet` 训练作业\n",
    "\n",
    "要训练TabNet自定义模型，您需要执行两个步骤：1）创建自定义训练作业，2）运行作业。\n",
    "\n",
    "#### 创建自定义训练作业\n",
    "\n",
    "使用 `CustomTrainingJob` 类创建自定义训练作业，需要以下参数：\n",
    "\n",
    "- `display_name`：自定义训练作业的可读名称。\n",
    "- `container_uri`：训练容器镜像。\n",
    "- `model_serving_container_image_uri`：可以为您的模型提供预测的容器的URI——要么是预构建的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3307f420d27"
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = \"petfinder\"  # Change to your dataset name.\n",
    "\n",
    "job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=f\"{DATASET_NAME}\",\n",
    "    container_uri=TRAIN_IMAGE,\n",
    "    model_serving_container_image_uri=DEPLOY_IMAGE,\n",
    ")\n",
    "\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xc_I_XHz8z6B"
   },
   "source": [
    "为TabNet训练配置参数设置\n",
    "\n",
    "以下表格显示了TabNet训练作业的参数：\n",
    "\n",
    "| 参数 | 数据类型 | 描述 | 是否必需 |\n",
    "|--|--|--|--|\n",
    "| `preprocess` | 布尔参数 | 指定此参数以启用自动预处理。 | 否|\n",
    "| `job_dir` | 字符串 | 保存模型输出文件的云存储目录。 | 是 |\n",
    "| `input_metadata_path` | 字符串 | 训练数据集的TabNet特定元数据的GCS路径。请参阅上文了解如何创建元数据。 | 否 . |\n",
    "| `training_data_path` | 字符串 | 存储训练数据的云存储模式。 | 是 |\n",
    "| `validation_data_path` | 字符串 | 存储评估数据的云存储模式。 | 否 |\n",
    "| `test_data_path` | 字符串 | 存储测试数据的云存储模式。 | 是 |\n",
    "| `input_type` | 字符串 | “bigquery”或“csv” - 输入表格数据的类型。如果提到了csv，则第一列被视为目标。如果CSV文件有标题，也传递标志“data_has_header”。如果使用“bigquery”，可以提供训练/验证数据路径，或者提供BigQuery项目、数据集和表名，以进行预处理生成训练和验证数据集。 | 是 |\n",
    "| `model_type` | 字符串 | 学习任务，如分类或回归。 | 是 |\n",
    "| `split_column` | 字符串 | 用于创建训练、验证和测试拆分的列名。列的值（也称为table['split_column']）应该是“TRAIN”、“VALIDATE”或“TEST”。“TEST”是可选的。仅适用于bigquery输入。 | 否 . |\n",
    "| `train_batch_size` | 整数 | 训练的批量大小。 | 否 - 默认值为1024。 |\n",
    "| `eval_split` | 浮点数 | 用于评估数据集的拆分比例，如果未提供`validation_data_path`。 | 否 - 默认值为0.2 |\n",
    "| `learning_rate` | 浮点数 | 训练的学习率。 | 否 - 默认值为指定优化器的默认学习率。 |\n",
    "| `eval_frequency_secs` | 整数 | 评估和检查点进行的频率。默认值为600。 | 否 . |\n",
    "| `num_parallel_reads` | 整数 | 用于读取输入文件的线程数。我们建议设置它等于或略低于机器的CPU数量，以获得最大性能。例如，每个GPU设置为6是一个很好的默认选择。 | 是 . |\n",
    "| `optimizer` | 字符串 | 训练优化器。支持任何TF2.3 Keras优化器的小写字符串名称（'sgd'、'adam'、'ftrl'等）。请参阅[ TensorFlow文档](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)。 | 否 - 默认值为'adam'。 |\n",
    "| `data_cache` | 字符串 | 选择将数据缓存在“memory”、“disk”或“no_cache”中。对于大型数据集，将数据缓存在内存中会导致内存不足错误，因此，我们建议选择“disk”。您可以在配置文件中指定磁盘大小（如下面的示例）。请确保请求一个足够大（例如TB级别）的磁盘来写入数据，适用于大型（B级别）数据集。 | 否，默认值为“memory” . |\n",
    "| `bq_project` | 字符串 | BigQuery项目的名称。如果input_type=bigquery并且使用了标志–preprocessing，则此项是必需的。这是指定训练、验证和测试数据路径的替代方法。 | 否 . |\n",
    "| `dataset_name` | 字符串 | BigQuery数据集的名称。如果input_type=bigquery并且使用了标志–preprocessing，则此项是必需的。这是指定训练、验证和测试数据路径的替代方法。 | 否 . |\n",
    "| `table_name` | 字符串 | BigQuery表的名称。如果input_type=bigquery并且使用了标志–preprocessing，则此项是必需的。这是指定训练、验证和测试数据路径的替代方法。 | 否 . |\n",
    "| `loss_function_type` | 字符串 | TabNet中有几种损失函数类型。对于回归：含有mse/mae。对于分类：含有cross_entropy/weighted_cross_entropy/focal_loss。| 否 . 如果数值为“default”，我们将用mse进行回归，用cross_entropy进行分类。|\n",
    "| `deterministic_data` | 布尔参数 | 数据从表格数据中读取的确定性。默认设置为False。设置为True时，实验是确定性的。为了在大型数据集上快速训练，我们建议选择deterministic_data=False，尽管结果中存在一些随机性（在大型数据集中可以忽略）. 请注意，在分布式训练中，确定性仍然无法保证，因为map-reduce导致由于有限精度的代数操作顺序而产生随机性。然而，在实践中这是非常小的，尤其在处理大型数据集时。对于需要100%确定性的情况，除了选择deterministic_data=True，我们建议使用单个GPU进行训练（例如使用MACHINE_TYPE=\"n1-highmem-8\"）。| 否，默认值为False . |\n",
    "| `stream_inputs` | 布尔参数 | 从GCS中流式处理输入数据而不是本地下载 - 此选项建议用于快速运行时。 | 否 . |\n",
    "| `large_category_dim` | 整数 | 嵌入的维度 - 如果分类列的不同类别数量大于large_category_thresh，则使用large_category_dim维度的嵌入，而不是1-D嵌入。默认值为1。我们建议增加它（例如，在大多数情况下增加到 ~5，甚至在数据集中类别数量非常大的情况下增加到 ~10），如果最重要的目标是提高准确性而不是计算效率和可解释性。 | 否 . |\n",
    "| `large_category_thresh` | 整数 | 分类列基数的阈值 - 如果分类列的不同类别数量大于large_category_thresh，则使用large_category_dim维度的嵌入，而不是1-D嵌入。默认值为300。我们建议降低它（例如到 ~10），如果最重要的目标是提高准确性而不是计算效率和可解释性。 | 否 . |\n",
    "| `yeo_johnson_transform` | 布尔参数 | 启用可训练的Yeo-Johnson Power变换（默认禁用）。请参阅此链接：https://www.stat.umn.edu/arc/yjpower.pdf 了解更多关于Yeo-Johnson Power变换的信息。通过我们的实现，变换参数将随着TabNet一起学习，以端到端的方式进行训练。| 否 . |\n",
    "| `apply_log_transform` | 布尔参数 | 如果元数据中包含对数变换统计数据并且此标志为true，则输入要素将被对数变换。如果不使用变换，请使用false，如果使用变换则使用true（默认值）。特别对于具有偏斜的数值分布的数据集，对数变换可能非常有帮助。 | 否 . |\n",
    "| `apply_quantile_transform` | 布尔参数 | 如果元数据中包含分位数统计数据并且此标志为true，则输入要素将被分位数变换。如果不使用变换，请使用false，如果使用变换则使用true（默认值）。特别对于具有偏斜的数值分布的数据集，分位数变换可能非常有帮助。目前支持BigQuery输入类型。 | 否 . |\n",
    "| `replace_transformed_features` | 布尔参数 | 如果为true，则对特征应用变换后该特征将被替换。如果为false（默认选项），那么变换后的特征将被添加到要素列列表中。选择true来用变换替换特征，选择false将变换后的特征作为新列附加。 | 否 . |\n",
    "| `target_column` | 字符串 | 标签列的名称。请注意，对于分类，标签需要是String或整数类型。 | 否 . |\n",
    "| `prediction_raw_inputs` | 布尔参数 | 如果设置了此参数，模型服务允许我们将要素作为张量字典而不是CSV行进行传递。 | 否 . |\n",
    "| `exclude_key` | 布尔参数 | 如果设置了此参数，我们将在输入/输出中排除一个键。该键对于批量预测过程中的输入和保存输出具有不可预测的顺序很有帮助。该键有助于将输出与输入匹配。 | 否 . |\n",
    "\n",
    "了解更多关于[ 使用内置TabNet算法入门](https://cloud.google.com/ai-platform/training/docs/algorithms/tab-net-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a987b40417de"
   },
   "outputs": [],
   "source": [
    "ALGORITHM = \"tabnet\"\n",
    "MODEL_TYPE = \"classification\"\n",
    "MODEL_NAME = f\"{DATASET_NAME}_{ALGORITHM}_{MODEL_TYPE}\"\n",
    "\n",
    "OUTPUT_DIR = f\"{BUCKET_URI}/{MODEL_NAME}\"\n",
    "print(\"Output dir: \", OUTPUT_DIR)\n",
    "\n",
    "CMDARGS = [\n",
    "    \"--preprocess\",\n",
    "    \"--data_has_header\",\n",
    "    f\"--training_data_path={TRAINING_DATA_PATH}\",\n",
    "    f\"--job-dir={OUTPUT_DIR}\",\n",
    "    f\"--model_type={MODEL_TYPE}\",\n",
    "    \"--max_steps=2000\",\n",
    "    \"--batch_size=4096\",\n",
    "    \"--learning_rate=0.01\",\n",
    "    \"--prediction_raw_inputs\",\n",
    "    \"--exclude_key\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_custom_job"
   },
   "source": [
    "### 训练TabNet模型\n",
    "\n",
    "使用`run`方法开始训练，需要传入以下参数：\n",
    "\n",
    "- `args`：要传递给TabNet训练容器的命令行参数。\n",
    "- `replica_count`：工作器副本的数量。\n",
    "- `model_display_name`：如果脚本生成一个托管`Model`，则为`Model`的显示名称。\n",
    "- `machine_type`：用于训练的机器类型。\n",
    "- `accelerator_type`：硬件加速器类型。\n",
    "- `accelerator_count`：要附加到工作器副本的加速器数量。\n",
    "\n",
    "`run`方法创建一个训练流水线来训练和创建一个`Model`对象。训练流水线完成后，`run`方法将返回`Model`对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0927403746f"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = OUTPUT_DIR\n",
    "\n",
    "if TRAIN_GPU:\n",
    "    model = job.run(\n",
    "        model_display_name=f\"{DATASET_NAME}\",\n",
    "        args=CMDARGS,\n",
    "        replica_count=1,\n",
    "        machine_type=TRAIN_COMPUTE,\n",
    "        base_output_dir=MODEL_DIR,\n",
    "        accelerator_type=TRAIN_GPU.name,\n",
    "        accelerator_count=TRAIN_NGPU,\n",
    "        sync=True,\n",
    "    )\n",
    "else:\n",
    "    model = job.run(\n",
    "        model_display_name=f\"{DATASET_NAME}\",\n",
    "        args=CMDARGS,\n",
    "        replica_count=1,\n",
    "        machine_type=TRAIN_COMPUTE,\n",
    "        base_output_dir=MODEL_DIR,\n",
    "        sync=True,\n",
    "    )\n",
    "\n",
    "print(model.gca_resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91d661ac0276"
   },
   "source": [
    "删除训练任务\n",
    "\n",
    "使用`delete()`方法来删除训练任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3e43fc3b7fe8"
   },
   "outputs": [],
   "source": [
    "job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:dedicated"
   },
   "source": [
    "### 部署模型\n",
    "\n",
    "在使用模型进行预测之前，您需要将其部署到一个`Endpoint`。您可以通过在`Model`资源上调用`deploy`函数来实现这一点。这将执行两个任务：\n",
    "\n",
    "1. 为部署`Model`资源创建一个`Endpoint`资源。\n",
    "2. 将`Model`资源部署到`Endpoint`资源中。\n",
    "\n",
    "\n",
    "函数接受以下参数：\n",
    "\n",
    "- `deployed_model_display_name`：部署模型的易读名称。\n",
    "- `traffic_split`：流量分配到端点的百分比，以一个或多个键/值对的字典形式指定。\n",
    "   - 如果只有一个模型，则指定为**{ \"0\": 100 }**，其中\"0\"表示上传的模型，100表示100%的流量。\n",
    "   - 如果端点上有现有模型，想要分配流量，则使用`model_id`来指定为**{ \"0\": percent, model_id: percent, ... }**，其中`model_id`是要部署到端点的现有模型的模型ID。百分比必须相加等于100。\n",
    "- `machine_type`：用于训练的机器类型。\n",
    "- `accelerator_type`：硬件加速器类型。\n",
    "- `accelerator_count`：要附加到工作副本的加速器数量。\n",
    "- `starting_replica_count`：初始提供的计算实例数量。\n",
    "- `max_replica_count`：要扩展到的最大计算实例数量。在本教程中，只有一个实例被提供。\n",
    "\n",
    "### 流量分配\n",
    "\n",
    "`traffic_split`参数以Python字典形式指定。您可以将多个模型实例部署到一个端点，然后设置每个实例接收的流量百分比。\n",
    "\n",
    "您可以使用流量分配逐渐将一个新模型引入生产环境。例如，如果您已经有一个在生产环境中的模型占据了100%的流量，您可以部署一个新模型到同一个端点，将10%的流量指向它，并将原始模型的流量减少到90%。这样可以在最小化对大多数用户影响的同时监控新模型的性能。\n",
    "\n",
    "### 计算实例扩展\n",
    "\n",
    "您可以指定一个单一实例（节点）来处理您的在线预测请求。本教程使用单一节点，因此变量`MIN_NODES`和`MAX_NODES`都设置为`1`。\n",
    "\n",
    "如果您想要使用多个节点来处理在线预测请求，将`MAX_NODES`设置为您希望使用的最大节点数量。Vertex AI会自动扩展用于提供预测的节点数量，直至达到您设置的最大数量。参考[定价页面](https://cloud.google.com/vertex-ai/pricing#prediction-prices)了解使用多个节点进行自动扩展的成本。\n",
    "\n",
    "### Endpoint\n",
    "\n",
    "该方法将会阻塞，直到模型部署完成，并最终返回一个`Endpoint`对象。如果这是第一次将模型部署到端点，则可能需要额外几分钟来完成资源的提供。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMH7GrYMlugy"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_NAME = f\"{DATASET_NAME}\"\n",
    "\n",
    "TRAFFIC_SPLIT = {\"0\": 100}\n",
    "\n",
    "MIN_NODES = 1\n",
    "MAX_NODES = 1\n",
    "\n",
    "if DEPLOY_GPU:\n",
    "    endpoint = model.deploy(\n",
    "        deployed_model_display_name=DEPLOYED_NAME,\n",
    "        traffic_split=TRAFFIC_SPLIT,\n",
    "        machine_type=DEPLOY_COMPUTE,\n",
    "        accelerator_type=DEPLOY_GPU.name,\n",
    "        accelerator_count=DEPLOY_NGPU,\n",
    "        min_replica_count=MIN_NODES,\n",
    "        max_replica_count=MAX_NODES,\n",
    "    )\n",
    "else:\n",
    "    endpoint = model.deploy(\n",
    "        deployed_model_display_name=DEPLOYED_NAME,\n",
    "        traffic_split=TRAFFIC_SPLIT,\n",
    "        machine_type=DEPLOY_COMPUTE,\n",
    "        accelerator_type=DEPLOY_COMPUTE.name,\n",
    "        accelerator_count=0,\n",
    "        min_replica_count=MIN_NODES,\n",
    "        max_replica_count=MAX_NODES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a7e8daa2350"
   },
   "source": [
    "### 获取服务签名\n",
    "\n",
    "接下来，将模型下载到本地并查询其服务签名。服务签名将采用以下形式：\n",
    "\n",
    "（\"feature_name_1\"，\"feature_name_2\"，...）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23374479e310"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "loaded = tf.saved_model.load(MODEL_DIR + \"/model\")\n",
    "loaded.signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9321a211f2f7"
   },
   "source": [
    "### 进行预测\n",
    "\n",
    "最后，您可以使用 `predict()` 方法进行预测。每个实例都用以下字典格式指定：\n",
    "\n",
    "    { \"feature_name_1\": value, \"feature_name_2\", value, ... }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "625fc7368b65"
   },
   "outputs": [],
   "source": [
    "prediction = endpoint.predict(\n",
    "    [\n",
    "        {\n",
    "            \"Age\": 3,\n",
    "            \"Breed1\": \"Tabby\",\n",
    "            \"Color1\": \"Black\",\n",
    "            \"Color2\": \"White\",\n",
    "            \"Fee\": 100,\n",
    "            \"FurLength\": \"Short\",\n",
    "            \"Gender\": \"Male\",\n",
    "            \"Health\": \"Healthy\",\n",
    "            \"MaturitySize\": \"Small\",\n",
    "            \"PhotoAmt\": 2,\n",
    "            \"Sterilized\": \"No\",\n",
    "            \"Type\": \"Cat\",\n",
    "            \"Vaccinated\": \"No\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9EZvfSUWrxS"
   },
   "source": [
    "超参数调整\n",
    "\n",
    "在成功训练模型、部署模型并调用模型进行预测之后，您可能希望优化模型训练过程中使用的超参数，以提高模型的准确性和性能。请参阅 Vertex AI 文档，了解超参数调整的概述以及如何在您的 Vertex 训练任务中使用它。\n",
    "\n",
    "在这个示例中，以下内容运行了一个 Vertex AI 超参数调整任务，包括 4 次试验，旨在最大化验证 AUC 指标。它优化的超参数是最大步数和学习率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91b2234d636c"
   },
   "source": [
    "### 创建试验配置\n",
    "\n",
    "接下来，您需要构建一个 YAML 文件，其中包含超参数试验设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f45751d3300"
   },
   "outputs": [],
   "source": [
    "config = f\"\"\"studySpec:\n",
    "  metrics:\n",
    "  - metricId: auc\n",
    "    goal: MAXIMIZE\n",
    "  parameters:\n",
    "  - parameterId: max_steps\n",
    "    integerValueSpec:\n",
    "      minValue: 2000\n",
    "      maxValue: 3000\n",
    "  - parameterId: learning_rate\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.0000001\n",
    "      maxValue: 0.1\n",
    "trialJobSpec:\n",
    "  workerPoolSpecs:\n",
    "  - machineSpec:\n",
    "      machineType: {TRAIN_COMPUTE}\n",
    "      acceleratorType: NVIDIA_TESLA_V100\n",
    "      acceleratorCount: 1\n",
    "    replicaCount: 1\n",
    "    diskSpec:\n",
    "      bootDiskType: pd-ssd\n",
    "      bootDiskSizeGb: 100\n",
    "    containerSpec:\n",
    "      imageUri: {TRAIN_IMAGE}\n",
    "      args:\n",
    "      - --preprocess \n",
    "      - --data_has_header\n",
    "      - --training_data_path={TRAINING_DATA_PATH}\n",
    "      - --job-dir={OUTPUT_DIR}\n",
    "      - --batch_size=1028\n",
    "      - --model_type={MODEL_TYPE}\n",
    "      - --prediction_raw_inputs\n",
    "\"\"\"\n",
    "\n",
    "!echo $'{config}' > ./config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dacb3b06fe6b"
   },
   "source": [
    "### 执行超参数调整试验\n",
    "\n",
    "接下来，您可以使用命令`gcloud ai hp-tuning-jobs create`来执行超参数调整作业。\n",
    "\n",
    "作业将异步运行。您可以使用`gcloud ai hp-tuning-jobs describe`来轮询作业的状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8865ecaeaaaa"
   },
   "outputs": [],
   "source": [
    "MAX_TRIAL_COUNT=4\n",
    "PARALLEL_TRIAL_COUNT=2\n",
    "\n",
    "output = ! gcloud ai hp-tuning-jobs create \\\n",
    "  --config=config.yaml \\\n",
    "  --max-trial-count={MAX_TRIAL_COUNT} \\\n",
    "  --parallel-trial-count={PARALLEL_TRIAL_COUNT} \\\n",
    "  --region=$REGION \\\n",
    "  --display-name={DATASET_NAME}\n",
    "\n",
    "print(output)\n",
    "\n",
    "try:\n",
    "    DESCRIBE = output[5]\n",
    "    print(\"Describe cmd:\", DESCRIBE)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e495a6d30fea"
   },
   "source": [
    "取消超参数调整作业\n",
    "\n",
    "接下来，使用命令`gcloud ai hp-tuning-jobs cancel`来取消超参数调整作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2f9aa4f68b92"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    DESCRIBE = output[5]\n",
    "    print(\"Describe cmd:\", DESCRIBE)\n",
    "\n",
    "    args = DESCRIBE.split(\" \")\n",
    "    JOB_ID = args[7]\n",
    "\n",
    "    ! gcloud ai hp-tuning-jobs cancel {JOB_ID} --region={REGION}\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理本项目中使用的所有 Google Cloud 资源，您可以 [删除为本教程使用的 Google Cloud 项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "delete_bucket = False\n",
    "\n",
    "# Delete BQ table\n",
    "! bq rm -f {PROJECT_ID}:{DATASET_NAME}.train\n",
    "\n",
    "try:\n",
    "    endpoint.undeploy_all()\n",
    "    endpoint.delete()\n",
    "    model.delete()\n",
    "    model_bq.delete()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "get_started_with_tabnet.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
