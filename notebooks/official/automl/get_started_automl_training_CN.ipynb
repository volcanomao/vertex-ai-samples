{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "# 使用AutoML训练开始\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/get_started_automl_training.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "        <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/get_started_automl_training.ipynb\">\n",
    "        <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab上运行\n",
    "        </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/automl/get_started_automl_training.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:mlops"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何在生产环境中使用AutoML。本教程涵盖了如何开始进行AutoML训练。\n",
    "\n",
    "了解更多关于[AutoML训练](https://cloud.google.com/vertex-ai/docs/training-overview)的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:mlops,stage2,get_started_automl_training"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用`AutoML`来在`Vertex AI`中进行训练。\n",
    "\n",
    "本教程使用以下谷歌云ML服务：\n",
    "\n",
    "- `AutoML训练`\n",
    "- `Vertex AI数据集`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 训练图像模型\n",
    "- 将图像模型导出为边缘模型\n",
    "- 训练表格模型\n",
    "- 将表格模型导出为云模型\n",
    "- 训练文本模型\n",
    "- 训练视频模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "recommendation:mlops,stage2,automl,training"
   },
   "source": [
    "### 建议\n",
    "\n",
    "在谷歌云上进行端到端的MLOps时，以下是在何时使用AutoML的最佳实践：\n",
    "\n",
    "* **您拥有有限数量的训练数据**\n",
    "\n",
    "* **您希望在尝试自定义模型之前建立一个基准度量**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:flowers,icn"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "#### 图像\n",
    "\n",
    "本教程使用的图像数据集是来自[TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview)的[Flowers数据集](https://www.tensorflow.org/datasets/catalog/tf_flowers)。本教程中的数据集版本存储在一个公共云存储桶中。训练模型可以预测给定图像中的花卉类型，包括五种花卉：雏菊、蒲公英、玫瑰、向日葵或郁金香。\n",
    "\n",
    "#### 表格\n",
    "\n",
    "本教程使用的表格数据集来自[BigQuery公共数据集](https://cloud.google.com/bigquery/public-data)中的GSOD数据集。在本教程中，您仅使用年、月和日字段来预测日均温度值（mean_temp）。\n",
    "\n",
    "#### 文本\n",
    "\n",
    "本教程使用的文本数据集是来自[Kaggle Datasets](https://www.kaggle.com/ritresearch/happydb)的[Happy Moments数据集](https://www.kaggle.com/ritresearch/happydb)。本教程中的数据集版本存储在一个公共云存储桶中。\n",
    "\n",
    "#### 视频\n",
    "\n",
    "本教程使用的视频数据集是来自[MIT](http://cbcl.mit.edu/publications/ps/Kuehne_etal_iccv11.pdf)的[Human Motion数据集](https://todo)中的高尔夫挥杆识别部分。在本教程中，您使用的数据集版本存储在一个公共云存储桶中。训练模型可以预测高尔夫挥杆开始的帧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb3451ce8e47"
   },
   "source": [
    "费用\n",
    "本教程使用谷歌云的计费组件：\n",
    "\n",
    "- Vertex AI\n",
    "- 云存储\n",
    "\n",
    "了解[Vertex AI定价](https://cloud.google.com/vertex-ai/pricing)和[云存储定价](https://cloud.google.com/storage/pricing)，并使用[定价计算器](https://cloud.google.com/products/calculator/)根据您的预计使用量生成费用估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_mlops"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装执行此笔记所需的软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_mlops"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Install the packages\n",
    "\n",
    "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
    "                                 google-cloud-storage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### 仅限 Colab 使用：取消注释以下单元格以重新启动内核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-ZBOjErv5mM"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfEglUHQk9S3"
   },
   "source": [
    "## 开始之前\n",
    "\n",
    "### 设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下方法：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "区域\n",
    "\n",
    "您也可以更改 Vertex AI 使用的 `REGION` 变量。了解有关 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations) 的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 验证您的Google Cloud账户\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动进行身份验证。请按照以下相关指示操作。\n",
    "\n",
    "**1. Vertex AI工作台**\n",
    "* 无需操作，因为您已经进行了身份验证。\n",
    "\n",
    "**2. 本地JupyterLab实例，取消注释并运行:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce6043da7b33"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0367eac06a10"
   },
   "source": [
    "3. 协作，取消注释并运行:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21ad4dbb4a61"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c13224697bfb"
   },
   "source": [
    "请查看如何在 https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples 上为您的服务账号授予云存储权限。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "创建一个存储桶，用于存储中间产物，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有在您的存储桶尚不存在时：运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在教程中使用的变量。\n",
    "### 导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import google.cloud.aiplatform as aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "### 初始化 Vertex AI SDK 用于 Python\n",
    "\n",
    "为您的项目和相应的存储桶初始化 Vertex AI SDK 用于 Python。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "automl_training_intro"
   },
   "source": [
    "## 自动机器学习训练任务\n",
    "\n",
    "自动机器学习可用于自动训练各种图像模型类型。 自动机器学习自动化以下内容：\n",
    "\n",
    "- 数据集预处理\n",
    "- 特征工程\n",
    "- 数据输入\n",
    "- 模型架构选择\n",
    "- 超参数调整\n",
    "- 训练模型\n",
    "\n",
    "了解有关[AutoML用户的Vertex AI](https://cloud.google.com/vertex-ai/docs/start/automl-users)的更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "automl_image_intro"
   },
   "source": [
    "自动机器学习图像模型\n",
    "\n",
    "AutoML 可以训练以下类型的图像模型：\n",
    "\n",
    "- 分类\n",
    "- 目标检测\n",
    "- 分割\n",
    "\n",
    "模型可以训练用于部署到云端，或者导出到边缘设备。\n",
    "\n",
    "了解更多关于[AutoML 模型类型](https://cloud.google.com/vertex-ai/docs/start/automl-model-types)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_preparation:image,u_dataset"
   },
   "source": [
    "### 数据准备\n",
    "\n",
    "对于图像数据，Vertex `Dataset` 资源有一些要求：\n",
    "\n",
    "- 图像必须存储在 Cloud Storage 存储桶中。\n",
    "- 每个图像文件必须是图像格式（PNG、JPEG、BMP 等）。\n",
    "- 在您的 Cloud Storage 存储桶中必须有一个包含每个图像路径和标签的索引文件。\n",
    "- 索引文件必须是 CSV 或 JSONL 格式。\n",
    "\n",
    "了解更多关于[准备图像数据](https://cloud.google.com/vertex-ai/docs/datasets/prepare-image)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_import_format:icn,u_dataset,csv"
   },
   "source": [
    "#### CSV\n",
    "\n",
    "对于图像分类，CSV索引文件有以下要求：\n",
    "\n",
    "- 没有标题。\n",
    "- 第一列是图像的云存储路径。\n",
    "- 第二列是标签。\n",
    "- 任何剩余列都是多标签图像分类的额外标签。\n",
    "\n",
    "对于图像目标检测，CSV索引文件有以下要求：\n",
    "\n",
    "- 没有标题。\n",
    "- 第一列是图像的云存储路径。\n",
    "- 第二列是标签。\n",
    "- 第三/第四列是边界框的左上角。坐标已标准化，介于0和1之间。\n",
    "- 第五/第六/第七列不使用，应为0。\n",
    "- 第八/第九列是边界框的右下角。\n",
    "\n",
    "##### ML_USE\n",
    "\n",
    "每行还可以指定数据项在数据集用于训练时分割时要分配给哪个拆分；否则，数据集将被随机分割：80/10/10。\n",
    "\n",
    "`ml_use`分配是通过在指定分配的列之前添加一列来指定的 - 作为第一列。该值可以是以下之一：训练、测试或验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_import_format:isg,u_dataset,jsonl"
   },
   "source": [
    "#### JSONL\n",
    "\n",
    "对于图像分类，JSONL索引文件具有以下要求：\n",
    "\n",
    "- 每个数据项都是单独的JSON对象，位于单独的一行上。\n",
    "- 键/值对`image_gcs_uri`是图像的Cloud Storage路径。\n",
    "- 键/值对`display_name`是图像的标签。\n",
    "\n",
    "    { 'image_gcs_uri': image, \n",
    "      'classification_annotations': \n",
    "          { 'display_name': label\n",
    "          }\n",
    "    }\n",
    "    \n",
    "对于多标签，标签被指定为`display_name`键/值对的列表：\n",
    "\n",
    "    { 'image_gcs_uri': image, \n",
    "      'classification_annotations': [\n",
    "          { 'display_name': label1\n",
    "          },\n",
    "          { 'display_name': labelN\n",
    "          },\n",
    "       ]\n",
    "    }\n",
    "    \n",
    "对于目标检测，JSONL索引文件具有以下要求：\n",
    "\n",
    "- 每个数据项都是单独的JSON对象，位于单独的一行上。\n",
    "- 键/值对`image_gcs_uri`是图像的Cloud Storage路径。\n",
    "- 键/值对`bounding_box_annotations`是一个列表：\n",
    "    - `display_name`：对象的标签\n",
    "    - `x_min`、`y_min`、`x_max`、`y_max`：边界框的坐标\n",
    "\n",
    "{\n",
    "  \"image_gcs_uri\": image,\n",
    "  \"bounding_box_annotations\": [\n",
    "    {\n",
    "      \"display name\": label,\n",
    "      \"x_min\": \"X_MIN\",\n",
    "      \"y_min\": \"Y_MIN\",\n",
    "      \"x_max\": \"X_MAX\",\n",
    "      \"y_max\": \"Y_MAX\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"displayName\": \"OBJECT2_LABEL\",\n",
    "      \"x_min\": \"X_MIN\",\n",
    "      \"y_min\": \"Y_MIN\",\n",
    "      \"x_max\": \"X_MAX\",\n",
    "      \"y_max\": \"Y_MAX\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "对于图像分割，JSONL索引文件具有以下要求：\n",
    "\n",
    "- 每个数据项都是单独的JSON对象，位于单独的一行上。\n",
    "- 键/值对`image_gcs_uri`是图像的Cloud Storage路径。\n",
    "- 键/值对`category_mask_uri`是PNG格式掩码图像的Cloud Storage路径。\n",
    "- 键/值对`annotation_spec_colors`是将掩码颜色映射到标签的列表。\n",
    "  - 键/值对`display_name`是像素颜色掩码的标签。\n",
    "  - 键/值对`color`是对应标签掩码的RGB标准化像素值（在0和1之间）。\n",
    "\n",
    "    { 'image_gcs_uri': image, \n",
    "      'segmentation_annotations': { 'category_mask_uri': mask_image, 'annotation_spec_colors' : [ \n",
    "          { 'display_name': label, 'color': {\"red\": value, \"blue\": value, \"green\": value} }, ...\n",
    "      ] \n",
    "    }\n",
    "    \n",
    "##### ML_USE\n",
    "\n",
    "每个JSONL对象还可以指定将数据项分配给哪个分割以进行训练；否则，数据集将随机分割为80/10/10。\n",
    "\n",
    "\"data_item_resource_labels\": {\n",
    "      \"aiplatform.googleapis.com/ml_use\": \"training|test|validation\"\n",
    "    }\n",
    "\n",
    "*注*: 字典键字段也可以使用驼峰命名法。例如，'image_gcs_uri'也可以是'imageGcsUri'。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_file:u_dataset,csv"
   },
   "source": [
    "云存储培训数据的位置。\n",
    "\n",
    "现在将变量`IMPORT_FILE`设置为云存储中CSV索引文件的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:flowers,csv,icn"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = (\n",
    "    \"gs://cloud-samples-data/vision/automl_classification/flowers/all_data_v2.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick_peek:csv"
   },
   "source": [
    "#### 快速查看您的数据\n",
    "\n",
    "本教程使用存储在公共云存储桶中的Happy Moments数据集的一个版本，使用CSV索引文件。\n",
    "\n",
    "首先快速查看数据。通过计算CSV索引文件中的行数（`wc -l`）来计算示例的数量，然后查看前几行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quick_peek:csv"
   },
   "outputs": [],
   "source": [
    "FILE = IMPORT_FILE\n",
    "\n",
    "count = ! gsutil cat $FILE | wc -l\n",
    "print(\"Number of Examples\", int(count[0]))\n",
    "\n",
    "print(\"First 10 rows\")\n",
    "! gsutil cat $FILE | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_dataset:image,icn"
   },
   "source": [
    "### 创建数据集\n",
    "\n",
    "接下来，使用`ImageDataset`类的`create`方法为`Dataset`资源创建数据集，需要以下参数：\n",
    "\n",
    "- `display_name`：`Dataset`资源的可读名称。\n",
    "- `gcs_source`：一个或多个数据集索引文件的列表，用于将数据项导入`Dataset`资源。\n",
    "- `import_schema_uri`：数据项的数据标注模式：\n",
    "  - `single_label`：二元和多类分类。\n",
    "  - `multi_label`：多标签多类分类。\n",
    "  - `bounding_box`：目标检测。\n",
    "  - `image_segmentation`：分割。\n",
    "\n",
    "了解更多关于[ImageDataset](https://cloud.google.com/vertex-ai/docs/datasets/prepare-image)的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataset:image,icn"
   },
   "outputs": [],
   "source": [
    "dataset = aiplatform.ImageDataset.create(\n",
    "    display_name=\"flowers\",\n",
    "    gcs_source=[IMPORT_FILE],\n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.image.single_label_classification,\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_automl_pipeline:image,edge,icn"
   },
   "source": [
    "### 创建并运行训练管线\n",
    "\n",
    "要训练AutoML模型，您需要执行两个步骤：1）创建训练管线，2）运行管线。\n",
    "\n",
    "#### 创建训练管线\n",
    "\n",
    "使用`AutoMLImageTrainingJob`类创建AutoML训练管线，需要以下参数：\n",
    "\n",
    "- `display_name`：`TrainingJob`资源的人类可读名称。\n",
    "- `prediction_type`：训练模型的任务类型。\n",
    "  - `classification`：图像分类模型。\n",
    "  - `object_detection`：图像目标检测模型。\n",
    "- `multi_label`：如果是分类任务，指定是单标签（`False`）还是多标签（`True`）。\n",
    "- `model_type`：用于部署的模型类型。\n",
    "  - `CLOUD`：在Google Cloud上部署。\n",
    "  - `CLOUD_HIGH_ACCURACY_1`：在Google Cloud上进行精度优化的部署。\n",
    "  - `CLOUD_LOW_LATENCY_`：在Google Cloud上进行延迟优化的部署。\n",
    "  - `MOBILE_TF_VERSATILE_1`：在边缘设备上部署。\n",
    "  - `MOBILE_TF_HIGH_ACCURACY_1`：在边缘设备上进行精度优化的部署。\n",
    "  - `MOBILE_TF_LOW_LATENCY_1`：在边缘设备上进行延迟优化的部署。\n",
    "- `base_model`：（可选项）从现有`Model`资源进行迁移学习，仅支持图像分类。\n",
    "\n",
    "实例化的对象是训练作业的有向无环图（DAG）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_automl_pipeline:image,edge,icn"
   },
   "outputs": [],
   "source": [
    "dag = aiplatform.AutoMLImageTrainingJob(\n",
    "    display_name=\"flowers\",\n",
    "    prediction_type=\"classification\",\n",
    "    multi_label=False,\n",
    "    model_type=\"MOBILE_TF_LOW_LATENCY_1\",\n",
    "    base_model=None,\n",
    ")\n",
    "\n",
    "print(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_automl_pipeline:image"
   },
   "source": [
    "#### 运行训练流水线\n",
    "\n",
    "接下来，您可以运行创建的DAG来启动训练作业，方法是调用 `run`，并传入以下参数：\n",
    "\n",
    "- `dataset`: 用于训练模型的 `Dataset` 资源。\n",
    "- `model_display_name`: 训练模型的可读名称。\n",
    "- `training_fraction_split`: 用于训练的数据集百分比。\n",
    "- `test_fraction_split`: 用于测试（留存数据）的数据集百分比。\n",
    "- `validation_fraction_split`: 用于验证的数据集百分比。\n",
    "- `budget_milli_node_hours`: （可选）以毫节点小时为单位指定的最大训练时间（1000 = 节点小时）。\n",
    "- `disable_early_stopping`: 如果为 `True`，则训练可能会在服务认为无法进一步改进模型目标测量之前完成，即使预算没有用完。\n",
    "\n",
    "当 `run` 方法完成后将返回 `Model` 资源。\n",
    "\n",
    "训练流水线的执行将需要超过 30 分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3eaba926cdfa"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING\"):\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_automl_pipeline:image"
   },
   "outputs": [],
   "source": [
    "model = dag.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"flowers\",\n",
    "    training_fraction_split=0.8,\n",
    "    validation_fraction_split=0.1,\n",
    "    test_fraction_split=0.1,\n",
    "    budget_milli_node_hours=8000,\n",
    "    disable_early_stopping=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "source": [
    "## 回顾模型评估分数\n",
    "\n",
    "在您的模型训练完成之后，您可以使用`list_model_evaluations()`方法回顾模型的评估分数。该方法将返回每个评估切片的迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "model_evaluations = model.list_model_evaluations()\n",
    "\n",
    "for model_evaluation in model_evaluations:\n",
    "    print(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:mbsdk,automatic"
   },
   "source": [
    "## 部署模型\n",
    "\n",
    "接下来，部署您的模型进行在线预测。要部署模型，您需要调用 `deploy` 方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy_model:mbsdk,automatic"
   },
   "outputs": [],
   "source": [
    "endpoint = model.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_prediction"
   },
   "source": [
    "发送一个在线预测请求\n",
    "\n",
    "向部署的模型发送在线预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_test_item"
   },
   "source": [
    "获取测试项目\n",
    "\n",
    "您将从数据集中随意选择一个示例作为测试项目。不必担心该示例很可能在训练模型时使用过。您只是在看如何进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_test_item:automl,icn,csv"
   },
   "outputs": [],
   "source": [
    "test_item = !gsutil cat $IMPORT_FILE | head -n1\n",
    "if len(str(test_item[0]).split(\",\")) == 3:\n",
    "    _, test_item, test_label = str(test_item[0]).split(\",\")\n",
    "else:\n",
    "    test_item, test_label = str(test_item[0]).split(\",\")\n",
    "\n",
    "print(test_item, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "predict_request:mbsdk,icn"
   },
   "source": [
    "### 进行预测\n",
    "\n",
    "现在您的 `Model` 资源已部署到 `Endpoint` 资源，您可以通过将预测请求发送到 Endpoint 资源进行在线预测。\n",
    "\n",
    "#### 请求\n",
    "\n",
    "在此示例中，由于您的测试项目位于公共 Cloud 存储桶中，您需要将其复制到您的存储桶中，并使用 `Cloud 存储 SDK` 读取图像的内容。为了将测试数据传递给预测服务，您需要将字节编码为 base64，这样可以使内容在通过网络传输二进制数据时安全免受修改。\n",
    "\n",
    "每个实例的格式为：\n",
    "\n",
    "    { 'content': { 'b64': base64编码的字节 } }\n",
    "\n",
    "由于 `predict()` 方法可以接受多个项目（实例），请将您的单个测试项目作为一个测试项目列表发送。\n",
    "\n",
    "#### 响应\n",
    "\n",
    "`predict()` 调用的响应是一个 Python 字典，具有以下条目：\n",
    "\n",
    "- `ids`：每个预测请求的内部分配的唯一标识符。\n",
    "- `displayNames`：每个类别标签的类名称。\n",
    "- `confidences`：每个类别标签的预测置信度，介于 0 和 1 之间。\n",
    "- `deployed_model_id`：执行预测的部署的 Model 资源的 Vertex AI 标识符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1c1d53e89beb"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "# Copy the test image to the Cloud storage bucket as \"test.jpg\"\n",
    "test_image_local = \"{}/test.jpg\".format(BUCKET_URI)\n",
    "! gsutil cp $test_item $test_image_local\n",
    "\n",
    "# Download the test image in bytes format\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "bucket = storage_client.bucket(bucket_name=BUCKET_URI[5:])\n",
    "test_content = bucket.get_blob(\"test.jpg\").download_as_bytes()\n",
    "\n",
    "# The format of each instance should conform to the deployed model's prediction input schema.\n",
    "instances = [{\"content\": base64.b64encode(test_content).decode(\"utf-8\")}]\n",
    "\n",
    "prediction = endpoint.predict(instances=instances)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b1b67898533"
   },
   "source": [
    "另一种方法是使用[GFile](https://www.tensorflow.org/api_docs/python/tf/io/gfile/GFile)。另外，可以使用来自tensorflow-io库的[GFile](https://www.tensorflow.org/api_docs/python/tf/io/gfile/GFile)方法直接从云存储中读取数据。以下代码片段执行相同的操作：\n",
    "\n",
    "```\n",
    "import base64\n",
    "import tensorflow as tf\n",
    "\n",
    "# 使用GFile读取测试文件\n",
    "with tf.io.gfile.GFile(test_item, \"rb\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# 每个实例的格式应符合部署模型的预测输入模式。\n",
    "instances = [{\"content\": base64.b64encode(content).decode(\"utf-8\")}]\n",
    "\n",
    "prediction = endpoint.predict(instances=instances)\n",
    "\n",
    "print(prediction)\n",
    "```\n",
    "然而，`tf.io.gfile.GFile`支持多个文件系统实现，包括本地文件、Google Cloud Storage（使用gs://前缀）和HDFS（使用hdfs://前缀）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "source": [
    "取消部署模型\n",
    "\n",
    "当您完成预测后，您可以从“端点”资源中取消部署模型。这将取消所有计算资源，并停止对部署模型的计费。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export_model:mbsdk,image"
   },
   "source": [
    "将模型导出为Edge模型\n",
    "\n",
    "您可以将AutoML云模型导出为`Edge`模型，然后可以自定义部署到边缘设备或本地下载。使用方法`export_model()`将模型导出到Cloud Storage，这需要以下参数：\n",
    "\n",
    "- `artifact_destination`：用于存储SavedFormat模型工件的Cloud Storage位置。\n",
    "- `export_format_id`：要保存模型格式的格式。对于AutoML云，只有一个选项：\n",
    "   - `tf-saved-model`：用于部署到容器的TensorFlow SavedFormat。\n",
    "   - `tflite`：用于部署到边缘或移动设备的TensorFlow Lite。\n",
    "   - `edgetpu-tflite`：用于TPU的TensorFlow Lite。\n",
    "   - `tf-js`：用于Web客户端的TensorFlow。\n",
    "   - `coral-ml`：用于Coral设备。\n",
    "\n",
    "- `sync`：是否同步或异步执行操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_model:mbsdk,image"
   },
   "outputs": [],
   "source": [
    "response = model.export_model(\n",
    "    artifact_destination=BUCKET_URI, export_format_id=\"tflite\", sync=True\n",
    ")\n",
    "\n",
    "model_package = response[\"artifactOutputUri\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "source": [
    "删除模型\n",
    "\n",
    "方法'delete()'将删除模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "source": [
    "删除数据集\n",
    "\n",
    "方法'delete()'将删除数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "dataset.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "source": [
    "删除终端点\n",
    "\n",
    "'delete（）'方法将删除终端点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "automl_tabular_intro"
   },
   "source": [
    "AutoML表格模型\n",
    "\n",
    "AutoML可以训练以下类型的表格模型：\n",
    "\n",
    "- 分类\n",
    "- 回归\n",
    "- 预测\n",
    "\n",
    "模型可以被训练以自动部署到云端，也可以被导出以手动部署到云端。\n",
    "\n",
    "了解更多关于[AutoML模型类型](https://cloud.google.com/vertex-ai/docs/start/automl-model-types)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_preparation:tabular,u_dataset"
   },
   "source": [
    "### 数据准备\n",
    "\n",
    "Vertex AI 的 `Dataset` 资源适用于表格数据，并对您的表格数据有一些要求。\n",
    "\n",
    "- 必须保存在 CSV 文件或 BigQuery 表格中。\n",
    "\n",
    "了解更多关于 [准备表格数据](https://cloud.google.com/vertex-ai/docs/datasets/prepare-tabular)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_import_format:lbn,u_dataset,csv"
   },
   "source": [
    "#### CSV\n",
    "\n",
    "对于表格模型，CSV 文件有一些要求：\n",
    "\n",
    "- 第一行必须是标题行 -- 请注意这与图像、文本和视频不同，这些要求是没有标题行。\n",
    "- 除了一列外，所有列都是特征。\n",
    "- 一列是标签，您将在随后创建训练流程时指定。\n",
    "\n",
    "##### ML_USE\n",
    "\n",
    "每一行还可以指定在数据集为训练集分割时分配给数据项的分割；否则，数据集将被随机分割：80/10/10。\n",
    "\n",
    "`ml_use` 分配通过在第一列之前添加一个列来指定分配方式。该值可以是：训练、测试或验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_file:u_dataset,bq"
   },
   "source": [
    "BigQuery培训数据的位置。\n",
    "\n",
    "现在将变量 `IMPORT_FILE` 设置为BigQuery中数据表的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:gsod,bq,lrg"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = \"bq://bigquery-public-data.samples.gsod\"\n",
    "BQ_TABLE = \"bigquery-public-data.samples.gsod\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_dataset:tabular,bq,lrg"
   },
   "source": [
    "### 创建数据集\n",
    "\n",
    "#### BigQuery输入数据\n",
    "\n",
    "接下来，使用`TabularDataset`类的`create`方法创建`Dataset`资源，该方法接受以下参数：\n",
    "\n",
    "- `display_name`：`Dataset`资源的可读名称。\n",
    "- `bq_source`：将数据项从BigQuery表导入到`Dataset`资源中。\n",
    "- `labels`：用户定义的元数据。在这个例子中，您存储包含用户定义数据的Cloud Storage存储桶的位置。\n",
    "\n",
    "了解更多关于[从BigQuery表创建TabularDataset](https://cloud.google.com/vertex-ai/docs/datasets/create-dataset-api#aiplatform_create_dataset_tabular_bigquery_sample-python)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataset:tabular,bq,lrg"
   },
   "outputs": [],
   "source": [
    "dataset = aiplatform.TabularDataset.create(\n",
    "    display_name=\"gsod\",\n",
    "    bq_source=[IMPORT_FILE],\n",
    "    labels={\"user_metadata\": BUCKET_URI[5:]},\n",
    ")\n",
    "\n",
    "label_column = \"mean_temp\"\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_transformations:gsod"
   },
   "outputs": [],
   "source": [
    "TRANSFORMATIONS = [\n",
    "    {\"auto\": {\"column_name\": \"year\"}},\n",
    "    {\"auto\": {\"column_name\": \"month\"}},\n",
    "    {\"auto\": {\"column_name\": \"day\"}},\n",
    "]\n",
    "\n",
    "label_column = \"mean_temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_automl_pipeline:tabular,lrg,transformations"
   },
   "source": [
    "### 创建并运行训练管道\n",
    "\n",
    "要训练一个AutoML模型，您需要执行两个步骤：1）创建一个训练管道，2）运行该管道。\n",
    "\n",
    "#### 创建训练管道\n",
    "\n",
    "使用`AutoMLTabularTrainingJob`类创建一个AutoML训练管道，包括以下参数：\n",
    "\n",
    "- `display_name`：`TrainingJob`资源的人类可读名称。\n",
    "- `optimization_prediction_type`：要为模型训练的任务类型。\n",
    "  - `classification`：一个表格分类模型。\n",
    "  - `regression`：一个表格回归模型。\n",
    "- `column_transformations`：（可选）要应用于输入列的转换。\n",
    "- `optimization_objective`：要最小化或最大化的优化目标。\n",
    "  - 二元分类：\n",
    "    - `minimize-log-loss`\n",
    "    - `maximize-au-roc`\n",
    "    - `maximize-au-prc`\n",
    "    - `maximize-precision-at-recall`\n",
    "    - `maximize-recall-at-precision`\n",
    "  - 多类分类：\n",
    "    - `minimize-log-loss`\n",
    "  - 回归：\n",
    "    - `minimize-rmse`\n",
    "    - `minimize-mae`\n",
    "    - `minimize-rmsle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_automl_pipeline:tabular,lrg,transformations"
   },
   "outputs": [],
   "source": [
    "dag = aiplatform.AutoMLTabularTrainingJob(\n",
    "    display_name=\"gsod\",\n",
    "    optimization_prediction_type=\"regression\",\n",
    "    optimization_objective=\"minimize-rmse\",\n",
    "    column_transformations=TRANSFORMATIONS,\n",
    ")\n",
    "\n",
    "print(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_automl_pipeline:tabular"
   },
   "source": [
    "运行训练流水线\n",
    "\n",
    "接下来，您可以通过调用`run`方法以以下参数来运行已创建的DAG以启动训练作业：\n",
    "\n",
    "- `dataset`: 用于训练模型的`Dataset`资源。\n",
    "- `model_display_name`: 受训模型的易理解名称。\n",
    "- `training_fraction_split`: 用于训练的数据集百分比。\n",
    "- `test_fraction_split`: 用于测试（保留数据）的数据集百分比。\n",
    "- `validation_fraction_split`: 用于验证的数据集百分比。\n",
    "- `target_column`: 要作为标签训练的列名。\n",
    "- `budget_milli_node_hours`: （可选）以毫小时为单位指定的最大训练时间（1000 = 小时）。\n",
    "- `disable_early_stopping`: 若为`True`，服务可能认为在整体预算内无法进一步提高模型目标指标时，训练可能会在使用整体预算前完成。\n",
    "\n",
    "完成`run`方法将返回`Model`资源。\n",
    "\n",
    "训练流水线的执行将需时 >30分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_automl_pipeline:tabular"
   },
   "outputs": [],
   "source": [
    "model = dag.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"gsod\",\n",
    "    training_fraction_split=0.8,\n",
    "    validation_fraction_split=0.1,\n",
    "    test_fraction_split=0.1,\n",
    "    budget_milli_node_hours=8000,\n",
    "    disable_early_stopping=False,\n",
    "    target_column=\"mean_temp\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "source": [
    "## 回顾模型评估分数\n",
    "\n",
    "在模型训练完成后，您可以使用`list_model_evaluations()`方法来查看模型的评估分数。这个方法将为每个评估切片返回一个迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "model_evaluations = model.list_model_evaluations()\n",
    "\n",
    "for model_evaluation in model_evaluations:\n",
    "    print(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:mbsdk,dedicated"
   },
   "source": [
    "## 部署模型\n",
    "\n",
    "接下来，为在线预测部署您的模型。要部署模型，您可以调用`deploy`方法，并使用以下参数：\n",
    "\n",
    "- `machine_type`：计算机类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy_model:mbsdk,dedicated"
   },
   "outputs": [],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "source": [
    "### 取消部署模型\n",
    "\n",
    "当您完成预测时，您可以从`Endpoint`资源中取消部署模型。这会取消所有计算资源，并停止部署模型的计费。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export_model:mbsdk,tabular"
   },
   "source": [
    "## 导出为云模型\n",
    "\n",
    "您可以将AutoML云模型导出为TensorFlow SavedFormat模型，然后可以自定义部署到云存储或本地下载。使用方法`export_model()`将模型导出到云存储，该方法接受以下参数：\n",
    "\n",
    "- `artifact_destination`：用于存储SavedFormat模型工件的云存储位置。\n",
    "- `export_format_id`：要保存模型格式为的格式。对于AutoML云，只有一个选项：\n",
    "   - `tf-saved-model`：TensorFlow SavedFormat\n",
    "- `sync`：是否同步或异步执行操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_model:mbsdk,tabular"
   },
   "outputs": [],
   "source": [
    "response = model.export_model(\n",
    "    artifact_destination=BUCKET_URI, export_format_id=\"tf-saved-model\", sync=True\n",
    ")\n",
    "\n",
    "model_package = response[\"artifactOutputUri\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "source": [
    "删除模型\n",
    "\n",
    "方法'delete()'将删除这个模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "source": [
    "删除数据集\n",
    "\n",
    "方法'delete（）'将删除数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "dataset.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "source": [
    "删除端点\n",
    "\n",
    "方法'delete()'将删除端点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "automl_text_intro"
   },
   "source": [
    "## AutoML 文本模型\n",
    "\n",
    "AutoML 可以训练以下类型的文本模型：\n",
    "\n",
    "- 分类\n",
    "- 情感分析\n",
    "- 实体提取\n",
    "\n",
    "了解更多关于[AutoML 模型类型](https://cloud.google.com/vertex-ai/docs/start/automl-model-types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_preparation:text,u_dataset"
   },
   "source": [
    "数据准备\n",
    "\n",
    "Vertex AI的文本“数据集”资源对您的文本数据有一些要求。\n",
    "\n",
    "- 文本示例必须存储在CSV或JSONL文件中。\n",
    "\n",
    "了解更多关于[准备文本数据](https://cloud.google.com/vertex-ai/docs/datasets/prepare-text)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_import_format:tcn,u_dataset,csv"
   },
   "source": [
    "#### CSV\n",
    "\n",
    "对于文本分类，CSV文件有一些要求：\n",
    "\n",
    "- 没有标题。\n",
    "- 第一列是文本示例或云存储路径到文本文件（.txt后缀）。\n",
    "- 第二列是标签。\n",
    "- 任何剩余列都是用于多标签文本分类的其他标签。\n",
    "\n",
    "对于文本情感分析，CSV文件有一些要求：\n",
    "\n",
    "- 没有标题。\n",
    "- 第一列是文本示例或云存储路径到文本文件（.txt后缀）。\n",
    "- 第二列是情感值。\n",
    "- 第三列是最大可能的情感值。\n",
    "\n",
    "##### ML_USE\n",
    "\n",
    "每行还可以指定在数据集进行训练拆分时将数据项分配给哪个拆分；否则，数据集将被随机分割：80/10/10。\n",
    "\n",
    "`ml_use` 分配是通过在第一列前加一个列来指定的。 可能的值是：训练、测试或验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "766c838de8a0"
   },
   "source": [
    "#### JSONL\n",
    "\n",
    "对于文本分类，JSONL文件有一些要求：\n",
    "\n",
    "- 每个数据项是一个单独的JSON对象，在单独的一行上。\n",
    "- 键/值对`text_gcs_uri`是文本文件的云存储路径。\n",
    "- 键/值对`text_content`是指定内联文本的备用方式。\n",
    "- 键/值对`display_name`是文本的标签。\n",
    "\n",
    "{\n",
    "  \"classification_annotation\": {\n",
    "    \"display_name\": label\n",
    "  },\n",
    "  \"text_content\": text\n",
    "}\n",
    "{\n",
    "  \"classification_annotation\": {\n",
    "    \"display_name\": label\n",
    "  },\n",
    "  \"text_gcs_uri\": \"gcs_uri_to_file\"\n",
    "}\n",
    "\n",
    "对于多标签，标签被指定为一个`display_name`键/值对的列表：\n",
    "\n",
    "       'classification_annotations': [\n",
    "          { 'display_name': label1\n",
    "          },\n",
    "          { 'display_name': labelN\n",
    "          },\n",
    "       ]\n",
    "\n",
    "对于文本情感分析，JSONL文件有一些要求：\n",
    "\n",
    "- 每个数据项是一个单独的JSON对象，在单独的一行上。\n",
    "- 键/值对`text_gcs_uri`是文本文件的云存储路径。\n",
    "- 键/值对`text_content`是指定内联文本的备用方式。\n",
    "- 键/值对`sentiment`是情感值，为大于0的整数值。\n",
    "- 键/值对`sentiment_max`是情感的最大可能值。\n",
    "\n",
    "{\n",
    "  \"sentiment_annotation\": {\n",
    "    \"sentiment\": number,\n",
    "    \"sentiment_max\": number\n",
    "  },\n",
    "  \"text_content\": text,\n",
    "}\n",
    "{\n",
    "  \"sentiment_annotation\": {\n",
    "    \"sentiment\": number,\n",
    "    \"sentiment_max\": number\n",
    "  },\n",
    "  \"text_gcs_uri\": \"gcs_uri_to_file\"\n",
    "}\n",
    "\n",
    "对于文本实体提取，JSONL文件有一些要求：\n",
    "\n",
    "- 每个数据项是一个单独的JSON对象，在单独的一行上。\n",
    "- 键/值对`text_gcs_uri`是文本文件的云存储路径。\n",
    "- 键/值对`text_content`是指定内联文本的备用方式。\n",
    "- 键/值对`start_offset`是文本起始的字符偏移量。\n",
    "- 键/值对`end_offset`是文本结束的字符偏移量。\n",
    "- 键/值对`display_name`是文本的标签。\n",
    "\n",
    "{\n",
    "    \"text_segment_annotations\": [\n",
    "      {\n",
    "        \"start_offset\":number,\n",
    "        \"end_offset\":number,\n",
    "        \"display_name\": label\n",
    "      },\n",
    "      ...\n",
    "    ],\n",
    "    \"textContent\": \"inline_text\"\n",
    "}\n",
    "{\n",
    "    \"textSegmentAnnotations\": [\n",
    "      {\n",
    "        \"start_offset\": number,\n",
    "        \"end_offset\": number,\n",
    "        \"displayName\": label\n",
    "      },\n",
    "      ...\n",
    "    ],\n",
    "    \"text_gcs_uri\": \"gcs_uri_to_file\"\n",
    "}\n",
    "\n",
    "##### ML_USE\n",
    "\n",
    "每个JSONL对象还可以额外指定将数据项分配给哪个拆分项，当数据集被拆分用于训练时；否则，数据集将被随机分割为80/10/10。\n",
    "\n",
    "\"data_item_resource_labels\": {\n",
    "      \"aiplatform.googleapis.com/ml_use\": \"training|test|validation\"\n",
    "    }\n",
    "\n",
    "*注意*：字典键字段也可以使用驼峰命名法。例如，'text_gcs_uri'也可以是'textGcsUri'。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_file:u_dataset,csv"
   },
   "source": [
    "云存储训练数据的位置。\n",
    "\n",
    "现在将变量`IMPORT_FILE`设置为云存储中CSV索引文件的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:happydb,csv,tcn"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = \"gs://cloud-ml-data/NL-classification/happiness.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick_peek:csv"
   },
   "source": [
    "快速查看您的数据\n",
    "\n",
    "本教程使用存储在公共云存储桶中的快乐时刻数据集的一个版本，使用一个CSV索引文件。\n",
    "\n",
    "首先快速查看数据。通过计算CSV索引文件中的行数（`wc -l`）来统计示例的数量，然后查看前几行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quick_peek:csv"
   },
   "outputs": [],
   "source": [
    "FILE = IMPORT_FILE\n",
    "\n",
    "count = ! gsutil cat $FILE | wc -l\n",
    "print(\"Number of Examples\", int(count[0]))\n",
    "\n",
    "print(\"First 10 rows\")\n",
    "! gsutil cat $FILE | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_dataset:text,tcn"
   },
   "source": [
    "### 创建数据集\n",
    "\n",
    "接下来，使用`TextDataset`类的`create`方法为`Dataset`资源创建数据集，需要以下参数：\n",
    "\n",
    "- `display_name`：`Dataset`资源的可读名称。\n",
    "- `gcs_source`：一个或多个数据集索引文件的列表，用于将数据项导入`Dataset`资源。\n",
    "- `import_schema_uri`：数据项的数据标记模式。\n",
    "  - `single_label`：二元和多类分类\n",
    "  - `multi_label`：多标签多类分类\n",
    "  - `sentiment`：情感分析\n",
    "  - `extraction`：实体提取\n",
    "\n",
    "了解更多关于[TextDataset](https://cloud.google.com/vertex-ai/docs/datasets/prepare-text)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataset:text,tcn"
   },
   "outputs": [],
   "source": [
    "dataset = aiplatform.TextDataset.create(\n",
    "    display_name=\"happydb\",\n",
    "    gcs_source=[IMPORT_FILE],\n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.text.single_label_classification,\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_automl_pipeline:text,tcn"
   },
   "source": [
    "### 创建和运行训练流程\n",
    "\n",
    "要训练一个AutoML模型，您需要执行两个步骤：1) 创建一个训练流程，2) 运行这个流程。\n",
    "\n",
    "#### 创建训练流程\n",
    "\n",
    "使用`AutoMLTextTrainingJob`类创建一个AutoML训练流程，需要以下参数：\n",
    "\n",
    "- `display_name`: `TrainingJob`资源的可读名称。\n",
    "- `prediction_type`: 为模型训练指定的任务类型。\n",
    "  - `classification`: 文本分类模型。\n",
    "  - `sentiment`: 文本情感分析模型。\n",
    "  - `extraction`: 文本实体提取模型。\n",
    "- `multi_label`: 如果是分类任务，指定是否是单标签(False)或多标签(True)。\n",
    "- `sentiment_max`: 如果是情感分析任务，指定最大情感值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_automl_pipeline:text,tcn"
   },
   "outputs": [],
   "source": [
    "dag = aiplatform.AutoMLTextTrainingJob(\n",
    "    display_name=\"happydb\",\n",
    "    prediction_type=\"classification\",\n",
    "    multi_label=False,\n",
    ")\n",
    "\n",
    "print(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_automl_pipeline:text"
   },
   "source": [
    "#### 运行训练流程\n",
    "\n",
    "接下来，您可以运行已创建的DAG来启动训练作业，方法是调用`run`方法，使用以下参数：\n",
    "\n",
    "- `dataset`：用于训练模型的`Dataset`资源。\n",
    "- `model_display_name`：经过训练的模型的人类可读名称。\n",
    "- `training_fraction_split`：用于训练的数据集的百分比。\n",
    "- `test_fraction_split`：用于测试（留出数据）的数据集的百分比。\n",
    "- `validation_fraction_split`：用于验证的数据集的百分比。\n",
    "\n",
    "当`run`方法完成时，将返回`Model`资源。\n",
    "\n",
    "训练流程的执行时间可能长达> 30分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_automl_pipeline:text"
   },
   "outputs": [],
   "source": [
    "model = dag.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"happydb\",\n",
    "    training_fraction_split=0.8,\n",
    "    validation_fraction_split=0.1,\n",
    "    test_fraction_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "source": [
    "## 查看模型评估分数\n",
    "\n",
    "在模型训练完成后，您可以使用`list_model_evaluations()`方法来查看模型的评估分数。该方法将返回每个评估切片的迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "model_evaluations = model.list_model_evaluations()\n",
    "\n",
    "for model_evaluation in model_evaluations:\n",
    "    print(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:mbsdk,automatic"
   },
   "source": [
    "部署模型\n",
    "\n",
    "接下来，部署您的模型以进行在线预测。要部署模型，您需要调用`deploy`方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy_model:mbsdk,automatic"
   },
   "outputs": [],
   "source": [
    "endpoint = model.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "source": [
    "取消模型部署\n",
    "\n",
    "当您完成预测时，您会从`Endpoint`资源中取消部署模型。这将取消所有计算资源并结束对部署模型的计费。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "source": [
    "#### 删除模型\n",
    "\n",
    "方法'delete()'将删除模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "source": [
    "删除数据集\n",
    "\n",
    "方法 'delete()' 将会删除数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "dataset.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "source": [
    "#### 删除端点\n",
    "\n",
    "方法 'delete()' 将删除端点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "endpoint_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "endpoint.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "automl_video_intro"
   },
   "source": [
    "## 自动ML视频模型\n",
    "\n",
    "自动ML可以训练以下类型的视频模型：\n",
    "\n",
    "- 分类\n",
    "- 目标跟踪\n",
    "- 动作识别\n",
    "\n",
    "模型可以被训练用于部署至云端，也可以导出到边缘设备。\n",
    "\n",
    "了解更多关于[AutoML模型类型](https://cloud.google.com/vertex-ai/docs/start/automl-model-types)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_preparation:text,u_dataset"
   },
   "source": [
    "### 数据准备\n",
    "\n",
    "针对文本的 Vertex AI `Dataset` 资源有一些关于您的文本数据的要求。\n",
    "\n",
    "- 文本示例必须存储在 CSV 或 JSONL 文件中。\n",
    "\n",
    "了解有关[准备视频数据](https://cloud.google.com/vertex-ai/docs/datasets/prepare-video)的更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "427212b48840"
   },
   "source": [
    "CSV\n",
    "\n",
    "对于视频分类，CSV文件有一些要求：\n",
    "\n",
    "- 没有标题。\n",
    "- 第一列是视频文件在云存储中的路径。\n",
    "- 第二列是标签。\n",
    "- 第三列是要分类的视频中的开始时间（秒）。\n",
    "- 第四列是要分类的视频中的结束时间（秒）。\n",
    "\n",
    "对于多标签分类，每个标签都是单独的行条目。\n",
    "\n",
    "对于视频目标追踪，CSV文件有一些要求：\n",
    "\n",
    "- 没有标题。\n",
    "- 第一列是视频文件在云存储中的路径。\n",
    "- 第二列是标签。\n",
    "- 第三列为空（空白）。\n",
    "- 第四列是在视频中开始跟踪对象的时间（秒）。\n",
    "- 第五到第八列是要追踪的对象的顶点。\n",
    "    - x_min\n",
    "    - y_min\n",
    "    - x_max\n",
    "    - y_max\n",
    "    \n",
    "对于动作识别，CSV文件有一些要求：\n",
    "\n",
    "- 没有标题。\n",
    "- 每行可以是以下四种格式之一：\n",
    "\n",
    "VIDEO_URI, TIME_SEGMENT_START, TIME_SEGMENT_END, LABEL, ANNOTATION_FRAME_TIMESTAMP\n",
    "\n",
    "VIDEO_URI, , , LABEL, ANNOTATION_FRAME_TIMESTAMP\n",
    "\n",
    "VIDEO_URI, TIME_SEGMENT_START, TIME_SEGMENT_END, LABEL, ANNOTATION_SEGMENT_START, ANNOTATION_SEGMENT_END\n",
    "\n",
    "VIDEO_URI, , , LABEL, ANNOTATION_SEGMENT_START, ANNOTATION_SEGMENT_END\n",
    "\n",
    "\n",
    "ML_USE\n",
    "\n",
    "每行还可以指定将数据项分配给哪个拆分当数据集分割用于训练；否则，数据集将被随机分割：80/10/10。\n",
    "\n",
    "ml_use分配通过在指定分配的列前添加一个列来指定。该值可以是以下之一：training，或test。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "461301339727"
   },
   "source": [
    "JSONL\n",
    "\n",
    "对于视频分类，CSV文件有一些要求：\n",
    "\n",
    "- 每个数据项是一个单独的JSON对象，放在单独的一行上。\n",
    "- 键/值对`video_gcs_uri`是文本文件的云存储路径。\n",
    "- 键/值对`display_name`是文本的标签。\n",
    "- 键/值对`start_time`是用于分类的开始时间（秒）。\n",
    "- 键/值对`end_time`是用于分类的结束时间（秒）。\n",
    "\n",
    "\n",
    "    {\n",
    "        \"video_gcs_uri\": video,\n",
    "        \"time_segment_annotations\": [{\n",
    "            \"display_name\": label,\n",
    "            \"start_time\": \"segment的开始时间\",\n",
    "            \"end_time\": \"segment的结束时间\"\n",
    "        }]\n",
    "    }\n",
    "\n",
    "对于视频对象跟踪，CSV文件有一些要求：\n",
    "\n",
    "- 每个数据项是一个单独的JSON对象，放在单独的一行上。\n",
    "- 键/值对`video_gcs_uri`是文本文件的云存储路径。\n",
    "\n",
    "    {\n",
    "        \"video_gcs_uri\": video,\n",
    "        \"temporal_bounding_box_annotations\": [{\n",
    "            \"display_name\": label,\n",
    "            \"x_min\": \"边界框的最左坐标\",\n",
    "            \"x_max\": \"边界框的最右坐标\",\n",
    "            \"y_min\": \"边界框的最上坐标\",\n",
    "            \"y_max\": \"边界框的最下坐标\",\n",
    "            \"time_offset\": \"检测到对象的时间帧\"\n",
    "        }]\n",
    "    }\n",
    "\n",
    "对于视频动作识别，CSV文件有一些要求：\n",
    "\n",
    "- 每个数据项是一个单独的JSON对象，放在单独的一行上。\n",
    "- 键/值对`video_gcs_uri`是文本文件的云存储路径。\n",
    "\n",
    "    {\n",
    "        \"video_gcs_uri': video,\n",
    "        \"time_segments\": [{\n",
    "          \"start_time\": \"完全注释段的开始时间\",\n",
    "          \"end_time\": \"段的结束时间\"}],\n",
    "        \"time_segment_annotations\": [{\n",
    "          \"display_name\": label,\n",
    "          \"start_time\": \"段的开始时间\",\n",
    "          \"end_time\": \"段的结束时间\"\n",
    "        }]\n",
    "    }\n",
    "\n",
    "ML_USE\n",
    "\n",
    "每个JSONL对象还可以指定将数据项分配给哪个拆分集，以用于训练；否则，数据集将被随机拆分：80/20。\n",
    "\n",
    "\"data_item_resource_labels\": {\n",
    "      \"aiplatform.googleapis.com/ml_use\": \"training|test\"\n",
    "    }\n",
    "\n",
    "*注意*：字典键字段也可以使用驼峰命名法。例如，'video_gcs_uri'也可以是'videoGcsUri'。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_file:u_dataset,csv"
   },
   "source": [
    "#### 云存储训练数据的位置。\n",
    "\n",
    "现在将变量`IMPORT_FILE`设置为在云存储中CSV索引文件的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:hmdb,csv,vcn"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = \"gs://automl-video-demo-data/hmdb_split1_5classes_train_inf.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick_peek:csv"
   },
   "source": [
    "快速查看您的数据\n",
    "\n",
    "本教程使用存储在公共云存储桶中的Happy Moments数据集的一个版本，使用CSV索引文件。\n",
    "\n",
    "首先快速查看数据。通过在CSV索引文件中计算行数（`wc -l`）来计算示例数量，然后查看前几行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quick_peek:csv"
   },
   "outputs": [],
   "source": [
    "FILE = IMPORT_FILE\n",
    "\n",
    "count = ! gsutil cat $FILE | wc -l\n",
    "print(\"Number of Examples\", int(count[0]))\n",
    "\n",
    "print(\"First 10 rows\")\n",
    "! gsutil cat $FILE | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_dataset:video,vcn"
   },
   "source": [
    "### 创建数据集\n",
    "\n",
    "接下来，使用`VideoDataset`类的`create`方法创建`Dataset`资源，该方法接受以下参数：\n",
    "\n",
    "- `display_name`：`Dataset`资源的人类可读名称。\n",
    "- `gcs_source`：要将数据项导入到`Dataset`资源中的一个或多个数据集索引文件列表。\n",
    "- `import_schema_uri`：数据项的数据标记模式。\n",
    "  - `classification`：二元和多类分类\n",
    "  - `object_tracking`：目标跟踪\n",
    "  - `action_recognition`：动作识别\n",
    "\n",
    "了解更多关于[VideoDataset](https://cloud.google.com/vertex-ai/docs/datasets/prepare-video)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataset:video,vcn"
   },
   "outputs": [],
   "source": [
    "dataset = aiplatform.VideoDataset.create(\n",
    "    display_name=\"human_motion\",\n",
    "    gcs_source=[IMPORT_FILE],\n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.video.classification,\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_automl_pipeline:video,vcn"
   },
   "source": [
    "### 创建并运行训练管道\n",
    "\n",
    "要训练一个AutoML模型，您需要执行两个步骤：1）创建一个训练管道，以及2）运行管道。\n",
    "\n",
    "#### 创建训练管道\n",
    "\n",
    "使用`AutoMLVideoTrainingJob`类创建一个AutoML训练管道，包括以下参数：\n",
    "\n",
    "- `display_name`：`TrainingJob`资源的人类可读名称。\n",
    "- `prediction_type`：为模型训练指定的任务类型。\n",
    "  - `classification`：视频分类模型。\n",
    "  - `object_tracking`：视频目标追踪模型。\n",
    "  - `action_recognition`：视频动作识别模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_automl_pipeline:video,vcn"
   },
   "outputs": [],
   "source": [
    "dag = aiplatform.AutoMLVideoTrainingJob(\n",
    "    display_name=\"human_motion\",\n",
    "    prediction_type=\"classification\",\n",
    ")\n",
    "\n",
    "print(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_automl_pipeline:video"
   },
   "source": [
    "运行培训管道\n",
    "\n",
    "接下来，通过调用方法`run`，使用以下参数来运行创建的DAG以启动训练作业：\n",
    "\n",
    "- `dataset`：用于训练模型的`Dataset`资源。\n",
    "- `model_display_name`：经过训练的模型的人类可读名称。\n",
    "- `training_fraction_split`：用于训练的数据集百分比。\n",
    "- `test_fraction_split`：用于测试（保留数据）的数据集百分比。\n",
    "\n",
    "`run`方法完成后将返回`Model`资源。\n",
    "\n",
    "培训管道的执行将需要超过30分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_automl_pipeline:video"
   },
   "outputs": [],
   "source": [
    "model = dag.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"human_motion\",\n",
    "    training_fraction_split=0.8,\n",
    "    test_fraction_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "source": [
    "## 检查模型评估分数\n",
    "\n",
    "在模型训练完成后，您可以使用`list_model_evaluations()`方法来检查其评估分数。该方法将为每个评估切片返回一个迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "model_evaluations = model.list_model_evaluations()\n",
    "\n",
    "for model_evaluation in model_evaluations:\n",
    "    print(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "source": [
    "删除模型\n",
    "\n",
    "方法 'delete()' 将删除该模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "source": [
    "删除数据集\n",
    "\n",
    "方法 'delete()' 将删除数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset_delete:mbsdk"
   },
   "outputs": [],
   "source": [
    "dataset.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup"
   },
   "source": [
    "# 清理\n",
    "\n",
    "要清理此项目中使用的所有谷歌云资源，您可以 [删除用于此教程的谷歌云项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup"
   },
   "outputs": [],
   "source": [
    "# Set this to true only if you'd like to delete your bucket\n",
    "delete_bucket = False\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_automl_training.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
