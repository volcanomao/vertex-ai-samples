{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18ebbd838e32"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mThXALJl9Yue"
   },
   "source": [
    "# 自动ML表格工作流管道\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/automl_tabular_on_vertex_pipelines.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "</a>\n",
    "\n",
    "<a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/automl_tabular_on_vertex_pipelines.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"> 在 GitHub 中查看\n",
    "</a>\n",
    "\n",
    "<a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/automl/automl_tabular_on_vertex_pipelines.ipynb\">\n",
    "        <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"> 在 Vertex AI Workbench 中打开\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcc745968395"
   },
   "source": [
    "## 概述\n",
    "\n",
    "在本教程中，您将使用两个Vertex AI Tabular Workflows管道来训练AutoML模型，使用不同的配置。您将看到如何使用`get_automl_tabular_pipeline_and_parameters`来自定义默认的AutoML Tabular管道，以及如何通过使用上一个管道运行的调整结果来减少AutoML模型的训练时间和成本的`get_skip_architecture_search_pipeline_and_parameters`。\n",
    "\n",
    "了解更多关于[端到端AutoML的Tabular工作流程](https://cloud.google.com/vertex-ai/docs/tabular-data/tabular-workflows/e2e-automl)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f887ec5c06c5"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用从[Google Cloud流水线组件](https://cloud.google.com/vertex-ai/docs/pipelines/introduction)（GCPC）下载的[Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction)创建两个回归模型。这些流水线将是由Google维护的Vertex AI表格工作流程流水线。这些流水线将展示不同的方式来定制Vertex表格训练过程。\n",
    "\n",
    "本教程使用以下Google Cloud ML服务：\n",
    "\n",
    "- `自动ML训练`\n",
    "- `Vertex AI数据集`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 创建一个训练流水线，将搜索空间从默认值减少以节省时间。\n",
    "- 创建一个训练流水线，重用先前流水线的架构搜索结果以节省时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eac26958afe8"
   },
   "source": [
    "数据集\n",
    "\n",
    "您将使用的数据集是[银行营销](https://archive.ics.uci.edu/ml/datasets/bank+marketing)。这些数据是葡萄牙银行机构直接营销活动（电话呼叫）的数据。二元分类的目标是预测客户是否会订阅定期存款。对于此笔记本，我们随机选择了原始数据集中90％的行，并将它们保存在托管在云存储上的train.csv文件中。要下载该文件，请点击[这里](https://storage.googleapis.com/cloud-samples-data/vertex-ai/tabular-workflows/datasets/bank-marketing/train.csv)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "181d4dfbf917"
   },
   "source": [
    "### 成本\n",
    "\n",
    "本教程使用 Google Cloud 的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解 [Vertex AI\n",
    "价格](https://cloud.google.com/vertex-ai/pricing) 和 [Cloud Storage\n",
    "价格](https://cloud.google.com/storage/pricing)，使用 [价格\n",
    "计算器](https://cloud.google.com/products/calculator/)\n",
    "根据您预计的使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装最新版本的用于Python的Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7-SzYTR9bo2"
   },
   "outputs": [],
   "source": [
    "!pip3 install --upgrade --quiet google-cloud-pipeline-components==1.0.25 \\\n",
    "                                google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### 只有 Colab: 取消注释以下单元格以重新启动内核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-ZBOjErv5mM"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfEglUHQk9S3"
   },
   "source": [
    "在开始之前\n",
    "\n",
    "设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下步骤：\n",
    "- 运行 `gcloud config list`。\n",
    "- 运行 `gcloud projects list`。\n",
    "- 参考支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zebLBGXOky2A"
   },
   "source": [
    "## 关于服务账号和权限的注意事项\n",
    "\n",
    "**默认情况下不需要任何配置**，如果遇到任何与权限相关的问题，请确保服务账号具有[端到端AutoML文档](https://cloud.google.com/vertex-ai/docs/tabular-data/tabular-workflows/service-accounts#e2e-automl)中列出的所需角色。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "区域\n",
    "\n",
    "您还可以更改 Vertex AI 使用的 `REGION` 变量。了解有关 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations) 的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "### 认证您的Google Cloud帐户\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动进行认证。请按照以下相关说明进行操作。\n",
    "\n",
    "**1. Vertex AI Workbench**\n",
    "* 不需要做任何操作，因为您已经认证通过。\n",
    "\n",
    "**2. 本地JupyterLab实例，取消注释并运行：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce6043da7b33"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0367eac06a10"
   },
   "source": [
    "3. 协作，取消注释并运行:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21ad4dbb4a61"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c13224697bfb"
   },
   "source": [
    "4. 服务账户或其他\n",
    "* 请参考如何为您的服务账户授予云存储权限，链接地址：https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产物，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有在您的存储桶不存在时：运行以下单元格以创建您的云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44accda192d5"
   },
   "source": [
    "#### 服务账号\n",
    "\n",
    "您可以使用服务账号来创建Vertex AI管道作业。如果您不想使用项目的Compute Engine服务账号，请将`SERVICE_ACCOUNT`设置为另一个服务账号ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0c9c4f84849"
   },
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = \"[your-service-account]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "604ae09ab6d3"
   },
   "outputs": [],
   "source": [
    "if (\n",
    "    SERVICE_ACCOUNT == \"\"\n",
    "    or SERVICE_ACCOUNT is None\n",
    "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
    "):\n",
    "    # Get your service account from gcloud\n",
    "    if not IS_COLAB:\n",
    "        shell_output = !gcloud auth list 2>/dev/null\n",
    "        SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\n",
    "\n",
    "    else:  # IS_COLAB:\n",
    "        shell_output = ! gcloud projects describe  $PROJECT_ID\n",
    "        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
    "        SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
    "\n",
    "    print(\"Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1ecb60964d5"
   },
   "source": [
    "设置Vertex AI Pipelines的服务帐户访问权限\n",
    "运行以下命令，将您的服务帐户访问权限授予读取和写入管道工件的存储桶，该存储桶是在上一步中创建的。每个服务帐户只需要运行此步骤一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a592f0a380c2"
   },
   "outputs": [],
   "source": [
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n",
    "\n",
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbbc3479a1da"
   },
   "source": [
    "导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8G6YmJT1yqkV"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# Import required modules\n",
    "import os\n",
    "import uuid\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from google.cloud import aiplatform, storage\n",
    "from google_cloud_pipeline_components.experimental.automl.tabular import \\\n",
    "    utils as automl_tabular_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0423f260423"
   },
   "source": [
    "初始化 Python 的 Vertex AI SDK，用于您的项目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad69f2590268"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LWH3PRF5o2v"
   },
   "source": [
    "### 定义辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9FPFT8c5oC0"
   },
   "outputs": [],
   "source": [
    "def get_bucket_name_and_path(uri):\n",
    "    no_prefix_uri = uri[len(\"gs://\") :]\n",
    "    splits = no_prefix_uri.split(\"/\")\n",
    "    return splits[0], \"/\".join(splits[1:])\n",
    "\n",
    "\n",
    "def download_from_gcs(uri):\n",
    "    bucket_name, path = get_bucket_name_and_path(uri)\n",
    "    storage_client = storage.Client(project=PROJECT_ID)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(path)\n",
    "    return blob.download_as_string()\n",
    "\n",
    "\n",
    "def write_to_gcs(uri: str, content: str):\n",
    "    bucket_name, path = get_bucket_name_and_path(uri)\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(path)\n",
    "    blob.upload_from_string(content)\n",
    "\n",
    "\n",
    "def generate_auto_transformation(column_names: List[str]) -> List[Dict[str, Any]]:\n",
    "    transformations = []\n",
    "    for column_name in column_names:\n",
    "        transformations.append({\"auto\": {\"column_name\": column_name}})\n",
    "    return transformations\n",
    "\n",
    "\n",
    "def write_auto_transformations(uri: str, column_names: List[str]):\n",
    "    transformations = generate_auto_transformation(column_names)\n",
    "    write_to_gcs(uri, json.dumps(transformations))\n",
    "\n",
    "\n",
    "def get_task_detail(\n",
    "    task_details: List[Dict[str, Any]], task_name: str\n",
    ") -> List[Dict[str, Any]]:\n",
    "    for task_detail in task_details:\n",
    "        if task_detail.task_name == task_name:\n",
    "            return task_detail\n",
    "\n",
    "\n",
    "def get_deployed_model_uri(\n",
    "    task_details,\n",
    "):\n",
    "    ensemble_task = get_task_detail(task_details, \"model-upload\")\n",
    "    return ensemble_task.outputs[\"model\"].artifacts[0].uri\n",
    "\n",
    "\n",
    "def get_no_custom_ops_model_uri(task_details):\n",
    "    ensemble_task = get_task_detail(task_details, \"automl-tabular-ensemble\")\n",
    "    return download_from_gcs(\n",
    "        ensemble_task.outputs[\"model_without_custom_ops\"].artifacts[0].uri\n",
    "    )\n",
    "\n",
    "\n",
    "def get_feature_attributions(\n",
    "    task_details,\n",
    "):\n",
    "    ensemble_task = get_task_detail(task_details, \"model-evaluation-2\")\n",
    "    return download_from_gcs(\n",
    "        ensemble_task.outputs[\"evaluation_metrics\"]\n",
    "        .artifacts[0]\n",
    "        .metadata[\"explanation_gcs_path\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_evaluation_metrics(\n",
    "    task_details,\n",
    "):\n",
    "    ensemble_task = get_task_detail(task_details, \"model-evaluation\")\n",
    "    return download_from_gcs(\n",
    "        ensemble_task.outputs[\"evaluation_metrics\"].artifacts[0].uri\n",
    "    )\n",
    "\n",
    "\n",
    "def load_and_print_json(s):\n",
    "    parsed = json.loads(s)\n",
    "    print(json.dumps(parsed, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvNFMRmBegZq"
   },
   "source": [
    "### 定义培训规范"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eV4JrwB8wAkg"
   },
   "outputs": [],
   "source": [
    "run_evaluation = True  # @param {type:\"boolean\"}\n",
    "run_distillation = False  # @param {type:\"boolean\"}\n",
    "root_dir = os.path.join(BUCKET_URI, \"automl_tabular_pipeline\")\n",
    "prediction_type = \"classification\"\n",
    "optimization_objective = \"minimize-log-loss\"\n",
    "target_column = \"deposit\"\n",
    "data_source_csv_filenames = \"gs://cloud-samples-data/vertex-ai/tabular-workflows/datasets/bank-marketing/train.csv\"\n",
    "data_source_bigquery_table_path = None  # format: bq://bq_project.bq_dataset.bq_table\n",
    "\n",
    "timestamp_split_key = None  # timestamp column name when using timestamp split\n",
    "stratified_split_key = None  # target column name when using stratified split\n",
    "training_fraction = 0.8\n",
    "validation_fraction = 0.1\n",
    "test_fraction = 0.1\n",
    "\n",
    "predefined_split_key = None\n",
    "if predefined_split_key:\n",
    "    training_fraction = None\n",
    "    validation_fraction = None\n",
    "    test_fraction = None\n",
    "\n",
    "weight_column = None\n",
    "\n",
    "features = [\n",
    "    \"age\",\n",
    "    \"job\",\n",
    "    \"marital\",\n",
    "    \"education\",\n",
    "    \"default\",\n",
    "    \"balance\",\n",
    "    \"housing\",\n",
    "    \"loan\",\n",
    "    \"contact\",\n",
    "    \"day\",\n",
    "    \"month\",\n",
    "    \"duration\",\n",
    "    \"campaign\",\n",
    "    \"pdays\",\n",
    "    \"previous\",\n",
    "    \"poutcome\",\n",
    "]\n",
    "transformations = generate_auto_transformation(features)\n",
    "transform_config_path = os.path.join(root_dir, f\"transform_config_{uuid.uuid4()}.json\")\n",
    "write_to_gcs(transform_config_path, json.dumps(transformations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyWGg2s09xOk"
   },
   "source": [
    "## 与VPC相关的配置\n",
    "\n",
    "如果需要使用自定义的Dataflow子网络，您可以通过`dataflow_subnetwork`参数进行设置。要求如下：\n",
    "1. `dataflow_subnetwork`必须是完全限定的子网络名称。\n",
    "   [[参考链接](https://cloud.google.com/dataflow/docs/guides/specifying-networks#example_network_and_subnetwork_specifications)]\n",
    "1. 以下服务账号必须在指定的Dataflow子网络上分配[Compute Network User角色](https://cloud.google.com/compute/docs/access/iam#compute.networkUser)：\n",
    "    1. Compute Engine默认服务账号：PROJECT_NUMBER-compute@developer.gserviceaccount.com\n",
    "    2. Dataflow服务账号：service-PROJECT_NUMBER@dataflow-service-producer-prod.iam.gserviceaccount.com\n",
    "\n",
    "如果您的项目已启用VPC-SC，请确保：\n",
    "\n",
    "1. 用于VPC-SC的Dataflow子网络已正确配置用于Dataflow。\n",
    "   [[参考链接](https://cloud.google.com/dataflow/docs/guides/routes-firewall)]\n",
    "2. `dataflow_use_public_ips`设置为False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TePNlLl9v1q"
   },
   "outputs": [],
   "source": [
    "# Dataflow's fully qualified subnetwork name, when empty the default subnetwork will be used.\n",
    "# Fully qualified subnetwork name is in the form of\n",
    "# https://www.googleapis.com/compute/v1/projects/HOST_PROJECT_ID/regions/REGION_NAME/subnetworks/SUBNETWORK_NAME\n",
    "# reference: https://cloud.google.com/dataflow/docs/guides/specifying-networks#example_network_and_subnetwork_specifications\n",
    "dataflow_subnetwork = None  # @param {type:\"string\"}\n",
    "# Specifies whether Dataflow workers use public IP addresses.\n",
    "dataflow_use_public_ips = True  # @param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-iXXE14voyR"
   },
   "source": [
    "自定义搜索空间并更改训练配置\n",
    "\n",
    "我们将创建一个跳过评估的 AutoML Tables 流水线，其中包括以下自定义设置：\n",
    "- 限制超参数搜索空间\n",
    "- 更改机器类型和调整/训练并行性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sG46cXVueb66"
   },
   "outputs": [],
   "source": [
    "study_spec_parameters_override = [\n",
    "    {\n",
    "        \"parameter_id\": \"model_type\",\n",
    "        \"categorical_value_spec\": {\n",
    "            \"values\": [\n",
    "                \"nn\"\n",
    "            ]  # The default value is [\"nn\", \"boosted_trees\"], this reduces the search space\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "worker_pool_specs_override = [\n",
    "    {\"machine_spec\": {\"machine_type\": \"n1-standard-8\"}},  # override for TF chief node\n",
    "    {},  # override for TF worker node, since it's not used, leave it empty\n",
    "    {},  # override for TF ps node, since it's not used, leave it empty\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": \"n1-standard-4\"  # override for TF evaluator node\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "# Number of weak models in the final ensemble model is\n",
    "# stage_2_num_selected_trials * 5. If unspecified, 5 is the default value for\n",
    "# stage_2_num_selected_trials.\n",
    "stage_2_num_selected_trials = 5\n",
    "\n",
    "# The pipeline output a TF saved model contains the following TF custom op:\n",
    "# - https://github.com/google/struct2tensor\n",
    "#\n",
    "# There are a few ways to run the model:\n",
    "# - Official prediction server docker image\n",
    "#   Please follow the \"Run the model server\" section in\n",
    "#   https://cloud.google.com/vertex-ai/docs/export/export-model-tabular#run-server\n",
    "# - Python or cpp runtimes like TF serving\n",
    "#   Please set export_additional_model_without_custom_ops so the pipeline\n",
    "#   outputs an additional model does does not depend on struct2tensor.\n",
    "#   - `get_no_custom_ops_model_uri` shows how to get the model artifact URI.\n",
    "#   - The input to the model is a dictionary of feature name to tensor. Use\n",
    "#     `saved_model_cli show --dir {saved_model.pb's path} --signature_def serving_default --tag serve`\n",
    "#     to find out more details.\n",
    "export_additional_model_without_custom_ops = False\n",
    "\n",
    "train_budget_milli_node_hours = 1000  # 1 hour\n",
    "\n",
    "(\n",
    "    template_path,\n",
    "    parameter_values,\n",
    ") = automl_tabular_utils.get_automl_tabular_pipeline_and_parameters(\n",
    "    PROJECT_ID,\n",
    "    REGION,\n",
    "    root_dir,\n",
    "    target_column,\n",
    "    prediction_type,\n",
    "    optimization_objective,\n",
    "    transform_config_path,\n",
    "    train_budget_milli_node_hours,\n",
    "    data_source_csv_filenames=data_source_csv_filenames,\n",
    "    data_source_bigquery_table_path=data_source_bigquery_table_path,\n",
    "    weight_column=weight_column,\n",
    "    predefined_split_key=predefined_split_key,\n",
    "    timestamp_split_key=timestamp_split_key,\n",
    "    stratified_split_key=stratified_split_key,\n",
    "    training_fraction=training_fraction,\n",
    "    validation_fraction=validation_fraction,\n",
    "    test_fraction=test_fraction,\n",
    "    study_spec_parameters_override=study_spec_parameters_override,\n",
    "    stage_1_tuner_worker_pool_specs_override=worker_pool_specs_override,\n",
    "    cv_trainer_worker_pool_specs_override=worker_pool_specs_override,\n",
    "    run_evaluation=run_evaluation,\n",
    "    run_distillation=run_distillation,\n",
    "    dataflow_subnetwork=dataflow_subnetwork,\n",
    "    dataflow_use_public_ips=dataflow_use_public_ips,\n",
    "    export_additional_model_without_custom_ops=export_additional_model_without_custom_ops,\n",
    ")\n",
    "\n",
    "job_id = \"automl-tabular-{}\".format(uuid.uuid4())\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=job_id,\n",
    "    location=REGION,  # launches the pipeline job in the specified region\n",
    "    template_path=template_path,\n",
    "    job_id=job_id,\n",
    "    pipeline_root=root_dir,\n",
    "    parameter_values=parameter_values,\n",
    "    enable_caching=False,\n",
    ")\n",
    "\n",
    "job.run()\n",
    "\n",
    "\n",
    "pipeline_task_details = job.gca_resource.job_detail.task_details\n",
    "\n",
    "if export_additional_model_without_custom_ops:\n",
    "    print(\n",
    "        \"trained model without custom TF ops:\",\n",
    "        get_no_custom_ops_model_uri(pipeline_task_details),\n",
    "    )\n",
    "\n",
    "if run_evaluation:\n",
    "    print(\"evaluation metrics:\")\n",
    "    load_and_print_json(get_evaluation_metrics(pipeline_task_details))\n",
    "\n",
    "    print(\"feature attributions:\")\n",
    "    load_and_print_json(get_feature_attributions(pipeline_task_details))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sF8a2RKtRhg"
   },
   "source": [
    "跳过架构搜索\n",
    "不必每次都进行架构搜索，我们可以重复使用现有的架构搜索结果。这可以有助于：\n",
    "1. 减少输出模型的变化\n",
    "2. 减少训练成本\n",
    "\n",
    "现有的架构搜索结果存储在`automl-tabular-stage-1-tuner`组件的`tuning_result_output`输出中。我们可以手动输入它或通过程序获取它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8hlPps2Rtpq-"
   },
   "outputs": [],
   "source": [
    "stage_1_tuner_task = get_task_detail(\n",
    "    pipeline_task_details, \"automl-tabular-stage-1-tuner\"\n",
    ")\n",
    "\n",
    "stage_1_tuning_result_artifact_uri = (\n",
    "    stage_1_tuner_task.outputs[\"tuning_result_output\"].artifacts[0].uri\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5F12ZL_uZZ3"
   },
   "source": [
    "运行跳过架构搜索管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4x4GA5sMuewX"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    template_path,\n",
    "    parameter_values,\n",
    ") = automl_tabular_utils.get_skip_architecture_search_pipeline_and_parameters(\n",
    "    PROJECT_ID,\n",
    "    REGION,\n",
    "    root_dir,\n",
    "    target_column,\n",
    "    prediction_type,\n",
    "    optimization_objective,\n",
    "    transform_config_path,\n",
    "    train_budget_milli_node_hours,\n",
    "    data_source_csv_filenames=data_source_csv_filenames,\n",
    "    data_source_bigquery_table_path=data_source_bigquery_table_path,\n",
    "    weight_column=weight_column,\n",
    "    predefined_split_key=predefined_split_key,\n",
    "    timestamp_split_key=timestamp_split_key,\n",
    "    stratified_split_key=stratified_split_key,\n",
    "    training_fraction=training_fraction,\n",
    "    validation_fraction=validation_fraction,\n",
    "    test_fraction=test_fraction,\n",
    "    stage_1_tuning_result_artifact_uri=stage_1_tuning_result_artifact_uri,\n",
    "    run_evaluation=run_evaluation,\n",
    "    dataflow_subnetwork=dataflow_subnetwork,\n",
    "    dataflow_use_public_ips=dataflow_use_public_ips,\n",
    ")\n",
    "\n",
    "job_id = \"automl-tabular-skip-architecture-search-{}\".format(uuid.uuid4())\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=job_id,\n",
    "    location=REGION,  # launches the pipeline job in the specified region\n",
    "    template_path=template_path,\n",
    "    job_id=job_id,\n",
    "    pipeline_root=root_dir,\n",
    "    parameter_values=parameter_values,\n",
    "    enable_caching=False,\n",
    ")\n",
    "\n",
    "job.run()\n",
    "\n",
    "# Get model URI\n",
    "skip_architecture_search_pipeline_task_details = (\n",
    "    job.gca_resource.job_detail.task_details\n",
    ")\n",
    "\n",
    "if export_additional_model_without_custom_ops:\n",
    "    print(\n",
    "        \"trained model without custom TF ops:\",\n",
    "        get_no_custom_ops_model_uri(pipeline_task_details),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43342a43176e"
   },
   "source": [
    "清理顶点和BigQuery资源\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在此教程中创建的各个资源：\n",
    "\n",
    "- 云存储存储桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad8d12061a65"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "automl_tabular_on_vertex_pipelines.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
