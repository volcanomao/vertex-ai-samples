{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# 为出口到边缘的自动机器学习模型训练图像对象检测\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/automl_image_object_detection_export_edge.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在 Colab 中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/automl_image_object_detection_export_edge.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/automl//automl_image_object_detection_export_edge.ipynb\">\n",
    "       <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在 Vertex AI 工作台中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:automl,export_edge"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何使用Vertex AI SDK创建图像对象检测模型，并将其导出为Edge模型，使用AutoML模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:automl,training,export_edge"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将使用Vertex SDK从Python脚本创建一个AutoML图像对象检测模型，然后将该模型导出为TFLite格式的Edge模型。您还可以使用`gcloud`命令行工具或在云控制台上在线创建AutoML模型。\n",
    "\n",
    "本教程使用以下Google Cloud ML服务：\n",
    "\n",
    "- Vertex AI `Datasets`\n",
    "- AutoML Image\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 创建一个Vertex `Dataset`资源。\n",
    "- 训练模型。\n",
    "- 从`Model`资源中将`Edge`模型导出到Cloud Storage。\n",
    "- 在本地下载模型。\n",
    "- 进行本地预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:salads,iod"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是来自[TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview)的[OpenImages数据集](https://www.tensorflow.org/datasets/catalog/open_images_v4)中的沙拉类别。这个数据集不需要任何特征工程。在本教程中使用的数据集版本存储在一个公共云存储桶中。训练模型可以预测图像中五种项目类别中沙拉项目的边界框位置和对应类型：沙拉、海鲜、番茄、烘焙食品、或奶酪。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "### 费用\n",
    "\n",
    "本教程使用谷歌云的可计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI的定价](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage的定价](https://cloud.google.com/storage/pricing)，并使用[Pricing Calculator](https://cloud.google.com/products/calculator/) 基于您的预期使用量生成费用估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "source": [
    "安装最新版本的Python的Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "! pip3 install --upgrade --quiet google-cloud-aiplatform\n",
    "\n",
    "if os.environ[\"IS_TESTING\"]:\n",
    "    ! pip3 install --upgrade tensorflow $USER_FLAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### 仅限Colab：取消注释以下单元格以重新启动内核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-ZBOjErv5mM"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "在你开始之前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "### 设置您的项目 ID\n",
    "\n",
    "**如果您不知道您的项目 ID**，请尝试以下方法：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面：[查找项目 ID](https://support.google.com/googleapi/answer/7014113)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "### 区域\n",
    "\n",
    "您也可以更改 Vertex AI 使用的 `REGION` 变量。了解更多关于 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcp_authenticate"
   },
   "source": [
    "验证您的Google Cloud账户\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动验证。请按照以下相关说明进行操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvQeFm3Gv5mR"
   },
   "source": [
    "1. 顶点 AI 工作台\n",
    "* 什么也不需要做，因为你已经通过验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ad1138a125ea"
   },
   "source": [
    "2. 本地 JupyterLab 实例，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce6043da7b33"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0367eac06a10"
   },
   "source": [
    "3. 合作，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21ad4dbb4a61"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c13224697bfb"
   },
   "source": [
    "查看如何在 https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples 上向您的服务帐号授予云存储权限。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产物，比如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有在您的存储桶不存在时才运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在本教程中使用的变量。\n",
    "### 导入库并定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import google.cloud.aiplatform as aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "## 初始化用于 Python 的 Vertex AI SDK\n",
    "\n",
    "为您的项目和相应的存储桶初始化用于 Python 的 Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tutorial_start:automl"
   },
   "source": [
    "# 教程\n",
    "\n",
    "现在你已经准备好开始创建你自己的AutoML图像目标检测模型了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_file:u_dataset,csv"
   },
   "source": [
    "云存储培训数据的位置。\n",
    "\n",
    "现在将变量`IMPORT_FILE`设置为Cloud Storage中CSV索引文件的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_file:salads,csv,iod"
   },
   "outputs": [],
   "source": [
    "IMPORT_FILE = \"gs://cloud-samples-data/vision/salads.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick_peek:csv"
   },
   "source": [
    "快速查看您的数据\n",
    "\n",
    "本教程使用存储在公共云存储桶中的沙拉数据集的版本，使用CSV索引文件。\n",
    "\n",
    "首先快速查看数据。您可以通过计算CSV索引文件中的行数（`wc -l`）来计算示例的数量，然后查看前几行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quick_peek:csv"
   },
   "outputs": [],
   "source": [
    "if \"IMPORT_FILES\" in globals():\n",
    "    FILE = IMPORT_FILES[0]\n",
    "else:\n",
    "    FILE = IMPORT_FILE\n",
    "\n",
    "count = ! gsutil cat $FILE | wc -l\n",
    "print(\"Number of Examples\", int(count[0]))\n",
    "\n",
    "print(\"First 10 rows\")\n",
    "! gsutil cat $FILE | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_dataset:image,iod"
   },
   "source": [
    "### 创建数据集\n",
    "\n",
    "接下来，使用`ImageDataset`类的`create`方法为`Dataset`资源创建数据集，需要提供以下参数：\n",
    "\n",
    "- `display_name`：`Dataset`资源的可读名称。\n",
    "- `gcs_source`：要将数据项导入`Dataset`资源的一个或多个数据集索引文件列表。\n",
    "- `import_schema_uri`：数据项的数据标记模式。\n",
    "\n",
    "这个操作可能需要几分钟时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataset:image,iod"
   },
   "outputs": [],
   "source": [
    "dataset = aiplatform.ImageDataset.create(\n",
    "    display_name=\"Salads\",\n",
    "    gcs_source=[IMPORT_FILE],\n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.image.bounding_box,\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_automl_pipeline:image,edge,iod"
   },
   "source": [
    "### 创建和运行训练管道\n",
    "\n",
    "要训练一个AutoML模型，您需要执行两个步骤：1) 创建一个训练管道，2) 运行该管道。\n",
    "\n",
    "#### 创建训练管道\n",
    "\n",
    "使用 `AutoMLImageTrainingJob` 类创建一个AutoML训练管道，具有以下参数：\n",
    "\n",
    "- `display_name`：`TrainingJob` 资源的人类可读名称。\n",
    "- `prediction_type`：训练模型的任务类型。\n",
    "  - `classification`：图像分类模型。\n",
    "  - `object_detection`：图像目标检测模型。\n",
    "- `multi_label`：如果是分类任务，是单标签 (`False`) 还是多标签 (`True`)。\n",
    "- `model_type`：部署模型的类型。\n",
    "  - `CLOUD`：部署在Google Cloud上。\n",
    "  - `CLOUD_HIGH_ACCURACY_1`：针对精度优化而非延迟部署在Google Cloud上。\n",
    "  - `CLOUD_LOW_LATENCY_`：针对延迟而非精度优化部署在Google Cloud上。\n",
    "  - `MOBILE_TF_VERSATILE_1`：部署在边缘设备上。\n",
    "  - `MOBILE_TF_HIGH_ACCURACY_1`：针对精度优化而非延迟部署在边缘设备上。\n",
    "  - `MOBILE_TF_LOW_LATENCY_1`：针对延迟而非精度优化部署在边缘设备上。\n",
    "- `base_model`：（可选）从现有的 `Model` 资源进行迁移学习 --仅支持图像分类。\n",
    "\n",
    "实例化的对象是训练作业的DAG（有向无环图）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_automl_pipeline:image,edge,iod"
   },
   "outputs": [],
   "source": [
    "dag = aiplatform.AutoMLImageTrainingJob(\n",
    "    display_name=\"salads\",\n",
    "    prediction_type=\"object_detection\",\n",
    "    multi_label=False,\n",
    "    model_type=\"MOBILE_TF_LOW_LATENCY_1\",\n",
    "    base_model=None,\n",
    ")\n",
    "\n",
    "print(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_automl_pipeline:image"
   },
   "source": [
    "#### 运行训练流水线\n",
    "\n",
    "接下来，您可以通过调用`run`方法来运行DAG从而开始训练作业，具体参数如下：\n",
    "\n",
    "- `dataset`：用于训练模型的`Dataset`资源。\n",
    "- `model_display_name`：训练模型的可读名称。\n",
    "- `training_fraction_split`：用于训练的数据集百分比。\n",
    "- `test_fraction_split`：用于测试（留出数据）的数据集百分比。\n",
    "- `validation_fraction_split`：用于验证的数据集百分比。\n",
    "- `budget_milli_node_hours`：（可选）以毫小时为单位指定的最大训练时间（1000 = 1小时）。\n",
    "- `disable_early_stopping`：如果`True`，服务可能认为无法进一步提高模型目标测量，因此训练可能在使用完整预算之前完成。\n",
    "\n",
    "`run`方法完成后将返回`Model`资源。\n",
    "\n",
    "训练流水线的执行将最多需要60分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_automl_pipeline:image"
   },
   "outputs": [],
   "source": [
    "model = dag.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"salads\",\n",
    "    training_fraction_split=0.8,\n",
    "    validation_fraction_split=0.1,\n",
    "    test_fraction_split=0.1,\n",
    "    budget_milli_node_hours=20000,\n",
    "    disable_early_stopping=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "source": [
    "## 回顾模型评估分数\n",
    "\n",
    "在模型训练完成后，您可以使用 `list_model_evaluations()` 方法查看其评估分数。该方法将返回每个评估切片的迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_the_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "model_evaluations = model.list_model_evaluations()\n",
    "\n",
    "for model_evaluation in model_evaluations:\n",
    "    print(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export_model:mbsdk,image"
   },
   "source": [
    "将模型导出为Edge模型\n",
    "\n",
    "您可以将AutoML图像目标检测模型导出为`Edge`模型，然后将其定制部署到边缘设备或在本地下载。使用`export_model()`方法将模型导出到云存储，该方法接受以下参数：\n",
    "\n",
    "- `artifact_destination`：存储SavedFormat模型工件的云存储位置。\n",
    "- `export_format_id`：要保存模型格式的格式。对于AutoML图像目标检测，有以下选项：\n",
    "   - `tf-saved-model`：用于部署到容器的TensorFlow SavedFormat。\n",
    "   - `tflite`：用于部署到边缘或移动设备的TensorFlow Lite。\n",
    "   - `edgetpu-tflite`：用于TPU的TensorFlow Lite。\n",
    "   - `tf-js`：用于Web客户端的TensorFlow。\n",
    "   - `coral-ml`：用于Coral设备。\n",
    "\n",
    "- `sync`：是否同步或异步执行操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_model:mbsdk,image"
   },
   "outputs": [],
   "source": [
    "response = model.export_model(\n",
    "    artifact_destination=BUCKET_URI, export_format_id=\"tflite\", sync=True\n",
    ")\n",
    "\n",
    "model_package = response[\"artifactOutputUri\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_model_artifacts:tflite"
   },
   "source": [
    "#### 下载TFLite模型文件\n",
    "\n",
    "现在您已经导出了您的模型的TFLite版本，您可以在本地测试导出的模型，但首先需要从云存储中下载它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_model_artifacts:tflite"
   },
   "outputs": [],
   "source": [
    "! gsutil ls $model_package\n",
    "# Download the model artifacts\n",
    "! gsutil cp -r $model_package tflite\n",
    "\n",
    "tflite_path = \"tflite/model.tflite\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "instantiate_tflite_interpreter"
   },
   "source": [
    "实例化一个TFLite解释器\n",
    "\n",
    "模型的TFLite版本不是TensorFlow SavedModel格式。您不能直接使用像predict()这样的方法。相反，您需要使用TFLite解释器。您必须首先为TFLite模型设置解释器，步骤如下：\n",
    "\n",
    "- 为TFLite模型实例化一个TFLite解释器。\n",
    "- 指示解释器为模型分配输入和输出张量。\n",
    "- 获取关于模型输入和输出张量的详细信息，这是预测所需的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "instantiate_tflite_interpreter"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "input_shape = input_details[0][\"shape\"]\n",
    "\n",
    "print(\"input tensor shape\", input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_test_item"
   },
   "source": [
    "获取测试项目\n",
    "\n",
    "您将从数据集中选择任意的示例作为测试项目。不必担心该示例很可能在训练模型时被使用过 — 我们只是想演示如何进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_test_item:image,224x224"
   },
   "outputs": [],
   "source": [
    "test_items = ! gsutil cat $IMPORT_FILE | head -n1\n",
    "test_item = test_items[0].split(\",\")[0]\n",
    "\n",
    "with tf.io.gfile.GFile(test_item, \"rb\") as f:\n",
    "    content = f.read()\n",
    "test_image = tf.io.decode_jpeg(content)\n",
    "print(\"test image shape\", test_image.shape)\n",
    "\n",
    "test_image = tf.image.resize(test_image, (192, 192))\n",
    "print(\"test image shape\", test_image.shape, test_image.dtype)\n",
    "\n",
    "test_image = tf.cast(test_image, dtype=tf.uint8).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "invoke_tflite_interpreter"
   },
   "source": [
    "#### 使用 TFLite 模型进行预测\n",
    "\n",
    "最后，您将使用您的 TFLite 模型进行预测，步骤如下：\n",
    "\n",
    "- 将测试图像转换为单个图像批次（`np.expand_dims`）。\n",
    "- 将输入张量设置为解释器的单个图像批次（`data`）。\n",
    "- 调用解释器。\n",
    "- 检索预测的 softmax 概率（`get_tensor`）。\n",
    "- 确定哪个标签具有最高的概率（`np.argmax`）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "invoke_tflite_interpreter"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "interpreter.set_tensor(input_details[0][\"index\"], data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "softmax = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "label = np.argmax(softmax)\n",
    "\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "清理工作\n",
    "\n",
    "为了清理本项目中使用的所有谷歌云资源，您可以删除您用于本教程的[谷歌云项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "outputs": [],
   "source": [
    "delete_bucket = False\n",
    "\n",
    "# Delete the dataset using the Vertex dataset object\n",
    "dataset.delete()\n",
    "\n",
    "# Delete the model using the Vertex model object\n",
    "model.delete()\n",
    "\n",
    "# Delete the AutoML trainig job\n",
    "dag.delete()\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "automl_image_object_detection_export_edge.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
