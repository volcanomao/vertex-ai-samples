{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright  2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# 在Vertex AI上使用PyTorch和Ray开始\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/ray_on_vertex_ai/get_started_with_pytorch_rov.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> 在Colab中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fray_on_vertex_ai%2Fget_started_with_pytorch_rov.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> 在Colab Enterprise中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/ray_on_vertex_ai/get_started_with_pytorch_rov.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> 在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/ray_on_vertex_ai/get_started_with_pytorch_rov.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> 在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24743cf4a1e1"
   },
   "source": [
    "**_注意_**：此笔记本已在以下环境中进行了测试：\n",
    "\n",
    "* Python 版本 = 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何使用 Ray on Vertex AI SDK 和 Vertex AI SDK 来训练和提供一个 PyTorch 图像分类模型。\n",
    "\n",
    "了解更多关于 [Ray on Vertex AI 概览](https://cloud.google.com/vertex-ai/docs/open-source/ray-on-vertex-ai/overview)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何通过在Vertex AI上利用Ray来高效分发PyTorch图像分类模型的训练过程。此外，您还将学习如何将训练好的模型顺利部署到Vertex AI Endpoint。\n",
    "\n",
    "本教程使用以下 Google Cloud ML 服务和资源：\n",
    "\n",
    "- Ray on Vertex AI\n",
    "- Vertex AI Model Registry\n",
    "- Vertex AI Prediction\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 准备训练脚本\n",
    "- 使用Ray Jobs API提交一个Ray作业\n",
    "- 从PyTorch下载一个训练好的图像模型\n",
    "- 创建一个自定义模型处理程序\n",
    "- 将模型工件打包在模型归档文件中\n",
    "- 在Vertex AI Model Registry中注册模型\n",
    "- 在Vertex AI Endpoint中部署模型\n",
    "- 进行在线预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08d289fa873f"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用[CIFAR-10数据集](https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html)，包含60000张32x32像素的彩色图片，分为10个类别，每个类别有6000张图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aed92deeb4a0"
   },
   "source": [
    "成本\n",
    "\n",
    "本教程使用 Google Cloud 的可计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解 [Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing)，\n",
    "以及 [Cloud Storage 价格](https://cloud.google.com/storage/pricing)，\n",
    "并使用 [定价计算器](https://cloud.google.com/products/calculator/)\n",
    "根据您预期的使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装以下所需的软件包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b4ef9b72d43"
   },
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    USER = \"--user\"\n",
    "else:\n",
    "    USER = \"\"\n",
    "\n",
    "! pip3 install {USER} google-cloud-aiplatform[ray]==1.56.0 ray[data]==2.9.3 ray[train]==2.9.3 ray[tune]==2.9.3 -q --no-warn-conflicts\n",
    "! pip3 install {USER} torch==2.1.2 torchvision==0.16.2 torchmetrics==1.2.1 torchserve==0.9.0 torch-model-archiver==0.9.0 -q --no-warn-conflicts\n",
    "! pip3 install {USER} google-auth==2.27.0 etils==1.5.2 -q --no-warn-conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58707a750154"
   },
   "source": [
    "### 仅限使用Colab：取消注释以下单元格以重新启动内核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f200f10a1da3"
   },
   "outputs": [],
   "source": [
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "## 在开始之前\n",
    "\n",
    "### 设置您的Google Cloud项目\n",
    "\n",
    "**无论您使用什么笔记本环境，以下步骤都是必需的。**\n",
    "\n",
    "1. [选择或创建一个Google Cloud项目](https://console.cloud.google.com/cloud-resource-manager)。当您第一次创建账号时，您将获得$300的免费信用用于计算/存储成本。\n",
    "\n",
    "2. [确保您的项目已启用计费](https://cloud.google.com/billing/docs/how-to/modify-project)。\n",
    "\n",
    "3. [启用Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。\n",
    "\n",
    "4. 如果您在本地运行这个笔记本，您需要安装[Cloud SDK](https://cloud.google.com/sdk)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "#### 设置您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下操作：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面：[找到项目ID](https://support.google.com/googleapi/answer/7014113)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### 区域\n",
    "\n",
    "您也可以更改 Vertex AI 使用的 `REGION` 变量。了解更多关于 [Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPrDj6HE9_EU"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "时间戳\n",
    "\n",
    "如果您正在参加现场教程会话，您可能会使用共享测试账户或项目。为避免在创建的资源之间发生名称冲突，您为每个实例会话创建一个时间戳，并将时间戳附加到您在本教程中创建的资源名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6Le1schAziq"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBCra4QMA2wR"
   },
   "source": [
    "###验证您的谷歌云账户\n",
    "\n",
    "根据您的Jupyter环境，您可能需要手动进行身份验证。请按照以下相关说明进行操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74ccc9e52986"
   },
   "source": [
    "1. Vertex AI Workbench\n",
    "* 无需操作，您已通过验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de775a3773ba"
   },
   "source": [
    "2. 本地JupyterLab实例，取消注释并运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "254614fa0c46"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef21552ccea8"
   },
   "source": [
    "3. 协作、取消注释并运行:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "603adbbf0532"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6b2ccc891ed"
   },
   "source": [
    "请查看如何将Cloud Storage权限授予您的服务帐户 https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶，用于存储中间产物，例如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "如果您的存储桶尚不存在：运行以下单元格以创建您的云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObZfmnat7BaA"
   },
   "source": [
    "将torch-model-archiver添加到PATH\n",
    "\n",
    "更新`PATH`环境变量以添加`torch-model-archiver`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRRsfkBu7C8M"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] = f'{os.environ.get(\"PATH\")}:~/.local/bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9ryiScCEapt"
   },
   "source": [
    "在 Vertex AI 上设置一个 Ray 集群"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwmK5nBBCgJa"
   },
   "source": [
    "在运行下面的代码之前，请确保在Vertex AI上[安装](https://cloud.google.com/vertex-ai/docs/open-source/ray-on-vertex-ai/set-up)Ray，并在Vertex AI上至少[创建](https://cloud.google.com/vertex-ai/docs/open-source/ray-on-vertex-ai/create-cluster)一个Ray集群。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mlq_1NLEonF"
   },
   "outputs": [],
   "source": [
    "import vertex_ray\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from vertex_ray import Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dorIZFvjnGKL"
   },
   "source": [
    "#### 初始化Vertex AI SDK用于Python\n",
    "\n",
    "为您的项目初始化Vertex AI SDK用于Python。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOOgvRJoQ6Xj"
   },
   "outputs": [],
   "source": [
    "vertex_ai.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15PYjIyOcx1d"
   },
   "source": [
    "定义集群配置\n",
    "\n",
    "要在 Vertex AI 上配置一个 Ray 集群，您可以使用默认的配置请求，也可以根据需要指定副本数量（节点数）、机器类型、磁盘规格和加速器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjLG3rsRbiHr"
   },
   "outputs": [],
   "source": [
    "head_node_type = Resources(\n",
    "    machine_type=\"n1-standard-16\",\n",
    "    node_count=1,\n",
    ")\n",
    "\n",
    "worker_node_types = [\n",
    "    Resources(\n",
    "        machine_type=\"n1-standard-16\",\n",
    "        node_count=2,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_O1xUMt7Z6r0"
   },
   "source": [
    "创建 Ray 集群\n",
    "\n",
    "使用与 Ray 一起使用的 Vertex AI SDK for Python 版本创建 Ray 集群。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZkHOH3v2i1p"
   },
   "outputs": [],
   "source": [
    "cluster_name = f\"ray-cluster-{TIMESTAMP}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-g6kLwqUj5n"
   },
   "outputs": [],
   "source": [
    "ray_cluster_name = vertex_ray.create_ray_cluster(\n",
    "    head_node_type=head_node_type,\n",
    "    worker_node_types=worker_node_types,\n",
    "    cluster_name=cluster_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmBlsbHAc2uO"
   },
   "source": [
    "获取Ray集群\n",
    "\n",
    "使用Python的Vertex AI SDK来获取Ray集群。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UzG2WyXbZJi"
   },
   "outputs": [],
   "source": [
    "ray_cluster = vertex_ray.get_ray_cluster(ray_cluster_name)\n",
    "print(\"Ray cluster on Vertex AI:\", ray_cluster_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ek1-iTbPjzdJ"
   },
   "source": [
    "### 设置教程文件夹\n",
    "\n",
    "在本教程中使用的文件夹设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbfKRabXj3la"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path as path\n",
    "\n",
    "root_path = path.cwd()\n",
    "tutorial_path = root_path / \"tutorial\"\n",
    "src_path = tutorial_path / \"src\"\n",
    "deliverables_path = tutorial_path / \"deliverables\"\n",
    "build_path = tutorial_path / \"build\"\n",
    "tests_path = tutorial_path / \"tests\"\n",
    "\n",
    "src_path.mkdir(parents=True, exist_ok=True)\n",
    "deliverables_path.mkdir(parents=True, exist_ok=True)\n",
    "build_path.mkdir(parents=True, exist_ok=True)\n",
    "tests_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import string\n",
    "import time\n",
    "\n",
    "# Ray - Training\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "# General\n",
    "from etils import epath\n",
    "from matplotlib import pyplot as plt\n",
    "from ray.job_submission import JobStatus, JobSubmissionClient\n",
    "# Serving\n",
    "from ray.tune import ExperimentAnalysis\n",
    "from vertex_ray.predict import torch as ray_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFgb-sZbBi8i"
   },
   "source": [
    "###设定变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zykxFjqUB9jt"
   },
   "outputs": [],
   "source": [
    "# training\n",
    "LOGGING_URI = epath.Path(BUCKET_URI) / \"logs\"\n",
    "EXPERIMENT_NAME = \"torch_on_rov\"\n",
    "TRAINING_URI = LOGGING_URI / EXPERIMENT_NAME\n",
    "TRAINING_PATH = deliverables_path / EXPERIMENT_NAME\n",
    "\n",
    "# serving\n",
    "DELIVERABLES_PATH = str(deliverables_path)\n",
    "BUILD_URI = str(epath.Path(BUCKET_URI) / \"build\")\n",
    "DEPLOY_IMAGE_URI = \"us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu.1-11:latest\"\n",
    "MODEL_NAME = \"torch_on_rov_cifar10\"\n",
    "DEPLOY_COMPUTE = \"n1-standard-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYQNboaOBk6B"
   },
   "source": [
    "### 定义辅助程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-bl6h54bqFz"
   },
   "outputs": [],
   "source": [
    "def get_id(k=3):\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=k))\n",
    "\n",
    "\n",
    "def plot_image_sample(test_dataset):\n",
    "    \"\"\"Plots a sample image from the CIFAR-10 dataset.\"\"\"\n",
    "\n",
    "    sample_idx = random.randrange(0, len(test_dataset))\n",
    "    image, _ = test_dataset[sample_idx]\n",
    "    pil_image = transforms.ToPILImage()(image)\n",
    "    plt.imshow(pil_image)\n",
    "    plt.show()\n",
    "\n",
    "    return pil_image\n",
    "\n",
    "\n",
    "def predict_from_image(pil_image, endpoint):\n",
    "    \"\"\"Predicts the class of an image using the given endpoint.\"\"\"\n",
    "    buffered_image = io.BytesIO()\n",
    "    pil_image.save(buffered_image, format=\"JPEG\")\n",
    "\n",
    "    data = {\"data\": base64.b64encode(buffered_image.getvalue()).decode(\"utf-8\")}\n",
    "    response = endpoint.predict(instances=[data])\n",
    "\n",
    "    return response.predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BH0TlP3PtTB"
   },
   "source": [
    "在这个教程中，您将使用Ray在Vertex AI上训练一个自定义图像分类模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qh2BbfWPXglw"
   },
   "source": [
    "#### 准备训练应用程序\n",
    "\n",
    "在开始训练之前，让我们看一下如何组装一个Ray作业来分发您的训练。\n",
    "\n",
    "Ray 2.4.0 使用 `train_loop_per_worker` 函数来执行分布式多工作器训练功能。\n",
    "\n",
    "在设置数据集和模型之后，首先定义您的单工作器PyTorch训练函数，然后将其转换为以下分布式多工作器训练函数：\n",
    "\n",
    "1. 使用 `ray.train.torch.prepare_data_loader` 对数据进行包装，并使用 `DistributedSampler` 进行分布式训练。\n",
    "\n",
    "2. 使用 `ray.train.torch.prepare_model` 函数对模型进行包装，并使用 `DistributedDataParallel` 进行分布式训练。\n",
    "\n",
    "有了多工作器训练函数之后，您需要定义 `ScalingConfig` 来指定期望的工作器数量，并指示分布式训练过程是否需要 GPUs。\n",
    "\n",
    "此外，您可以定义一个 `RunConfig` 来指定检查点和同步行为，以及一些额外的训练循环参数。\n",
    "\n",
    "最后，将所有内容传递给 `TorchTrainer`，Ray 使用它来利用分布式数据并行性（使用 PyTorch 的分布式后端）来分发您的训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pznqJKCpEcL3"
   },
   "source": [
    "### 准备训练脚本\n",
    "\n",
    "文件 `src/task.py` 是执行 Ray 分布式训练作业的 Python 脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCFfhM7RP4RI"
   },
   "outputs": [],
   "source": [
    "training_script = \"\"\"\n",
    "# libraries\n",
    "\n",
    "# general libraries\n",
    "import os\n",
    "import argparse\n",
    "from etils import epath\n",
    "import tempfile\n",
    "\n",
    "# training libraries\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchmetrics.aggregation import MeanMetric\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "\n",
    "# ray libraries\n",
    "import ray\n",
    "from ray import train\n",
    "from ray.train import ScalingConfig, RunConfig, CheckpointConfig, Checkpoint\n",
    "from ray.train.torch import TorchTrainer, TorchCheckpoint\n",
    "\n",
    "\n",
    "# helpers\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "    parser.add_argument('--batch-size', dest='batch_size',\n",
    "                        type=int, default=16, help='Batch size')\n",
    "    parser.add_argument('--epochs', dest='epochs',\n",
    "                        type=int, default=10, help='Number of epochs')\n",
    "    parser.add_argument('--lr', dest='lr',\n",
    "                        type=int, default=1e-3, help='Learning rate')\n",
    "    parser.add_argument('--num-workers', dest='num_workers',\n",
    "                        type=int, default=1, help='Number of workers')\n",
    "    parser.add_argument('--use-gpu', dest='use_gpu', action='store_true',\n",
    "                        default=False, help='Use GPU')\n",
    "    parser.add_argument('--experiment-name', dest='experiment_name', type=str,\n",
    "                        default='cifar10-torch', help='Experiment name')\n",
    "    parser.add_argument('--logging-dir', dest='logging_dir',\n",
    "                        type=str, default='./logs', help='Logging directory')\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "    \n",
    "# Create a simple model\n",
    "class Cifar10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cifar10Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train_epoch(train_loader, model, loss_fn, optimizer, device):\n",
    "    # initiate training\n",
    "    model.train()\n",
    "    train_loss = MeanMetric()\n",
    "    train_accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "    # load metrics to device\n",
    "    train_loss.to(device)\n",
    "    train_accuracy.to(device)\n",
    "\n",
    "    # training loop\n",
    "    for batch, (data, target) in enumerate(train_loader):\n",
    "        # move data to device\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # compute error\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        train_loss.update(loss)\n",
    "        train_accuracy.update(output, target)\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print results\n",
    "        if batch % 100 == 0:\n",
    "            print(f'batch {batch}, loss {loss.item():.4f}')\n",
    "\n",
    "    # compute loss and metrics\n",
    "    train_loss = Tensor.numpy(train_loss.compute(), force=True).item()\n",
    "    train_accuracy = Tensor.numpy(train_accuracy.compute(), force=True).item()\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "\n",
    "def evaluate_epoch(test_loader, model, loss_fn, device):\n",
    "    # initiate evaluation\n",
    "    model.eval()\n",
    "    test_loss = MeanMetric()\n",
    "    test_accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "    # load metrics to device\n",
    "    test_loss.to(device)\n",
    "    test_accuracy.to(device)\n",
    "\n",
    "    # evaluation loop\n",
    "    for batch, (data, target) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            # move data to device\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # get loss and accuracy\n",
    "            output = model(data)\n",
    "            test_loss.update(loss_fn(output, target))\n",
    "            test_accuracy.update(output, target)\n",
    "\n",
    "    # compute loss and metrics\n",
    "    test_loss = Tensor.numpy(test_loss.compute(), force=True).item()\n",
    "    test_accuracy = Tensor.numpy(test_accuracy.compute(), force=True).item()\n",
    "\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    # set configuration\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "    learning_rate = config[\"learning_rate\"]\n",
    "\n",
    "    # get device\n",
    "    device = train.torch.get_device() if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    # read dataset\n",
    "    normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root=\"./train\",\n",
    "                                     transform=transform,\n",
    "                                     train=True, download=True)\n",
    "\n",
    "    test_dataset = datasets.CIFAR10(root=\"./test\",\n",
    "                                    transform=transform,\n",
    "                                    train=False, download=True)\n",
    "\n",
    "    # create data loaders\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "    train_loader = train.torch.prepare_data_loader(train_loader)\n",
    "    test_loader = train.torch.prepare_data_loader(test_loader)\n",
    "\n",
    "    # create model\n",
    "    model = Cifar10Model()\n",
    "    model = train.torch.prepare_model(model)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # train model\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss, train_accuracy = train_epoch(train_loader, model, loss_fn, optimizer, device)\n",
    "        test_loss, test_accuracy = evaluate_epoch(test_loader, model, loss_fn, device)\n",
    "\n",
    "        # report metrics and model checkpoint\n",
    "        train.report(\n",
    "            metrics={\"train_loss\": train_loss, \"train_accuracy\": train_accuracy,\n",
    "                     \"test_loss\": test_loss, \"test_accuracy\": test_accuracy},\n",
    "            checkpoint=TorchCheckpoint.from_state_dict(model.state_dict())\n",
    "        )\n",
    "            \n",
    "            \n",
    "def main():\n",
    "    # set configuration\n",
    "    args = get_args()\n",
    "    config = vars(args)\n",
    "\n",
    "    # initialize ray session\n",
    "    ray.init()\n",
    "\n",
    "    # train model\n",
    "    train_loop_config = {\"learning_rate\": config['lr'], \"batch_size\": config['batch_size'],\n",
    "                         \"epochs\": config['epochs']}\n",
    "    scaling_config = ScalingConfig(num_workers=config['num_workers'], use_gpu=config['use_gpu'])\n",
    "    run_config = RunConfig(checkpoint_config=CheckpointConfig(num_to_keep=1),\n",
    "                           storage_path=config['logging_dir'],\n",
    "                           name=config['experiment_name'])\n",
    "\n",
    "    trainer = TorchTrainer(\n",
    "        train_loop_per_worker=train_loop_per_worker,\n",
    "        train_loop_config=train_loop_config,\n",
    "        run_config=run_config,\n",
    "        scaling_config=scaling_config\n",
    "    )\n",
    "    result = trainer.fit()\n",
    "    print(f\"Last result: {result.metrics}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "with open(src_path / \"task.py\", \"w\") as f:\n",
    "    f.write(training_script)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AOOmNti23qc"
   },
   "source": [
    "### 准备`requirements`文件\n",
    "\n",
    "`requirements.txt`文件包含你的Ray应用程序运行所需的依赖项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83KUQQylbrJR"
   },
   "outputs": [],
   "source": [
    "requirements = \"\"\"\n",
    "importlib_resources==6.1.1\n",
    "etils==1.5.2\n",
    "ray[data]==2.9.3\n",
    "ray[train]==2.9.3\n",
    "ray[tune]==2.9.3\n",
    "torch==2.1.2\n",
    "torchvision==0.16.2\n",
    "torchmetrics==1.2.1\n",
    "\"\"\"\n",
    "\n",
    "with open(tutorial_path / \"requirements.txt\", \"w\") as f:\n",
    "    f.write(requirements)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYcmfEvZ3C1i"
   },
   "source": [
    "使用Ray Jobs API提交一个Ray作业\n",
    "\n",
    "使用Ray Jobs API将脚本提交到Vertex AI上的Ray集群，并使用公共Ray仪表板地址。\n",
    "\n",
    "需要强调的是，如果您更喜欢以编程方式提交作业，Ray Jobs API是首选选项。如果您更喜欢交互式的Python开发环境，也可以使用Ray on Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPRtGm9IJ09g"
   },
   "source": [
    "启动客户提交工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FljDHRQ63EP4"
   },
   "outputs": [],
   "source": [
    "client = JobSubmissionClient(address=f\"vertex_ray://{ray_cluster.dashboard_address}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDHIlGlQJ2oi"
   },
   "source": [
    "提交工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myMOWdlV3rp_"
   },
   "outputs": [],
   "source": [
    "id = get_id()\n",
    "\n",
    "job_id = client.submit_job(\n",
    "    submission_id=f\"ray-job-{TIMESTAMP}-{id}\",\n",
    "    entrypoint=f\"python3 task.py --experiment-name={EXPERIMENT_NAME} --num-workers=2 --logging-dir={LOGGING_URI}\",\n",
    "    runtime_env={\n",
    "        \"pip\": {\"packages\": str(tutorial_path / \"requirements.txt\")},\n",
    "        \"working_dir\": str(src_path),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viL5MsRTJ5Df"
   },
   "source": [
    "检查工作状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TnQfy6VK5pvr"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    job_status = client.get_job_status(job_id)\n",
    "    if job_status == JobStatus.SUCCEEDED:\n",
    "        print(\"Job succeeded!\")\n",
    "        break\n",
    "    else:\n",
    "        if job_status == JobStatus.FAILED:\n",
    "            print(\"Job failed!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Job is running...\")\n",
    "            time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67FI31SqKFdF"
   },
   "source": [
    "### 检查模型产物\n",
    "\n",
    "当Ray训练作业完成后，在Cloud Storage位置中检查模型产物。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_JOYhXQKK8U"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -l {TRAINING_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKUOXlN-MBaU"
   },
   "source": [
    "## 提供 PyTorch 模型\n",
    "\n",
    "您可以通过以下方式在 Vertex AI 上使用 TorchServe 来提供 PyTorch 模型：\n",
    "\n",
    "1. 下载 Ray 训练检查点。\n",
    "2. 从 Ray TorchCheckpoint 中获取 PyTorch 模型。\n",
    "3. 使用 Torch Model Archiver 工具，封装训练好的模型工件，包括模型工件、模型模块和自定义处理程序，创建一个存档文件。\n",
    "4. 在 Vertex AI Model Registry 中注册模型。\n",
    "5. 将模型部署到 Vertex AI 端点以进行预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fN5YQ60PXbYq"
   },
   "source": [
    "### 下载Ray训练检查点\n",
    "\n",
    "下载Ray训练作业的所有结果检查点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBf0_agLhrLV"
   },
   "outputs": [],
   "source": [
    "! gsutil -q cp -r {TRAINING_URI} {DELIVERABLES_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VavpxaY1hlSN"
   },
   "source": [
    "### 获取最佳训练检查点\n",
    "\n",
    "使用`ExperimentAnalysis`来根据相关指标和模式检索最佳检查点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUBEKpK1gVx9"
   },
   "outputs": [],
   "source": [
    "experiment_analysis = ExperimentAnalysis(TRAINING_PATH)\n",
    "log_path = experiment_analysis.get_best_trial(metric=\"test_accuracy\", mode=\"max\")\n",
    "best_checkpoint = experiment_analysis.get_best_checkpoint(\n",
    "    log_path, metric=\"test_accuracy\", mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bf2YPC5nlzjL"
   },
   "source": [
    "使用Ray TorchCheckpoint从PyTorch模型。将TorchCheckpoint转换为PyTorch模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78577f79de54"
   },
   "outputs": [],
   "source": [
    "class Cifar10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cifar10Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_definition = Cifar10Model()\n",
    "torch_model = ray_torch.get_pytorch_model_from(best_checkpoint, model=model_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CY5AV09xm0dl"
   },
   "source": [
    "### 构建PyTorch模型存档（.mar）文件\n",
    "\n",
    "TorchServe允许您通过将所有模型工件打包到单个模型存档文件中来提供Torch模型。 在这种情况下，需要以下信息来创建一个独立的模型存档：\n",
    "\n",
    "1. 序列化文件\n",
    "2. 模型文件\n",
    "3. 处理程序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvfiYnrZ63iN"
   },
   "source": [
    "保留模型\n",
    "\n",
    "`model.pt` 包含模型的 state_dict。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLR_MZS_tXuq"
   },
   "outputs": [],
   "source": [
    "torch.save(torch_model.state_dict(), build_path / \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vl-xT_zDmOvg"
   },
   "source": [
    "#### 创建`model`模块\n",
    "\n",
    "`model.py`文件应包含模型架构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nT9Szm-LA8Uh"
   },
   "outputs": [],
   "source": [
    "model_script = \"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Cifar10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cifar10Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\"\"\"\n",
    "\n",
    "with open(build_path / \"model.py\", \"w\") as model_file:\n",
    "    model_file.write(model_script)\n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5Jc76AmBP-C"
   },
   "source": [
    "#### 创建 `custom_handler` 模块\n",
    "\n",
    "`custom_handler.py` 文件使用 TorchServe 内置的 `image_classifier` 处理程序名称来处理自定义 TorchServe 推理逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDpXiVHnBPJ-"
   },
   "outputs": [],
   "source": [
    "custom_handler_script = '''\n",
    "# Based on https://github.com/pytorch/serve/blob/master/examples/image_classifier/mnist/mnist_handler.py\n",
    "\n",
    "from torchvision import transforms\n",
    "from ts.torch_handler.image_classifier import ImageClassifier\n",
    "from torch.profiler import ProfilerActivity\n",
    "\n",
    "\n",
    "class Cifar10Classifier(ImageClassifier):\n",
    "    \"\"\"\n",
    "    Cifar10Classifier handler class. This handler extends ImageClassifier class\n",
    "    \"\"\"\n",
    "\n",
    "    label_names = [\n",
    "        \"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "    ]\n",
    "\n",
    "    image_processing = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Cifar10Classifier, self).__init__()\n",
    "        self.profiler_args = {\n",
    "            \"activities\": [ProfilerActivity.CPU],\n",
    "            \"record_shapes\": True,\n",
    "        }\n",
    "\n",
    "    def postprocess(self, data):\n",
    "        \"\"\"\n",
    "        Post-process function to convert the predicted class id to label\n",
    "        \"\"\"\n",
    "        predictions = data.argmax(1).tolist()\n",
    "        return [self.label_names[pred] for pred in predictions]\n",
    "\n",
    "'''\n",
    "\n",
    "with open(build_path / \"custom_handler.py\", \"w\") as custom_handler_file:\n",
    "    custom_handler_file.write(custom_handler_script)\n",
    "custom_handler_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2YY73mBByKt"
   },
   "source": [
    "使用Torch模型归档工具将模型产品打包到一个模型归档文件（.mar）中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVzPb0oxETee"
   },
   "outputs": [],
   "source": [
    "build_script = \"\"\"\n",
    "torch-model-archiver -f --model-name cifar10 \\\n",
    "    --version 1.0  \\\n",
    "    --model-file model.py \\\n",
    "    --serialized-file model.pt \\\n",
    "    --handler custom_handler.py \\\n",
    "    --export-path .\n",
    "\"\"\"\n",
    "\n",
    "with open(build_path / \"build.sh\", \"w\") as build_file:\n",
    "    build_file.write(build_script)\n",
    "build_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d09sIVOaCFQE"
   },
   "outputs": [],
   "source": [
    "! cd {str(build_path)} && chmod +x ./build.sh && ./build.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zljbquGFtHP"
   },
   "source": [
    "#### 将 `mar` 文件上传到存储桶\n",
    "\n",
    "将 .mar 文件存储到云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPejvg6uFzBG"
   },
   "outputs": [],
   "source": [
    "!gsutil cp {str(build_path)}/cifar10.mar {BUILD_URI}/model.mar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yi3I6JotDw3k"
   },
   "source": [
    "在Vertex AI模型注册表中注册模型作为模型资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kyOITop38H7"
   },
   "outputs": [],
   "source": [
    "registered_model = vertex_ai.Model.upload(\n",
    "    display_name=MODEL_NAME,\n",
    "    serving_container_image_uri=DEPLOY_IMAGE_URI,\n",
    "    artifact_uri=BUILD_URI,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ko3IfZgbEG1J"
   },
   "source": [
    "### 部署模型以进行预测\n",
    "\n",
    "创建一个 Vertex AI 终端节点，并部署注册的模型以进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSukFOf04IMv"
   },
   "outputs": [],
   "source": [
    "endpoint = registered_model.deploy(\n",
    "    deployed_model_display_name=MODEL_NAME,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    accelerator_type=None,\n",
    "    accelerator_count=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzHtXzv0E2sg"
   },
   "source": [
    "进行在线预测\n",
    "\n",
    "从`CIFAR10`数据集中抽样一张图片以获取在线预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdRjvCOX4hVn"
   },
   "outputs": [],
   "source": [
    "test_dataset = datasets.CIFAR10(\n",
    "    root=tests_path / \"data\",\n",
    "    transform=transforms.ToTensor(),\n",
    "    train=False,\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFuZC39WbIJL"
   },
   "source": [
    "将采样图像可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDWLHAuPWo_7"
   },
   "outputs": [],
   "source": [
    "pil_image = plot_image_sample(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeuZLWpRbLyT"
   },
   "source": [
    "发送一个预测请求并获取预测的类别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPqDTh184fM0"
   },
   "outputs": [],
   "source": [
    "predictions = predict_from_image(pil_image, endpoint)\n",
    "\n",
    "for pred in predictions:\n",
    "    print(\"Predicted class:\", pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于本教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在此教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "delete_endpoint = False\n",
    "delete_model = False\n",
    "delete_ray_cluster = False\n",
    "delete_bucket = False\n",
    "delete_tutorial = False\n",
    "\n",
    "# Delete endpoint resource\n",
    "if delete_endpoint or os.getenv(\"IS_TESTING\"):\n",
    "    endpoint.delete(force=True)\n",
    "\n",
    "# Delete model resource\n",
    "if delete_model or os.getenv(\"IS_TESTING\"):\n",
    "    registered_model.delete()\n",
    "\n",
    "# Delete ray on vertex cluster\n",
    "if delete_ray_cluster or os.getenv(\"IS_TESTING\"):\n",
    "    vertex_ray.delete_ray_cluster(ray_cluster.cluster_resource_name)\n",
    "\n",
    "# Delete tutorial folder\n",
    "if delete_tutorial or os.getenv(\"IS_TESTING\"):\n",
    "    shutil.rmtree(tutorial_path)\n",
    "\n",
    "# Delete Cloud Storage objects that were created\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil -q -m rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_with_pytorch_rov.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
