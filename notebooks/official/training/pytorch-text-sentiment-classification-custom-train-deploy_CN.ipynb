{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18ebbd838e32"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16f0f41c2f9c"
   },
   "source": [
    "# 在 Vertex AI 上培训、调整和部署 PyTorch 文本情感分类模型\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_evaluation/model_based_llm_evaluation/autosxs_check_alignment_against_human_preference_data.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> 在 Colab 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Ftraining%2Fpytorch-text-sentiment-classification-custom-train-deploy.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> 在 Colab Enterprise 中打开\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/training/pytorch-text-sentiment-classification-custom-train-deploy.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> 在 Workbench 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/pytorch-text-sentiment-classification-custom-train-deploy.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> 在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4339ebfdf7a0"
   },
   "source": [
    "## 概览\n",
    "\n",
    "本笔记本演示了如何使用 Vertex AI 和 Pytorch SDK 对一个预训练的 [BERT](https://huggingface.co/bert-base-cased) 模型进行微调，构建并部署一个文本情感分类模型。这个示例受到了 Hugging Face 的 [Token_Classification](https://github.com/huggingface/notebooks/blob/master/examples/token_classification.ipynb) 和 [Run_Glue](https://github.com/huggingface/transformers/blob/v2.5.0/examples/run_glue.py) 笔记本的启发。\n",
    "\n",
    "您可以在[Hugging Face Hub](https://huggingface.co/bert-base-cased)找到有关该模型的更多详细信息。想要了解更多使用最先进的 PyTorch/Tensorflow/JAX 的笔记本，请探索 [Hugging FaceNotebooks](https://huggingface.co/transformers/notebooks.html)。\n",
    "\n",
    "了解更多关于[自定义训练](https://cloud.google.com/vertex-ai/docs/training/custom-training)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9283a2954aef"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何在[Vertex AI](https://cloud.google.com/vertex-ai)上构建、训练、调整和部署一个PyTorch模型。您主要关注Vertex AI上对自定义模型训练和部署的支持。\n",
    "\n",
    "\n",
    "此教程使用以下谷歌云机器学习服务：\n",
    "\n",
    "- Vertex AI `工作台`\n",
    "- Vertex AI `训练`（自定义Python包训练）\n",
    "- Vertex AI `模型注册`\n",
    "- Vertex AI `端点`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 为文本分类模型创建训练包。\n",
    "- 在Vertex AI上进行自定义训练模型。\n",
    "- 检查创建的模型工件。\n",
    "- 为预测创建一个自定义容器。\n",
    "- 使用自定义容器将训练好的模型部署到Vertex AI端点。\n",
    "- 发送在线预测请求到部署的模型并验证。\n",
    "- 清理本笔记本中创建的资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab69c72f7c47"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是来自[Kaggle数据集](https://www.kaggle.com/ritresearch/happydb)的[Happy Moments数据集](https://www.kaggle.com/ritresearch/happydb)。在本教程中使用的数据集版本存储在公共云存储桶中。\n",
    "\n",
    "有关该数据集的更多信息可以在[HappyDB网站](https://rit-public.github.io/HappyDB/)找到。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "181d4dfbf917"
   },
   "source": [
    "### 成本\n",
    "\n",
    "本教程使用谷歌云的计费组件：\n",
    "\n",
    "- Vertex AI\n",
    "- 云存储\n",
    "- 云构建\n",
    "- Artifact Registry\n",
    "\n",
    "了解[Vertex AI 定价](https://cloud.google.com/vertex-ai/pricing)、[云存储定价](https://cloud.google.com/storage/pricing)、[云构建定价](https://cloud.google.com/build/pricing)、[Artifact Registry 定价](https://cloud.google.com/artifact-registry/pricing) ，并使用[定价计算器](https://cloud.google.com/products/calculator/) 生成一个基于您预期使用量的成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a571eed9ece"
   },
   "source": [
    "开始吧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### 为 Python 安装 Vertex AI SDK 和其他必需的软件包。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3848df1e5b0"
   },
   "source": [
    "## 安装\n",
    "\n",
    "安装执行此笔记本所需的软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f967c29cbed"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### 重新启动运行时（仅适用于Colab）\n",
    "\n",
    "为了使用新安装的软件包，您必须重新启动Google Colab上的运行时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRvKdaPDTznN"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54c5ef8a8f43"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️内核即将重新启动。请等待它完成后再继续下一步。⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f82e28c631cc"
   },
   "source": [
    "### 在谷歌 Colab 上验证您的笔记本环境\n",
    "\n",
    "在谷歌 Colab 上验证您的环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46604f70e831"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef3990d0482a"
   },
   "source": [
    "### 设置Google Cloud项目信息并初始化Python版Vertex AI SDK\n",
    "\n",
    "要开始使用Vertex AI，您必须拥有一个现有的Google Cloud项目并[启用Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。了解有关[设置项目和开发环境](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b45b2839f8b9"
   },
   "source": [
    "UUID\n",
    "\n",
    "如果您正在参加现场教程会话，您可能会使用共享测试账户或项目。为了避免资源创建时用户之间的名称冲突，为每个实例会话创建一个uuid，并将uuid附加到您在本教程中创建的资源名称上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e80050370d51"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产物，例如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有当您的存储桶尚不存在时：运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $LOCATION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "###引入库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poijnGfZCFYi"
   },
   "source": [
    "导入Vertex AI Python SDK和其他所需的Python库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "528bfbda0197"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf.json_format import MessageToDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d0f7629c309"
   },
   "source": [
    "定义常数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "290fd65fc20c"
   },
   "source": [
    "定义本教程所需的常数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9022ff0e121b"
   },
   "outputs": [],
   "source": [
    "# Name for the package application / model / repository\n",
    "APP_NAME = \"finetuned-bert-classifier\"\n",
    "\n",
    "# URI for the pre-built container for custom training\n",
    "PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.1-11:latest\"\n",
    ")\n",
    "\n",
    "# Name of the folder where the python package needs to be stored\n",
    "PYTHON_PACKAGE_APPLICATION_DIR = \"python_package\"\n",
    "\n",
    "# Path to the source distribution tar of the python package\n",
    "source_package_file_name = f\"{PYTHON_PACKAGE_APPLICATION_DIR}/dist/trainer-0.1.tar.gz\"\n",
    "\n",
    "# GCS path where the python package is stored\n",
    "python_package_gcs_uri = (\n",
    "    f\"{BUCKET_URI}/pytorch-on-gcp/{APP_NAME}/train/python_package/trainer-0.1.tar.gz\"\n",
    ")\n",
    "\n",
    "# Module name for training application\n",
    "python_module_name = \"trainer.task\"\n",
    "\n",
    "# Training job's display name\n",
    "JOB_NAME = f\"{APP_NAME}-pytorch-pkg-train-{UUID}\"\n",
    "\n",
    "# Set training job's machine-type\n",
    "TRAIN_MACHINE_TYPE = \"n1-standard-8\"\n",
    "# Set training job's accelerator type\n",
    "TRAIN_ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
    "# Set no. of h/w accelerators needed for the training job\n",
    "TRAIN_ACCELERATOR_COUNT = 1\n",
    "\n",
    "# Set the name of the container image for prediction\n",
    "CUSTOM_PREDICTOR_IMAGE_URI = f\"{LOCATION}-docker.pkg.dev/{PROJECT_ID}/{APP_NAME}/pytorch_predict_{APP_NAME}:latest\"\n",
    "\n",
    "# Set the version for model-deployment\n",
    "VERSION = 1\n",
    "# Set the model display name\n",
    "model_display_name = f\"{APP_NAME}-v{VERSION}\"\n",
    "# Set the model description\n",
    "model_description = \"PyTorch based text classifier with custom container\"\n",
    "\n",
    "# Set the health route for prediction container\n",
    "health_route = \"/ping\"\n",
    "# Set the predict route for prediction container\n",
    "predict_route = f\"/predictions/{APP_NAME}\"\n",
    "# Set the serving container ports for prediction\n",
    "serving_container_ports = [7080]\n",
    "\n",
    "# Set the display name for endpoint\n",
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "# Set the machine-type for deployment\n",
    "DEPLOY_MACHINE_TYPE = \"n1-standard-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d31e7ad1192"
   },
   "source": [
    "### 为Python初始化Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0d689f14d93c"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d52388cb4fd"
   },
   "source": [
    "### 定制Vertex AI培训\n",
    "\n",
    "__推荐的培训应用程序结构__\n",
    "\n",
    "您可以按照自己喜欢的方式构建培训应用程序。然而，[以下结构](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container#structure)通常在Vertex AI示例中使用，并且将项目组织得类似可以让您更容易地跟随示例。\n",
    "\n",
    "以下`python_package`目录结构展示了一个示例打包方法。\n",
    "\n",
    "```\n",
    "├── python_package\n",
    "│   ├── setup.py\n",
    "│   └── trainer\n",
    "│       ├── __init__.py\n",
    "│       ├── experiment.py\n",
    "│       ├── metadata.py\n",
    "│       ├── model.py\n",
    "│       ├── task.py\n",
    "│       └── utils.py\n",
    "└── pytorch-text-sentiment-classification-custom-train-deploy.ipynb    --> 这个笔记本\n",
    "```\n",
    "\n",
    "* 主项目目录包含您的`setup.py`文件以及依赖项。\n",
    "* 在`trainer`目录中：\n",
    "   - `task.py` - 主应用程序模块初始化并解析任务参数（超参数）。它也作为训练器的入口点。\n",
    "   - `model.py` - 包括一个从预训练模型创建具有序列分类头的模型的函数。\n",
    "   - `experiment.py` - 运行模型训练和评估实验，并导出最终模型。\n",
    "   - `metadata.py` - 定义用于分类任务的元数据，如预定义模型、数据集名称和目标标签。\n",
    "   - `utils.py` - 包括实用函数，例如用于读取数据、将模型保存到云存储桶等函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ae8e41b828e1"
   },
   "source": [
    "### 为 Python 软件包创建所需的文件\n",
    "\n",
    "为 Python 软件包创建目录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d257b5c3c6b4"
   },
   "outputs": [],
   "source": [
    "!mkdir -p python_package/trainer\n",
    "!mkdir -p python_package/scripts\n",
    "!touch ./python_package/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "854420bdf10a"
   },
   "source": [
    "创建`model.py`文件，该文件返回指定的预训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "112375025f5f"
   },
   "outputs": [],
   "source": [
    "%%writefile ./python_package/trainer/model.py\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from trainer import metadata\n",
    "\n",
    "def create(num_labels):\n",
    "    \"\"\"create the model by loading a pretrained model or define your \n",
    "    own\n",
    "\n",
    "    Args:\n",
    "      num_labels: number of target labels\n",
    "    \"\"\"\n",
    "    # Create the model, loss function, and optimizer\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        metadata.PRETRAINED_MODEL_NAME,\n",
    "        num_labels=num_labels\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fb1f3dfe245"
   },
   "source": [
    "创建`utils.py`文件，定义用于数据加载、预处理和模型保存的实用函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d34c987cdb27"
   },
   "outputs": [],
   "source": [
    "%%writefile ./python_package/trainer/utils.py\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset, load_metric, ReadInstruction, DatasetDict, Dataset\n",
    "from trainer import metadata\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        metadata.PRETRAINED_MODEL_NAME,\n",
    "        use_fast=True,\n",
    "    )\n",
    "    \n",
    "    # Tokenize the texts\n",
    "    tokenizer_args = (\n",
    "        (examples['text'],) \n",
    "    )\n",
    "    result = tokenizer(*tokenizer_args, \n",
    "                       padding='max_length', \n",
    "                       max_length=metadata.MAX_SEQ_LENGTH, \n",
    "                       truncation=True)\n",
    "    \n",
    "    # We can extract this automatically but the unique() method of the dataset\n",
    "    # is not reporting the label -1 which shows up in the pre-processing\n",
    "    # hence the additional -1 term in the dictionary\n",
    "    \n",
    "    label_to_id = metadata.TARGET_LABELS\n",
    "    \n",
    "    # Map labels to IDs (not necessary for GLUE tasks)\n",
    "    if label_to_id is not None and \"label\" in examples:\n",
    "        result[\"label\"] = [label_to_id[l] for l in examples[\"label\"]]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def load_data(args):\n",
    "    \"\"\"Loads the data into two different data loaders. (Train, Test)\n",
    "\n",
    "        Args:\n",
    "            args: arguments passed to the python script\n",
    "    \"\"\"\n",
    "    # dataset loading repeated here to make this cell idempotent\n",
    "    # since we are over-writing datasets variable\n",
    "    \n",
    "    df_train = pd.read_csv(metadata.TRAIN_DATA)\n",
    "    df_test = pd.read_csv(metadata.TEST_DATA)\n",
    "    \n",
    "    dataset = DatasetDict({\"train\": Dataset.from_pandas(df_train),\"test\": Dataset.from_pandas(df_test)})\n",
    "\n",
    "    dataset = dataset.map(preprocess_function, \n",
    "                          batched=True, \n",
    "                          load_from_cache_file=True)\n",
    "\n",
    "    train_dataset, test_dataset = dataset[\"train\"], dataset[\"test\"]\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "def save_model(args):\n",
    "    \"\"\"Saves the model to Google Cloud Storage or local file system\n",
    "\n",
    "    Args:\n",
    "      args: contains name for saved model.\n",
    "    \"\"\"\n",
    "    scheme = 'gs://'\n",
    "    if args.job_dir.startswith(scheme):\n",
    "        job_dir = args.job_dir.split(\"/\")\n",
    "        bucket_name = job_dir[2]\n",
    "        object_prefix = \"/\".join(job_dir[3:]).rstrip(\"/\")\n",
    "\n",
    "        if object_prefix:\n",
    "            model_path = '{}/{}'.format(object_prefix, args.model_name)\n",
    "        else:\n",
    "            model_path = '{}'.format(args.model_name)\n",
    "\n",
    "        bucket = storage.Client().bucket(bucket_name)    \n",
    "        local_path = os.path.join(\"/tmp\", args.model_name)\n",
    "        files = [f for f in os.listdir(local_path) if os.path.isfile(os.path.join(local_path, f))]\n",
    "        for file in files:\n",
    "            local_file = os.path.join(local_path, file)\n",
    "            blob = bucket.blob(\"/\".join([model_path, file]))\n",
    "            blob.upload_from_filename(local_file)\n",
    "        print(f\"Saved model files in gs://{bucket_name}/{model_path}\")\n",
    "    else:\n",
    "        print(f\"Saved model files at {os.path.join('/tmp', args.model_name)}\")\n",
    "        print(f\"To save model files in GCS bucket, please specify job_dir starting with gs://\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f048e99def15"
   },
   "source": [
    "为训练应用程序中使用的常量定义创建`metadata.py`文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30715ff75292"
   },
   "outputs": [],
   "source": [
    "%%writefile ./python_package/trainer/metadata.py\n",
    "\n",
    "# Task type can be either 'classification', 'regression', or 'custom'.\n",
    "# This is based on the target feature in the dataset.\n",
    "TASK_TYPE = 'classification'\n",
    "\n",
    "# Dataset paths\n",
    "    \n",
    "TRAIN_DATA = \"gs://cloud-samples-data/ai-platform-unified/datasets/text/happydb/happydb_train.csv\"\n",
    "TEST_DATA = \"gs://cloud-samples-data/ai-platform-unified/datasets/text/happydb/happydb_test.csv\"\n",
    "\n",
    "# pre-trained model name\n",
    "PRETRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "\n",
    "# List of the class values (labels) in a classification dataset.\n",
    "TARGET_LABELS = {\"leisure\": 0, \"exercise\":1, \"enjoy_the_moment\":2, \"affection\":3,\"achievement\":4, \"nature\":5, \"bonding\":6}\n",
    "\n",
    "\n",
    "# maximum sequence length\n",
    "MAX_SEQ_LENGTH = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26e7322f4639"
   },
   "source": [
    "创建一个名为`experiment.py`的文件，定义用于超参数调整和训练的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "049f50cd8671"
   },
   "outputs": [],
   "source": [
    "%%writefile ./python_package/trainer/experiment.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import hypertune\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    EvalPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    TrainerCallback\n",
    ")\n",
    "\n",
    "from trainer import model, metadata, utils\n",
    "\n",
    "\n",
    "class HPTuneCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    A custom callback class that reports a metric to hypertuner\n",
    "    at the end of each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, metric_tag, metric_value):\n",
    "        super(HPTuneCallback, self).__init__()\n",
    "        self.metric_tag = metric_tag\n",
    "        self.metric_value = metric_value\n",
    "        self.hpt = hypertune.HyperTune()\n",
    "        \n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        print(f\"HP metric {self.metric_tag}={kwargs['metrics'][self.metric_value]}\")\n",
    "        self.hpt.report_hyperparameter_tuning_metric(\n",
    "            hyperparameter_metric_tag=self.metric_tag,\n",
    "            metric_value=kwargs['metrics'][self.metric_value],\n",
    "            global_step=state.epoch)\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}\n",
    "\n",
    "\n",
    "def train(args, model, train_dataset, test_dataset):\n",
    "    \"\"\"Create the training loop to load pretrained model and tokenizer and \n",
    "    start the training process\n",
    "\n",
    "    Args:\n",
    "      args: read arguments from the runner to set training hyperparameters\n",
    "      model: The neural network that you are training\n",
    "      train_dataset: The training dataset\n",
    "      test_dataset: The test dataset for evaluation\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        metadata.PRETRAINED_MODEL_NAME,\n",
    "        use_fast=True,\n",
    "    )\n",
    "    \n",
    "    # set training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=args.learning_rate,\n",
    "        per_device_train_batch_size=args.batch_size,\n",
    "        per_device_eval_batch_size=args.batch_size,\n",
    "        num_train_epochs=args.num_epochs,\n",
    "        weight_decay=args.weight_decay,\n",
    "        output_dir=os.path.join(\"/tmp\", args.model_name)\n",
    "    )\n",
    "    \n",
    "    # initialize our Trainer\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        data_collator=default_data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    # add hyperparameter tuning callback to report metrics when enabled\n",
    "    if args.hp_tune == \"y\":\n",
    "        trainer.add_callback(HPTuneCallback(\"accuracy\", \"eval_accuracy\"))\n",
    "    \n",
    "    # training\n",
    "    trainer.train()\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "\n",
    "def run(args):\n",
    "    \"\"\"Load the data, train, evaluate, and export the model for serving and\n",
    "     evaluating.\n",
    "\n",
    "    Args:\n",
    "      args: experiment parameters.\n",
    "    \"\"\"\n",
    "    # Open our dataset\n",
    "    train_dataset, test_dataset = utils.load_data(args)\n",
    "\n",
    "    label_list = train_dataset.unique(\"label\")\n",
    "    num_labels = len(label_list)\n",
    "    \n",
    "    # Create the model, loss function, and optimizer\n",
    "    text_classifier = model.create(num_labels=num_labels)\n",
    "    \n",
    "    # Train / Test the model\n",
    "    trainer = train(args, text_classifier, train_dataset, test_dataset)\n",
    "\n",
    "    metrics = trainer.evaluate(eval_dataset=test_dataset)\n",
    "    trainer.save_metrics(\"all\", metrics)\n",
    "\n",
    "    # Export the trained model\n",
    "    trainer.save_model(os.path.join(\"/tmp\", args.model_name))\n",
    "\n",
    "    # Save the model to GCS\n",
    "    if args.job_dir:\n",
    "        utils.save_model(args)\n",
    "    else:\n",
    "        print(f\"Saved model files at {os.path.join('/tmp', args.model_name)}\")\n",
    "        print(f\"To save model files in GCS bucket, please specify job_dir starting with gs://\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aad46cadaaa"
   },
   "source": [
    "创建`task.py`文件，这是运行训练应用的主文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ad78a00cba1"
   },
   "outputs": [],
   "source": [
    "%%writefile ./python_package/trainer/task.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from trainer import experiment\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    \"\"\"Define the task arguments with the default values.\n",
    "\n",
    "    Returns:\n",
    "        experiment parameters\n",
    "    \"\"\"\n",
    "    args_parser = argparse.ArgumentParser()\n",
    "\n",
    "\n",
    "    # Experiment arguments\n",
    "    args_parser.add_argument(\n",
    "        '--batch-size',\n",
    "        help='Batch size for each training and evaluation step.',\n",
    "        type=int,\n",
    "        default=16)\n",
    "    args_parser.add_argument(\n",
    "        '--num-epochs',\n",
    "        help=\"\"\"\\\n",
    "        Maximum number of training data epochs on which to train.\n",
    "        If both --train-size and --num-epochs are specified,\n",
    "        --train-steps are: (train-size/train-batch-size) * num-epochs.\\\n",
    "        \"\"\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "    )\n",
    "    args_parser.add_argument(\n",
    "        '--seed',\n",
    "        help='Random seed (default: 42)',\n",
    "        type=int,\n",
    "        default=42,\n",
    "    )\n",
    "\n",
    "    # Estimator arguments\n",
    "    args_parser.add_argument(\n",
    "        '--learning-rate',\n",
    "        help='Learning rate value for the optimizers.',\n",
    "        default=2e-5,\n",
    "        type=float)\n",
    "    args_parser.add_argument(\n",
    "        '--weight-decay',\n",
    "        help=\"\"\"\n",
    "      The factor by which the learning rate should decay by the end of the\n",
    "      training.\n",
    "\n",
    "      decayed_learning_rate =\n",
    "        learning_rate * decay_rate ^ (global_step / decay_steps)\n",
    "\n",
    "      If set to 0 (default), then no decay occurs.\n",
    "      If set to 0.5, then the learning rate should reach 0.5 of its original\n",
    "          value at the end of the training.\n",
    "      Note that decay_steps is set to train_steps.\n",
    "      \"\"\",\n",
    "        default=0.01,\n",
    "        type=float)\n",
    "\n",
    "    # Enable hyperparameter\n",
    "    args_parser.add_argument(\n",
    "        '--hp-tune',\n",
    "        default=\"n\",\n",
    "        help='Enable hyperparameter tuning. Valida values are: \"y\" - enable, \"n\" - disable')\n",
    "    \n",
    "    # Saved model arguments\n",
    "    args_parser.add_argument(\n",
    "        '--job-dir',\n",
    "        default=os.getenv('AIP_MODEL_DIR'),\n",
    "        help='GCS location to export models')\n",
    "    args_parser.add_argument(\n",
    "        '--model-name',\n",
    "        default=\"finetuned-bert-classifier\",\n",
    "        help='The name of your saved model')\n",
    "\n",
    "    return args_parser.parse_args()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Setup / Start the experiment\n",
    "    \"\"\"\n",
    "    args = get_args()\n",
    "    print(args)\n",
    "    experiment.run(args)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92a191c72823"
   },
   "source": [
    "以下是用于训练应用程序的`setup.py`文件。`setup.py`文件内的`find_packages()`函数包括`trainer`目录在包内，因为它包含`__init__.py`，告诉 [Python Setuptools](https://setuptools.readthedocs.io/en/latest/) 将父目录的所有子目录包含为依赖项。\n",
    "\n",
    "在`setup.py`中，您还需要指定用于训练应用程序的Python包，例如`transformers`、`datasets`、`cloudml-hypertune`和`tqdm`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1b4a2de28849"
   },
   "outputs": [],
   "source": [
    "%%writefile ./{PYTHON_PACKAGE_APPLICATION_DIR}/setup.py\n",
    "\n",
    "from setuptools import find_packages\n",
    "from setuptools import setup\n",
    "import setuptools\n",
    "\n",
    "from distutils.command.build import build as _build\n",
    "import subprocess\n",
    "\n",
    "\n",
    "REQUIRED_PACKAGES = [\n",
    "    'transformers',\n",
    "    'datasets',\n",
    "    'tqdm',\n",
    "    'cloudml-hypertune'\n",
    "]\n",
    "\n",
    "setup(\n",
    "    name='trainer',\n",
    "    version='0.1',\n",
    "    install_requires=REQUIRED_PACKAGES,\n",
    "    packages=find_packages(),\n",
    "    include_package_data=True,\n",
    "    description='Vertex AI | Training | PyTorch | Text Classification | Python Package'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf62c83bdcbc"
   },
   "source": [
    "运行以下命令以创建源代码分发。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11d1299bcc12"
   },
   "outputs": [],
   "source": [
    "!cd {PYTHON_PACKAGE_APPLICATION_DIR} && python3 setup.py sdist --formats=gztar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e61169bcd7a"
   },
   "source": [
    "现在将带有训练应用程序的源分发上传至云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bff74cab1888"
   },
   "outputs": [],
   "source": [
    "!gsutil cp {source_package_file_name} {python_package_gcs_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d00f9beaba7"
   },
   "source": [
    "验证源分发在云存储桶中存在。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "376bc46aa1e0"
   },
   "outputs": [],
   "source": [
    "!gsutil ls -l {python_package_gcs_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88e4fd6394a0"
   },
   "source": [
    "### 在Vertex AI中使用预构建容器运行自定义作业\n",
    "\n",
    "在这个笔记本中，您将使用Hugging Face Datasets并使用PyTorch fine-tuning Hugging Face Transformers库中的transformer模型进行情感分析任务。您无需从头开始构建PyTorch环境来运行训练应用程序，因为Vertex AI提供了[预构建容器](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers#available_container_images)。\n",
    "\n",
    "Vertex AI预构建容器是Docker容器镜像，可用于自定义训练。它们包括基于机器学习框架和框架版本的训练代码中使用的一些常见依赖项。\n",
    "\n",
    "您将使用[PyTorch的预构建容器](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers#pytorch)和打包的训练应用程序在Vertex AI上运行训练作业。\n",
    "\n",
    "使用[PyTorch预构建容器](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers#pytorch)和打包为Python源分发的训练代码配置一个[Custom Job](https://cloud.google.com/vertex-ai/docs/training/create-custom-job)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c87d5618d366"
   },
   "outputs": [],
   "source": [
    "job = aiplatform.CustomPythonPackageTrainingJob(\n",
    "    display_name=JOB_NAME,\n",
    "    python_package_gcs_uri=python_package_gcs_uri,\n",
    "    python_module_name=python_module_name,\n",
    "    container_uri=PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfe709ea0a2f"
   },
   "source": [
    "使用以下参数运行自定义训练作业：\n",
    "- `machine_type`：作业需要在其中运行的机器类型。\n",
    "- `accelerator_type`：用于运行作业的硬件加速器类型。其中之一为_ACCELERATOR_TYPE_UNSPECIFIED_、_NVIDIA_TESLA_K80_、_NVIDIA_TESLA_P100_、_NVIDIA_TESLA_V100_、_NVIDIA_TESLA_P4_、_NVIDIA_TESLA_T4_、_NVIDIA_TELSA_A100_\n",
    "- `accelerator_count`：要连接到工作程序副本的加速器数量。\n",
    "- `replica_count`：工作程序副本数量。\n",
    "- `args`：要传递给Python脚本的命令行参数。\n",
    "\n",
    "了解有关 Vertex AI 的[自定义 Python-Package 训练](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomPythonPackageTrainingJob)的更多信息。\n",
    "\n",
    "*注意*：此训练作业可能需要超过24小时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3709beb73e2"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING\"):\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8ac1bcb31a7"
   },
   "outputs": [],
   "source": [
    "training_args = [\"--num-epochs\", \"2\", \"--model-name\", APP_NAME]\n",
    "\n",
    "model = job.run(\n",
    "    replica_count=1,\n",
    "    machine_type=TRAIN_MACHINE_TYPE,\n",
    "    accelerator_type=TRAIN_ACCELERATOR_TYPE,\n",
    "    accelerator_count=TRAIN_ACCELERATOR_COUNT,\n",
    "    args=training_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d0f5ea96675"
   },
   "source": [
    "验证模型工件在作业成功完成后是否由训练代码写入到云存储中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "502123b87fa3"
   },
   "outputs": [],
   "source": [
    "job_response = MessageToDict(job._gca_resource._pb)\n",
    "GCS_MODEL_ARTIFACTS_URI = job_response[\"trainingTaskInputs\"][\"baseOutputDirectory\"][\n",
    "    \"outputUriPrefix\"\n",
    "]\n",
    "print(f\"Model artifacts are available at {GCS_MODEL_ARTIFACTS_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3d2205d5224f"
   },
   "outputs": [],
   "source": [
    "!gsutil ls -lr $GCS_MODEL_ARTIFACTS_URI/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9caf6a802e99"
   },
   "source": [
    "部署\n",
    "\n",
    "在Vertex AI上部署PyTorch模型需要您使用一个自定义容器，在Vertex AI端点上提供在线预测。您部署一个运行PyTorch的TorchServe工具的容器，以便为情感分析任务的微调变换器模型提供预测服务。然后，您可以使用Vertex AI的在线预测服务对输入文本的情感进行分类。\n",
    "\n",
    "使用自定义容器在Vertex AI上部署模型需要提供一个Docker容器镜像，其中运行一个HTTP服务器应用程序，比如在这种情况下是TorchServe。了解更多关于在Vertex AI上的预测容器要求。\n",
    "\n",
    "基本上，部署PyTorch模型到Vertex AI需要以下步骤：\n",
    "\n",
    "1. 打包训练的模型文件，包括默认或自定义处理程序，通过使用Torch模型打包工具创建一个压缩文件。\n",
    "2. 构建一个与Vertex AI兼容的自定义容器，以使用TorchServe提供模型服务。\n",
    "3. 将带有自定义容器镜像的模型上传以作为Vertex AI模型资源提供预测服务。\n",
    "4. 创建一个Vertex AI端点和部署模型资源。\n",
    "\n",
    "创建一个自定义模型处理程序来处理预测请求\n",
    "\n",
    "将输入文本传递给微调的变换器模型时，输入文本需要进行预处理。一旦模型生成预测，还需要对生成的输出进行一些后处理以将其标记为底层类别并提供它们的概率（或置信度分数）。\n",
    "\n",
    "为包含类似预处理和后处理步骤，您可以创建一个打包在模型文件中的自定义处理程序脚本。稍后，在部署时，TorchServe执行该脚本。\n",
    "\n",
    "自定义处理程序脚本执行以下操作：\n",
    "\n",
    "- 在将输入文本发送给模型进行推理之前进行预处理\n",
    "- 自定义模型在推理时如何被调用\n",
    "- 在发送回响应之前从模型输出进行后处理\n",
    "\n",
    "从TorchServe文档中了解更多关于定义自定义处理程序的内容。\n",
    "\n",
    "创建一个目录来定义一个函数用来处理预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f109c2317225"
   },
   "outputs": [],
   "source": [
    "!mkdir -p predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d6f534e5895"
   },
   "source": [
    "创建一个名为 `custom_handler.py` 的文件，在部署时处理预测请求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e37fd93bcfa5"
   },
   "outputs": [],
   "source": [
    "%%writefile predictor/custom_handler.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class TransformersClassifierHandler(BaseHandler):\n",
    "    \"\"\"\n",
    "    The handler takes an input string and returns the classification text \n",
    "    based on the serialized transformers checkpoint.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(TransformersClassifierHandler, self).__init__()\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, ctx):\n",
    "        \"\"\" Loads the model.pt file and initialized the model object.\n",
    "        Instantiates Tokenizer for preprocessor to use\n",
    "        Loads labels to name mapping file for post-processing inference response\n",
    "        \"\"\"\n",
    "        self.manifest = ctx.manifest\n",
    "\n",
    "        properties = ctx.system_properties\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        self.device = torch.device(\"cuda:\" + str(properties.get(\"gpu_id\")) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Read model serialize/pt file\n",
    "        serialized_file = self.manifest[\"model\"][\"serializedFile\"]\n",
    "        model_pt_path = os.path.join(model_dir, serialized_file)\n",
    "        if not os.path.isfile(model_pt_path):\n",
    "            raise RuntimeError(\"Missing the model.pt or pytorch_model.bin file\")\n",
    "        \n",
    "        # Load model\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        logger.debug('Transformer model from path {0} loaded successfully'.format(model_dir))\n",
    "        \n",
    "        # Ensure to use the same tokenizer used during training\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "        # Read the mapping file, index to object name\n",
    "        mapping_file_path = os.path.join(model_dir, \"index_to_name.json\")\n",
    "\n",
    "        if os.path.isfile(mapping_file_path):\n",
    "            with open(mapping_file_path) as f:\n",
    "                self.mapping = json.load(f)\n",
    "        else:\n",
    "            logger.warning('Missing the index_to_name.json file. Inference output defaults.')\n",
    "            self.mapping = {\"0\": \"Negative\",  \"1\": \"Positive\"}\n",
    "\n",
    "        self.initialized = True\n",
    "\n",
    "    def preprocess(self, data):\n",
    "        \"\"\" Preprocessing input request by tokenizing\n",
    "            Extend with your own preprocessing steps as needed\n",
    "        \"\"\"\n",
    "        text = data[0].get(\"data\")\n",
    "        if text is None:\n",
    "            text = data[0].get(\"body\")\n",
    "        sentences = text.decode('utf-8')\n",
    "        logger.info(\"Received text: '%s'\", sentences)\n",
    "\n",
    "        # Tokenize the texts\n",
    "        tokenizer_args = ((sentences,))\n",
    "        inputs = self.tokenizer(*tokenizer_args,\n",
    "                                padding='max_length',\n",
    "                                max_length=128,\n",
    "                                truncation=True,\n",
    "                                return_tensors = \"pt\")\n",
    "        return inputs\n",
    "\n",
    "    def inference(self, inputs):\n",
    "        \"\"\" Predict the class of a text using a trained transformer model.\n",
    "        \"\"\"\n",
    "        prediction = self.model(inputs['input_ids'].to(self.device))[0].argmax().item()\n",
    "\n",
    "        if self.mapping:\n",
    "            prediction = self.mapping[str(prediction)]\n",
    "\n",
    "        logger.info(\"Model predicted: '%s'\", prediction)\n",
    "        return [prediction]\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        return inference_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e504b5529b8"
   },
   "source": [
    "### 生成一个用于类别名称的文件\n",
    "\n",
    "对于自定义处理程序，创建以下映射文件（`index_to_name.json`），用于将目标标签与它们的有意义的名称关联起来，同时格式化预测响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3c4969c2759"
   },
   "outputs": [],
   "source": [
    "%%writefile ./predictor/index_to_name.json\n",
    "\n",
    "{\n",
    "    \"0\": \"leisure\",\n",
    "    \"1\": \"exercise\",\n",
    "    \"2\": \"enjoy_the_moment\",\n",
    "    \"3\": \"affection\",\n",
    "    \"4\": \"achievement\",\n",
    "    \"5\": \"nature\",\n",
    "    \"6\": \"bonding\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6f0026a985fa"
   },
   "source": [
    "### 创建一个自定义容器映像来提供预测\n",
    "\n",
    "接下来，您可以使用[Artifact Registry](https://cloud.google.com/artifact-registry)和[Cloud Build](https://cloud.google.com/build)按照以下步骤创建自定义容器映像：\n",
    "\n",
    "#### 下载模型工件\n",
    "\n",
    "从云存储下载作为训练（或超参数调整）工作的一部分保存的模型工件到本地目录。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86b272c76889"
   },
   "source": [
    "在云存储桶中验证模型工件文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0d160b2911ac"
   },
   "outputs": [],
   "source": [
    "!gsutil ls -r $GCS_MODEL_ARTIFACTS_URI/model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38d171b3eb23"
   },
   "source": [
    "将文件从云存储复制到本地目录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9138f330c9f2"
   },
   "outputs": [],
   "source": [
    "!gsutil -m cp -r $GCS_MODEL_ARTIFACTS_URI/model/ ./predictor/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2f9c5a82b1ed"
   },
   "outputs": [],
   "source": [
    "!ls -ltrR ./predictor/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ec61feb1188"
   },
   "source": [
    "为镜像创建一个Dockerfile\n",
    "\n",
    "通过以下步骤创建一个以TorchServe为基础镜像的Dockerfile：\n",
    "\n",
    "- 安装依赖项，如`transformers`。\n",
    "- 将模型 artifacts 添加到容器镜像中的`/home/model-server/`目录。\n",
    "- 将自定义处理程序脚本添加到容器镜像中的`/home/model-server/`目录。\n",
    "- 创建`/home/model-server/config.properties`来定义服务配置（健康和预测监听端口）。\n",
    "- 运行[Torch模型打包工具](https://github.com/pytorch/serve/tree/master/model-archiver#creating-a-model-archive)来创建一个模型存档文件，文件是从复制到容器镜像中的`/home/model-server/`目录中的文件创建的。模型存档保存在`/home/model-server/model-store/`目录中，名称为`<模型名称>.mar`。\n",
    "- 启动TorchServe HTTP服务器，该服务器引用配置属性并启用模型的服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6602ec14439c"
   },
   "outputs": [],
   "source": [
    "%%bash -s $APP_NAME\n",
    "\n",
    "APP_NAME=$1\n",
    "\n",
    "cat << EOF > ./predictor/Dockerfile\n",
    "\n",
    "FROM pytorch/torchserve:latest-cpu\n",
    "\n",
    "# install dependencies\n",
    "RUN python3 -m pip install --upgrade pip\n",
    "RUN pip3 install transformers\n",
    "\n",
    "USER model-server\n",
    "\n",
    "# copy model artifacts, custom handler and other dependencies\n",
    "COPY ./custom_handler.py /home/model-server/\n",
    "COPY ./index_to_name.json /home/model-server/\n",
    "COPY ./model/$APP_NAME/ /home/model-server/\n",
    "\n",
    "# create torchserve configuration file\n",
    "USER root\n",
    "RUN printf \"\\nservice_envelope=json\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /home/model-server/config.properties\n",
    "USER model-server\n",
    "\n",
    "# expose health and prediction listener ports from the image\n",
    "EXPOSE 7080\n",
    "EXPOSE 7081\n",
    "\n",
    "# create model archive file packaging model artifacts and dependencies\n",
    "RUN torch-model-archiver -f \\\n",
    "  --model-name=$APP_NAME \\\n",
    "  --version=1.0 \\\n",
    "  --serialized-file=/home/model-server/pytorch_model.bin \\\n",
    "  --handler=/home/model-server/custom_handler.py \\\n",
    "  --extra-files \"/home/model-server/config.json,/home/model-server/tokenizer.json,/home/model-server/training_args.bin,/home/model-server/tokenizer_config.json,/home/model-server/special_tokens_map.json,/home/model-server/vocab.txt,/home/model-server/index_to_name.json\" \\\n",
    "  --export-path=/home/model-server/model-store\n",
    "\n",
    "# run Torchserve HTTP serve to respond to prediction requests\n",
    "CMD [\"torchserve\", \\\n",
    "     \"--start\", \\\n",
    "     \"--ts-config=/home/model-server/config.properties\", \\\n",
    "     \"--models\", \\\n",
    "     \"$APP_NAME=$APP_NAME.mar\", \\\n",
    "     \"--model-store\", \\\n",
    "     \"/home/model-server/model-store\"]\n",
    "EOF\n",
    "\n",
    "echo \"Writing ./predictor/Dockerfile\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d3993843108"
   },
   "source": [
    "创建一个 Docker 仓库\n",
    "\n",
    "在 Artifact Registry 中创建您自己的 Docker 仓库，将 Docker 镜像推送到该仓库以提供预测服务。\n",
    "\n",
    "1. 运行 `gcloud artifacts repositories create` 命令，创建一个新的 Docker 仓库，并指定区域和描述。\n",
    "\n",
    "2. 运行 `gcloud artifacts repositories list` 命令，验证您的仓库是否已创建。\n",
    "\n",
    "将 `APP_NAME` 设置为您的仓库名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd1c0a3fbcdb"
   },
   "outputs": [],
   "source": [
    "# Create the repository in Artifact registry\n",
    "! gcloud artifacts repositories create {APP_NAME} --repository-format=docker --location={LOCATION} --description=\"Docker repository\"\n",
    "\n",
    "# List all repositories and check your repository\n",
    "! gcloud artifacts repositories list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4601a036e327"
   },
   "source": [
    "#### 使用带有镜像路径标签的docker映像来构建\n",
    "\n",
    "接下来，您可以使用Cloud Build在创建的存储库中构建docker映像。Cloud Build尝试定位标签中提供的存储库路径。\n",
    "\n",
    "了解更多关于[使用Cloud Build构建和推送docker映像](https://cloud.google.com/build/docs/build-push-docker-image)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fb45b22c008"
   },
   "outputs": [],
   "source": [
    "!gcloud builds submit --region={LOCATION} --tag=$CUSTOM_PREDICTOR_IMAGE_URI ./predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c331bdaf370"
   },
   "source": [
    "### 部署服务容器到 Vertex AI\n",
    "\n",
    "接下来，您在 Vertex AI 上创建一个模型资源，并将模型部署到 Vertex AI 端点。您必须将模型部署到端点以进行在线预测服务。部署的模型会运行自定义容器映像以提供预测。\n",
    "\n",
    "#### 创建一个 Vertex AI 模型资源\n",
    "\n",
    "使用创建的模型工件和容器映像创建一个 Vertex AI 模型资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5a1472f735b"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=model_display_name,\n",
    "    description=model_description,\n",
    "    serving_container_image_uri=CUSTOM_PREDICTOR_IMAGE_URI,\n",
    "    serving_container_predict_route=predict_route,\n",
    "    serving_container_health_route=health_route,\n",
    "    serving_container_ports=serving_container_ports,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7720d771633"
   },
   "source": [
    "创建一个Vertex AI终端点，部署已注册的Vertex AI模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fc8fe6b64dd1"
   },
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint.create(display_name=endpoint_display_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "061ab3d05205"
   },
   "source": [
    "部署模型到端点\n",
    "\n",
    "部署模型会将物理资源与模型关联起来，使其能够以低延迟提供在线预测。\n",
    "\n",
    "**注意：** 部署资源需要几分钟时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d65aae3de6c1"
   },
   "outputs": [],
   "source": [
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=model_display_name,\n",
    "    machine_type=DEPLOY_MACHINE_TYPE,\n",
    "    sync=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "094f7b4d8007"
   },
   "source": [
    "### 发送在线预测请求\n",
    "\n",
    "现在，使用Vertex AI SDK for Python调用部署模型的端点，为一些测试实例进行预测。\n",
    "\n",
    "#### 格式化在线预测的输入\n",
    "\n",
    "本笔记本使用[TorchServe的基于KServe的推理API](https://pytorch.org/serve/inference_api.html#kserve-inference-api)，它也是[Vertex AI预测兼容格式](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#prediction)。对于在线预测请求，请将预测输入实例格式化为带有base64编码的JSON，如下所示：\n",
    "\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"data\": {\n",
    "            \"b64\": \"<base64编码的字符串>\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5f0b7f8fc9a"
   },
   "outputs": [],
   "source": [
    "test_instances = [\n",
    "    b\"I went to a meeting that went really well.\",\n",
    "    b\"I ran four miles this morning with a good time.\",\n",
    "    b\"Watching the storms we had yesterday.  The lightning was incredible!\",\n",
    "    b\"The last night I said with her 'I love you '. And she said ' Yes'.\",\n",
    "    b\"I had followed a complex recipe making roasted duck, which took me hours and I had successfully made it.\",\n",
    "    b\"I woke up this morning to birds chirping.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0a24c94d66c"
   },
   "source": [
    "### 发送在线预测请求\n",
    "\n",
    "格式化输入文本字符串，使用格式化的输入请求调用预测端点并获取响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "515acf48503c"
   },
   "outputs": [],
   "source": [
    "# print the test instances and their responses\n",
    "for instance in test_instances:\n",
    "    print(f\"Input text: \\n\\t{instance.decode('utf-8')}\\n\")\n",
    "    b64_encoded = base64.b64encode(instance)\n",
    "    test_instance = [{\"data\": {\"b64\": f\"{str(b64_encoded.decode('utf-8'))}\"}}]\n",
    "    print(f\"Formatted input: \\n{json.dumps(test_instance, indent=4)}\\n\")\n",
    "    prediction = endpoint.predict(instances=test_instance)\n",
    "    print(f\"Prediction response: \\n\\t{prediction}\")\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "787f896a1daa"
   },
   "source": [
    "清理工作\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源：\n",
    "\n",
    "- 生成的文件和文件夹\n",
    "- 训练任务\n",
    "- Vertex AI 模型\n",
    "- Vertex AI 端点\n",
    "- Cloud Storage 存储桶（将`delete_bucket`设置为**True**以删除存储桶）\n",
    "- 图像仓库（Artifact Registry）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdefede69285"
   },
   "outputs": [],
   "source": [
    "delete_bucket = False\n",
    "\n",
    "# Delete files in trainer folder\n",
    "os.remove(\"./python_package/trainer/init.py\")\n",
    "\n",
    "# Delete directories generated\n",
    "os.rmdir(\"./python_package/trainer\")\n",
    "os.rmdir(\"./python_package/scripts\")\n",
    "os.rmdir(\"./python_package\")\n",
    "os.rmdir(\"predictor\")\n",
    "\n",
    "\n",
    "# Delete the Custom training job\n",
    "job.delete()\n",
    "\n",
    "# Undeploy the model from the endpoint\n",
    "endpoint.undeploy_all()\n",
    "# Delete the endpoint\n",
    "endpoint.delete()\n",
    "\n",
    "# Delete the Vertex AI Model resource\n",
    "model.delete()\n",
    "\n",
    "# Delete the Cloud Storage bucket\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil -m rm -r $BUCKET_URI\n",
    "\n",
    "# Delete artifact repository\n",
    "! gcloud artifacts repositories delete $APP_NAME --location=$LOCATION --quiet"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "pytorch-text-sentiment-classification-custom-train-deploy.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
