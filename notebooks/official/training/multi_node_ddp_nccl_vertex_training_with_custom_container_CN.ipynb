{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6b56b1c7b76"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c414a395a19b"
   },
   "source": [
    "使用CPU和Vertex AI上的多节点NCCL分布式数据并行训练的PyTorch图像分类\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/multi_node_ddp_nccl_vertex_training_with_custom_container.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> 在Colab中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Ftraining%2Fmulti_node_ddp_nccl_vertex_training_with_custom_container.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> 在Colab Enterprise中打开\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/training/multi_node_ddp_nccl_vertex_training_with_custom_container.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> 在Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/multi_node_ddp_nccl_vertex_training_with_custom_container.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> 在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "196084857666"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示如何使用Vertex AI SDK for Python和自定义容器创建一个分布式NCCL PyTorch训练作业。这有助于您的训练作业扩展以处理大量数据。\n",
    "\n",
    "了解更多关于[Vertex AI训练](https://cloud.google.com/vertex-ai/docs/training/custom-training)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f34250c9e39"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用 Vertex AI SDK for Python 和自定义容器创建一个分布式 PyTorch 训练作业。您将设置一个自定义容器，一个 Vertex AI TensorBoard 实例，并运行一个自定义训练作业。\n",
    "\n",
    "本教程使用以下 Vertex AI 服务：\n",
    "\n",
    "- Vertex AI TensorBoard\n",
    "- Vertex AI 训练\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 使用 Artifact Registry 和 Docker 构建自定义容器。\n",
    "- 创建一个 Vertex AI TensorBoard 实例来存储您的 Vertex AI 实验。\n",
    "- 使用 Vertex AI SDK for Python 运行一个 Vertex AI 训练作业。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ee27912fc7e"
   },
   "source": [
    "数据集\n",
    "\n",
    "本教程使用的数据集是<a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST数据库</a>。手写数字MNIST数据库有一个包含60,000个示例的训练集，和一个包含10,000个示例的测试集。该数据集是从手写数字的二进制图像构建的较大数据集的子集。这些数字已经被尺寸归一化，并居中于固定尺寸的图像中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72ce3c3e56b3"
   },
   "source": [
    "### 成本\n",
    "\n",
    "本教程使用谷歌云的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "\n",
    "* 云存储\n",
    "\n",
    "* Vertex AI TensorBoard（请注意，Vertex AI TensorBoard 每月收取唯一活跃用户每月300美元的费用。活跃用户通过Vertex AI TensorBoard UI 进行测量。您还需要为在云存储中存储的TensorBoard日志和与Vertex AI TensorBoard一起使用的谷歌云资源付费。 <a href='https://cloud.google.com/vertex-ai/pricing#tensorboard'>查看最新价格。</a>)\n",
    "\n",
    "了解有关[Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing) 和[云存储价格](https://cloud.google.com/storage/pricing)的信息，并使用[Pricing Calculator](https://cloud.google.com/products/calculator/),  根据您的预期使用情况生成一个成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0316df526f8"
   },
   "source": [
    "开始吧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03d216c7f7b1"
   },
   "source": [
    "### 为Python安装Vertex AI SDK和其他必需的软件包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6d015287b38d"
   },
   "outputs": [],
   "source": [
    "# Install the Vertex AI SDK for Python\n",
    "! pip3 install --quiet --upgrade google-cloud-aiplatform\n",
    "\n",
    "# Install other required libraries\n",
    "! pip3 install --quiet torch \\\n",
    "                        torchvision \\\n",
    "                        tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35942e320683"
   },
   "source": [
    "### 重启运行时（仅适用于Colab）\n",
    "\n",
    "为了使用新安装的软件包，您必须在Google Colab上重启运行时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7e5937088c8"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ee775571c2b5"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️内核将重新启动。在继续下一步之前，请等待完成。⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92e68cfc3a90"
   },
   "source": [
    "### 验证您的笔记本环境（仅限Colab）\n",
    "\n",
    "在Google Colab上验证您的环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46604f70e831"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80f70e8aa911"
   },
   "source": [
    "设置Google Cloud项目信息\n",
    "\n",
    "了解更多有关[设置项目和开发环境](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3989ed5bea75"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶，用于存储中间产物，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "如果您的存储桶尚不存在：运行以下单元格以创建您的云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "306bf9ab7f7f"
   },
   "source": [
    "初始化 Vertex AI SDK for Python\n",
    "\n",
    "要开始使用 Vertex AI，您必须拥有一个现有的 Google Cloud 项目，并启用 [Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dc6b3ba241c"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05d881f62170"
   },
   "source": [
    "### 服务帐户\n",
    "\n",
    "您可以使用服务帐户来运行Vetex AI CustomContainerTrainingJob。如果您不想使用您项目的Compute Engine服务帐户，将`SERVICE_ACCOUNT`设置为另一个服务帐户ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "034c005865b1"
   },
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = \"[your-service-account]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "137e835d3759"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if (\n",
    "    SERVICE_ACCOUNT == \"\"\n",
    "    or SERVICE_ACCOUNT is None\n",
    "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
    "):\n",
    "    # Get your service account from gcloud\n",
    "    if not IS_COLAB:\n",
    "        shell_output = !gcloud auth list 2>/dev/null\n",
    "        SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\n",
    "\n",
    "    else:  # IS_COLAB:\n",
    "        shell_output = ! gcloud projects describe  $PROJECT_ID\n",
    "        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
    "        SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
    "\n",
    "    print(\"Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2d242773d707"
   },
   "source": [
    "### 启用Artifact Registry API\n",
    "您必须为您的项目启用[Artifact Registry API](https://cloud.google.com/artifact-registry/docs/reference/rest)服务。\n",
    "\n",
    "<a href=\"https://cloud.google.com/artifact-registry/docs/enable-service\">了解更多关于启用服务的信息</a>。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00ceac726715"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "! gcloud services enable artifactregistry.googleapis.com\n",
    "\n",
    "if os.getenv(\"IS_TESTING\"):\n",
    "    ! sudo apt-get update --yes && sudo apt-get --only-upgrade --yes install google-cloud-sdk-cloud-run-proxy google-cloud-sdk-harbourbridge google-cloud-sdk-cbt google-cloud-sdk-gke-gcloud-auth-plugin google-cloud-sdk-kpt google-cloud-sdk-local-extract google-cloud-sdk-minikube google-cloud-sdk-app-engine-java google-cloud-sdk-app-engine-go google-cloud-sdk-app-engine-python google-cloud-sdk-spanner-emulator google-cloud-sdk-bigtable-emulator google-cloud-sdk-nomos google-cloud-sdk-package-go-module google-cloud-sdk-firestore-emulator kubectl google-cloud-sdk-datastore-emulator google-cloud-sdk-app-engine-python-extras google-cloud-sdk-cloud-build-local google-cloud-sdk-kubectl-oidc google-cloud-sdk-anthos-auth google-cloud-sdk-app-engine-grpc google-cloud-sdk-pubsub-emulator google-cloud-sdk-datalab google-cloud-sdk-skaffold google-cloud-sdk google-cloud-sdk-terraform-tools google-cloud-sdk-config-connector\n",
    "    ! gcloud components update --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12c03eca5908"
   },
   "source": [
    "创建训练应用程序\n",
    "\n",
    "在进行本地训练之前，请为您的训练应用程序创建一个源代码文件、一个需求文件和一个 Docker 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f058ed522e8"
   },
   "outputs": [],
   "source": [
    "PYTHON_PACKAGE_APPLICATION_DIR = \"trainer\"\n",
    "\n",
    "# Create the app folder\n",
    "!mkdir -p $PYTHON_PACKAGE_APPLICATION_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "436cc7d0197e"
   },
   "source": [
    "### 创建训练脚本\n",
    "\n",
    "创建运行PyTorch分布式训练的训练文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34d5b6e85332"
   },
   "outputs": [],
   "source": [
    "%%writefile {PYTHON_PACKAGE_APPLICATION_DIR}/task.py\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Main program for PyTorch distributed training.\n",
    "Adapted from: https://github.com/narumiruna/pytorch-distributed-example\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "from torch import distributed\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils import data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def parse_args():\n",
    "\n",
    "  parser = argparse.ArgumentParser()\n",
    "\n",
    "  # Using environment variables for Cloud Storage directories\n",
    "  # see more details in https://cloud.google.com/vertex-ai/docs/training/code-requirements\n",
    "  parser.add_argument(\n",
    "      '--model-dir', default=os.getenv('AIP_MODEL_DIR'), type=str,\n",
    "      help='a Cloud Storage URI of a directory intended for saving model artifacts')\n",
    "  parser.add_argument(\n",
    "      '--tensorboard-log-dir', default=os.getenv('AIP_TENSORBOARD_LOG_DIR'), type=str,\n",
    "      help='a Cloud Storage URI of a directory intended for saving TensorBoard')\n",
    "  parser.add_argument(\n",
    "      '--checkpoint-dir', default=os.getenv('AIP_CHECKPOINT_DIR'), type=str,\n",
    "      help='a Cloud Storage URI of a directory intended for saving checkpoints')\n",
    "\n",
    "  parser.add_argument(\n",
    "      '--backend', type=str, default='gloo',\n",
    "      help='Use the `nccl` backend for distributed GPU training.'\n",
    "           'Use the `gloo` backend for distributed CPU training.')\n",
    "  parser.add_argument(\n",
    "      '--init-method', type=str, default='env://',\n",
    "      help='URL specifying how to initialize the package.')\n",
    "  parser.add_argument(\n",
    "      '--world-size', type=int, default=os.environ.get('WORLD_SIZE', 1),\n",
    "      help='The total number of nodes in the cluster. '\n",
    "           'This variable has the same value on every node.')\n",
    "  parser.add_argument(\n",
    "      '--rank', type=int, default=os.environ.get('RANK', 0),\n",
    "      help='A unique identifier for each node. '\n",
    "           'On the master worker, this is set to 0. '\n",
    "           'On each worker, it is set to a different value from 1 to WORLD_SIZE - 1.')\n",
    "  parser.add_argument(\n",
    "      '--epochs', type=int, default=20)\n",
    "  parser.add_argument(\n",
    "      '--no-cuda', action='store_true')\n",
    "  parser.add_argument(\n",
    "      '-lr', '--learning-rate', type=float, default=1e-3)\n",
    "  parser.add_argument(\n",
    "      '--batch-size', type=int, default=128)\n",
    "  parser.add_argument(\n",
    "      '--local-mode', action='store_true', help='use local mode when running on your local machine')\n",
    "\n",
    "  args = parser.parse_args()\n",
    "\n",
    "  return args\n",
    "\n",
    "def makedirs(model_dir):\n",
    "  if os.path.exists(model_dir) and os.path.isdir(model_dir):\n",
    "    shutil.rmtree(model_dir)\n",
    "  os.makedirs(model_dir)\n",
    "  return\n",
    "\n",
    "def distributed_is_initialized():\n",
    "  if distributed.is_available():\n",
    "    if distributed.is_initialized():\n",
    "      return True\n",
    "  return False\n",
    "\n",
    "class Average(object):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.sum = 0\n",
    "    self.count = 0\n",
    "\n",
    "  def __str__(self):\n",
    "    return '{:.6f}'.format(self.average)\n",
    "\n",
    "  @property\n",
    "  def average(self):\n",
    "    return self.sum / self.count\n",
    "\n",
    "  def update(self, value, number):\n",
    "    self.sum += value * number\n",
    "    self.count += number\n",
    "\n",
    "class Accuracy(object):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.correct = 0\n",
    "    self.count = 0\n",
    "\n",
    "  def __str__(self):\n",
    "    return '{:.2f}%'.format(self.accuracy * 100)\n",
    "\n",
    "  @property\n",
    "  def accuracy(self):\n",
    "    return self.correct / self.count\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def update(self, output, target):\n",
    "    pred = output.argmax(dim=1)\n",
    "    correct = pred.eq(target).sum().item()\n",
    "\n",
    "    self.correct += correct\n",
    "    self.count += output.size(0)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, device):\n",
    "    super(Net, self).__init__()\n",
    "    self.fc = torch.nn.Linear(784, 10).to(device)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.fc(x.view(x.size(0), -1))\n",
    "\n",
    "class MNISTDataLoader(data.DataLoader):\n",
    "\n",
    "  def __init__(self, root, batch_size, train=True):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.MNIST(root, train=train, transform=transform, download=True)\n",
    "    sampler = None\n",
    "    if train and distributed_is_initialized():\n",
    "      sampler = data.DistributedSampler(dataset)\n",
    "\n",
    "    super(MNISTDataLoader, self).__init__(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(sampler is None),\n",
    "        sampler=sampler,\n",
    "    )\n",
    "\n",
    "class Trainer(object):\n",
    "\n",
    "  def __init__(self,\n",
    "      model,\n",
    "      optimizer,\n",
    "      train_loader,\n",
    "      test_loader,\n",
    "      device,\n",
    "      model_name,\n",
    "      checkpoint_path\n",
    "  ):\n",
    "    self.model = model\n",
    "    self.optimizer = optimizer\n",
    "    self.train_loader = train_loader\n",
    "    self.test_loader = test_loader\n",
    "    self.device = device\n",
    "    self.model_name = model_name\n",
    "    self.checkpoint_path = checkpoint_path\n",
    "\n",
    "  def save(self, model_dir):\n",
    "    model_path = os.path.join(model_dir, self.model_name)\n",
    "    torch.save(self.model.state_dict(), model_path)\n",
    "\n",
    "  def fit(self, epochs, is_chief, writer):\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "      print('Epoch: {}, Training ...'.format(epoch))\n",
    "      train_loss, train_acc = self.train()\n",
    "\n",
    "      if is_chief:\n",
    "        test_loss, test_acc = self.evaluate()\n",
    "        writer.add_scalar('Loss/train', train_loss.average, epoch)\n",
    "        writer.add_scalar('Loss/test', test_loss.average, epoch)\n",
    "        writer.add_scalar('Accuracy/train', train_acc.accuracy, epoch)\n",
    "        writer.add_scalar('Accuracy/test', test_acc.accuracy, epoch)\n",
    "        torch.save(self.model.state_dict(), self.checkpoint_path)\n",
    "\n",
    "        print(\n",
    "            'Epoch: {}/{},'.format(epoch, epochs),\n",
    "            'train loss: {}, train acc: {},'.format(train_loss, train_acc),\n",
    "            'test loss: {}, test acc: {}.'.format(test_loss, test_acc),\n",
    "        )\n",
    "\n",
    "  def train(self):\n",
    "\n",
    "    self.model.train()\n",
    "\n",
    "    train_loss = Average()\n",
    "    train_acc = Accuracy()\n",
    "\n",
    "    for data, target in self.train_loader:\n",
    "      data = data.to(self.device)\n",
    "      target = target.to(self.device)\n",
    "\n",
    "      output = self.model(data)\n",
    "      loss = torch.nn.functional.cross_entropy(output, target)\n",
    "\n",
    "      self.optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "\n",
    "      train_loss.update(loss.item(), data.size(0))\n",
    "      train_acc.update(output, target)\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def evaluate(self):\n",
    "    self.model.eval()\n",
    "\n",
    "    test_loss = Average()\n",
    "    test_acc = Accuracy()\n",
    "\n",
    "    for data, target in self.test_loader:\n",
    "      data = data.to(self.device)\n",
    "      target = target.to(self.device)\n",
    "\n",
    "      output = self.model(data)\n",
    "      loss = torch.nn.functional.cross_entropy(output, target)\n",
    "\n",
    "      test_loss.update(loss.item(), data.size(0))\n",
    "      test_acc.update(output, target)\n",
    "\n",
    "    return test_loss, test_acc\n",
    "\n",
    "def main():\n",
    "\n",
    "  args = parse_args()\n",
    "\n",
    "  local_data_dir = './tmp/data'\n",
    "  local_model_dir = './tmp/model'\n",
    "  local_tensorboard_log_dir = './tmp/logs'\n",
    "  local_checkpoint_dir = './tmp/checkpoints'\n",
    "\n",
    "  model_dir = args.model_dir or local_model_dir\n",
    "  tensorboard_log_dir = args.tensorboard_log_dir or local_tensorboard_log_dir\n",
    "  checkpoint_dir = args.checkpoint_dir or local_checkpoint_dir\n",
    "\n",
    "  gs_prefix = 'gs://'\n",
    "  gcsfuse_prefix = '/gcs/'\n",
    "  if model_dir and model_dir.startswith(gs_prefix):\n",
    "    model_dir = model_dir.replace(gs_prefix, gcsfuse_prefix)\n",
    "  if tensorboard_log_dir and tensorboard_log_dir.startswith(gs_prefix):\n",
    "    tensorboard_log_dir = tensorboard_log_dir.replace(gs_prefix, gcsfuse_prefix)\n",
    "  if checkpoint_dir and checkpoint_dir.startswith(gs_prefix):\n",
    "    checkpoint_dir = checkpoint_dir.replace(gs_prefix, gcsfuse_prefix)\n",
    "\n",
    "  writer = SummaryWriter(tensorboard_log_dir)\n",
    "\n",
    "  is_chief = args.rank == 0\n",
    "  if is_chief:\n",
    "    makedirs(checkpoint_dir)\n",
    "    print(f'Checkpoints will be saved to {checkpoint_dir}')\n",
    "\n",
    "  checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint.pt')\n",
    "  print(f'checkpoint_path is {checkpoint_path}')\n",
    "\n",
    "  if args.world_size > 1:\n",
    "    print('Initializing distributed backend with {} nodes'.format(args.world_size))\n",
    "    distributed.init_process_group(\n",
    "          backend=args.backend,\n",
    "          init_method=args.init_method,\n",
    "          world_size=args.world_size,\n",
    "          rank=args.rank,\n",
    "      )\n",
    "    print(f'[{os.getpid()}]: '\n",
    "          f'world_size = {distributed.get_world_size()}, '\n",
    "          f'rank = {distributed.get_rank()}, '\n",
    "          f'backend={distributed.get_backend()} \\n', end='')\n",
    "\n",
    "  if torch.cuda.is_available() and not args.no_cuda:\n",
    "    device = torch.device('cuda:{}'.format(args.rank))\n",
    "  else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "  model = Net(device=device)\n",
    "  if distributed_is_initialized():\n",
    "    model.to(device)\n",
    "    model = DistributedDataParallel(model)\n",
    "\n",
    "  if is_chief:\n",
    "    # All processes should see same parameters as they all start from same\n",
    "    # random parameters and gradients are synchronized in backward passes.\n",
    "    # Therefore, saving it in one process is sufficient.\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(f'Initial chief checkpoint is saved to {checkpoint_path}')\n",
    "\n",
    "  # Use a barrier() to make sure that process 1 loads the model after process\n",
    "  # 0 saves it.\n",
    "  if distributed_is_initialized():\n",
    "    distributed.barrier()\n",
    "    # configure map_location properly\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    print(f'Initial chief checkpoint is saved to {checkpoint_path} with map_location {device}')\n",
    "  else:\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(f'Initial chief checkpoint is loaded from {checkpoint_path}')\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "  train_loader = MNISTDataLoader(\n",
    "      local_data_dir, args.batch_size, train=True)\n",
    "  test_loader = MNISTDataLoader(\n",
    "      local_data_dir, args.batch_size, train=False)\n",
    "\n",
    "  trainer = Trainer(\n",
    "      model=model,\n",
    "      optimizer=optimizer,\n",
    "      train_loader=train_loader,\n",
    "      test_loader=test_loader,\n",
    "      device=device,\n",
    "      model_name='mnist.pt',\n",
    "      checkpoint_path=checkpoint_path,\n",
    "  )\n",
    "  trainer.fit(args.epochs, is_chief, writer)\n",
    "\n",
    "  if model_dir == local_model_dir:\n",
    "    makedirs(model_dir)\n",
    "    trainer.save(model_dir)\n",
    "    print(f'Model is saved to {model_dir}')\n",
    "\n",
    "  print(f'Tensorboard logs are saved to: {tensorboard_log_dir}')\n",
    "\n",
    "  writer.close()\n",
    "\n",
    "  if is_chief:\n",
    "    os.remove(checkpoint_path)\n",
    "\n",
    "  if distributed_is_initialized():\n",
    "    distributed.destroy_process_group()\n",
    "\n",
    "  return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "253359c5153a"
   },
   "source": [
    "创建需求文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46423aa093f3"
   },
   "outputs": [],
   "source": [
    "%%writefile {PYTHON_PACKAGE_APPLICATION_DIR}/requirements.txt\n",
    "\n",
    "torch\n",
    "torchvision\n",
    "tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34bea792269a"
   },
   "source": [
    "### 创建Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "774a0be3a796"
   },
   "outputs": [],
   "source": [
    "%%writefile {PYTHON_PACKAGE_APPLICATION_DIR}/Dockerfile\n",
    "\n",
    "\n",
    "FROM pytorch/pytorch:1.8.1-cuda11.1-cudnn8-runtime\n",
    "\n",
    "RUN apt-get update && \\\n",
    "    apt-get install -y curl gnupg && \\\n",
    "    echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main\" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list && \\\n",
    "    curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key --keyring /usr/share/keyrings/cloud.google.gpg  add - && \\\n",
    "    apt-get update -y && \\\n",
    "    apt-get install google-cloud-sdk -y\n",
    "\n",
    "COPY . /trainer\n",
    "\n",
    "WORKDIR /trainer\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "ENTRYPOINT [\"python\", \"-m\", \"task\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57bf6f8b4361"
   },
   "source": [
    "在本地运行您的训练脚本以测试您的应用程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0c6e7dfb3c6"
   },
   "outputs": [],
   "source": [
    "%run trainer/task.py --epochs 5 --no-cuda --local-mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31dfdeede587"
   },
   "outputs": [],
   "source": [
    "# List the outputs\n",
    "! ls ./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8f3ea1210749"
   },
   "source": [
    "创建一个自定义图像用于训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23f3ba8346f4"
   },
   "source": [
    "### 创建一个私有的Docker仓库\n",
    "\n",
    "您的第一步是在Artifact Registry中创建自己的Docker仓库。\n",
    "\n",
    "1. 运行`gcloud artifacts repositories create`命令，使用您的区域创建一个新的Docker仓库，描述为\"docker repository\"。\n",
    "\n",
    "2. 运行`gcloud artifacts repositories list`命令，验证您的仓库已经创建成功。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64fee26c2dff"
   },
   "outputs": [],
   "source": [
    "# Set the name for your private repo\n",
    "PRIVATE_REPO = \"my-docker-repo-unique\"\n",
    "\n",
    "# Create the repository\n",
    "! gcloud artifacts repositories create {PRIVATE_REPO} --repository-format=docker --location={LOCATION} --description=\"Docker repository\"\n",
    "\n",
    "# List the repositories and verify\n",
    "! gcloud artifacts repositories list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38e62011c5e1"
   },
   "outputs": [],
   "source": [
    "DEPLOY_IMAGE = (\n",
    "    f\"{LOCATION}-docker.pkg.dev/\" + PROJECT_ID + f\"/{PRIVATE_REPO}\" + \"/tf_serving\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "775c3eca365c"
   },
   "outputs": [],
   "source": [
    "print(\"Deployment:\", DEPLOY_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "535932b8c42d"
   },
   "source": [
    "在笔记本环境中执行\n",
    "\n",
    "如果您在笔记本环境中运行本教程，例如在Vertex AI工作台中，请按照以下步骤进行。\n",
    "\n",
    "如果您在Colab上运行，请跳转到“在Colab中执行”部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd295337455e"
   },
   "source": [
    "### 配置私有仓库的身份验证\n",
    "在推送或拉取容器镜像之前，配置Docker使用gcloud命令行工具对您区域的Artifact Registry发出的请求进行身份验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79c3fe4ab7f6"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! gcloud auth configure-docker {LOCATION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a822a118c210"
   },
   "source": [
    "### 构建和推送用于提供服务的镜像\n",
    "设置用于提供预测的 TensorFlow Serving 镜像。\n",
    "\n",
    "以下代码：\n",
    "1. 从 Docker Hub 拉取相应的 CPU 或 GPU Docker 镜像用于 TF Serving。\n",
    "2. 为将镜像与 Artifact Registry 注册创建标签。\n",
    "3. 将镜像注册到 Artifact Registry。\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/tfx/serving/docker\">了解有关 TensorFlow Serving 的更多信息</a>。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfec228d9de2"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! cd trainer && docker build -t $DEPLOY_IMAGE -f Dockerfile .\n",
    "    ! docker run --rm $DEPLOY_IMAGE --epochs 5 --no-cuda --local-mode\n",
    "    ! docker push $DEPLOY_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7102219bb621"
   },
   "source": [
    "在Colab中执行\n",
    "\n",
    "使用Cloud Build构建并推送Docker镜像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "736e3c0d1fd8"
   },
   "outputs": [],
   "source": [
    "if IS_COLAB:\n",
    "    ! cd trainer && gcloud builds submit --timeout=1800s --region={LOCATION} --tag $DEPLOY_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73c92c9298e9"
   },
   "source": [
    "创建一个 Vertex AI Tensorboard 实例\n",
    "\n",
    "在下面为您的 Tensorboard 实例设置一个显示名称，然后运行 create 命令。\n",
    "\n",
    "**注意:** 要使用现有的 Vertex AI Tensorboard 实例，请使用以下方法。\n",
    "\n",
    "```\n",
    "tensorboard_name = \"您的 Tensorboard 资源名称或 Tensorboard 实例 ID\"\n",
    "tensorboard = aiplatform.Tensorboard(tensorboard_name=tensorboard_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bde509558cd5"
   },
   "outputs": [],
   "source": [
    "# Set display name for Tensorboard instance\n",
    "TENSORBOARD_DISPLAY_NAME = \"pytorch-image-classify-multi-node-ddp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6d7908c0083c"
   },
   "outputs": [],
   "source": [
    "# Create the Tensorboard instance\n",
    "tensorboard = aiplatform.Tensorboard.create(\n",
    "    display_name=TENSORBOARD_DISPLAY_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4cac84e04ac"
   },
   "source": [
    "创建一个顶点 AI 自定义容器训练作业\n",
    "\n",
    "了解有关[为自定义训练配置计算资源的更多信息](https://cloud.google.com/vertex-ai/docs/training/configure-compute)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f92e8fdd44ee"
   },
   "outputs": [],
   "source": [
    "# Set display name for your training job\n",
    "JOB_DISPLAY_NAME = \"pytorch-image-classify-multi-node-ddp-training\"\n",
    "# Set a Cloud Storage output path\n",
    "GCS_OUTPUT_URI_PREFIX = f\"{BUCKET_URI}/{JOB_DISPLAY_NAME}\"\n",
    "# Set the number of replicas in the workerpool\n",
    "REPLICA_COUNT = 1\n",
    "# Set the machine type for running the training job\n",
    "MACHINE_TYPE = \"n1-standard-4\"\n",
    "# Set the number of accelerators needed for training\n",
    "ACCELERATOR_COUNT = 1\n",
    "# Set the accelerator type\n",
    "ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
    "# Set the args to be passed to the training application\n",
    "ARGS = [\n",
    "    \"--backend\",\n",
    "    \"nccl\",\n",
    "    \"--no-cuda\",\n",
    "    \"--batch-size\",\n",
    "    \"128\",\n",
    "    \"--epochs\",\n",
    "    \"25\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae4c57df7e07"
   },
   "outputs": [],
   "source": [
    "# Create the custom container training job\n",
    "custom_container_training_job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=JOB_DISPLAY_NAME,\n",
    "    container_uri=DEPLOY_IMAGE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24e0350a3c68"
   },
   "source": [
    "运行训练任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35cf3ecdf0df"
   },
   "outputs": [],
   "source": [
    "custom_container_training_job.run(\n",
    "    args=ARGS,\n",
    "    base_output_dir=GCS_OUTPUT_URI_PREFIX,\n",
    "    replica_count=REPLICA_COUNT,\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_count=ACCELERATOR_COUNT,\n",
    "    accelerator_type=ACCELERATOR_TYPE,\n",
    "    tensorboard=tensorboard.resource_name,\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49d10dded73b"
   },
   "outputs": [],
   "source": [
    "print(f\"Custom Training Job Name: {custom_container_training_job.resource_name}\")\n",
    "print(f\"GCS Output URI Prefix: {GCS_OUTPUT_URI_PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78398f52807b"
   },
   "source": [
    "查看培训输出结果物品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fc74422de1d1"
   },
   "outputs": [],
   "source": [
    "! gsutil ls $GCS_OUTPUT_URI_PREFIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5e99a6a05b10"
   },
   "source": [
    "清理工作\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以删除用于本教程的[Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源：\n",
    "\n",
    "- Vertex AI训练作业\n",
    "- Vertex AI Tensorboard\n",
    "- Cloud Storage存储桶\n",
    "- Artifact Registry存储库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0c1b3f7466b"
   },
   "outputs": [],
   "source": [
    "# Delete the training job\n",
    "custom_container_training_job.delete()\n",
    "\n",
    "# Delete the Tensorboard instance\n",
    "delete_tensorboard = False  # Set True for deletion\n",
    "\n",
    "if delete_tensorboard:\n",
    "    tensorboard.delete()\n",
    "\n",
    "# Delete the Cloud Storage bucket\n",
    "delete_bucket = False  # Set True for deletion\n",
    "\n",
    "if delete_bucket:\n",
    "    ! gsutil rm -r $BUCKET_URI\n",
    "\n",
    "# Delete the repository in Artifact Registry\n",
    "! gcloud artifacts repositories delete {PRIVATE_REPO} --location {LOCATION} --quiet\n",
    "\n",
    "# Remove the outputs from the local execution\n",
    "! rm -rf ./tmp\n",
    "\n",
    "# Remove the training app folder\n",
    "! rm -rf ./trainer"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "multi_node_ddp_nccl_vertex_training_with_custom_container.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
