{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "q7r5vp1ZZROn"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "在Vertex AI上使用Cloud Storage中的数据训练PyTorch模型\n",
    "\n",
    "在Colab中打开\n",
    "在Colab企业版中打开\n",
    "在Workbench中打开\n",
    "在GitHub上查看"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程向您展示如何使用PyTorch和存储在云存储中的数据集创建自定义训练作业。\n",
    "\n",
    "了解更多关于[在Vertex AI中集成PyTorch](https://cloud.google.com/vertex-ai/docs/start/pytorch)的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "目标\n",
    "\n",
    "在本教程中，您将学习如何使用PyTorch和存储在云存储上的数据集创建一个训练作业。您将构建一个使用GCSFuse加载存储桶中数据的自定义训练脚本。该自定义训练脚本创建了一个简单的神经网络，并将模型工件保存到云存储桶中。\n",
    "\n",
    "本教程使用以下Vertex AI服务：\n",
    "\n",
    "- Vertex AI 训练\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 编写一个创建训练集和测试集并训练模型的自定义训练脚本。\n",
    "- 使用Vertex AI SDK for Python 运行\"CustomTrainingJob\"。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08d289fa873f"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用[MNIST手写样本](https://en.wikipedia.org/wiki/MNIST_database)，该数据集对手写数字进行分类。对于本教程，数据集的CSV版本已经上传到了一个云存储桶中，可供您使用。您可以在[Kaggle](https://www.kaggle.com/datasets/oddrationale/mnist-in-csv?select=mnist_train.csv)上找到该数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aed92deeb4a0"
   },
   "source": [
    "### 费用\n",
    "\n",
    "本教程使用 Google Cloud 的可计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing)，以及[Cloud Storage 价格](https://cloud.google.com/storage/pricing)，并使用[定价计算器](https://cloud.google.com/products/calculator/)根据您的预计使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1566ddfb0d0d"
   },
   "source": [
    "## 要求\n",
    "\n",
    "这个教程需要使用一个针对PyTorch优化的笔记本电脑。如果您在Vertex AI Workbench中运行此笔记本，请确保您的笔记本镜像符合以下要求：\n",
    "\n",
    "+ PyTorch 1.13 笔记本\n",
    "+ 1个NVIDIA T4 GPU\n",
    "\n",
    "Colab 笔记本符合要求（在安装和验证之后）。您可能需要切换到启用GPU的运行时。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cc240e9c1a6"
   },
   "source": [
    "开始吧!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### 为Python安装Vertex AI SDK和其他必需的软件包\n",
    "\n",
    "### 安装Vertex AI SDK for Python和其他必需的软件包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4LrAIokarTK"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
    "                                google-cloud-storage \\\n",
    "                                torch==1.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67e101d52a4c"
   },
   "source": [
    "重新启动运行时（仅限Colab）\n",
    "\n",
    "要使用新安装的软件包，您必须在Google Colab上重新启动运行时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bfcf20418562"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e669f8088ac3"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ 内核将重新启动。在继续下一步之前，请等待它完成。⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dccb1c8feb6"
   },
   "source": [
    "### 验证您的笔记本环境（仅限Colab）\n",
    "\n",
    "在Google Colab上验证您的环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cc7251520a07"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "### 设置Google Cloud项目信息\n",
    "\n",
    "了解更多关于[设置项目和开发环境](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3f4a7fc51051"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产物，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}\n",
    "BUCKET_PREFIX = \"pytorch-on-gcs\"  # @param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "如果您的存储桶尚不存在：运行下面的单元格来创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39dbc83d5530"
   },
   "source": [
    "初始化用于Python的Vertex AI SDK\n",
    "\n",
    "要开始使用Vertex AI，您必须拥有一个现有的Google Cloud项目并[启用Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86fa44b5ab17"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Py_tlZxxacOq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from google.cloud import aiplatform\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e54d6bccf451"
   },
   "source": [
    "提供数据的URI\n",
    "\n",
    "如前所述，本教程使用经典的MNIST手写数字数据集作为输入。该数据集已经存储在一个公共可用的云存储位置上供您使用。您可以直接在训练脚本中使用这些CSV文件。\n",
    "\n",
    "**注意**：您可以使用[PyTorch数据集库](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST)下载该数据集。为了学习目的，本教程在云存储上使用了该数据集的副本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9b5044d31ed9"
   },
   "outputs": [],
   "source": [
    "TRAIN_URI = \"gs://cloud-samples-data/vertex-ai/training/pytorch/mnist_train.csv\"\n",
    "TEST_URI = \"gs://cloud-samples-data/vertex-ai/training/pytorch/mnist_test.csv\"\n",
    "\n",
    "print(TRAIN_URI)\n",
    "print(TEST_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7zjKtBsLOrL"
   },
   "source": [
    "# [可选] 检查来自云存储的数据集\n",
    "\n",
    "在创建训练脚本之前，快速查看一下云存储中的CSV文件中包含的数据。您可以使用 PyTorch 中的 `Dataset` 和 `DataLoader` 类来实例化一个数据集，然后使用 [matplotlib](https://matplotlib.org/stable/index.html) 来绘制数据。\n",
    "\n",
    "首先将CSV文件下载到您的本地开发环境中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1MQpp0QLRWK"
   },
   "outputs": [],
   "source": [
    "! gsutil -m cp -r $TRAIN_URI .\n",
    "! gsutil -m cp -r $TEST_URI ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "365a4f9c588b"
   },
   "source": [
    "接下来，您需要定义一个继承自基类`Dataset`的自定义图像数据集。\n",
    "\n",
    "请注意，您的自定义`Dataset`类必须重写`__init__`，`__len__`和`__getitem__`方法。这些方法是由`DataLoader`类使用的，用于遍历数据集。\n",
    "\n",
    "以下`CustomImageDataset`类具有几个显著特点。首先，图像的尺寸被硬编码为28像素高，28像素宽。这对应于MNIST数据集中图像的尺寸。\n",
    "\n",
    "其次，该数据集使用[`pandas.Dataframe`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)对象来读取CSV文件并访问其中的数据。\n",
    "\n",
    "最后，`__getitem__`方法需要从CSV文件中的每一行提取图像和标签。这两个值作为元组提供给调用者。\n",
    "\n",
    "图像本身需要从一维向量值（列表）转换为二维矩阵（列表的列表）。此外，CSV文件中以整数形式存储的灰度值需要转换为介于0.0和1.0之间的浮点值。要进行此转换，您将灰度值乘以1/255的十进制等价值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9Z2j58NlIu7"
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    width = 28  # hard-coded width & height of image matrix\n",
    "    height = 28\n",
    "\n",
    "    def __init__(self, data_file, transform=None, target_transform=None):\n",
    "        self.dataset = pd.read_csv(data_file)\n",
    "        self.transform = (\n",
    "            transform  # We would use ToTensor() if we were taking in raw images\n",
    "        )\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.dataset.at[idx, \"label\"]\n",
    "        image = self.dataset.iloc[idx, 1:]\n",
    "\n",
    "        # Create a matrix from the pandas.Series\n",
    "        image = image.to_numpy() * 0.00392156862745098  # 1 / 255\n",
    "        image = image.reshape(self.width, self.height)\n",
    "        image = image.astype(float)\n",
    "        image = torch.Tensor(image)\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wv4TdH9_otsu"
   },
   "outputs": [],
   "source": [
    "train_set = CustomImageDataset(\"mnist_train.csv\")\n",
    "test_set = CustomImageDataset(\"mnist_test.csv\")\n",
    "\n",
    "batch_size = 64\n",
    "shuffle = False\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=shuffle)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bc84344443d"
   },
   "source": [
    "当数据集加载到 `DataLoader` 对象中后，您可以检查它们。对于本教程，数据集以64个数据集行的批次提供给训练应用程序。每个数据集行包含一个28x28的图像和一个标签（一个介于0和9之间的值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFzN3mS-Tlhl"
   },
   "outputs": [],
   "source": [
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "    print(len(X))\n",
    "    print(len(y))\n",
    "\n",
    "    first_image = X[0]\n",
    "    first_label = y[0]\n",
    "\n",
    "    print(len(first_image))\n",
    "    print(first_label)  # This is a Tensor object with a single scalar value, 5\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1479af04fb9e"
   },
   "source": [
    "从数据集中绘制一幅图像。\n",
    "\n",
    "为了验证数据质量，绘制数据集中的第一项，以验证它是否呈现出与标签匹配的图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HaLdouYmTBq"
   },
   "outputs": [],
   "source": [
    "first_image, label = (None, None)\n",
    "for i in range(len(train_set)):\n",
    "    sample = train_set[i]\n",
    "    sample, label = sample\n",
    "    first_image = sample.numpy()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUJowAEVrI9w"
   },
   "outputs": [],
   "source": [
    "np.shape(first_image)\n",
    "imgplot = plt.imshow(first_image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBdwLPRQK4lS"
   },
   "source": [
    "## [可选] 在本地训练神经网络\n",
    "\n",
    "虽然在 Vertex AI 上训练不需要这一步骤，但你可以使用 PyTorch 在本地训练模型。本教程声明了一个 `NeuralNetwork` 类，它继承自 PyTorch 的 [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=nn+module#torch.nn.Module) 类。`nn.Module` 类为所有神经网络模块提供了一个基类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxHfdDaVK2_p"
   },
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512, dtype=torch.float),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxWBegh4NRYl"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn) -> bool:\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    accuracy = 100 * correct\n",
    "    print(f\"Test Error: \\n Accuracy: {(accuracy):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    if accuracy <= 0.0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Define a loss function and an optimizer.\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    is_going_well = test(test_dataloader, model, loss_fn)\n",
    "    if not is_going_well:\n",
    "        print(\"unacceptable accuracy\")\n",
    "        break\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_xoA1zDzany"
   },
   "source": [
    "## 创建训练脚本\n",
    "\n",
    "不管其他的事情，训练自定义PyTorch模型在Vertex AI上的主要任务是创建一个训练脚本。这个脚本被加载到一个[用于PyTorch训练的预构建容器](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers#pytorch)中，然后作为一个[在Vertex AI训练服务上运行的自定义训练作业](https://cloud.google.com/vertex-ai/docs/training/create-custom-job)运行。\n",
    "\n",
    "第一步是为您的自定义训练作业选择一组兼容的加速器和训练图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AeXG25Lv0hIv"
   },
   "outputs": [],
   "source": [
    "TRAIN_GPU, TRAIN_NGPU = (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_T4, 1)\n",
    "if TRAIN_GPU:\n",
    "    TRAIN_VERSION = \"pytorch-gpu.1-13\"\n",
    "else:\n",
    "    TRAIN_VERSION = \"pytorch-xla.1-11\"\n",
    "\n",
    "TRAIN_IMAGE = \"{}-docker.pkg.dev/vertex-ai/training/{}:latest\".format(\n",
    "    LOCATION.split(\"-\")[0], TRAIN_VERSION\n",
    ")\n",
    "\n",
    "MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0EqfgBk2JbD"
   },
   "source": [
    "### 编写训练脚本\n",
    "\n",
    "接下来，在创建训练作业之前，您需要将训练脚本命名为'task.py'并保存到文件中。请注意，该脚本包含您之前检查过的数据集、数据加载器和神经网络模块。\n",
    "\n",
    "在训练脚本中，训练脚本是使用[存储FUSE](https://cloud.google.com/storage/docs/gcs-fuse)从云存储加载的。FUSE将云存储桶挂载为训练容器文件系统中的文件夹。这使得训练脚本能够加载存储在存储桶中的文件作为数据集。FUSE还允许训练脚本将训练的输出，即模型产物，存储在云存储桶中。\n",
    "\n",
    "要使用通过FUSE挂载到容器的存储桶，您需要用文件夹路径`/gcs/`替换存储桶URI中的`gs://`部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziL1zM9E1Ptx"
   },
   "outputs": [],
   "source": [
    "# Make folder for Python training script\n",
    "if not os.path.exists(\"trainer\"):\n",
    "    os.mkdir(\"trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "361c5b0c9949"
   },
   "outputs": [],
   "source": [
    "%%writefile trainer/task.py\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch CNN Training')\n",
    "parser.add_argument('--train_uri', dest='train_uri',\n",
    "                    type=str, help='Storage location of training CSV')\n",
    "parser.add_argument('--test_uri', dest='test_uri',\n",
    "                    type=str, help='Storage location of test CSV')\n",
    "parser.add_argument('--model-dir', dest='model_dir',\n",
    "                    default=os.getenv('AIP_MODEL_DIR'), type=str, help='Model directory')\n",
    "parser.add_argument('--batch_size', dest='batch_size',\n",
    "                    type=int, default=16, help='Batch size')\n",
    "parser.add_argument('--epochs', dest='epochs',\n",
    "                    type=int, default=20, help='Number of epochs')\n",
    "parser.add_argument('--lr', dest='lr',\n",
    "                    type=int, default=20, help='Learning rate')\n",
    "args = parser.parse_args()\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    width = 28\n",
    "    height = 28\n",
    "\n",
    "    def __init__(self, data_file, transform=None, target_transform=None):\n",
    "        self.dataset = pd.read_csv(data_file)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.dataset.at[idx, \"label\"]\n",
    "        image = self.dataset.iloc[idx,1:]\n",
    "\n",
    "        # Create a matrix from the pandas.Series\n",
    "        image = image.to_numpy() * 0.00392156862745098 # 1 / 255\n",
    "        image = image.reshape(self.width, self.height)\n",
    "        image = image.astype(float)\n",
    "        image = torch.Tensor(image)\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512, dtype=torch.float),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "def get_data(train_gcs_uri, test_gcs_uri):\n",
    "\n",
    "    train_set = CustomImageDataset(train_gcs_uri)\n",
    "    test_set = CustomImageDataset(test_gcs_uri)\n",
    "\n",
    "    # HARDCODED batch_size and shuffle-can customize\n",
    "    batch_size = 64\n",
    "    shuffle = False\n",
    "\n",
    "    train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=shuffle)\n",
    "    test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "def get_model():\n",
    "    logging.info(\"Get model architecture\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    gpu_id = \"0\" if torch.cuda.is_available() else None\n",
    "    logging.info(f\"Device: {device}\")\n",
    "\n",
    "    model = NeuralNetwork()\n",
    "    model.to(device)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "    return model, loss, optimizer, device\n",
    "\n",
    "def train_model(model, loss_func, optimizer, train_loader, test_loader, device):\n",
    "    def train(dataloader, model, loss_fn, optimizer):\n",
    "        size = len(dataloader.dataset)\n",
    "        model.train()\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                loss, current = loss.item(), batch * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    def test(dataloader, model, loss_fn):\n",
    "        size = len(dataloader.dataset)\n",
    "        num_batches = len(dataloader)\n",
    "        model.eval()\n",
    "        test_loss, correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                pred = model(X)\n",
    "                test_loss += loss_fn(pred, y).item()\n",
    "                correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= num_batches\n",
    "        correct /= size\n",
    "        accuracy = 100 * correct\n",
    "        print(f\"Test Error: \\n Accuracy: {(accuracy):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    # Define a loss function and an optimizer.\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    epochs = 5\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_loader, model, loss_fn, optimizer)\n",
    "        test(test_loader, model, loss_fn)\n",
    "\n",
    "    # Done training\n",
    "    return model\n",
    "\n",
    "# import data from Cloud Storage\n",
    "logging.info('importing training data')\n",
    "gs_prefix = 'gs://'\n",
    "gcsfuse_prefix = '/gcs/'\n",
    "\n",
    "if args.train_uri.startswith(gs_prefix):\n",
    "    args.train_uri.replace(gs_prefix, gcsfuse_prefix)\n",
    "\n",
    "if args.test_uri.startswith(gs_prefix):\n",
    "    args.test_uri.replace(gs_prefix, gcsfuse_prefix)\n",
    "\n",
    "train_dataset, test_dataset = get_data(train_gcs_uri=args.train_uri,\n",
    "                                      test_gcs_uri=args.test_uri)\n",
    "\n",
    "logging.info('starting training')\n",
    "model, loss, optimizer, device = get_model()\n",
    "train_model(model, loss, optimizer, train_dataset, test_dataset, device)\n",
    "\n",
    "\n",
    "# export model to gcs using GCSFuse\n",
    "logging.info('start saving')\n",
    "logging.info(\"Exporting model artifacts ...\")\n",
    "gs_prefix = 'gs://'\n",
    "gcsfuse_prefix = '/gcs/'\n",
    "if args.model_dir.startswith(gs_prefix):\n",
    "    args.model_dir = args.model_dir.replace(gs_prefix, gcsfuse_prefix)\n",
    "    dirpath = os.path.split(args.model_dir)[0]\n",
    "    if not os.path.isdir(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "gcs_model_path = os.path.join(os.path.join(args.model_dir, 'model.pth'))\n",
    "torch.save(model.state_dict(), gcs_model_path)\n",
    "logging.info(f'Model is saved to {args.model_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97695e9c8655"
   },
   "source": [
    "### 创建训练任务\n",
    "\n",
    "一旦您将训练脚本写入文件，现在可以开始训练模型了。对于这个模型，在调用 `CustomTrainingJob.run()` 时提供以下参数。还请注意，`args` 列表中提供的字符串是训练脚本中定义的参数。\n",
    "\n",
    "+ `--train_uri` 和 `--test_uri` 参数指向一个公开可用的 Cloud Storage 存储桶中的 CSV 文件。训练脚本使用 Storage FUSE 访问这些文件。\n",
    "+ `--model_dir` 参数指向一个您必须提供给脚本的存储桶。训练脚本会在存储桶上创建一个新文件夹来存储模型构件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1edd9128828e"
   },
   "outputs": [],
   "source": [
    "# Use timestamped path to save your model in Cloud Storage\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Set a display name for the training job\n",
    "JOB_DISPLAY_NAME = \"pytorch-custom-job\"\n",
    "\n",
    "# Create a custom training job in Vertex AI\n",
    "job = aiplatform.CustomTrainingJob(\n",
    "    display_name=JOB_DISPLAY_NAME,\n",
    "    script_path=\"trainer/task.py\",\n",
    "    container_uri=TRAIN_IMAGE,\n",
    ")\n",
    "\n",
    "# Run the job\n",
    "job.run(\n",
    "    replica_count=1,\n",
    "    machine_type=TRAIN_COMPUTE,\n",
    "    accelerator_type=TRAIN_GPU.name,\n",
    "    accelerator_count=TRAIN_NGPU,\n",
    "    args=[\n",
    "        \"--train_uri\",\n",
    "        TRAIN_URI,\n",
    "        \"--test_uri\",\n",
    "        TEST_URI,\n",
    "        \"--model-dir\",\n",
    "        f\"{BUCKET_URI}/{BUCKET_PREFIX}/{TIMESTAMP}/\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。否则，您可以删除在本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "# Delete training job created\n",
    "job.delete(sync=False)\n",
    "\n",
    "# Delete Cloud Storage objects that were created\n",
    "delete_bucket = False\n",
    "if delete_bucket:\n",
    "    ! gsutil -m rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "pytorch_gcs_data_training.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
