{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Nmi2KIicB7S"
   },
   "source": [
    "# 分布式顶点 AI 超参数调整\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/distributed_hyperparameter_tuning.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> 在 Colab 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Ftraining%2Fdistributed_hyperparameter_tuning.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> 在 Colab Enterprise 中打开\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/training/distributed_hyperparameter_tuning.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> 在 Workbench 中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/distributed_hyperparameter_tuning.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> 在 GitHub 上查看\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c582cc111a01"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本笔记本演示如何使用Vertex AI Training来运行一个超参数调整作业，以发现ML模型的最佳超参数值。为了加快训练过程，使用了`tf.distribute`模块中的`MirroredStrategy`来在单台机器上的多个GPU上分发训练。\n",
    "\n",
    "了解更多关于[Vertex AI超参数调整](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60d57f1c2ae0"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在这个笔记本中，您将在一个Docker容器中从Python脚本创建一个自定义训练模型。您将学习如何修改训练应用程序代码以进行超参数调整，并使用Python SDK提交Vertex AI超参数调整作业。\n",
    "\n",
    "本教程使用以下谷歌云ML服务：\n",
    "\n",
    "- `Vertex AI训练`\n",
    "- `Vertex AI超参数调整`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 使用Python包进行训练。\n",
    "- 在超参数调整时报告准确度。\n",
    "- 使用GCSFuse将模型工件保存到Cloud Storage。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是来自[TensorFlow数据集](https://www.tensorflow.org/datasets)的“马或人类数据集”。训练模型可以预测图像是马还是人的。\n",
    "\n",
    "### 成本\n",
    "\n",
    "本教程使用Google Cloud的计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "了解[Vertex AI的定价](https://cloud.google.com/vertex-ai/pricing)和[Cloud Storage的定价](https://cloud.google.com/storage/pricing)，并使用[Pricing Calculator](https://cloud.google.com/products/calculator/)基于您的预期使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b1ffd5ab768"
   },
   "source": [
    "开始吧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip"
   },
   "source": [
    "安装Vertex AI SDK for Python和其他所需的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyy5Lbnzg5fi"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade google-cloud-aiplatform -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff555b32bab8"
   },
   "source": [
    "### 重新启动运行时（仅适用于Colab）\n",
    "\n",
    "要使用新安装的软件包，您必须重新启动Google Colab上的运行时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f09b4dff629a"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54c5ef8a8f43"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ 内核将重新启动。等待它完成后再继续下一步。⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f82e28c631cc"
   },
   "source": [
    "### 在Colab上验证您的笔记本环境\n",
    "\n",
    "在Google Colab上验证您的环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46604f70e831"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef3990d0482a"
   },
   "source": [
    "### 设置Google Cloud项目信息并初始化Python的Vertex AI SDK\n",
    "\n",
    "要开始使用Vertex AI，您必须拥有一个现有的Google Cloud项目并[启用Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。了解更多关于[设置项目和开发环境](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5755d1a554f"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产品，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d2de92accb67"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://dist-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "只有当您的存储桶不存在时：运行以下单元格来创建您的云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {LOCATION} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf"
   },
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRUOFELefqf1"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reBCSTKOg47l"
   },
   "source": [
    "编写Dockerfile\n",
    "\n",
    "容器化代码的第一步是创建一个Dockerfile。在Dockerfile中，您将包含运行映像所需的所有命令，例如安装必要的库和设置训练代码的入口点。\n",
    "\n",
    "此Dockerfile使用了Deep Learning Container TensorFlow Enterprise 2.5 GPU Docker映像。Google Cloud上的Deep Learning Containers预装了许多常见的ML和数据科学框架。下载该映像后，此Dockerfile安装了[CloudML Hypertune](https://github.com/GoogleCloudPlatform/cloudml-hypertune)库，并设置了训练代码的入口点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e231837fe138"
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-6\n",
    "WORKDIR /\n",
    "\n",
    "# Installs hypertune library\n",
    "RUN pip install cloudml-hypertune\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY trainer /trainer\n",
    "\n",
    "# Sets up the entry point to invoke the trainer.\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c2ea367c79d"
   },
   "source": [
    "### 创建训练应用程序代码\n",
    "\n",
    "接下来，你需要创建一个trainer目录，其中包含一个名为`task.py`的脚本，用来存储你的训练应用程序的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MjJTYC86hPOZ"
   },
   "outputs": [],
   "source": [
    "# Create trainer directory\n",
    "\n",
    "! mkdir trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea83c1253a74"
   },
   "source": [
    "在下一个单元格中，您将编写训练脚本`task.py`的内容。这个文件从TensorFlow数据集中下载_horses or humans_数据集，并使用`tf.distribute`模块中的`MirroredStrategy`训练一个`tf.keras`功能模型。\n",
    "\n",
    "有一些专门用于使用超参数调整服务的组件：\n",
    "\n",
    "* 脚本导入了`hypertune`库。请注意，Dockerfile中包含了pip安装hypertune库的说明。\n",
    "* 函数`get_args()`为您希望调整的每个超参数定义了一个命令行参数。在这个例子中，将调整的超参数是学习率、优化器中的动量值和模型中最后一个隐藏层中的单元数。传递给这些参数的值然后用于设置代码中相应的超参数。\n",
    "* 在`main()`函数的末尾，使用`hypertune`库定义要优化的指标。在这个例子中，将优化的指标是验证准确率。这一指标传递给`HyperTune`的实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9b52fd75d90f"
   },
   "outputs": [],
   "source": [
    "%%writefile trainer/task.py\n",
    "\n",
    "import argparse\n",
    "import hypertune\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "def get_args():\n",
    "  \"\"\"Parses args. Must include all hyperparameters you want to tune.\"\"\"\n",
    "\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\n",
    "      '--learning_rate', required=True, type=float, help='learning rate')\n",
    "  parser.add_argument(\n",
    "      '--momentum', required=True, type=float, help='SGD momentum value')\n",
    "  parser.add_argument(\n",
    "      '--units',\n",
    "      required=True,\n",
    "      type=int,\n",
    "      help='number of units in last hidden layer')\n",
    "  parser.add_argument(\n",
    "      '--epochs',\n",
    "      required=False,\n",
    "      type=int,\n",
    "      default=10,\n",
    "      help='number of training epochs')\n",
    "  args = parser.parse_args()\n",
    "  return args\n",
    "\n",
    "\n",
    "def preprocess_data(image, label):\n",
    "  \"\"\"Resizes and scales images.\"\"\"\n",
    "\n",
    "  image = tf.image.resize(image, (150, 150))\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "\n",
    "def create_dataset(batch_size):\n",
    "  \"\"\"Loads Horses Or Humans dataset and preprocesses data.\"\"\"\n",
    "\n",
    "  data, info = tfds.load(\n",
    "      name='horses_or_humans', as_supervised=True, with_info=True)\n",
    "\n",
    "  # Create train dataset\n",
    "  train_data = data['train'].map(preprocess_data)\n",
    "  train_data = train_data.shuffle(1000)\n",
    "  train_data = train_data.batch(batch_size)\n",
    "\n",
    "  # Create validation dataset\n",
    "  validation_data = data['test'].map(preprocess_data)\n",
    "  validation_data = validation_data.batch(64)\n",
    "\n",
    "  return train_data, validation_data\n",
    "\n",
    "\n",
    "def create_model(units, learning_rate, momentum):\n",
    "  \"\"\"Defines and compiles model.\"\"\"\n",
    "\n",
    "  inputs = tf.keras.Input(shape=(150, 150, 3))\n",
    "  x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "  x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "  x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
    "  x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "  x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "  x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "  x = tf.keras.layers.Flatten()(x)\n",
    "  x = tf.keras.layers.Dense(units, activation='relu')(x)\n",
    "  outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "  model = tf.keras.Model(inputs, outputs)\n",
    "  model.compile(\n",
    "      loss='binary_crossentropy',\n",
    "      optimizer=tf.keras.optimizers.SGD(\n",
    "          learning_rate=learning_rate, momentum=momentum),\n",
    "      metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "\n",
    "def main():\n",
    "  args = get_args()\n",
    "\n",
    "  # Create Strategy\n",
    "  strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "  # Scale batch size\n",
    "  GLOBAL_BATCH_SIZE = 64 * strategy.num_replicas_in_sync  \n",
    "  train_data, validation_data = create_dataset(GLOBAL_BATCH_SIZE)\n",
    "\n",
    "  # Wrap model variables within scope\n",
    "  with strategy.scope():\n",
    "    model = create_model(args.units, args.learning_rate, args.momentum)\n",
    "\n",
    "  # Train model\n",
    "  history = model.fit(\n",
    "      train_data, epochs=args.epochs, validation_data=validation_data)\n",
    "\n",
    "  # Define Metric\n",
    "  hp_metric = history.history['val_accuracy'][-1]\n",
    "\n",
    "  hpt = hypertune.HyperTune()\n",
    "  hpt.report_hyperparameter_tuning_metric(\n",
    "      hyperparameter_metric_tag='accuracy',\n",
    "      metric_value=hp_metric,\n",
    "      global_step=args.epochs)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dc0a526f77e"
   },
   "source": [
    "### 构建容器\n",
    "\n",
    "在接下来的单元格中，您将构建容器并将其推送到Google容器注册表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a42d0b918ab4"
   },
   "outputs": [],
   "source": [
    "# Set the IMAGE_URI\n",
    "IMAGE_URI = f\"gcr.io/{PROJECT_ID}/horse-human:hypertune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "360a5271fbdb"
   },
   "outputs": [],
   "source": [
    "# Build the docker image\n",
    "! docker build -f Dockerfile -t $IMAGE_URI ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "526475da6370"
   },
   "outputs": [],
   "source": [
    "# Push it to Google Container Registry:\n",
    "! docker push $IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaff6f5be7f6"
   },
   "source": [
    "### 在Vertex AI上创建和运行超参数调优任务\n",
    "\n",
    "一旦您的容器被推送到Google容器注册表，您可以使用Vertex SDK来创建和运行超参数调优任务。\n",
    "\n",
    "您定义以下规格：\n",
    "* `worker_pool_specs`：指定机器类型和Docker镜像的字典。这个示例定义了一个带有一个`n1-standard-4`机器和两个`NVIDIA_TESLA_T4` GPU的单节点集群。\n",
    "* `parameter_spec`：指定要优化的参数的字典。字典键是分配给您训练应用程序代码中每个超参数的命令行参数的字符串，字典值是参数规范。参数规范包括超参数的类型、最小/最大值和比例。\n",
    "* `metric_spec`：指定要优化的指标的字典。字典键是您在训练应用程序代码中设置的`hyperparameter_metric_tag`，值是优化目标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aec22792ee84"
   },
   "outputs": [],
   "source": [
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": \"n1-standard-4\",\n",
    "            \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "            \"accelerator_count\": 2,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\"image_uri\": IMAGE_URI},\n",
    "    }\n",
    "]\n",
    "\n",
    "metric_spec = {\"accuracy\": \"maximize\"}\n",
    "\n",
    "parameter_spec = {\n",
    "    \"learning_rate\": hpt.DoubleParameterSpec(min=0.001, max=1, scale=\"log\"),\n",
    "    \"momentum\": hpt.DoubleParameterSpec(min=0, max=1, scale=\"linear\"),\n",
    "    \"units\": hpt.DiscreteParameterSpec(values=[64, 128, 512], scale=None),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffd01019a764"
   },
   "source": [
    "创建一个`CustomJob`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2eed1471a24"
   },
   "outputs": [],
   "source": [
    "# Create a CustomJob\n",
    "\n",
    "JOB_NAME = \"horses-humans-hyperparam-job\"\n",
    "\n",
    "my_custom_job = aiplatform.CustomJob(\n",
    "    display_name=JOB_NAME,\n",
    "    project=PROJECT_ID,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=BUCKET_URI,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e5ee7ee5ae4"
   },
   "source": [
    "接下来，创建并运行一个`HyperparameterTuningJob`。\n",
    "\n",
    "需要注意的一些参数是：\n",
    "\n",
    "* `max_trial_count`: 设置服务运行试验的最大次数上限。建议的做法是从较小数量的试验开始，并了解你选择的超参数在扩展之前的影响程度。\n",
    "\n",
    "* `parallel_trial_count`: 如果您使用并行试验，服务将为多个训练处理集群提供资源。在创建作业时指定的工作池规范将用于每个单独的训练集群。增加并行试验的数量可以减少超参数调整作业的运行时间；但是，这可能会降低作业的效果。这是因为默认的调整策略使用先前试验的结果来指导后续试验中值的分配。\n",
    "\n",
    "* `search_algorithm`: 可用的搜索算法有网格、随机或默认(None)。默认选项应用贝叶斯优化来搜索可能的超参数值空间，是推荐的算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bb6ca1b103ef"
   },
   "outputs": [],
   "source": [
    "# Create and run HyperparameterTuningJob\n",
    "\n",
    "hp_job = aiplatform.HyperparameterTuningJob(\n",
    "    display_name=JOB_NAME,\n",
    "    custom_job=my_custom_job,\n",
    "    metric_spec=metric_spec,\n",
    "    parameter_spec=parameter_spec,\n",
    "    max_trial_count=15,\n",
    "    parallel_trial_count=3,\n",
    "    project=PROJECT_ID,\n",
    "    search_algorithm=None,\n",
    ")\n",
    "\n",
    "hp_job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "396d86efe829"
   },
   "source": [
    "点击输出中生成的链接以在云控制台中查看您的运行情况。当作业完成时，您将看到调试试验的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bee87f15ff24"
   },
   "source": [
    "将以下英文文本翻译为中文: ![console_ui_results](tuning_results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除在此教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "# Set this to true only if you'd like to delete your bucket\n",
    "delete_bucket = False\n",
    "\n",
    "hp_job.delete()\n",
    "\n",
    "!gcloud container images delete $IMAGE_URI --force-delete-tags --quiet\n",
    "\n",
    "if delete_bucket:\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "distributed_hyperparameter_tuning.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
