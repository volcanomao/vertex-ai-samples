{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6b56b1c7b76"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c414a395a19b"
   },
   "source": [
    "使用自定义容器在CPU上使用Vertex AI培训的PyTorch图像分类多节点分布式数据并行训练\n",
    "\n",
    "# 在谷歌协作平台中查看\n",
    "# 在谷歌云协作企业版中查看\n",
    "# 在工作台中打开\n",
    "# 在GitHub上查看\n",
    "\n",
    "请点击链接以获取更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "196084857666"
   },
   "source": [
    "## 概览\n",
    "\n",
    "本教程演示了如何使用 Vertex AI SDK for Python 和自定义容器创建一个分布式 PyTorch 训练作业。这将帮助您的训练作业扩展以处理大量数据。\n",
    "\n",
    "了解更多关于[Vertex AI Training](https://cloud.google.com/vertex-ai/docs/training/custom-training)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f34250c9e39"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用Vertex AI SDK和自定义容器创建一个分布式的PyTorch训练作业。您将设置GCP来使用自定义容器、Vertex TensorBoard实例并运行自定义训练作业。\n",
    "\n",
    "本教程使用以下Google Cloud ML服务：\n",
    "\n",
    "- `Vertex AI SDK`\n",
    "- `Vertex AI TensorBoard`\n",
    "- `CustomContainerTrainingJob`\n",
    "- `Artifact Registry`\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 设置您的GCP项目：设置PROJECT_ID、LOCATION及SERVICE_ACCOUNT\n",
    "- 创建一个云存储桶\n",
    "- 使用Artifact Registry和Docker构建自定义容器\n",
    "- 创建一个Vertex AI TensorBoard实例来存储您的Vertex AI实验\n",
    "- 运行一个Vertex AI SDK CustomContainerTrainingJob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ee27912fc7e"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是<a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST数据库</a>。手写数字MNIST数据库有一个包含60,000个样本的训练集和一个包含10,000个样本的测试集。它是来自NIST的一个更大数据集的子集。这些数字经过了尺寸规范化，并居中在固定大小的图像中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72ce3c3e56b3"
   },
   "source": [
    "成本\n",
    "\n",
    "本教程使用谷歌云的计费组件：\n",
    "* Vertex AI\n",
    "* 云存储\n",
    "* Vertex AI TensorBoard\n",
    "\n",
    "了解[Vertex AI定价](https://cloud.google.com/vertex-ai/pricing)和[云存储定价](https://cloud.google.com/storage/pricing)，并使用[定价计算器](https://cloud.google.com/products/calculator/)，根据您预期的使用量生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "开始吧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### 为Python安装Vertex AI SDK和其他必需的软件包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6d015287b38d"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade google-cloud-aiplatform -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "重新启动运行时（仅限Colab）\n",
    "\n",
    "为了使用新安装的软件包，您必须重新启动Google Colab上的运行时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRvKdaPDTznN"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"> <b>⚠️ 内核将重新启动。在继续下一步之前，请等待它完成。⚠️</b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### 在谷歌Colab上验证您的笔记本环境\n",
    "\n",
    "在谷歌Colab上验证您的环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyKGtVQjgx13"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### 设置Google Cloud项目信息并初始化用于Python的Vertex AI SDK\n",
    "\n",
    "要开始使用Vertex AI，您必须拥有一个现有的Google Cloud项目并[启用Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。了解更多关于[设置项目和开发环境](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nqwi-5ufWp_B"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U674iQcZ1ocJ"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶来存储中间产物，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YRd2bWg1rwY"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = \"gs://your-bucket-name-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkvIAsPx1w7o"
   },
   "source": [
    "只有在您的存储桶尚不存在时：运行以下单元格以创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3-RyUv21z1H"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $LOCATION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUO6ZXQZ11c_"
   },
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABoI6kJg1586"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVzZdeJd17NH"
   },
   "source": [
    "### 初始化用于 Python 的 Vertex AI SDK\n",
    "\n",
    "为您的项目初始化用于 Python 的 Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYX_-zdI192i"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05d881f62170"
   },
   "source": [
    "#### 服务账号\n",
    "\n",
    "您使用服务账号运行Vetex AI CustomContainerTrainingJob。如果您不想使用您的项目的Compute Engine服务账号，请将 `SERVICE_ACCOUNT` 设定为另一个服务账号ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "034c005865b1"
   },
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = \"[your-service-account]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12c03eca5908"
   },
   "source": [
    "### 创建自定义的Python训练包\n",
    "\n",
    "在你可以进行本地训练之前，你必须创建源代码文件、要求文件和Docker文件。\n",
    "\n",
    "你将创建一个目录，并将所有文件写入该文件夹中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f058ed522e8"
   },
   "outputs": [],
   "source": [
    "PYTHON_PACKAGE_APPLICATION_DIR = \"trainer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bc3955a567b"
   },
   "outputs": [],
   "source": [
    "!mkdir -p $PYTHON_PACKAGE_APPLICATION_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "436cc7d0197e"
   },
   "source": [
    "### 编写培训脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34d5b6e85332"
   },
   "outputs": [],
   "source": [
    "%%writefile {PYTHON_PACKAGE_APPLICATION_DIR}/task.py\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Main program for PyTorch distributed training.\n",
    "Adapted from: https://github.com/narumiruna/pytorch-distributed-example\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "from torch import distributed\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils import data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def parse_args():\n",
    "\n",
    "  parser = argparse.ArgumentParser()\n",
    "\n",
    "  # Using environment variables for Cloud Storage directories\n",
    "  # see more details in https://cloud.google.com/vertex-ai/docs/training/code-requirements\n",
    "  parser.add_argument(\n",
    "      '--model-dir', default=os.getenv('AIP_MODEL_DIR'), type=str,\n",
    "      help='a Cloud Storage URI of a directory intended for saving model artifacts')\n",
    "  parser.add_argument(\n",
    "      '--tensorboard-log-dir', default=os.getenv('AIP_TENSORBOARD_LOG_DIR'), type=str,\n",
    "      help='a Cloud Storage URI of a directory intended for saving TensorBoard')\n",
    "  parser.add_argument(\n",
    "      '--checkpoint-dir', default=os.getenv('AIP_CHECKPOINT_DIR'), type=str,\n",
    "      help='a Cloud Storage URI of a directory intended for saving checkpoints')\n",
    "\n",
    "  parser.add_argument(\n",
    "      '--backend', type=str, default='gloo',\n",
    "      help='Use the `nccl` backend for distributed GPU training.'\n",
    "           'Use the `gloo` backend for distributed CPU training.')\n",
    "  parser.add_argument(\n",
    "      '--init-method', type=str, default='env://',\n",
    "      help='URL specifying how to initialize the package.')\n",
    "  parser.add_argument(\n",
    "      '--world-size', type=int, default=os.environ.get('WORLD_SIZE', 1),\n",
    "      help='The total number of nodes in the cluster. '\n",
    "           'This variable has the same value on every node.')\n",
    "  parser.add_argument(\n",
    "      '--rank', type=int, default=os.environ.get('RANK', 0),\n",
    "      help='A unique identifier for each node. '\n",
    "           'On the master worker, this is set to 0. '\n",
    "           'On each worker, it is set to a different value from 1 to WORLD_SIZE - 1.')\n",
    "  parser.add_argument(\n",
    "      '--epochs', type=int, default=20)\n",
    "  parser.add_argument(\n",
    "      '--no-cuda', action='store_true')\n",
    "  parser.add_argument(\n",
    "      '-lr', '--learning-rate', type=float, default=1e-3)\n",
    "  parser.add_argument(\n",
    "      '--batch-size', type=int, default=128)\n",
    "  parser.add_argument(\n",
    "      '--local-mode', action='store_true', help='use local mode when running on your local machine')\n",
    "\n",
    "  args = parser.parse_args()\n",
    "\n",
    "  return args\n",
    "\n",
    "def makedirs(model_dir):\n",
    "  if os.path.exists(model_dir) and os.path.isdir(model_dir):\n",
    "    shutil.rmtree(model_dir)\n",
    "  os.makedirs(model_dir)\n",
    "  return\n",
    "\n",
    "def distributed_is_initialized():\n",
    "  if distributed.is_available():\n",
    "    if distributed.is_initialized():\n",
    "      return True\n",
    "  return False\n",
    "\n",
    "class Average(object):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.sum = 0\n",
    "    self.count = 0\n",
    "\n",
    "  def __str__(self):\n",
    "    return '{:.6f}'.format(self.average)\n",
    "\n",
    "  @property\n",
    "  def average(self):\n",
    "    return self.sum / self.count\n",
    "\n",
    "  def update(self, value, number):\n",
    "    self.sum += value * number\n",
    "    self.count += number\n",
    "\n",
    "class Accuracy(object):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.correct = 0\n",
    "    self.count = 0\n",
    "\n",
    "  def __str__(self):\n",
    "    return '{:.2f}%'.format(self.accuracy * 100)\n",
    "\n",
    "  @property\n",
    "  def accuracy(self):\n",
    "    return self.correct / self.count\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def update(self, output, target):\n",
    "    pred = output.argmax(dim=1)\n",
    "    correct = pred.eq(target).sum().item()\n",
    "\n",
    "    self.correct += correct\n",
    "    self.count += output.size(0)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, device):\n",
    "    super(Net, self).__init__()\n",
    "    self.fc = torch.nn.Linear(784, 10).to(device)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.fc(x.view(x.size(0), -1))\n",
    "\n",
    "class MNISTDataLoader(data.DataLoader):\n",
    "\n",
    "  def __init__(self, root, batch_size, train=True):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.MNIST(root, train=train, transform=transform, download=True)\n",
    "    sampler = None\n",
    "    if train and distributed_is_initialized():\n",
    "      sampler = data.DistributedSampler(dataset)\n",
    "\n",
    "    super(MNISTDataLoader, self).__init__(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(sampler is None),\n",
    "        sampler=sampler,\n",
    "    )\n",
    "\n",
    "class Trainer(object):\n",
    "\n",
    "  def __init__(self,\n",
    "      model,\n",
    "      optimizer,\n",
    "      train_loader,\n",
    "      test_loader,\n",
    "      device,\n",
    "      model_name,\n",
    "      checkpoint_path\n",
    "  ):\n",
    "    self.model = model\n",
    "    self.optimizer = optimizer\n",
    "    self.train_loader = train_loader\n",
    "    self.test_loader = test_loader\n",
    "    self.device = device\n",
    "    self.model_name = model_name\n",
    "    self.checkpoint_path = checkpoint_path\n",
    "\n",
    "  def save(self, model_dir):\n",
    "    model_path = os.path.join(model_dir, self.model_name)\n",
    "    torch.save(self.model.state_dict(), model_path)\n",
    "\n",
    "  def fit(self, epochs, is_chief, writer):\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "      print('Epoch: {}, Training ...'.format(epoch))\n",
    "      train_loss, train_acc = self.train()\n",
    "\n",
    "      if is_chief:\n",
    "        test_loss, test_acc = self.evaluate()\n",
    "        writer.add_scalar('Loss/train', train_loss.average, epoch)\n",
    "        writer.add_scalar('Loss/test', test_loss.average, epoch)\n",
    "        writer.add_scalar('Accuracy/train', train_acc.accuracy, epoch)\n",
    "        writer.add_scalar('Accuracy/test', test_acc.accuracy, epoch)\n",
    "        torch.save(self.model.state_dict(), self.checkpoint_path)\n",
    "\n",
    "        print(\n",
    "            'Epoch: {}/{},'.format(epoch, epochs),\n",
    "            'train loss: {}, train acc: {},'.format(train_loss, train_acc),\n",
    "            'test loss: {}, test acc: {}.'.format(test_loss, test_acc),\n",
    "        )\n",
    "\n",
    "  def train(self):\n",
    "\n",
    "    self.model.train()\n",
    "\n",
    "    train_loss = Average()\n",
    "    train_acc = Accuracy()\n",
    "\n",
    "    for data, target in self.train_loader:\n",
    "      data = data.to(self.device)\n",
    "      target = target.to(self.device)\n",
    "\n",
    "      output = self.model(data)\n",
    "      loss = torch.nn.functional.cross_entropy(output, target)\n",
    "\n",
    "      self.optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "\n",
    "      train_loss.update(loss.item(), data.size(0))\n",
    "      train_acc.update(output, target)\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def evaluate(self):\n",
    "    self.model.eval()\n",
    "\n",
    "    test_loss = Average()\n",
    "    test_acc = Accuracy()\n",
    "\n",
    "    for data, target in self.test_loader:\n",
    "      data = data.to(self.device)\n",
    "      target = target.to(self.device)\n",
    "\n",
    "      output = self.model(data)\n",
    "      loss = torch.nn.functional.cross_entropy(output, target)\n",
    "\n",
    "      test_loss.update(loss.item(), data.size(0))\n",
    "      test_acc.update(output, target)\n",
    "\n",
    "    return test_loss, test_acc\n",
    "\n",
    "def main():\n",
    "\n",
    "  args = parse_args()\n",
    "\n",
    "  local_data_dir = './tmp/data'\n",
    "  local_model_dir = './tmp/model'\n",
    "  local_tensorboard_log_dir = './tmp/logs'\n",
    "  local_checkpoint_dir = './tmp/checkpoints'\n",
    "\n",
    "  model_dir = args.model_dir or local_model_dir\n",
    "  tensorboard_log_dir = args.tensorboard_log_dir or local_tensorboard_log_dir\n",
    "  checkpoint_dir = args.checkpoint_dir or local_checkpoint_dir\n",
    "\n",
    "  gs_prefix = 'gs://'\n",
    "  gcsfuse_prefix = '/gcs/'\n",
    "  if model_dir and model_dir.startswith(gs_prefix):\n",
    "    model_dir = model_dir.replace(gs_prefix, gcsfuse_prefix)\n",
    "  if tensorboard_log_dir and tensorboard_log_dir.startswith(gs_prefix):\n",
    "    tensorboard_log_dir = tensorboard_log_dir.replace(gs_prefix, gcsfuse_prefix)\n",
    "  if checkpoint_dir and checkpoint_dir.startswith(gs_prefix):\n",
    "    checkpoint_dir = checkpoint_dir.replace(gs_prefix, gcsfuse_prefix)\n",
    "\n",
    "  writer = SummaryWriter(tensorboard_log_dir)\n",
    "\n",
    "  is_chief = args.rank == 0\n",
    "  if is_chief:\n",
    "    makedirs(checkpoint_dir)\n",
    "    print(f'Checkpoints will be saved to {checkpoint_dir}')\n",
    "\n",
    "  checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint.pt')\n",
    "  print(f'checkpoint_path is {checkpoint_path}')\n",
    "\n",
    "  if args.world_size > 1:\n",
    "    print('Initializing distributed backend with {} nodes'.format(args.world_size))\n",
    "    distributed.init_process_group(\n",
    "          backend=args.backend,\n",
    "          init_method=args.init_method,\n",
    "          world_size=args.world_size,\n",
    "          rank=args.rank,\n",
    "      )\n",
    "    print(f'[{os.getpid()}]: '\n",
    "          f'world_size = {distributed.get_world_size()}, '\n",
    "          f'rank = {distributed.get_rank()}, '\n",
    "          f'backend={distributed.get_backend()} \\n', end='')\n",
    "\n",
    "  if torch.cuda.is_available() and not args.no_cuda:\n",
    "    device = torch.device('cuda:{}'.format(args.rank))\n",
    "  else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "  model = Net(device=device)\n",
    "  if distributed_is_initialized():\n",
    "    model.to(device)\n",
    "    model = DistributedDataParallel(model)\n",
    "\n",
    "  if is_chief:\n",
    "    # All processes should see same parameters as they all start from same\n",
    "    # random parameters and gradients are synchronized in backward passes.\n",
    "    # Therefore, saving it in one process is sufficient.\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(f'Initial chief checkpoint is saved to {checkpoint_path}')\n",
    "\n",
    "  # Use a barrier() to make sure that process 1 loads the model after process\n",
    "  # 0 saves it.\n",
    "  if distributed_is_initialized():\n",
    "    distributed.barrier()\n",
    "    # configure map_location properly\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    print(f'Initial chief checkpoint is saved to {checkpoint_path} with map_location {device}')\n",
    "  else:\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(f'Initial chief checkpoint is loaded from {checkpoint_path}')\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "  train_loader = MNISTDataLoader(\n",
    "      local_data_dir, args.batch_size, train=True)\n",
    "  test_loader = MNISTDataLoader(\n",
    "      local_data_dir, args.batch_size, train=False)\n",
    "\n",
    "  trainer = Trainer(\n",
    "      model=model,\n",
    "      optimizer=optimizer,\n",
    "      train_loader=train_loader,\n",
    "      test_loader=test_loader,\n",
    "      device=device,\n",
    "      model_name='mnist.pt',\n",
    "      checkpoint_path=checkpoint_path,\n",
    "  )\n",
    "  trainer.fit(args.epochs, is_chief, writer)\n",
    "\n",
    "  if model_dir == local_model_dir:\n",
    "    makedirs(model_dir)\n",
    "    trainer.save(model_dir)\n",
    "    print(f'Model is saved to {model_dir}')\n",
    "\n",
    "  print(f'Tensorboard logs are saved to: {tensorboard_log_dir}')\n",
    "\n",
    "  writer.close()\n",
    "\n",
    "  if is_chief:\n",
    "    os.remove(checkpoint_path)\n",
    "\n",
    "  if distributed_is_initialized():\n",
    "    distributed.destroy_process_group()\n",
    "\n",
    "  return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "253359c5153a"
   },
   "source": [
    "### 写需求文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46423aa093f3"
   },
   "outputs": [],
   "source": [
    "%%writefile {PYTHON_PACKAGE_APPLICATION_DIR}/requirements.txt\n",
    "\n",
    "torch\n",
    "torchvision\n",
    "tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34bea792269a"
   },
   "source": [
    "写docker文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "774a0be3a796"
   },
   "outputs": [],
   "source": [
    "%%writefile {PYTHON_PACKAGE_APPLICATION_DIR}/Dockerfile\n",
    "\n",
    "\n",
    "FROM pytorch/pytorch:1.8.1-cuda11.1-cudnn8-runtime\n",
    "\n",
    "RUN apt-get update && \\\n",
    "    apt-get install -y curl gnupg && \\\n",
    "    echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main\" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list && \\\n",
    "    curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key --keyring /usr/share/keyrings/cloud.google.gpg  add - && \\\n",
    "    apt-get update -y && \\\n",
    "    apt-get install google-cloud-sdk -y\n",
    "\n",
    "COPY . /trainer\n",
    "\n",
    "WORKDIR /trainer\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "ENTRYPOINT [\"python\", \"-m\", \"task\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57bf6f8b4361"
   },
   "source": [
    "本地培训"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5d8a3443da0"
   },
   "outputs": [],
   "source": [
    "! ls trainer\n",
    "! cat trainer/requirements.txt\n",
    "! pip install -r trainer/requirements.txt\n",
    "! cat trainer/task.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0c6e7dfb3c6"
   },
   "outputs": [],
   "source": [
    "%run trainer/task.py --epochs 5 --no-cuda --local-mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31dfdeede587"
   },
   "outputs": [],
   "source": [
    "! ls ./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3614fcdfcd62"
   },
   "source": [
    "清理临时文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48d56ec621cc"
   },
   "outputs": [],
   "source": [
    "! rm -rf ./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8f3ea1210749"
   },
   "source": [
    "### 使用自定义容器进行Vertex AI训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93002a20a2a6"
   },
   "source": [
    "### 构建自定义容器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2d242773d707"
   },
   "source": [
    "启用Artifact Registry API\n",
    "您必须为您的项目启用Artifact Registry API服务。\n",
    "\n",
    "<a href=\"https://cloud.google.com/artifact-registry/docs/enable-service\">了解有关启用服务的更多信息</a>。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d72f89cabd5"
   },
   "outputs": [],
   "source": [
    "! gcloud services enable artifactregistry.googleapis.com\n",
    "\n",
    "if os.getenv(\"IS_TESTING\"):\n",
    "    ! sudo apt-get update --yes && sudo apt-get --only-upgrade --yes install google-cloud-sdk-cloud-run-proxy google-cloud-sdk-harbourbridge google-cloud-sdk-cbt google-cloud-sdk-gke-gcloud-auth-plugin google-cloud-sdk-kpt google-cloud-sdk-local-extract google-cloud-sdk-minikube google-cloud-sdk-app-engine-java google-cloud-sdk-app-engine-go google-cloud-sdk-app-engine-python google-cloud-sdk-spanner-emulator google-cloud-sdk-bigtable-emulator google-cloud-sdk-nomos google-cloud-sdk-package-go-module google-cloud-sdk-firestore-emulator kubectl google-cloud-sdk-datastore-emulator google-cloud-sdk-app-engine-python-extras google-cloud-sdk-cloud-build-local google-cloud-sdk-kubectl-oidc google-cloud-sdk-anthos-auth google-cloud-sdk-app-engine-grpc google-cloud-sdk-pubsub-emulator google-cloud-sdk-datalab google-cloud-sdk-skaffold google-cloud-sdk google-cloud-sdk-terraform-tools google-cloud-sdk-config-connector\n",
    "    ! gcloud components update --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23f3ba8346f4"
   },
   "source": [
    "### 创建一个私有的 Docker 仓库\n",
    "您的第一步是在 Google Artifact Registry 中创建自己的 Docker 仓库。\n",
    "\n",
    "1 - 运行 gcloud artifacts repositories create 命令，在您的区域创建一个新的 Docker 仓库，并使用描述“docker 仓库”。\n",
    "\n",
    "2 - 运行 gcloud artifacts repositories list 命令来验证您的仓库是否已创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64fee26c2dff"
   },
   "outputs": [],
   "source": [
    "PRIVATE_REPO = \"my-docker-repo\"\n",
    "\n",
    "! gcloud artifacts repositories create {PRIVATE_REPO} --repository-format=docker --location={LOCATION} --description=\"Docker repository\"\n",
    "\n",
    "! gcloud artifacts repositories list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38e62011c5e1"
   },
   "outputs": [],
   "source": [
    "DEPLOY_IMAGE = (\n",
    "    f\"{LOCATION}-docker.pkg.dev/\" + PROJECT_ID + f\"/{PRIVATE_REPO}\" + \"/tf_serving\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "775c3eca365c"
   },
   "outputs": [],
   "source": [
    "print(\"Deployment:\", DEPLOY_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "535932b8c42d"
   },
   "source": [
    "# 在工作台执行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd295337455e"
   },
   "source": [
    "### 配置私有存储库的身份验证\n",
    "在推送或拉取容器镜像之前，请配置Docker使用gcloud命令行工具对您地区的Artifact Registry发出的请求进行身份验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79c3fe4ab7f6"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if not IS_COLAB:\n",
    "    ! gcloud auth configure-docker {LOCATION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a822a118c210"
   },
   "source": [
    "### Docker容器镜像用于提供\n",
    "设定用于提供预测的TensorFlow Serving Docker容器镜像。\n",
    "\n",
    "1. 从Docker Hub上拉取相对应的CPU或GPU TensorFlow Serving Docker镜像。\n",
    "2. 为镜像创建一个标签以在Artifact Registry注册。\n",
    "3. 将镜像注册到Artifact Registry。\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/tfx/serving/docker\">了解更多关于TensorFlow Serving的信息</a>。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfec228d9de2"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! cd trainer && docker build -t $DEPLOY_IMAGE -f Dockerfile .\n",
    "    ! docker run --rm $DEPLOY_IMAGE --epochs 5 --no-cuda --local-mode\n",
    "    ! docker push $DEPLOY_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7102219bb621"
   },
   "source": [
    "在Colab中执行\n",
    "\n",
    "使用Cloud Build构建和推送一个Docker镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "736e3c0d1fd8"
   },
   "outputs": [],
   "source": [
    "if IS_COLAB:\n",
    "    ! cd trainer && gcloud builds submit --timeout=1800s --region={LOCATION} --tag $DEPLOY_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73c92c9298e9"
   },
   "source": [
    "### 创建一个 Vertex AI TensorBoard 实例\n",
    "\n",
    "注意: <a href=\"https://cloud.google.com/vertex-ai/pricing#tensorboard\">Vertex AI TensorBoard </a> 每个唯一活跃用户收取每月 $300 的费用。活跃用户通过 Vertex AI TensorBoard UI 进行衡量。您还需为使用 Vertex AI TensorBoard 的 Google Cloud 资源付费，例如存储在 Cloud Storage 中的 TensorBoard 日志。</a> 请查看上面的链接以获取最新价格信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bde509558cd5"
   },
   "outputs": [],
   "source": [
    "content_name = \"pt-img-cls-multi-node-ddp-cust-cont\"\n",
    "content_name = content_name + \"-cpu-unique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6d7908c0083c"
   },
   "outputs": [],
   "source": [
    "tensorboard = aiplatform.Tensorboard.create(\n",
    "    display_name=content_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1f0a4f54037"
   },
   "source": [
    "选项：使用之前创建的Vertex AI Tensorboard实例\n",
    "\n",
    "```\n",
    "tensorboard_name =“您的Tensorboard资源名称或Tensorboard ID”\n",
    "tensorboard = aiplatform.Tensorboard（tensorboard_name = tensorboard_name）\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4cac84e04ac"
   },
   "source": [
    "运行Vertex AI SDK CustomContainerTrainingJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f92e8fdd44ee"
   },
   "outputs": [],
   "source": [
    "display_name = content_name\n",
    "gcs_output_uri_prefix = f\"{BUCKET_URI}/{display_name}\"\n",
    "\n",
    "replica_count = 4\n",
    "machine_type = \"n1-standard-4\"\n",
    "\n",
    "args = [\n",
    "    \"--backend\",\n",
    "    \"gloo\",\n",
    "    \"--no-cuda\",\n",
    "    \"--batch-size\",\n",
    "    \"128\",\n",
    "    \"--epochs\",\n",
    "    \"25\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae4c57df7e07"
   },
   "outputs": [],
   "source": [
    "custom_container_training_job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=display_name,\n",
    "    container_uri=DEPLOY_IMAGE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35cf3ecdf0df"
   },
   "outputs": [],
   "source": [
    "custom_container_training_job.run(\n",
    "    args=args,\n",
    "    base_output_dir=gcs_output_uri_prefix,\n",
    "    replica_count=replica_count,\n",
    "    machine_type=machine_type,\n",
    "    tensorboard=tensorboard.resource_name,\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49d10dded73b"
   },
   "outputs": [],
   "source": [
    "print(f\"Custom Training Job Name: {custom_container_training_job.resource_name}\")\n",
    "print(f\"GCS Output URI Prefix: {gcs_output_uri_prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78398f52807b"
   },
   "source": [
    "### 查看培训输出成果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fc74422de1d1"
   },
   "outputs": [],
   "source": [
    "! gsutil ls $gcs_output_uri_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5e99a6a05b10"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有 Google Cloud 资源，您可以[删除用于此教程的 Google Cloud 项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除此教程中创建的各个资源：\n",
    "\n",
    "- Vertex AI Tensorboard\n",
    "- 云存储桶\n",
    "- 工件存储库\n",
    "- 生成的文件/文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0c1b3f7466b"
   },
   "outputs": [],
   "source": [
    "# Set this to true only if you'd like to delete your bucket\n",
    "delete_bucket = False\n",
    "\n",
    "# Set this to true only if you'd like to delete your tensorboard\n",
    "delete_tensorboard = False\n",
    "\n",
    "# Set this to true only if you'd like to delete your artifact repository\n",
    "delete_artifact_repository = False\n",
    "\n",
    "! gsutil rm -rf $gcs_output_uri_prefix\n",
    "\n",
    "! rm -rf ./trainer\n",
    "\n",
    "if delete_artifact_repository:\n",
    "    !gcloud artifacts repositories delete {PRIVATE_REPO} --location={LOCATION} --quiet\n",
    "\n",
    "if delete_bucket:\n",
    "    ! gsutil rm -r $BUCKET_URI\n",
    "\n",
    "if delete_tensorboard:\n",
    "    tensorboard.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "multi_node_ddp_gloo_vertex_training_with_custom_container.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
