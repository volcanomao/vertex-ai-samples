{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "# 使用Vertex AI分布式训练开始\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/get_started_with_vertex_distributed_training.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> 在Colab中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Ftraining%2Fget_started_with_vertex_distributed_training.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> 在Colab企业版中打开\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/training/get_started_with_vertex_distributed_training.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> 在Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/get_started_with_vertex_distributed_training.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> 在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:mlops"
   },
   "source": [
    "## 概览\n",
    "\n",
    "本教程演示了如何使用Vertex AI Python客户端库来进行TensorFlow模型的分布式训练。\n",
    "\n",
    "**注意：** Colab和Docker之间存在不兼容性，直到平台解决这个问题，Docker部分可能无法正常工作。\n",
    "\n",
    "了解更多关于[Vertex AI分布式训练](https://cloud.google.com/vertex-ai/docs/training/distributed-training)的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:mlops,stage2,get_started_vertex_distributed_training"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何在训练时使用`Vertex AI`的分布式训练功能。\n",
    "\n",
    "本教程使用以下Vertex AI服务：\n",
    "\n",
    "- Vertex AI分布式训练\n",
    "- Vertex AI Reduction Server\n",
    "\n",
    "本教程涵盖以下分布式训练技术：\n",
    "\n",
    "- `MirroredStrategy`：在具有多个GPU的单个VM上训练。\n",
    "- `MultiWorkerMirroredStrategy`（自动）：在多个VM上进行训练，并自动设置副本。\n",
    "- `MultiWorkerMirroredStrategy`：在多个具有精细控制副本的VM上进行训练。\n",
    "- `ReductionServer`：在多个VM上进行训练，并通过**Vertex AI Reduction Server**同步更新。\n",
    "- `TPUTraining`：使用多个云TPU进行训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "recommendation:mlops,stage2,vertex,distributed_training"
   },
   "source": [
    "### 推荐\n",
    "\n",
    "在谷歌云上执行端到端 MLOps 时，以下是在 Vertex AI 分布式训练中使用的最佳实践：\n",
    "\n",
    "**单个 VM / 单个设备（OneDeviceStrategy）**\n",
    "\n",
    "您正在进行实验，总训练数据和模型参数数量很小。\n",
    "\n",
    "如果模型参数的数量非常小，可能无法从 GPU 中获得太多好处，可以考虑使用 VM 的 CPU。\n",
    "\n",
    "**单个 VM / 多个计算设备（MirroredStrategy）**\n",
    "\n",
    "模型参数数量非常大，但总训练数据很小。\n",
    "\n",
    "**多个 VM / 多个计算设备（MultiWorkerMirroredStrategy）**\n",
    "\n",
    "模型参数数量非常大，总训练数据也非常大。\n",
    "\n",
    "**ReductionServer**\n",
    "\n",
    "在大量 VM 上进行训练，模型参数更新的同步非常庞大时。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:custom,boston,lrg"
   },
   "source": [
    "### 数据集\n",
    "\n",
    "本教程使用的数据集是[波士顿房价数据集](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)。在本教程中使用的数据集版本已经内置在TensorFlow中。经过训练的模型预测房屋的中位价格，单位为1K美元。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d10166df7141"
   },
   "source": [
    "成本\n",
    "\n",
    "本教程使用了谷歌云的可计费组件：\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "* Artifact Registry\n",
    "\n",
    "了解[Vertex AI价格](https://cloud.google.com/vertex-ai/pricing)、[Cloud Storage价格](https://cloud.google.com/storage/pricing)和[Artifact Registry价格](https://cloud.google.com/artifact-registry/pricing)，使用[Pricing Calculator](https://cloud.google.com/products/calculator/)根据您的预计使用情况生成成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1ea81ac77f0"
   },
   "source": [
    "开始吧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkYpRvOQyVYb"
   },
   "source": [
    "### 为Python安装Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xs_Kt8RcyXTC"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16220914acc5"
   },
   "source": [
    "### 重新启动运行时（仅限Colab）\n",
    "\n",
    "为了使用新安装的包，您必须重新启动Google Colab上的运行时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "157953ab28f0"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c87a2a5d7e35"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ 内核即将重新启动。在继续下一步之前请等待完成。⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dccb1c8feb6"
   },
   "source": [
    "### 验证您在Google Colab上的笔记本环境 (仅限Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cc7251520a07"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "### 设置谷歌云项目信息\n",
    "\n",
    "了解更多关于[设置项目和开发环境](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10f695aad5fb"
   },
   "source": [
    "### 启用Artifact Registry API\n",
    "\n",
    "首先，您必须为您的项目启用Artifact Registry API服务。\n",
    "\n",
    "了解更多关于[启用服务](https://cloud.google.com/artifact-registry/docs/enable-service)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4c3147ca0f49"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "! gcloud services enable artifactregistry.googleapis.com\n",
    "\n",
    "if os.getenv(\"IS_TESTING\"):\n",
    "    ! sudo apt-get update --yes && sudo apt-get --only-upgrade --yes install google-cloud-sdk-cloud-run-proxy google-cloud-sdk-harbourbridge google-cloud-sdk-cbt google-cloud-sdk-gke-gcloud-auth-plugin google-cloud-sdk-kpt google-cloud-sdk-local-extract google-cloud-sdk-minikube google-cloud-sdk-app-engine-java google-cloud-sdk-app-engine-go google-cloud-sdk-app-engine-python google-cloud-sdk-spanner-emulator google-cloud-sdk-bigtable-emulator google-cloud-sdk-nomos google-cloud-sdk-package-go-module google-cloud-sdk-firestore-emulator kubectl google-cloud-sdk-datastore-emulator google-cloud-sdk-app-engine-python-extras google-cloud-sdk-cloud-build-local google-cloud-sdk-kubectl-oidc google-cloud-sdk-anthos-auth google-cloud-sdk-app-engine-grpc google-cloud-sdk-pubsub-emulator google-cloud-sdk-datalab google-cloud-sdk-skaffold google-cloud-sdk google-cloud-sdk-terraform-tools google-cloud-sdk-config-connector\n",
    "    ! gcloud components update --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61efa7b08cee"
   },
   "source": [
    "在Artifact Registry中创建一个存储库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7479d575df98"
   },
   "outputs": [],
   "source": [
    "# Specify the name of your repo\n",
    "REPO_NAME = \"vertex-distributed-unique\"\n",
    "\n",
    "# Create the repo\n",
    "! gcloud artifacts repositories create {REPO_NAME} --repository-format=docker --location={LOCATION} --description=\"Docker repository\"\n",
    "\n",
    "# List all the repos and verify that your repo is created\n",
    "! gcloud artifacts repositories list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "创建一个云存储桶\n",
    "\n",
    "创建一个存储桶，用于存储中间产物，如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "如果您的存储桶尚不存在：运行以下单元格以创建您的云存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $LOCATION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "### 初始化用于Python的Vertex AI SDK\n",
    "\n",
    "要开始使用Vertex AI，您必须拥有一个现有的Google Cloud项目并[启用Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbvYPSTDulvS"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,prediction,ngpu,mbsdk"
   },
   "source": [
    "设置硬件加速器\n",
    "\n",
    "您可以为训练和预测设置硬件加速器。\n",
    "\n",
    "将变量`TRAIN_GPU/TRAIN_NGPU`和`DEPLOY_GPU/DEPLOY_NGPU`设置为使用支持GPU的容器映像以及分配给虚拟机（VM）实例的GPU数量。例如，要使用一个具有4个Nvidia Telsa T4 GPU分配给每个VM的GPU容器映像，您需要指定：\n",
    "\n",
    "(aiplatform.AcceleratorType.NVIDIA_TESLA_T4, 4)\n",
    "\n",
    "否则，请指定`(None, None)`以在CPU上运行容器映像。\n",
    "\n",
    "了解有关[您地区的硬件加速器支持](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators)的更多信息。\n",
    "\n",
    "**注意：**已知TF在版本2.3之前的GPU支持中在加载自定义模型时会失败。此问题已在TF版本2.3及以上版本中修复。这是由生成在服务函数中的静态图操作所导致的。如果您在自己的自定义模型上遇到此问题，请使用支持GPU的TF 2.3容器映像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PryARdnoulvT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"IS_TESTING_TRAIN_GPU\"):\n",
    "    TRAIN_GPU, TRAIN_NGPU = (\n",
    "        aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_T4,\n",
    "        int(os.getenv(\"IS_TESTING_TRAIN_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    TRAIN_GPU, TRAIN_NGPU = (aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_T4, 1)\n",
    "\n",
    "if os.getenv(\"IS_TESTING_DEPLOY_GPU\"):\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (\n",
    "        aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_T4,\n",
    "        int(os.getenv(\"IS_TESTING_DEPLOY_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction"
   },
   "source": [
    "设置预构建的容器\n",
    "\n",
    "设置用于训练和预测的预构建的Docker容器映像。\n",
    "\n",
    "有关最新列表，请参见[用于训练的预构建容器](https://cloud.google.com/ai-platform-unified/docs/training/pre-built-containers)。\n",
    "\n",
    "有关最新列表，请参见[用于预测的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LhhUFw2nulvT"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TF\"):\n",
    "    TF = os.getenv(\"IS_TESTING_TF\")\n",
    "else:\n",
    "    TF = \"2.8\".replace(\".\", \"-\")\n",
    "\n",
    "if TF[0] == \"2\":\n",
    "    if TRAIN_GPU:\n",
    "        TRAIN_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        TRAIN_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf2-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf2-cpu.{}\".format(TF)\n",
    "else:\n",
    "    if TRAIN_GPU:\n",
    "        TRAIN_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        TRAIN_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "\n",
    "TRAIN_IMAGE = \"{}-docker.pkg.dev/vertex-ai/training/{}:latest\".format(\n",
    "    LOCATION.split(\"-\")[0], TRAIN_VERSION\n",
    ")\n",
    "DEPLOY_IMAGE = \"{}-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(\n",
    "    LOCATION.split(\"-\")[0], DEPLOY_VERSION\n",
    ")\n",
    "\n",
    "print(\"Training:\", TRAIN_IMAGE, TRAIN_GPU, TRAIN_NGPU)\n",
    "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU, DEPLOY_NGPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training"
   },
   "source": [
    "#### 设置机器配置\n",
    "\n",
    "接下来，设置用于训练的机器配置。\n",
    "\n",
    "- 将变量`TRAIN_COMPUTE`设置为配置用于训练的虚拟机的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`：每个vCPU 3.75GB的内存\n",
    "     - `n1-highmem`：每个vCPU 6.5GB的内存\n",
    "     - `n1-highcpu`：每个vCPU 0.9GB的内存\n",
    " - `vCPUs`：数量为\\[2, 4, 8, 16, 32, 64, 96 \\]\n",
    "\n",
    "**注意：**以下配置不支持训练：\n",
    "\n",
    " - `standard`：2个vCPUs\n",
    " - `highcpu`：2、4和8个vCPUs\n",
    "\n",
    "**注意：**您也可以使用n2和e2机器类型进行训练和部署，但它们不支持GPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vytMaukeulvT"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TRAIN_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_TRAIN_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mirrored_intro"
   },
   "source": [
    "## 镜像策略\n",
    "\n",
    "当在单个虚拟机上进行训练时，您可以选择使用单个计算设备进行训练，也可以在同一虚拟机上使用多个计算设备进行训练。使用Vertex AI分布式训练，您可以指定虚拟机实例的计算设备数量和计算设备类型：CPU，GPU。\n",
    "\n",
    "Vertex AI分布式训练支持TensorFlow模型的*tf.distribute.MirroredStrategy*。要在同一虚拟机上跨多个计算设备进行训练，您需要在Python训练脚本中执行以下附加步骤：\n",
    "\n",
    "1. 设置*tf.distribute.MirrorStrategy*。\n",
    "2. 在*tf.distribute.MirrorStrategy*范围内编译模型。这告诉MirroredStrategy应该在您的计算设备之间镜像哪些变量。\n",
    "3. 将每个计算设备的批量大小增加到*num_devices* x *batch size*。\n",
    "\n",
    "在转换期间，批处理的分发以及对模型参数的更新也是同步的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_pp_training_job:mbsdk"
   },
   "source": [
    "### 创建和运行自定义训练作业\n",
    "\n",
    "要训练一个自定义模型，您需要执行两个步骤：1) 创建一个自定义训练作业，以及 2) 运行这个作业。\n",
    "\n",
    "#### 创建自定义训练作业\n",
    "\n",
    "使用`CustomTrainingJob`类创建一个自定义训练作业，具有以下参数：\n",
    "\n",
    "- `display_name`：自定义训练作业的可读名称。\n",
    "- `container_uri`：训练容器镜像。\n",
    "\n",
    "- `python_package_gcs_uri`：Python训练包的位置，以tarball格式。\n",
    "- `python_module_name`：Python包中训练脚本的相对路径。\n",
    "- `model_serving_container_uri`：用于部署模型的容器镜像。\n",
    "\n",
    "**注意：** 不需要`requirements`参数。您可以在Python包的`setup.py`脚本中指定任何要求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhw34XoOulvU"
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"boston-unique\"\n",
    "\n",
    "job = aiplatform.CustomPythonPackageTrainingJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    python_package_gcs_uri=f\"{BUCKET_URI}/trainer_boston.tar.gz\",\n",
    "    python_module_name=\"trainer.task\",\n",
    "    container_uri=TRAIN_IMAGE,\n",
    "    model_serving_container_image_uri=DEPLOY_IMAGE,\n",
    "    project=PROJECT_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_training_package"
   },
   "source": [
    "### 检查培训包\n",
    "\n",
    "#### 包布局\n",
    "\n",
    "在开始培训之前，查看 Python 包如何组装以用于自定义培训工作。解压缩后，包含以下目录/文件布局的包。\n",
    "\n",
    "- PKG-INFO\n",
    "- README.md\n",
    "- setup.cfg\n",
    "- setup.py\n",
    "- trainer\n",
    "  - \\_\\_init\\_\\_.py\n",
    "  - task.py\n",
    "\n",
    "文件 `setup.cfg` 和 `setup.py` 是将包安装到 Docker 镜像的操作环境的指令。\n",
    "\n",
    "文件 `trainer/task.py` 是执行自定义培训工作的 Python 脚本。\n",
    "\n",
    "**注意**：在引用工作池规范时，目录斜杠被替换为点（`trainer.task`），并且文件后缀（`.py`）被省略。\n",
    "\n",
    "#### 包装\n",
    "\n",
    "在以下单元格中，您将装配培训包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IAaZpZyyulvU"
   },
   "outputs": [],
   "source": [
    "# Make folder for Python training script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\nsetuptools.setup(\\n\\n    install_requires=[\\n\\n        'tensorflow==2.8.0',\\n\\n        'tensorflow_datasets==1.3.0',\\n\\n    ],\\n\\n    packages=setuptools.find_packages())\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\nName: Boston Housing cloud\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taskpy_contents:mirrored,boston"
   },
   "source": [
    "#### Task.py 内容\n",
    "\n",
    "在下一个单元格中，编写训练脚本 task.py 的内容。\n",
    "\n",
    "总结来说，task.py 脚本执行以下操作：\n",
    "\n",
    "- 从命令行 (`--model_dir`) 或环境变量 `AIP_MODEL_DIR` 获取保存模型 artifact 的目录。\n",
    "- 从 TF.Keras 内置数据集加载波士顿房屋数据集。\n",
    "- 使用 TF.Keras 模型 API 构建一个简单的深度神经网络模型。\n",
    "- 编译模型（`compile()`）。\n",
    "- 根据参数 `args.distribute` 设置训练分发策略。\n",
    "- 用由 `args.epochs` 指定的 epoch 训练模型（`fit()`）。\n",
    "- 将训练好的模型保存到指定的模型目录中（`save(args.model_dir)`）。\n",
    "- 将每个特征的最大值保存到指定的参数文件中（`f.write(str(params))`）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKzddzl6ulvV"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "# Single, Mirrored and MultiWorker Distributed Training\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model-dir', dest='model_dir',\n",
    "                    default=os.getenv('AIP_MODEL_DIR'), type=str, help='Model dir.')\n",
    "parser.add_argument('--lr', dest='lr',\n",
    "                    default=0.001, type=float,\n",
    "                    help='Learning rate.')\n",
    "parser.add_argument('--epochs', dest='epochs',\n",
    "                    default=10, type=int,\n",
    "                    help='Number of epochs.')\n",
    "parser.add_argument('--steps', dest='steps',\n",
    "                    default=100, type=int,\n",
    "                    help='Number of steps per epoch.')\n",
    "parser.add_argument('--batch_size', dest='batch_size',\n",
    "                    default=16, type=int,\n",
    "                    help='Size of a batch.')\n",
    "parser.add_argument('--distribute', dest='distribute', type=str, default='single',\n",
    "                    help='distributed training strategy')\n",
    "parser.add_argument('--param-file', dest='param_file',\n",
    "                    default='/tmp/param.txt', type=str,\n",
    "                    help='Output file for parameters')\n",
    "args = parser.parse_args()\n",
    "\n",
    "logging.info('DEVICES'  + str(device_lib.list_local_devices()))\n",
    "\n",
    "# Single Machine, single compute device\n",
    "if args.distribute == 'single':\n",
    "    if tf.test.is_gpu_available():\n",
    "        strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    else:\n",
    "        strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
    "    logging.info(\"Single device training\")\n",
    "# Single Machine, multiple compute device\n",
    "elif args.distribute == 'mirrored':\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    logging.info(\"Mirrored Strategy distributed training\")\n",
    "# Multi Machine, multiple compute device\n",
    "elif args.distribute == 'multiworker':\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "    logging.info(\"Multi-worker Strategy distributed training\")\n",
    "    logging.info('TF_CONFIG = {}'.format(os.environ.get('TF_CONFIG', 'Not found')))\n",
    "    # Single Machine, multiple TPU devices\n",
    "elif args.distribute == 'tpu':\n",
    "    cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n",
    "    tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
    "    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "\n",
    "logging.info('num_replicas_in_sync = {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "def _is_chief(task_type, task_id):\n",
    "    ''' Check for primary if multiworker training\n",
    "    '''\n",
    "    return (task_type == 'chief') or (task_type == 'worker' and task_id == 0) or task_type is None\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    # Scaling Boston Housing data features\n",
    "    def scale(feature):\n",
    "        max = np.max(feature)\n",
    "        feature = (feature / max).astype(float)\n",
    "        return feature, max\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "        path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
    "    )\n",
    "\n",
    "    params = []\n",
    "    for _ in range(13):\n",
    "        x_train[_], max = scale(x_train[_])\n",
    "        x_test[_], _ = scale(x_test[_])\n",
    "    params.append(max)\n",
    "\n",
    "    # store the normalization (max) value for each feature\n",
    "    with tf.io.gfile.GFile(args.param_file, 'w') as f:\n",
    "        f.write(str(params))\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def get_model():\n",
    "    model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(128, activation='relu', input_shape=(13,)),\n",
    "          tf.keras.layers.Dense(128, activation='relu'),\n",
    "          tf.keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "          loss='mse',\n",
    "          optimizer=tf.keras.optimizers.RMSprop(learning_rate=args.lr)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train(model, x_train, y_train):\n",
    "    NUM_WORKERS = strategy.num_replicas_in_sync\n",
    "    # Here the batch size scales up by number of workers since\n",
    "    # `tf.data.Dataset.batch` expects the global batch size.\n",
    "    GLOBAL_BATCH_SIZE = args.batch_size * NUM_WORKERS\n",
    "\n",
    "    model.fit(x_train, y_train, epochs=args.epochs, batch_size=GLOBAL_BATCH_SIZE)\n",
    "\n",
    "    if args.distribute == 'multiworker':\n",
    "        task_type, task_id = (strategy.cluster_resolver.task_type,\n",
    "                              strategy.cluster_resolver.task_id)\n",
    "    else:\n",
    "        task_type, task_id = None, None\n",
    "\n",
    "    if args.distribute==\"tpu\":\n",
    "        save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "        model.save(args.model_dir, options=save_locally)\n",
    "    # single, mirrored or primary for multiworker\n",
    "    elif _is_chief(task_type, task_id):\n",
    "        model.save(args.model_dir)\n",
    "    # non-primary workers for multi-workers\n",
    "    else:\n",
    "        # each worker saves their model instance to a unique temp location\n",
    "        worker_dir = args.model_dir + '/workertemp_' + str(task_id)\n",
    "        tf.io.gfile.makedirs(worker_dir)\n",
    "        model.save(worker_dir)\n",
    "\n",
    "with strategy.scope():\n",
    "    # Creation of dataset, and model building/compiling need to be within\n",
    "    # `strategy.scope()`.\n",
    "    model = get_model()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_data()\n",
    "\n",
    "train(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tarball_training_script"
   },
   "source": [
    "将培训脚本存储在您的云存储桶中。\n",
    "\n",
    "接下来，将培训文件夹打包成压缩的tar文件，然后存储到您的云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFUHioqTulvV"
   },
   "outputs": [],
   "source": [
    "! rm -f custom.tar custom.tar.gz\n",
    "! tar cvf custom.tar custom\n",
    "! gzip custom.tar\n",
    "! gsutil cp custom.tar.gz $BUCKET_URI/trainer_boston.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_custom_pp_training_job:mirrored"
   },
   "source": [
    "运行自定义的Python软件包训练任务\n",
    "\n",
    "接下来，通过调用`run()`方法来运行自定义的任务，开始训练工作。参数与运行自定义训练任务时相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LnUX0UkvulvV"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = BUCKET_URI\n",
    "MODEL_DISPLAY_NAME = \"boston-unique\"\n",
    "CMDARGS = [\"--epochs=5\", \"--batch_size=16\", \"--distribute=mirrored\"]\n",
    "\n",
    "model = job.run(\n",
    "    model_display_name=MODEL_DISPLAY_NAME,\n",
    "    args=CMDARGS,\n",
    "    replica_count=1,\n",
    "    machine_type=TRAIN_COMPUTE,\n",
    "    accelerator_type=TRAIN_GPU.name,\n",
    "    accelerator_count=TRAIN_NGPU,\n",
    "    base_output_dir=MODEL_DIR,\n",
    "    sync=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "delete_job"
   },
   "source": [
    "删除自定义训练工作\n",
    "\n",
    "在训练工作完成后，您可以使用`delete()`方法删除训练工作。在完成之前，可以使用`cancel()`方法取消训练工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUWHFpPoulvW"
   },
   "outputs": [],
   "source": [
    "job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_delete:mbsdk"
   },
   "source": [
    "删除模型\n",
    "\n",
    "同样，`delete()` 方法会删除模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0gqCUTEulvW"
   },
   "outputs": [],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "multiworker_intro"
   },
   "source": [
    "多工镜像策略\n",
    "\n",
    "使用Vertex AI分布式训练，您可以使用多个VM实例进行训练。\n",
    "\n",
    "Vertex AI分布式训练支持TensorFlow和PyTorch模型的*tf.distribute.MultiWorkerMirroredStrategy*。要在多个VM上进行训练，您需要在Python训练脚本中执行以下额外步骤：\n",
    "\n",
    "1. 执行镜像策略的所有步骤，只不过需要将MultiWorkerMirroredStrategy替换MirroredStrategy。\n",
    "2. 设置工作节点池。\n",
    "3. 更改模型保存方式，使非主要工作节点将其模型实例保存到唯一的临时目录中。\n",
    "\n",
    "**注意:** 您无需构造TF_CONFIG环境变量，Vertex AI分布式训练会自动构造它。\n",
    "\n",
    "了解更多关于[分布式训练](https://cloud.google.com/vertex-ai/docs/training/distributed-training)的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "worker_pools"
   },
   "source": [
    "### Worker pools\n",
    "\n",
    "如果您在Vertex AI中运行分布式训练作业，则需要在训练集群中指定多台机器（节点）。训练服务会为您指定的机器类型分配资源。在给定节点上运行的作业称为副本。具有相同配置的一组副本称为工作池。\n",
    "\n",
    "训练集群中的每个副本都被指定为分布式训练中的一个单一角色或任务。例如：\n",
    "\n",
    "- **主副本**：指定一个副本作为主副本。此任务负责管理其他副本并报告整个作业的状态。\n",
    "\n",
    "- **工作者**：一个或多个副本可以被指定为工作者。这些副本按照您在作业配置中指定的方式执行其工作。\n",
    "\n",
    "- **参数服务器**：如果您的ML框架支持，可以指定一个或多个副本作为参数服务器。这些副本存储模型参数并在工作者之间协调共享模型状态。\n",
    "\n",
    "- **评估器**：如果您的ML框架支持，可以指定一个或多个副本为评估器。这些副本可用于评估您的模型。如果您正在使用TensorFlow，请注意，TensorFlow通常希望您最多使用一个评估器。\n",
    "\n",
    "要配置分布式训练作业，请定义您的工作池列表（workerPoolSpecs[]），为每种任务指定一个WorkerPoolSpec：\n",
    "\n",
    "**注意：**工作池是按顺序排列的（0..3）：\n",
    "\n",
    "**workerPoolSpecs[0]**：主、首席、调度程序或“主”\n",
    "\n",
    "**workerPoolSpecs[1]**：次要、副本、工作者\n",
    "\n",
    "**workerPoolSpecs[2]**：参数服务器、减少服务器\n",
    "\n",
    "**workerPoolSpecs[3]**：评估器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "multiworker_methods"
   },
   "source": [
    "### Multi-Worker Mirrored Strategy的分布式训练选项\n",
    "\n",
    "设置工作池取决于您用于训练的Vertex AI方法。\n",
    "\n",
    "**CustomTrainingJob** / **CustomContainerTrainingJob** / **CustomPythonPackageTrainingJob**\n",
    "\n",
    "`replica_count`包括主要和次要（replica_count-1），并且共享相同的机器类型和加速器。\n",
    "\n",
    "您无法指定参数服务器或评估节点。\n",
    "\n",
    "**CustomJob**\n",
    "\n",
    "您可以指定一个`worker_pool_spec`，在其中可以为四个工作池中的每一个指定详细设置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXvPN8P6ulvX"
   },
   "source": [
    "### 创建和运行自定义训练任务\n",
    "\n",
    "要训练一个自定义模型，您需要进行两个步骤：1）创建一个自定义训练任务，以及2）运行该任务。\n",
    "\n",
    "#### 创建自定义训练任务\n",
    "\n",
    "使用`CustomTrainingJob`类创建一个自定义训练任务，需要提供以下参数：\n",
    "\n",
    "- `display_name`：自定义训练任务的可读名称。\n",
    "- `container_uri`：训练容器镜像。\n",
    "- `python_package_gcs_uri`：Python训练包的位置（.tarball文件）。\n",
    "- `python_module_name`：Python包中训练脚本的相对路径。\n",
    "- `model_serving_container_uri`：用于部署模型的容器镜像。\n",
    "\n",
    "**注意：** 没有`requirements`参数。您需要在Python包中的`setup.py`脚本中指定任何依赖关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kYcFsVSEulvX"
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"boston-unique\"\n",
    "\n",
    "job = aiplatform.CustomPythonPackageTrainingJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    python_package_gcs_uri=f\"{BUCKET_URI}/trainer_boston.tar.gz\",\n",
    "    python_module_name=\"trainer.task\",\n",
    "    container_uri=TRAIN_IMAGE,\n",
    "    model_serving_container_image_uri=DEPLOY_IMAGE,\n",
    "    project=PROJECT_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_custom_pp_training_job:multiworker"
   },
   "source": [
    "运行自定义的Python包训练作业\n",
    "\n",
    "接下来，通过调用`run()`方法来运行自定义作业，开始训练作业。参数与运行CustomTrainingJob时相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHRxPU32ulvX"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = BUCKET_URI\n",
    "\n",
    "CMDARGS = [\"--epochs=5\", \"--batch_size=16\", \"--distribute=multiworker\"]\n",
    "\n",
    "try:\n",
    "    model = job.run(\n",
    "        model_display_name=MODEL_DISPLAY_NAME,\n",
    "        args=CMDARGS,\n",
    "        replica_count=4,\n",
    "        machine_type=TRAIN_COMPUTE,\n",
    "        accelerator_type=TRAIN_GPU.name,\n",
    "        accelerator_count=TRAIN_NGPU,\n",
    "        base_output_dir=MODEL_DIR,\n",
    "        sync=True,\n",
    "    )\n",
    "except Exception as e:\n",
    "    # may fail duing model.save() -- seems to be some issue when merging checkpoints from the workers\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92D_hbuVulvX"
   },
   "source": [
    "### 删除自定义训练作业\n",
    "\n",
    "在训练作业完成后，您可以使用 `delete()` 方法删除训练作业。在完成之前，可以使用 `cancel()` 方法取消训练作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqrfWkB3ulvX"
   },
   "outputs": [],
   "source": [
    "job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "customjob_intro:multiworker"
   },
   "source": [
    "### 使用CustomJob进行分布式多工作器训练\n",
    "\n",
    "使用`CustomJob`进行分布式多工作器训练具有对主副本的细粒度控制以及可选择为参数服务器和评估器指定工作器池的优势。创建一个`CustomJob`包括以下步骤：\n",
    "\n",
    "1. 为每个工作器池指定详细信息。\n",
    "2. 将训练包嵌入Docker镜像中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_docker_container:training"
   },
   "source": [
    "### 构建一个自定义的训练容器\n",
    "\n",
    "要使用您自己的自定义训练容器，您需要构建一个 Docker 文件，并将您的训练脚本嵌入到容器中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "write_docker_file:training,multiworker"
   },
   "source": [
    "#### 编写Docker文件内容\n",
    "\n",
    "容器化您的代码的第一步是创建一个Docker文件。在Docker文件中，包括运行容器镜像所需的所有命令。Docker安装您指定的所有库，并设置训练代码的入口点。\n",
    "\n",
    "Docker文件中的步骤包括:\n",
    "\n",
    "1. 从 TensorFlow 仓库中安装预定义的深度学习镜像。\n",
    "2. 将 Python 训练代码复制到镜像中，随后会展示。\n",
    "3. 将 Python 训练脚本的入口点设置为 `trainer/task.py`。请注意，ENTRYPOINT 命令中省略了 `.py`，因为这是隐含的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGI2viDAulvY"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/Dockerfile\n",
    "\n",
    "FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-8\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY trainer /trainer\n",
    "\n",
    "# Sets up the entry point to invoke the trainer.\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea91554a10a8"
   },
   "source": [
    "#### 配置身份验证到您的仓库\n",
    "\n",
    "在推送或拉取容器镜像之前，配置Docker使用gcloud命令行工具对您的地区的Artifact Registry进行请求的身份验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4eae17cce6bd"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if not IS_COLAB:\n",
    "    ! gcloud auth configure-docker {LOCATION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "name_container:training"
   },
   "source": [
    "#### 本地构建容器镜像\n",
    "\n",
    "使用 `docker build` 命令本地构建您的容器镜像。\n",
    "\n",
    "使用 `-t` 标志提供仓库名称作为标签。了解更多关于将镜像添加到[Artifact Registry](https://cloud.google.com/artifact-registry/docs/docker/store-docker-container-images#add-image)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cc28b1a4d16"
   },
   "outputs": [],
   "source": [
    "# Specify the repository name where the image needs to be uploaded\n",
    "TRAIN_IMAGE = f\"{LOCATION}-docker.pkg.dev/{PROJECT_ID}/{REPO_NAME}/boston:v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmw5cakNulvY"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    # build the image locally with the repository name as a tag\n",
    "    ! docker build custom -t $TRAIN_IMAGE\n",
    "else:\n",
    "    # install docker daemon\n",
    "    ! apt-get -qq install docker.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_container:training"
   },
   "source": [
    "# 在本地测试容器\n",
    "\n",
    "在笔记本实例中运行容器5个周期，以确保它可以正常工作。\n",
    "\n",
    "**注意**：如果您在笔记本环境中运行此教程，例如 Vertex AI workbench，请继续以下步骤。而如果您在 Colab 上运行，请跳转到\"[在Colab中运行](#在Colab中运行)\"部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJGLjU-TulvZ"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! docker run $TRAIN_IMAGE --epochs=5 --model-dir=./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "register_container:training"
   },
   "source": [
    "#### 注册自定义容器\n",
    "\n",
    "在本地运行容器完成后，将其推送到Artifact Registry。\n",
    "\n",
    "在配置身份验证和为本地映像打标签之后，您可以将映像推送到您创建的存储库中。\n",
    "\n",
    "要推送Docker映像，请运行以下命令："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GAXGjae7ulvZ"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! docker push $TRAIN_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f50e9c553fb7"
   },
   "source": [
    "#### 在Colab中执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7e8c98f1e56"
   },
   "outputs": [],
   "source": [
    "%%bash -s $IS_COLAB $TRAIN_IMAGE\n",
    "if [ $1 == \"False\" ]; then\n",
    "  exit 0\n",
    "fi\n",
    "set -x\n",
    "dockerd -b none --iptables=0 -l warn &\n",
    "for i in $(seq 5); do [ ! -S \"/var/run/docker.sock\" ] && sleep 2 || break; done\n",
    "docker build custom -t $2\n",
    "docker run $2 --epochs=5 --model-dir=./\n",
    "docker push $2\n",
    "kill $(jobs -p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "worker_pool_primary"
   },
   "source": [
    "主要工作池\n",
    "\n",
    "主要工作池（索引0）协调所有其他副本完成的工作。 将“replica_count”设置为1。\n",
    "\n",
    "由于此工作者是协调而不是训练，因此请使用通用目的的 CPU，而不是 GPU。\n",
    "\n",
    "了解有关[用于训练的机器类型](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types)的更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CEAnXBzCulvZ"
   },
   "outputs": [],
   "source": [
    "PRIMARY_COMPUTE = \"n2-highcpu-64\"\n",
    "\n",
    "MODEL_DIR = BUCKET_URI\n",
    "\n",
    "CMDARGS = [\n",
    "    \"--model-dir=\" + MODEL_DIR,\n",
    "    \"--epochs=5\",\n",
    "    \"--batch_size=16\",\n",
    "    \"--distribute=multiworker\",\n",
    "]\n",
    "\n",
    "CONTAINER_SPEC = {\"image_uri\": TRAIN_IMAGE, \"command\": \"trainer.task\", \"args\": CMDARGS}\n",
    "\n",
    "PRIMARY_WORKER_POOL = {\n",
    "    \"replica_count\": 1,\n",
    "    \"machine_spec\": {\"machine_type\": PRIMARY_COMPUTE, \"accelerator_count\": 0},\n",
    "    \"container_spec\": CONTAINER_SPEC,\n",
    "}\n",
    "\n",
    "WORKER_POOL_SPECS = [PRIMARY_WORKER_POOL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "worker_pool_training"
   },
   "source": [
    "培训工人池\n",
    "\n",
    "次要工人池（索引1）执行模型培训。每个副本都安装有您的培训软件包的实例。\n",
    "\n",
    "每个副本可能具有一个（单设备培训）或多个（镜像）用于培训的计算设备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6dchPSfNulvZ"
   },
   "outputs": [],
   "source": [
    "TRAIN_WORKER_POOL = {\n",
    "    \"replica_count\": 4,\n",
    "    \"machine_spec\": {\n",
    "        \"machine_type\": TRAIN_COMPUTE,\n",
    "        \"accelerator_count\": TRAIN_NGPU,\n",
    "        \"accelerator_type\": TRAIN_GPU,\n",
    "    },\n",
    "    \"container_spec\": CONTAINER_SPEC,\n",
    "}\n",
    "\n",
    "WORKER_POOL_SPECS.append(TRAIN_WORKER_POOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "custom_job:worker_pool"
   },
   "source": [
    "使用工作人员池规范创建CustomJob\n",
    "\n",
    "接下来，为多工作人员分布式培训工作创建CustomJob。\n",
    "\n",
    "指定以下参数：\n",
    "\n",
    "- `display_name`：自定义工作的显示名称。\n",
    "\n",
    "- `worker_pool_specs`：每个工作人员池的详细规格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2VgmqEOulva"
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"boston-unique\"\n",
    "\n",
    "job = aiplatform.CustomJob(\n",
    "    display_name=DISPLAY_NAME, worker_pool_specs=WORKER_POOL_SPECS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_custom_job:multiworker"
   },
   "source": [
    "运行定制作业\n",
    "\n",
    "接下来，运行定制作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hg8vnI_Wulva"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    job.run(sync=True)\n",
    "except Exception as e:\n",
    "    # may fail in multi-worker to find startup script\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WT76Sc-culva"
   },
   "source": [
    "### 删除自定义训练任务\n",
    "\n",
    "训练任务完成后，您可以使用 `delete()` 方法删除训练任务。在完成之前，训练任务可以使用 `cancel()` 方法取消。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_IxVfuDulva"
   },
   "outputs": [],
   "source": [
    "job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reduction_server_intro"
   },
   "source": [
    "## 降幅服务器\n",
    "\n",
    "为了加快大型模型的训练速度，许多工程团队正在采用分布式训练，使用ML加速器的规模扩展集群。然而，在规模化的分布式训练中会带来一系列挑战。特别是节点之间有限的网络带宽使得分布式训练的性能优化困难，特别是对于大型集群配置。\n",
    "\n",
    "Vertex AI降幅服务器优化了NVIDIA GPU上同步数据并行算法的多节点分布式训练的带宽和延迟。同步数据并行是许多广泛采用的分布式训练框架的基础，包括TensorFlow的MultiWorkerMirroredStrategy、Horovod和PyTorch Distributed。通过优化这些框架使用的all-reduce集合操作的带宽使用和延迟，降幅服务器可以降低大型训练作业的时间和成本。\n",
    "\n",
    "了解更多关于[在Vertex AI上使用降幅服务器优化训练性能](https://cloud.google.com/blog/topics/developers-practitioners/optimize-training-performance-reduction-server-vertex-ai)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "worker_pool_reduction_server"
   },
   "outputs": [],
   "source": [
    "reduction_server_count = 1\n",
    "reduction_server_machine_type = \"n1-highcpu-16\"\n",
    "reduction_server_image_uri = (\n",
    "    \"us-docker.pkg.dev/vertex-ai-restricted/training/reductionserver:latest\"\n",
    ")\n",
    "\n",
    "PARAMETER_POOL = {\n",
    "    \"replica_count\": reduction_server_count,\n",
    "    \"machine_spec\": {\n",
    "        \"machine_type\": reduction_server_machine_type,\n",
    "    },\n",
    "    \"container_spec\": {\"image_uri\": reduction_server_image_uri},\n",
    "}\n",
    "WORKER_POOL_SPECS.append(PARAMETER_POOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8Av8ATVulvb"
   },
   "source": [
    "### 使用工作池规范创建CustomJob\n",
    "\n",
    "接下来，为多工作人员分布式培训工作创建`CustomJob`。\n",
    "\n",
    "指定以下参数：\n",
    "\n",
    "- `display_name`：自定义作业的显示名称。\n",
    "\n",
    "- `worker_pool_specs`：每个工作池的详细规范。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUWEP1Lmulvb"
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"boston-unique\"\n",
    "\n",
    "job = aiplatform.CustomJob(\n",
    "    display_name=DISPLAY_NAME, worker_pool_specs=WORKER_POOL_SPECS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_95FH8jeulvb"
   },
   "source": [
    "运行自定义作业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEbrY05Gulvb"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    job.run(sync=True)\n",
    "except Exception as e:\n",
    "    # may fail in multi-worker to find startup script\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8R2Bnmwmulvb"
   },
   "source": [
    "### 删除自定义训练作业\n",
    "\n",
    "在训练作业完成后，您可以使用 `delete()` 方法来删除训练作业。在完成之前，训练作业可以使用 `cancel()` 方法取消。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1geVE3Lulvb"
   },
   "outputs": [],
   "source": [
    "job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpu_intro"
   },
   "source": [
    "## 云 TPU 训练\n",
    "\n",
    "为了进一步加快训练速度，您的组织可以利用谷歌的云张量处理单元 (TPU) 云。\n",
    "\n",
    "云 TPU 是谷歌产品如翻译、照片、搜索、助手和 Gmail 所使用的定制机器学习 ASIC。云 TPU 旨在在谷歌云上运行尖端机器学习模型与 AI 服务。它的定制高速网络在单个云中提供超过 100 petaflops 的性能。\n",
    "\n",
    "了解有关[云 TPU](https://cloud.google.com/tpu)的更多信息。\n",
    "\n",
    "**注意**：TPU 虚拟机训练目前是一项可选择的功能。您的 GCP 项目必须首先被添加到功能允许列表中。请通过电子邮件将您的项目信息 (项目 ID/编号) 发送至 vertex-ai-tpu-vm-training-support@google.com 以允许列表。您的项目准备好后将收到一封电子邮件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "docker_write:tpu"
   },
   "source": [
    "### 为 TPU 训练编写 Docker 文件\n",
    "\n",
    "目前，还没有专门用于在 TPU 上进行训练的 Vertex AI Docker 镜像。但是，您可以自己制作一个，按照以下步骤操作：\n",
    "\n",
    "1. 创建一个纯净的 Python 3 镜像（例如，`python3:8`）。\n",
    "2. 获取并安装 TPU 库（`libtpu.so`）。\n",
    "3. 从您的训练包中复制训练器代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQVPtknpulvb"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/Dockerfile\n",
    "FROM python:3.8\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY trainer /trainer\n",
    "\n",
    "RUN pip3 install tensorflow-datasets\n",
    "\n",
    "# Install TPU Tensorflow and dependencies.\n",
    "# libtpu.so must be under the '/lib' directory.\n",
    "RUN wget https://storage.googleapis.com/cloud-tpu-tpuvm-artifacts/libtpu/20210525/libtpu.so -O /lib/libtpu.so\n",
    "RUN chmod 777 /lib/libtpu.so\n",
    "\n",
    "RUN wget https://storage.googleapis.com/cloud-tpu-tpuvm-artifacts/tensorflow/20210525/tf_nightly-2.6.0-cp38-cp38-linux_x86_64.whl\n",
    "RUN pip3 install tf_nightly-2.6.0-cp38-cp38-linux_x86_64.whl\n",
    "RUN rm tf_nightly-2.6.0-cp38-cp38-linux_x86_64.whl\n",
    "# Sets up the entry point to invoke the trainer.\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "docker_push:tpu"
   },
   "source": [
    "构建并推送Docker镜像到Artifact Registry。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_d_zEXUulvc"
   },
   "outputs": [],
   "source": [
    "# Specify the repository name where the image needs to be uploaded\n",
    "TPU_TRAIN_IMAGE = f\"{LOCATION}-docker.pkg.dev/{PROJECT_ID}/{REPO_NAME}/tpu-train:latest\"\n",
    "\n",
    "if not IS_COLAB:\n",
    "    # build the image locally with the repository name as a tag\n",
    "    ! docker build --quiet -t $TPU_TRAIN_IMAGE custom\n",
    "    # push the image to artifact registry\n",
    "    ! docker push $TPU_TRAIN_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1662bb56b144"
   },
   "source": [
    "如果您正在使用Colab，请运行下面的单元格来构建并推送图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8099b51c559c"
   },
   "outputs": [],
   "source": [
    "%%bash -s $IS_COLAB $TPU_TRAIN_IMAGE\n",
    "if [ $1 == \"False\" ]; then\n",
    "  exit 0\n",
    "fi\n",
    "set -x\n",
    "dockerd -b none --iptables=0 -l warn &\n",
    "for i in $(seq 5); do [ ! -S \"/var/run/docker.sock\" ] && sleep 2 || break; done\n",
    "docker build --quiet custom -t $2\n",
    "docker push $2\n",
    "kill $(jobs -p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "worker_pool_tpu"
   },
   "source": [
    "TPU工作人员规范池\n",
    "\n",
    "接下来，创建工作人员规范池。\n",
    "\n",
    "对于TPUs：\n",
    "\n",
    "- 仅创建一个工作人员池（主要）。\n",
    "- 将机器类型设置为`cloud-tpu`。\n",
    "- 将加速器类型设置为`TPU`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d514eU7lulvc"
   },
   "outputs": [],
   "source": [
    "# Use TPU Accelerators. Temporarily using numeric codes, until types are added to the SDK\n",
    "#   6 = TPU_V2\n",
    "#   7 = TPU_V3\n",
    "TRAIN_TPU, TRAIN_NTPU = (7, 8)\n",
    "TRAIN_COMPUTE = \"cloud-tpu\"\n",
    "\n",
    "\n",
    "if not TRAIN_NTPU or TRAIN_NTPU < 2:\n",
    "    TRAIN_STRATEGY = \"single\"\n",
    "else:\n",
    "    TRAIN_STRATEGY = \"tpu\"\n",
    "print(TRAIN_STRATEGY)\n",
    "\n",
    "EPOCHS = 20\n",
    "STEPS = 10000\n",
    "\n",
    "TRAINER_ARGS = [\n",
    "    \"--epochs=\" + str(EPOCHS),\n",
    "    \"--steps=\" + str(STEPS),\n",
    "    \"--distribute=\" + TRAIN_STRATEGY,\n",
    "]\n",
    "\n",
    "\n",
    "WORKER_POOL_SPECS = [\n",
    "    {\n",
    "        \"container_spec\": {\n",
    "            \"args\": TRAINER_ARGS,\n",
    "            \"image_uri\": TPU_TRAIN_IMAGE,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": TRAIN_COMPUTE,\n",
    "            \"accelerator_type\": TRAIN_TPU,\n",
    "            \"accelerator_count\": TRAIN_NTPU,\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "print(WORKER_POOL_SPECS[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RruSqNfrulvc"
   },
   "source": [
    "### 使用worker pool规格创建CustomJob\n",
    "\n",
    "接下来，为多工作节点分布式训练作业创建一个`CustomJob`：\n",
    "\n",
    "- `display_name`：自定义作业的显示名称。\n",
    "\n",
    "- `worker_pool_specs`：每个工作节点池的详细规格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QvSqbbHulvc"
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"boston-unique\"\n",
    "\n",
    "job = aiplatform.CustomJob(\n",
    "    display_name=DISPLAY_NAME, worker_pool_specs=WORKER_POOL_SPECS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iw4L3UIfulvd"
   },
   "source": [
    "### 运行自定义作业\n",
    "\n",
    "接下来，运行自定义作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmqCNS78ulvd"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    job.run(sync=True)\n",
    "except Exception as e:\n",
    "    # may fail in multi-worker to find startup script\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWZoH9QKulvd"
   },
   "source": [
    "### 删除自定义训练作业\n",
    "\n",
    "在训练作业完成后，您可以使用 `delete()` 方法删除训练作业。在完成之前，可以使用 `cancel()` 方法取消训练作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lt8BJ4iBulvd"
   },
   "outputs": [],
   "source": [
    "job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除您用于本教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源：\n",
    "\n",
    "\n",
    "- 云存储存储桶\n",
    "- 工件存储库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U98Wzc01ulvd"
   },
   "outputs": [],
   "source": [
    "# Set this to true only if you'd like to delete your bucket\n",
    "delete_bucket = False\n",
    "\n",
    "if delete_bucket:\n",
    "    ! gsutil rm -r $BUCKET_URI\n",
    "\n",
    "# Delete the repo in Artifact Registry\n",
    "!gcloud artifacts repositories delete --location=$LOCATION $REPO_NAME --quiet\n",
    "\n",
    "# Delete the locally generated files\n",
    "!rm -rf custom/\n",
    "!rm custom.tar.gz"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_with_vertex_distributed_training.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
