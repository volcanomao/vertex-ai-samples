{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# 通过Vertex AI Training启动LightGBM\n",
    "\n",
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/get_started_vertex_training_lightgbm.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> 在Colab中运行\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/get_started_vertex_training_lightgbm.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      在GitHub上查看\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/training/get_started_vertex_training_lightgbm.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      在Vertex AI Workbench中打开\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/>\n",
    "这份笔记本是[Rajesh Thallam](https://github.com/RajeshThallam/vertex-ai-labs/blob/main/07-vertex-train-deploy-lightgbm/vertex-train-deploy-lightgbm-model.ipynb)的笔记本的修订版。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:mlops"
   },
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何使用Vertex AI Training来训练一个LightGBM模型。\n",
    "\n",
    "了解更多关于[自定义训练](https://cloud.google.com/vertex-ai/docs/training/custom-training)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:mlops,stage2,get_started_vertex_training_xgboost"
   },
   "source": [
    "### 目标\n",
    "\n",
    "在本教程中，您将学习如何使用`Vertex AI Training`来训练一个LightGBM自定义模型。\n",
    "\n",
    "本教程使用以下Google Cloud ML服务：\n",
    "\n",
    "- `Vertex AI Training`\n",
    "- `Vertex AI Model` 资源\n",
    "\n",
    "执行的步骤包括：\n",
    "\n",
    "- 使用Python包进行训练。\n",
    "- 使用GCSFuse将模型工件保存到Cloud Storage。\n",
    "- 构建一个FastAPI预测服务器。\n",
    "- 构建一个Dockerfile部署镜像。\n",
    "- 在本地测试部署镜像。\n",
    "- 创建一个`Vertex AI Model`资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:iris,lcn"
   },
   "source": [
    "数据集\n",
    "\n",
    "本教程使用的数据集是来自[TensorFlow数据集](https://www.tensorflow.org/datasets/catalog/iris)的[Iris数据集](https://www.tensorflow.org/datasets/catalog/iris)。这个数据集不需要任何特征工程。本教程中的数据集版本存储在公共云存储存储桶中。训练后的模型可以预测三种Iris花种类中的一种：山鸢尾、维吉尼亚或变色鸢尾。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de76bb18c85b"
   },
   "source": [
    "### 成本\n",
    "\n",
    "本教程使用谷歌云的计费组件：\n",
    "* Vertex AI\n",
    "* 云存储\n",
    "\n",
    "了解[Vertex AI 价格](https://cloud.google.com/vertex-ai/pricing)和[云存储价格](https://cloud.google.com/storage/pricing)，并使用[定价计算器](https://cloud.google.com/products/calculator/)生成基于您预计使用量的成本估算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "source": [
    "安装以下软件包以执行此笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "! pip3 install --upgrade google-cloud-aiplatform  -q\n",
    "! pip3 install -U google-cloud-storage  -q\n",
    "! pip3 install -U lightgbm  -q\n",
    "! pip3 install --upgrade google-auth -q\n",
    "\n",
    "if os.getenv(\"IS_TESTING\"):\n",
    "    ! pip3 install --upgrade tensorflow -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58707a750154"
   },
   "source": [
    "只有在Colab上才能执行：取消注释以下单元格以重启内核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f200f10a1da3"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "设定您的项目ID\n",
    "\n",
    "**如果您不知道您的项目ID**，请尝试以下步骤：\n",
    "* 运行 `gcloud config list`。\n",
    "* 运行 `gcloud projects list`。\n",
    "* 查看支持页面：[查找项目ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "### 设置区域\n",
    "\n",
    "**可选**: 更新 'REGION' 变量以指定您想要使用的区域。了解更多关于[Vertex AI 区域](https://cloud.google.com/vertex-ai/docs/general/locations)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsN5NJKSu-GU"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBCra4QMA2wR"
   },
   "source": [
    "### 验证您的谷歌云账户\n",
    "\n",
    "要验证您的谷歌云账户，请按照您的Jupyter环境的说明进行操作：\n",
    "\n",
    "**1. Vertex AI Workbench**\n",
    "<br>您已经通过身份验证。\n",
    "\n",
    "**2. 本地JupyterLab实例**\n",
    "<br>取消注释并运行以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "254614fa0c46"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef21552ccea8"
   },
   "source": [
    "取消注释并运行以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "603adbbf0532"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c13224697bfb"
   },
   "source": [
    "4. 服务账号或其他\n",
    "* 请参阅如何在https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples上为您的服务账号授予Cloud Storage权限。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### 创建一个云存储桶\n",
    "\n",
    "创建一个存储桶，用于存储中间产物，例如数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "只有在您的存储桶尚不存在时：运行以下单元格即可创建您的云存储存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### 设置变量\n",
    "\n",
    "接下来，设置一些在教程中将要使用的变量。\n",
    "### 导入库和定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3c0380967f5"
   },
   "outputs": [],
   "source": [
    "print(f\"LightGBM version {lightgbm.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "初始化Python的Vertex SDK\n",
    "\n",
    "为您的项目和对应的存储桶初始化Python的Vertex AI SDK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gar_enable_api"
   },
   "source": [
    "### 启用Artifact Registry API\n",
    "\n",
    "首先，您必须为您的项目启用Artifact Registry API服务。\n",
    "\n",
    "了解更多关于[启用服务](https://cloud.google.com/artifact-registry/docs/enable-service)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gar_enable_api"
   },
   "outputs": [],
   "source": [
    "! gcloud services enable artifactregistry.googleapis.com\n",
    "\n",
    "if os.getenv(\"IS_TESTING\"):\n",
    "    ! sudo apt-get update --yes && sudo apt-get --only-upgrade --yes install google-cloud-sdk-cloud-run-proxy google-cloud-sdk-harbourbridge google-cloud-sdk-cbt google-cloud-sdk-gke-gcloud-auth-plugin google-cloud-sdk-kpt google-cloud-sdk-local-extract google-cloud-sdk-minikube google-cloud-sdk-app-engine-java google-cloud-sdk-app-engine-go google-cloud-sdk-app-engine-python google-cloud-sdk-spanner-emulator google-cloud-sdk-bigtable-emulator google-cloud-sdk-nomos google-cloud-sdk-package-go-module google-cloud-sdk-firestore-emulator kubectl google-cloud-sdk-datastore-emulator google-cloud-sdk-app-engine-python-extras google-cloud-sdk-cloud-build-local google-cloud-sdk-kubectl-oidc google-cloud-sdk-anthos-auth google-cloud-sdk-app-engine-grpc google-cloud-sdk-pubsub-emulator google-cloud-sdk-datalab google-cloud-sdk-skaffold google-cloud-sdk google-cloud-sdk-terraform-tools google-cloud-sdk-config-connector\n",
    "    ! gcloud components update --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gar_create_repo"
   },
   "source": [
    "### 创建一个私有的Docker仓库\n",
    "\n",
    "您的第一步是在Google Artifact Registry中创建自己的Docker仓库。\n",
    "\n",
    "1. 运行`gcloud artifacts repositories create`命令，使用您的地区创建一个新的Docker仓库，并添加描述“docker仓库”。\n",
    "\n",
    "2. 运行`gcloud artifacts repositories list`命令来验证您的仓库是否已经创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gar_create_repo"
   },
   "outputs": [],
   "source": [
    "PRIVATE_REPO = \"prediction\"\n",
    "\n",
    "! gcloud artifacts repositories create {PRIVATE_REPO} --repository-format=docker --location={REGION} --description=\"Prediction repository\"\n",
    "\n",
    "! gcloud artifacts repositories list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gar_auth"
   },
   "source": [
    "### 配置私人仓库的身份验证\n",
    "\n",
    "在推送或拉取容器镜像之前，配置Docker使用`gcloud`命令行工具，对您区域的`Artifact Registry`进行身份验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gar_auth"
   },
   "outputs": [],
   "source": [
    "! gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction,xgboost"
   },
   "source": [
    "设置预先构建的容器\n",
    "\n",
    "为训练和预测设置预先构建的Docker容器镜像。\n",
    "\n",
    "有关最新列表，请参阅[用于训练的预构建容器](https://cloud.google.com/ai-platform-unified/docs/training/pre-built-containers)。\n",
    "\n",
    "有关最新列表，请参阅[预测用的预构建容器](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "container:training,prediction,xgboost"
   },
   "outputs": [],
   "source": [
    "TRAIN_VERSION = \"scikit-learn-cpu.0-23\"\n",
    "DEPLOY_VERSION = \"lightgbm-cpu\"\n",
    "\n",
    "# prebuilt\n",
    "TRAIN_IMAGE = \"{}-docker.pkg.dev/vertex-ai/training/{}:latest\".format(\n",
    "    REGION.split(\"-\")[0], TRAIN_VERSION\n",
    ")\n",
    "\n",
    "DEPLOY_IMAGE = \"{}-docker.pkg.dev/{}/{}/{}:latest\".format(\n",
    "    REGION, PROJECT_ID, PRIVATE_REPO, DEPLOY_VERSION\n",
    ")\n",
    "print(\"Deploy image:\", DEPLOY_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training,prediction"
   },
   "source": [
    "#### 设置机器类型\n",
    "\n",
    "接下来，设置用于训练和预测的机器类型。\n",
    "\n",
    "- 将变量`TRAIN_COMPUTE`和`DEPLOY_COMPUTE`设置为配置用于训练和预测的虚拟机的计算资源。\n",
    " - `机器类型`\n",
    "     - `n1-standard`：每个vCPU 3.75GB的内存。\n",
    "     - `n1-highmem`：每个vCPU 6.5GB的内存\n",
    "     - `n1-highcpu`：每个vCPU 0.9GB的内存\n",
    " - `vCPUs`：\\[2, 4, 8, 16, 32, 64, 96\\]的数量\n",
    "\n",
    "*注意：以下类型不支持用于训练：*\n",
    "\n",
    " - `standard`：2个vCPUs\n",
    " - `highcpu`：2、4和8个vCPUs\n",
    "\n",
    "*注意：您也可以使用n2和e2机器类型进行训练和部署，但它们不支持GPU*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "machine:training,prediction"
   },
   "outputs": [],
   "source": [
    "MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)\n",
    "\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_training_package:xgboost"
   },
   "source": [
    "### 检查培训包\n",
    "\n",
    "#### 包布局\n",
    "\n",
    "在开始培训之前，您将查看Python包如何为自定义培训工作流程进行组装。解压缩后，包含以下目录/文件布局的包。\n",
    "\n",
    "- PKG-INFO\n",
    "- README.md\n",
    "- setup.cfg\n",
    "- setup.py\n",
    "- trainer\n",
    "  - \\_\\_init\\_\\_.py\n",
    "  - task.py\n",
    "\n",
    "文件`setup.cfg`和`setup.py`是将包安装到Docker镜像的操作环境中的指令。\n",
    "\n",
    "文件`trainer/task.py`是用于执行自定义培训工作流程的Python脚本。*注意*，当在工作线程池规格中引用它时，我们将目录斜杠替换为点号(`trainer.task`)，并丢弃文件后缀(`.py`)。\n",
    "\n",
    "#### 包组装\n",
    "\n",
    "在以下单元格中，您将组装培训包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4wS4eISox9V"
   },
   "outputs": [],
   "source": [
    "# Make folder for Python training script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\nsetuptools.setup(\\n\\n    install_requires=[\\n\\n'lightgbm'    ],\\n\\n    packages=setuptools.find_packages())\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\nName: Iris tabular classification\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taskpy_contents:iris,xgboost"
   },
   "source": [
    "### 为Python培训包创建任务脚本\n",
    "\n",
    "接下来，您需要创建`task.py`脚本来驱动培训包。一些值得注意的步骤包括:\n",
    "\n",
    "- 命令行参数:\n",
    "    - `model-dir`: 保存训练模型的位置。当使用Vertex AI自定义培训时，位置将在环境变量`AIP_MODEL_DIR`中指定。\n",
    "    \n",
    "- 数据预处理(`get_data()`):\n",
    "    - 下载数据集并拆分为训练集和测试集。\n",
    "- 训练(`train_model()`):\n",
    "    - 训练模型\n",
    "- 模型艺术品保存\n",
    "    - 将模型艺术品和评估指标保存在由`model-dir`指定的云存储位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taskpy_contents:xgboost,iris"
   },
   "outputs": [],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "# Single Instance Training for Iris\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "logging.info(\"Parsing arguments\")\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--model-dir', \n",
    "    dest='model_dir',        \n",
    "    default=os.getenv('AIP_MODEL_DIR'), \n",
    "    type=str, \n",
    "    help='Location to export GCS model')\n",
    "args = parser.parse_args()\n",
    "logging.info(args)\n",
    "\n",
    "def get_data():\n",
    "    # Download data\n",
    "    logging.info(\"Downloading data\")\n",
    "    iris = load_iris()\n",
    "    print(iris.data.shape)\n",
    "\n",
    "    # split data\n",
    "    print(\"Splitting data into test and train\")\n",
    "    x, y = iris.data, iris.target\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=123)\n",
    "\n",
    "    # create dataset for lightgbm\n",
    "    print(\"creating dataset for LightGBM\")\n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)\n",
    "    \n",
    "    return lgb_train, lgb_eval\n",
    "\n",
    "def train_model(lgb_train, lg_eval):\n",
    "    # specify your configurations as a dict\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'metric': {'multi_error'},\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "        'num_class' : 3\n",
    "    }\n",
    "\n",
    "    # train lightgbm model\n",
    "    logging.info('Starting training...')\n",
    "    model = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=20,\n",
    "                    valid_sets=lgb_eval)\n",
    "    \n",
    "    return model\n",
    "\n",
    "lgb_train, lgb_eval = get_data()\n",
    "model = train_model(lgb_train, lgb_eval)\n",
    "\n",
    "# GCSFuse conversion\n",
    "gs_prefix = 'gs://'\n",
    "gcsfuse_prefix = '/gcs/'\n",
    "if args.model_dir.startswith(gs_prefix):\n",
    "    args.model_dir = args.model_dir.replace(gs_prefix, gcsfuse_prefix)\n",
    "    dirpath = os.path.split(args.model_dir)[0]\n",
    "    if not os.path.isdir(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "        \n",
    "# save model to file\n",
    "logging.info('Saving model...')\n",
    "model_filename = 'model.txt'\n",
    "gcs_model_path = os.path.join(args.model_dir, model_filename)\n",
    "model.save_model(gcs_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tarball_training_script"
   },
   "source": [
    "将培训脚本存储在您的云存储桶中\n",
    "\n",
    "接下来，您可以将培训文件夹打包成一个压缩的tar文件，然后将它存储在您的云存储桶中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnmdycf6ox9X"
   },
   "outputs": [],
   "source": [
    "! rm -f custom.tar custom.tar.gz\n",
    "! tar cvf custom.tar custom\n",
    "! gzip custom.tar\n",
    "! gsutil cp custom.tar.gz $BUCKET_URI/trainer_iris.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_custom_pp_training_job:mbsdk"
   },
   "source": [
    "### 创建和运行自定义训练作业\n",
    "\n",
    "要训练一个自定义模型，您需要执行两个步骤：1) 创建一个自定义训练作业，2) 运行作业。\n",
    "\n",
    "#### 创建自定义训练作业\n",
    "\n",
    "使用`CustomTrainingJob`类创建一个自定义训练作业，包括以下参数：\n",
    "\n",
    "- `display_name`：自定义训练作业的人类可读名称。\n",
    "- `container_uri`：训练容器镜像。\n",
    "\n",
    "- `python_package_gcs_uri`：Python训练包的位置，以tarball格式存储。\n",
    "- `python_module_name`：Python包中训练脚本的相对路径。\n",
    "\n",
    "*注意*：没有requirements参数。您可以在Python包的`setup.py`脚本中指定任何要求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVEMz1xqox9X"
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"iris_\"\n",
    "\n",
    "job = aiplatform.CustomPythonPackageTrainingJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    python_package_gcs_uri=f\"{BUCKET_URI}/trainer_iris.tar.gz\",\n",
    "    python_module_name=\"trainer.task\",\n",
    "    container_uri=TRAIN_IMAGE,\n",
    "    project=PROJECT_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prepare_custom_cmdargs:iris,xgboost"
   },
   "source": [
    "### 准备你的命令行参数\n",
    "\n",
    "现在为你的自定义训练容器定义命令行参数:\n",
    "\n",
    "- `args`: 传递给作为容器入口点设置的可执行文件的命令行参数。\n",
    "  - `--model-dir` : 对于我们的演示，我们使用这个命令行参数来指定存储模型工件的位置。\n",
    "    - 直接: 将 Cloud Storage 位置作为命令行参数传递给你的训练脚本（设置变量 `DIRECT = True`），或\n",
    "    - 间接: 服务将 Cloud Storage 位置作为环境变量 `AIP_MODEL_DIR` 传递给你的训练脚本（设置变量 `DIRECT = False`）。在这种情况下，你告诉服务作业规范中的模型工件位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AoUfpBqVox9Y"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = \"{}/model\".format(BUCKET_URI)\n",
    "\n",
    "DIRECT = False\n",
    "if DIRECT:\n",
    "    CMDARGS = [\n",
    "        \"--model_dir=\" + MODEL_DIR,\n",
    "    ]\n",
    "else:\n",
    "    CMDARGS = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_custom_job:mbsdk"
   },
   "source": [
    "运行自定义训练任务\n",
    "\n",
    "接下来，通过调用方法`run`，使用以下参数运行自定义作业来开始训练作业：\n",
    "\n",
    "- `args`：传递给训练脚本的命令行参数。\n",
    "- `replica_count`：用于训练的计算实例数量（replica_count = 1 表示单节点训练）。\n",
    "- `machine_type`：计算实例的机器类型。\n",
    "- `accelerator_type`：硬件加速器类型。\n",
    "- `accelerator_count`：要附加到工作副本的加速器数量。\n",
    "- `base_output_dir`：用于写入模型工件的Cloud Storage位置。\n",
    "- `sync`：是否阻塞直到作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCruQq1aox9Y"
   },
   "outputs": [],
   "source": [
    "job.run(\n",
    "    args=CMDARGS,\n",
    "    replica_count=1,\n",
    "    machine_type=TRAIN_COMPUTE,\n",
    "    base_output_dir=MODEL_DIR,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "model_path_to_deploy = MODEL_DIR + \"/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "list_job"
   },
   "source": [
    "### 列出一个定制的培训工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBM_KLMSox9Y"
   },
   "outputs": [],
   "source": [
    "_job = job.list(filter=\"display_name=iris\")\n",
    "print(_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "custom_job_wait:mbsdk"
   },
   "source": [
    "### 等待自定义训练作业完成\n",
    "\n",
    "接下来，等待自定义训练作业完成。或者，可以在`run()`方法中将参数`sync`设置为`True`，以阻塞直到自定义训练作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHPMHbSyox9Z"
   },
   "outputs": [],
   "source": [
    "job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "delete_job"
   },
   "source": [
    "删除一个自定义训练作业\n",
    "\n",
    "在训练作业完成后，您可以使用`delete()`方法删除训练作业。在完成之前，可以使用`cancel()`方法取消训练作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlYg7Sp-ox9Z"
   },
   "outputs": [],
   "source": [
    "job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2478e67d679f"
   },
   "source": [
    "### 验证模型工件\n",
    "\n",
    "接下来，请验证训练脚本是否成功将训练好的模型保存到您的云存储位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c644f0d3a201"
   },
   "outputs": [],
   "source": [
    "print(f\"Model path with trained model artifacts {model_path_to_deploy}\")\n",
    "\n",
    "! gsutil ls $model_path_to_deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_model:migration,new"
   },
   "source": [
    "将LightGBM模型部署到Vertex AI端点\n",
    "\n",
    "使用FastAPI构建一个HTTP服务器\n",
    "\n",
    "接下来，您可以使用FastAPI将HTTP服务器实现为自定义部署容器。该容器必须监听并响应存活检查，健康检查和预测请求。HTTP服务器必须在0.0.0.0上监听请求。\n",
    "\n",
    "了解更多关于部署容器要求的信息。\n",
    "\n",
    "了解更多关于FastAPI。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b28b53f8b3f4"
   },
   "outputs": [],
   "source": [
    "# Make folder for serving script\n",
    "! rm -rf serve\n",
    "! mkdir serve\n",
    "\n",
    "# Make the predictor subfolder\n",
    "! mkdir serve/app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8baa8361ecb4"
   },
   "source": [
    "创建用于服务容器的要求文件\n",
    "\n",
    "接下来，为服务器环境创建`requirements.txt`文件，指定需要安装在服务容器上的Python软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2dd3e671130"
   },
   "outputs": [],
   "source": [
    "%%writefile serve/requirements.txt\n",
    "\n",
    "numpy\n",
    "scikit-learn>=0.24\n",
    "pandas\n",
    "lightgbm==3.2.1\n",
    "google-cloud-storage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07c16e1003ef"
   },
   "source": [
    "### 编写 FastAPI 服务脚本\n",
    "\n",
    "接下来，您可以使用 `FastAPI` 编写 HTTP 服务器的服务脚本，如下所示：\n",
    "\n",
    "- `app`: 实例化一个 `FastAPI` 应用程序\n",
    "- `health()`: 定义对健康请求的响应。\n",
    "    - 返回状态码 200\n",
    "- `predict()`: 定义对预测请求的响应。\n",
    "    - `body = await request.json()`: 异步等待 HTTP 请求。\n",
    "    - `instances = body[\"instances\"]` : 预测请求的内容。\n",
    "    - `inputs = np.asarray(instances)`: 将预测请求重新格式化为 numpy 数组。\n",
    "    - `outputs = model.predict(inputs)`: 调用模型进行预测。\n",
    "    - `return {\"predictions\": ... }`: 在响应主体中返回格式化的预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97b0cd77339c"
   },
   "outputs": [],
   "source": [
    "%%writefile serve/app/main.py\n",
    "from fastapi.logger import logger\n",
    "from fastapi import FastAPI, Request\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import lightgbm as lgb\n",
    "\n",
    "import logging\n",
    "\n",
    "gunicorn_logger = logging.getLogger('gunicorn.error')\n",
    "logger.handlers = gunicorn_logger.handlers\n",
    "\n",
    "if __name__ != \"main\":\n",
    "    logger.setLevel(gunicorn_logger.level)\n",
    "else:\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "model_f = \"/model/model.txt\"\n",
    "\n",
    "logger.info(\"Loading model\")\n",
    "_model = lgb.Booster(model_file=model_f)\n",
    "logger.info(\"Loading target class labels\")\n",
    "_class_names = load_iris().target_names\n",
    "\n",
    "@app.get(os.environ['AIP_HEALTH_ROUTE'], status_code=200)\n",
    "def health():\n",
    "    \"\"\" health check to ensure HTTP server is ready to handle \n",
    "        prediction requests\n",
    "    \"\"\"\n",
    "    return {\"status\": \"healthy\"}\n",
    "\n",
    "\n",
    "@app.post(os.environ['AIP_PREDICT_ROUTE'])\n",
    "async def predict(request: Request):\n",
    "    body = await request.json()\n",
    "\n",
    "    instances = body[\"instances\"]\n",
    "    inputs = np.asarray(instances)\n",
    "    \n",
    "    outputs = _model.predict(inputs)\n",
    "\n",
    "    logger.info(f\"Outputs {outputs}\")\n",
    "    return {\"predictions\": [_class_names[class_num] for class_num in np.argmax(outputs, axis=1)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea37d0597e2b"
   },
   "source": [
    "### 添加预启动脚本\n",
    "FastAPI将在启动服务器之前执行此脚本。 为了在AI平台（Unified）上以期望的端口运行FastAPI，将`PORT`环境变量设置为等于`AIP_HTTP_PORT`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e029a2d85935"
   },
   "outputs": [],
   "source": [
    "%%writefile serve/app/prestart.sh\n",
    "\n",
    "#!/bin/bash\n",
    "export PORT=$AIP_HTTP_PORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a402c1f4bcc"
   },
   "source": [
    "### 存储测试实例\n",
    "\n",
    "接下来，您将创建合成示例，随后测试 FastAPI 服务器和训练后的 LightGBM 模型。\n",
    "\n",
    "了解有关[自定义模型预测请求的 JSON 格式](https://cloud.google.com/ai-platform-unified/docs/predictions/online-predictions-custom-models#request-body-details)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d45c868ccaed"
   },
   "outputs": [],
   "source": [
    "%%writefile serve/instances.json\n",
    "{\n",
    "    \"instances\": [\n",
    "        [6.7, 3.1, 4.7, 1.5],\n",
    "        [4.6, 3.1, 1.5, 0.2]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ae1b8aead6c"
   },
   "source": [
    "## 构建并推送预测容器到Artifact Registry\n",
    "\n",
    "编写Dockerfile，使用`tiangolo/uvicorn-gunicorn-fastapi`作为基础镜像。这将自动运行 FastAPI，使用 Gunicorn 和 Uvicorn。\n",
    "\n",
    "了解更多关于[使用Docker部署FastAPI](https://fastapi.tiangolo.com/deployment/docker/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "289dcdf1c4f4"
   },
   "outputs": [],
   "source": [
    "%%bash -s $MODEL_DIR\n",
    "\n",
    "MODEL_DIR=$1\n",
    "\n",
    "mkdir -p ./serve/model/\n",
    "gsutil cp -r ${MODEL_DIR}/model/ ./serve/model/ \n",
    "\n",
    "cat > ./serve/Dockerfile <<EOF\n",
    "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
    "\n",
    "COPY ./app /app\n",
    "COPY ./model /\n",
    "COPY requirements.txt requirements.txt\n",
    "\n",
    "RUN pip3 install -r requirements.txt\n",
    "\n",
    "EXPOSE 7080\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"7080\"]\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f3bca44ead4"
   },
   "source": [
    "构建容器本地\n",
    "\n",
    "接下来，您需要构建并打标签自定义部署容器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64261b86085e"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if not IS_COLAB:\n",
    "    ! docker build --tag={DEPLOY_IMAGE} ./serve\n",
    "else:\n",
    "    # install docker daemon\n",
    "    ! apt-get -qq install docker.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c746c507aba6"
   },
   "source": [
    "在本地以分离模式运行和测试容器（可选）\n",
    "\n",
    "在本地以分离模式运行容器，并提供容器所需的环境变量。这些环境变量将在部署后由 AI 平台预测提供给容器。测试`/health`和`/predict`路由，然后停止运行的镜像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6534859e481b"
   },
   "source": [
    "在将容器映像推送到工件存储库以与顶点预测一起使用之前，您可以在本地环境中将其作为容器运行，以验证服务器是否按预期工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3246b3a01d92"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! docker rm local-iris 2>/dev/null\n",
    "    ! docker run -t -d --rm -p 7080:7080 \\\n",
    "        --name=local-iris \\\n",
    "        -e AIP_HTTP_PORT=7080 \\\n",
    "        -e AIP_HEALTH_ROUTE=/health \\\n",
    "        -e AIP_PREDICT_ROUTE=/predict \\\n",
    "        -e AIP_STORAGE_URI={MODEL_DIR} \\\n",
    "        {DEPLOY_IMAGE}\n",
    "    ! docker container ls\n",
    "    ! sleep 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bdfb565a253"
   },
   "source": [
    "健康检查\n",
    "\n",
    "向容器的服务器发送健康检查。输出应为{\"status\": \"healthy\"}。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdc1f41f8dcc"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! curl http://localhost:7080/health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c92e4992b2f4"
   },
   "source": [
    "如果成功，服务器将返回以下响应：\n",
    "\n",
    "```\n",
    "{\n",
    "  \"status\": \"healthy\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5433a0c62a99"
   },
   "source": [
    "检查预测\n",
    "\n",
    "向容器的服务器发送一个预测请求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "458de32ee979"
   },
   "outputs": [],
   "source": [
    "! curl -X POST \\\n",
    "  -d @serve/instances.json \\\n",
    "  -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "  http://localhost:7080/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "db78dc1f2313"
   },
   "source": [
    "这个请求使用了一个测试句子。如果成功，服务器会以下面的格式返回预测结果：\n",
    "\n",
    "```\n",
    "{\"predictions\":[\"versicolor\",\"setosa\"]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc16b5fa1b6d"
   },
   "source": [
    "请停止本地容器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8127f3e5b74"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! docker stop local-iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c57c65c5d25"
   },
   "source": [
    "将服务容器推送到Artifact Registry\n",
    "\n",
    "将带有推理代码和依赖项的容器映像推送到Artifact Registry。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8f1fc336bf79"
   },
   "outputs": [],
   "source": [
    "if not IS_COLAB:\n",
    "    ! docker push $DEPLOY_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f50e9c553fb7"
   },
   "source": [
    "在Colab中执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7e8c98f1e56"
   },
   "outputs": [],
   "source": [
    "%%bash -s $IS_COLAB $DEPLOY_IMAGE\n",
    "if [ $1 == \"False\" ]; then\n",
    "  exit 0\n",
    "fi\n",
    "set -x\n",
    "dockerd -b none --iptables=0 -l warn &\n",
    "for i in $(seq 5); do [ ! -S \"/var/run/docker.sock\" ] && sleep 2 || break; done\n",
    "docker build --tag={DEPLOY_IMAGE} ./serve\n",
    "docker push $2\n",
    "kill $(jobs -p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ac8627fc8434"
   },
   "source": [
    "将服务容器部署到 Vertex 预测\n",
    "我们在 Vertex AI 上创建一个模型资源，并将模型部署到 Vertex Endpoints。在使用模型之前，您必须将模型部署到一个端点。部署的模型会运行自定义容器映像来提供预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_model:mbsdk"
   },
   "source": [
    "## 上传模型\n",
    "\n",
    "接下来，使用`Model.upload()`方法将您的模型上传到`Model`资源，参数如下：\n",
    "\n",
    "- `display_name`：`Model`资源的人类可读名称。\n",
    "- `artifact`：训练模型工件的云存储位置。\n",
    "- `serving_container_image_uri`：服务容器的镜像。\n",
    "- `serving_container_predict_route`：发送预测请求到容器的HTTP路径。\n",
    "- `serving_container_health_route`：发送健康检查请求到容器的HTTP路径。\n",
    "- `serving_container_ports`：容器监听请求的端口。\n",
    "- `sync`：是否异步或同步执行上传。\n",
    "\n",
    "如果`upload()`方法以异步方式运行，您可以随后使用`wait()`方法阻塞直到完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c34825f267d4"
   },
   "outputs": [],
   "source": [
    "APP_NAME = \"iris\"\n",
    "\n",
    "model_display_name = f\"{APP_NAME}\"\n",
    "model_description = \"LightGBM based iris flower classifier with custom container\"\n",
    "\n",
    "MODEL_NAME = APP_NAME\n",
    "health_route = \"/ping\"\n",
    "predict_route = \"/predict\"\n",
    "serving_container_ports = [7080]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=model_display_name,\n",
    "        description=model_description,\n",
    "        serving_container_image_uri=DEPLOY_IMAGE,\n",
    "        serving_container_predict_route=predict_route,\n",
    "        serving_container_health_route=health_route,\n",
    "        serving_container_ports=serving_container_ports,\n",
    "    )\n",
    "\n",
    "    model.wait()\n",
    "\n",
    "    print(model.display_name)\n",
    "    print(model.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_batch_predictions:migration"
   },
   "source": [
    "进行批量预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batchpredictionjobs_create:migration,new,mbsdk"
   },
   "source": [
    "文档 - [批量预测请求 - Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_test_items:xgboost,tabular,iris"
   },
   "source": [
    "制作测试项\n",
    "\n",
    "你将使用合成数据作为测试数据项。不要担心我们使用合成数据--我们只是想展示如何进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "make_test_items:xgboost,tabular,iris"
   },
   "outputs": [],
   "source": [
    "INSTANCES = [[6.7, 3.1, 4.7, 1.5], [4.6, 3.1, 1.5, 0.2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_batch_file:custom,tabular,list"
   },
   "source": [
    "制作批量输入文件\n",
    "\n",
    "现在制作一个批量输入文件，您将把它存储在本地云存储桶中。预测请求中的每个实例都是以下形式的列表：\n",
    "\n",
    "                        [ [ 内容_1], [内容_2] ]\n",
    "\n",
    "- `内容`: 测试项的特征值列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae7342e19f2b"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "[json.dumps(record) for record in INSTANCES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "make_batch_file:custom,tabular,list"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gcs_input_uri = f\"{BUCKET_URI}/{APP_NAME}/test/batch_input/test.jsonl\"\n",
    "with tf.io.gfile.GFile(gcs_input_uri, \"w\") as f:\n",
    "    for i in INSTANCES:\n",
    "        f.write(str(i) + \"\\n\")\n",
    "\n",
    "! gsutil cat $gcs_input_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request:mbsdk,jsonl,custom,cpu"
   },
   "source": [
    "### 发起批量预测请求\n",
    "\n",
    "现在您的模型资源已经训练完成，您可以通过调用batch_predict()方法发起批量预测，使用以下参数：\n",
    "\n",
    "- `job_display_name`: 批量预测作业的可读名称。\n",
    "- `gcs_source`: 一个或多个批量请求输入文件的列表。\n",
    "- `gcs_destination_prefix`: 用于存储批量预测结果的Cloud Storage位置。\n",
    "- `instances_format`: 输入实例的格式，可以是'csv'或'jsonl'。默认为'jsonl'。\n",
    "- `predictions_format`: 输出预测的格式，可以是'csv'或'jsonl'。默认为'jsonl'。\n",
    "- `machine_type`: 用于训练的机器类型。\n",
    "- `sync`: 如果设置为True，则调用将会阻塞，直到异步批处理作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request:mbsdk,jsonl,custom,cpu"
   },
   "outputs": [],
   "source": [
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    MIN_NODES = 1\n",
    "    MAX_NODES = 1\n",
    "\n",
    "    batch_predict_job = model.batch_predict(\n",
    "        job_display_name=f\"{APP_NAME}\",\n",
    "        gcs_source=gcs_input_uri,\n",
    "        gcs_destination_prefix=f\"{BUCKET_URI}/{APP_NAME}/test/batch_output/\",\n",
    "        instances_format=\"jsonl\",\n",
    "        predictions_format=\"jsonl\",\n",
    "        model_parameters=None,\n",
    "        machine_type=DEPLOY_COMPUTE,\n",
    "        starting_replica_count=MIN_NODES,\n",
    "        max_replica_count=MAX_NODES,\n",
    "        sync=False,\n",
    "    )\n",
    "\n",
    "    print(batch_predict_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "source": [
    "### 等待批量预测作业完成\n",
    "\n",
    "接下来，等待批处理作业完成。或者，可以在`batch_predict()`方法中将参数`sync`设置为`True`，以阻塞直到批处理预测作业完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_request_wait:mbsdk"
   },
   "outputs": [],
   "source": [
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    batch_predict_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "get_batch_prediction:mbsdk,custom,lcn"
   },
   "source": [
    "### 获取预测结果\n",
    "\n",
    "接下来，从已完成的批量预测作业中获取结果。\n",
    "\n",
    "结果将被写入您在批量预测请求中指定的Cloud Storage输出桶中。您可以调用方法`iter_outputs()`来获取包含结果的每个云存储文件的列表。每个文件以JSON格式包含一个或多个预测请求：\n",
    "\n",
    "- `instance`：预测请求。\n",
    "- `prediction`：预测响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_batch_prediction:mbsdk,custom,lcn"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    bp_iter_outputs = batch_predict_job.iter_outputs()\n",
    "\n",
    "    prediction_results = list()\n",
    "    for blob in bp_iter_outputs:\n",
    "        if blob.name.split(\"/\")[-1].startswith(\"prediction\"):\n",
    "            prediction_results.append(blob.name)\n",
    "\n",
    "    tags = list()\n",
    "    for prediction_result in prediction_results:\n",
    "        gfile_name = f\"gs://{bp_iter_outputs.bucket.name}/{prediction_result}\"\n",
    "        with tf.io.gfile.GFile(name=gfile_name, mode=\"r\") as gfile:\n",
    "            for line in gfile.readlines():\n",
    "                line = json.loads(line)\n",
    "                print(line)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "make_online_predictions:migration"
   },
   "source": [
    "进行在线预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:migration,new,mbsdk"
   },
   "source": [
    "文档 - [在线预测请求](https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deploy_model:mbsdk,cpu"
   },
   "source": [
    "部署模型\n",
    "\n",
    "接下来，部署您的模型以进行在线预测。要部署模型，您需要调用`deploy`方法，并提供以下参数：\n",
    "\n",
    "- `deployed_model_display_name`：部署模型的可读名称。\n",
    "- `traffic_split`：在端点上流入此模型的流量百分比，以字典形式指定一个或多个键值对。\n",
    "如果只有一个模型，则指定为{ \"0\": 100 }，其中\"0\"指该模型已上传，100表示100%的流量。\n",
    "如果端点上有现有模型，要对流量进行分割，则使用model_id指定为{ \"0\": 百分比, model_id: 百分比, ... }，其中model_id是已部署端点的现有模型的模型id。百分比必须累加等于100。\n",
    "- `machine_type`：用于训练的机器类型。\n",
    "- `starting_replica_count`：初始配备的计算实例数量。\n",
    "- `max_replica_count`：要扩展到的计算实例的最大数量。在本教程中，仅配备一个实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy_model:mbsdk,cpu"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_NAME = f\"{APP_NAME}\"\n",
    "\n",
    "TRAFFIC_SPLIT = {\"0\": 100}\n",
    "\n",
    "MIN_NODES = 1\n",
    "MAX_NODES = 1\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    endpoint = model.deploy(\n",
    "        deployed_model_display_name=DEPLOYED_NAME,\n",
    "        traffic_split=TRAFFIC_SPLIT,\n",
    "        machine_type=DEPLOY_COMPUTE,\n",
    "        min_replica_count=MIN_NODES,\n",
    "        max_replica_count=MAX_NODES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "predict_request:mbsdk,custom,lcn"
   },
   "source": [
    "### 进行预测\n",
    "\n",
    "现在您的`Model`资源已部署到`Endpoint`资源，您可以通过向`Endpoint`资源发送预测请求进行在线预测。\n",
    "\n",
    "#### 请求\n",
    "\n",
    "每个实例的格式为：\n",
    "\n",
    "    [feature_list]\n",
    "\n",
    "由于predict()方法可以接受多个项目（实例），请将您的单个测试项目作为一个测试项目列表发送。\n",
    "\n",
    "#### 响应\n",
    "\n",
    "从predict()调用的响应是一个包含以下条目的Python字典：\n",
    "\n",
    "- `ids`：每个预测请求的内部分配的唯一标识符。\n",
    "- `predictions`：每个类别标签的预测置信度，介于0和1之间。\n",
    "- `deployed_model_id`：进行预测的已部署`Model`资源的Vertex AI标识符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "predict_request:mbsdk,custom,lcn"
   },
   "outputs": [],
   "source": [
    "instances_list = INSTANCES\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    prediction = endpoint.predict(instances_list)\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "source": [
    "解除部署模型\n",
    "\n",
    "当你完成预测后，你可以从`Endpoint`资源中解除部署模型。这将释放所有计算资源并停止对部署模型的计费。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "undeploy_model:mbsdk"
   },
   "outputs": [],
   "source": [
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gar_delete_repo"
   },
   "source": [
    "删除您的私有Docker存储库\n",
    "\n",
    "最后，一旦您的私有存储库变得过时，请使用命令 `gcloud artifacts repositories delete` 在 `Google Artifact Registry` 中删除它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gar_delete_repo"
   },
   "outputs": [],
   "source": [
    "! gcloud artifacts repositories delete {PRIVATE_REPO} --location={REGION} --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "source": [
    "清理\n",
    "\n",
    "要清理此项目中使用的所有Google Cloud资源，您可以[删除用于本教程的Google Cloud项目](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects)。\n",
    "\n",
    "否则，您可以删除本教程中创建的各个资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:mbsdk"
   },
   "outputs": [],
   "source": [
    "# Delete the model using the Vertex model object\n",
    "try:\n",
    "    model.delete()\n",
    "    endpoint.delete()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "delete_bucket = False\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get_started_vertex_training_lightgbm.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
